<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CONVENTION</title>
    <url>/Learning-CS-Journey/CONVENTION/</url>
    <content><![CDATA[文档写作约定
中文与英文字母之间必须间隔一个空格
文档中的所有中文均采用中文逗号和中文句号，且都为半角字符。
中文与英文之间的冒号均采用中文半角字符。
汉字与汉字之间的的花括号均采用中文半角字符，英文与英文之间均采用英文半角字符，汉字与英文之间也采用英文英文半角字符。

排版规范：

中文文案排版指北 - GitHub
写给大家看的中文排版指南 - 知乎
中文文案排版细则 - Dawner
中文技术文档写作风格指南

提 issue&#x2F;question 推荐阅读资料：

《提问的智慧》
《如何向开源社区提问题
《如何有效地报告 Bug》
《如何向开源项目提交无法解答的问题》。

]]></content>
      <categories>
        <category>Learning-CS-Journey</category>
      </categories>
      <tags>
        <tag>cONVENTION</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/Learning-CS-Journey/README/</url>
    <content><![CDATA[

1. Learning Computer Science Journey本项目是记录本人学习计算机科学这类学科知识点的历程。从计算机底层硬件到应用层软件等知识点。包括最底层的汇编语言(Assemble)、高级的 C、C++、Go 语言、计算机网络基础(ComputerNetwork)、操数据结构与算法(DataStructure)、设计模式(DesignPattern)、操作系统(Operating System)、Linux 基础与 Linux 环境编程(Linux)、数据库(MySQL、Redis)、脚本语言(Shell)、界面编程(Qt)、轻量级的 Web 服务器(Nginx)、GitHub 和 Git 及 SVN 代码管理工具使用(Git-SVN)、嵌入式系统中 STM 系列芯片模板工程的创建(Embedded)、常用的学习工具和学习网站之谈(StudyTool)、Markdown 和 Jupyter Notebook 基本语法(markdown)、基本的一些哲学思想和英语美句(Philosophy)。
2. C 语言C 语言是自己接触的第一门语言，基本的语法在大学时就已经学过，这里不再讲基础的语法，仅仅只是记录自己在工作中对 C 语言知识点的补充，常用常更新。包括底层的一些知识点，字符编码、指针、函数指针、结构体、内存分配等常见的点。

字符编码
内存存放顺序
断点调试
变量与数据类型
Volatile 关键字用法解释
为什么会出现段错误
C 语言中常见的基础语法的补充
C 语言中精髓之一：指针函数和函数指针
Const 关键字
restrict 关键字
exteren 关键字
最常见得 void 含义和用法
内存初始化函数 memset
memcpy 与 strcpy 函数的区别及用法
memcmp 与 strcmp 函数的区别及用法
typedef 用法剖析
C 语言中精髓之一：结构体和字节对齐
word, half word, double word 用法及区别
C 语言中精髓之一：指针
枚举类型
C 语言中的状态机
C 语言中精髓之一：数组与指针的结合
用到的比较生僻的库函数：atoi()、 fprintf()、snprintf()
常见的转义字符和 ASCII 码
C 语言中最重要的部分：内存分布
sizeof() 与 strlen() 的区别
程序入口函数 main() 分析
提高效率之一的 do{…}(false) 用法
容易的混淆的 * 和 ++ 的优先级使用
C 语言中精髓之一：回调函数
static 关键字
细谈 C 语言中的字符串
编写 C 程序时需遵循的编码规范

3. C++C++ 语言是一门非常复杂的语言，虽然是 C+ 语言是对 C 语言的的强化，但是现代的 C++ 已经与 C 相差很大了，几乎是另一种语言。学习 C++ 需要花费的很长时间，它的知识点不仅广泛还很细粒、灵活性很高。自己在学习时，学习知识点时，学习的快，忘记的也快，因此，自己就把学习过程中的一些理解、笔记和体会记录下来。
3.1. C++ 基础这部分主要是 C++ 的基础知识点，常用的语法，该板块涉及的内容比较多。





3.2. C++ 高级C++ 的核心思想是面向对象，这个板块包含了 C++ 面向对象的内容：封装、继承、多态；泛型编程、输入输出流、元编程等。



3.3. C++ 新特性主要介绍 C++11、C++14、C++17、C++20 的新特性，



3.4. C++STL标准库是非常重要的，熟练地使用并知道其内部的原理对自己的编码是非常有帮助的。STL 是编写 C++ 的大牛们创造的一个非常优秀的作品，里面有很多的东西值得学习和探讨。





3.5. C++ 内存管理C++ 不同 Java、Python、GO 等，C++ 没有垃圾回收机制，内存的分配和释放都需自己手动管理，因此真真理解 C++ 编译器中的内存管理机制是非常重要的。这部分的内容，目前只写了部分，后面的内容，以后在完善。

C++ 中 enable_shared_from_this 用法
Core dump 调试用法
Valgrind 内存泄漏检查的利器
C++ 编程规范
C++ 中的并发处理
多线程时线程池的使用
非常值得学习的 C&#x2F;C++ 服务端开源库

4. 内功修炼计算机底层知识的加深理解
书籍

《程序员的自我修养—链接、装载与库》
《深入理解计算机系统 第 3 版》，对应的英文版:《Computer Systems. A Programmer’s Perspective [3rd ed]》
《老码识途 从机器码到框架的系统观逆向修炼之路》

视频

B 站：卡内基 · 梅隆大学 - CSAPP

5. 操作系统操作系统是一门与底层硬件结合比较紧密的课程，掌握好操作系统，对自己的软件体系有很好的帮助。一般我是通过看视频和看书来增强这方便的知识。
5.1. MIT-CS6.8285.2. Operating Systems: Three Easy Pieces操作系统导论 (Operating Systems: Three Easy Pieces) 一本非常好的书籍，并且电子版本是免费的。这是自己操作系统的启蒙之书，通过阅读这本书，自己加深了对操作系统的认识和理解，以下是自己在学习过程中整理出来的一些笔记。

Virtualization(虚拟化)

CPU 的虚拟化
抽象的地址空间
对内存操作的 API 接口调用分析
地址转换
分段
操作系统对空闲空间的管理
分页机制
快速地址转换
页表机制
交换机制
交换策略


Currency(并发)

并发的概念与线程的概念
线程操作的 API 接口
线程中锁的机制
条件变量
信号量
多线程并发过程中导致线程死锁问题的讨论
基于事件的并发问题


很多经典的论点引证
5.3. 清华大学 OS
清华大学操作系统课程 (2019)：Gitbook 上清华大学操作系统课程 (2019)。
操作系统 (Operating Systems) (2019): 清华大学 2019 学期操作系统课程主页。
操作系统 (Operating Systems) (2020): 清华大学 2020 学期操作系统课程主页。
uCore OS 实验指导书和源码网址 (2020): 清华大学 2020 学期 uCore OS 实验指导书。
Operating System Concepts Ninth Edition: 操作系统概念第九版英文版在线主页。

6. 计算机网络计算机网络基础知识





计算机网络常用网络术语缩写
HTTP 基础
Wireshark 网络抓包工具使用分析

6.1. 斯坦福大学 CS144课程官方网站

CS 144: Introduction to Computer Networking, Fall 2020：为主。
CS144: Introduction to Computer Networking, Fall 2010: 可选。

书籍

《计算机网络：自顶向下方法》
Computer Networking: a Top Down Approach 8th edition:《计算机网络：自顶向下方法》原书的英文版，最新版本为第八版。
Wireshark Labs: 书籍配套的 Wireshark 实验
Instructor Resources: 与该书籍配套的一些重要学习指导资源。
Online presentations Video: 由于新冠病毒的影响，原书作者之一 Jim Kurose 通过在线学习的方式，给学生授课。每章节不仅包含了授课的 PPT、视频，还有知识点检测以及授课中问题的汇总，总之，质量是非常的好。
Computer-Networking-A-Top-Down-Approach-8th-Edtion Github 上一位学习者收集的这本书的一些资料，非常的好。

视频

B 站：斯坦福大学 Introduction to Computer Networking (CS 144)

他人笔记

知乎：CS144: 什么，你学不会 TCP？那就来自己写一个吧！
返回主页康宇 PL’s Blog  笔记很好，需要深入挖掘。 
Lab
Github: huangrt01TCP-Lab
Github: CS144 sponge: 重点推荐。

7. 数据结构与算法数据结构与算法分为数据和算法两个大类。复杂的算法都是由基本的数据结构组合而成的。
数据结构与算法笔记



8. 设计模式C++ 语言实现的的 23 中设计模式





9. 数据库MySQL 数据库基础



10. Git-SVN从最简单的 Git 使用，到 Git 内部原理，一步步带你窥探其的奥秘
SVN 工具
11. Go
Go 语言基础
Go 标准库

12. Linux
Linux 基础知识点






编译链接原理及过程分析
GDB 调试常用命令及底层原理探讨
具有编辑器之神称为的 VIM 用法探讨
CMAKE 原理及其语法探讨
Makefile 原理和用法
Linux 下索引节点 inode 分析
Linux 下常用工具集汇总
Linux 下重点之一：Linux 环境系统编程

13. ShellShell 基础语法分析
14. RedisRedis 基础用法
15. Nginx
Nginx 常用基础用法解释
XML 基础语法

16. 分布式视频

B 站：MIT 6.824

书籍

《数据密集型应用系统设计》

17. Qt
Qt 常见基础组件用法   

18. 汇编语言
基础汇编指令解释

19. Markdown
编写 Markdown 文档的 typora 软件常用使用说明
LaTeX 数学公式编写的利器
希腊字母表
Jupyter 基础语法讲解

20. 工具
draw.io 绘图工具常用快捷键
Jetbrains 系列软件使用技巧
VSCode 常用快捷键
掌握这些 windows10 系统快捷键，大幅度提高日常工作效率
积累了许多常用的习学习网站
IPAD 比较好的收费的软件

21. 哲学自己本身对哲学十分感兴趣，记下自己平时生活中的一些哲学思想。
如何把明面做好，相当于是做一个宣传，需要好好的的规划。
如何把复杂的东西描绘成最简单的东西？让一个门外汉也能看懂自己写的文章。
学习知识形成体系结构，脑海里有概念，对计算机专业学科的一些专业术语要有了解，这样看英文源文档，才看得懂，看的速度才快。
22. 自学指导
cs_study_plan: Github 上一份硬核计算机科学 CS 自学计划
TeachYourselfCS-CN: 自学计算机科学课程，推荐一些比较好的书籍和课程。

]]></content>
      <categories>
        <category>Learning-CS-Journey</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
      </tags>
  </entry>
  <entry>
    <title>STARCHARTS</title>
    <url>/Learning-CS-Journey/STARCHARTS/</url>
    <content><![CDATA[Stargazers over time 
]]></content>
      <categories>
        <category>Learning-CS-Journey</category>
      </categories>
      <tags>
        <tag>sTARCHARTS</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/cpp/hello-world/</url>
    <content><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick StartCreate a new post$ hexo new &quot;My New Post&quot;

More info: Writing
Run server$ hexo server

More info: Server
Generate static files$ hexo generate

More info: Generating
Deploy to remote sites$ hexo deploy

More info: Deployment
]]></content>
      <categories>
        <category>cpp</category>
      </categories>
      <tags>
        <tag>tag1</tag>
        <tag>tag2</tag>
      </tags>
  </entry>
  <entry>
    <title>AIGC</title>
    <url>/AI/AI/AIGC/</url>
    <content><![CDATA[AI ModelChatGPTChatGPT官网： https://openai.com/
CharGPT是 OpenAI公司开发的人工智能聊天程序，于 2022年11月推出。该程序使用基于GPT-3.5、GPT-4架构的大型语言模型並以强化学习训练。主要是以文字的方式与用户进行互动，可以用于自动生成文本、生成摘要、自问自答。基于输入的文本可以自动生成歌曲、诗歌，对软件开发者，可以进行辅助编程。同类的产品：谷歌的 Bard，百度的文心一言，阿里巴巴的通义千问，清华大学开放的 ChatGLM，科大讯飞的星火，复旦大学推出的 MOSS，美国 Anthropic 公司推出的 Claude
MidjourneyMidjourney官网： https://www.midjourney.com/
Midjourney是一款2022年3月面世的AI绘画工具。只需要输入文字，通过AI模型就能生出对应的图片。最初是由美国一家工作室开发的，于2022年3月首次亮相，在8月迭代至V3版本并开始引发一定的关注，而2023年更新的V5版本让Midjourney及其作品成功“出圈”，代表作是“中国情侣”图片。
Stable DiffusionStable Diffusion官网： https://stability.ai/
Stable Diffusion是2022年发布的深度学习文本到图像生成模型。它主要用于根据文本的描述产生详细图像，尽管它也可以应用于其他任务，如内补绘制、外补绘制，以及在提示词指导下产生图生图的翻译。
它是一种潜在变量模型的扩散模型，由慕尼黑大学的CompVis研究团体开发的各种生成性人工神经网络。它是由初创公司StabilityAI、CompVis与Runway合作开发，并得到EleutherAI和LAION的支持。截至2022年10月，StabilityAI筹集了1.01亿美元的资金。Stable Diffusion的代码和模型权重已公开发布，可以在大多数配备有适度GPU的电脑硬件上运行。而以前的专有文生图模型（如DALL-E和Midjourney）只能通过云端运算服务访问。
一句话概括，Stable Diffusion 是一种 AI 动画生成工具，用于生成绘画和视频。2023年5月，Stable Diffusion已经可以生成视频。
 教程：https://stable-diffusion-art.com/qr-code/
Novel AINovel AI官网： https://novelai.net/
NovelAI 是由美国特拉华州的 Anlatan 公司开发的云端软件即服务（SaaS）模式订阅制服务，其下有辅助故事写作以及文本到图像生成功能，于2021年6月15日推出测试版，2022年10月3日推出图像生成服务。Novel AI 用于故事写作和和绘画。它使用的GPT的模型进行故事写作。
ProgramGithub Copilot

代码预测
代码解释
代码生成
代码调试

AI 编辑器
Cursor
Composer
Windsurf
Trae

LLMLLM: large language model
AGI: Artificial General Intelligence
NVIDIA开源框架

Blackwell

ProtocolModel Context Protocol(MCP)

introduction: https://modelcontextprotocol.io/introduction
Github specification: https://github.com/modelcontextprotocol/specification
Github: https://github.com/modelcontextprotocol
Anthropic official: https://www.anthropic.com/news/model-context-protocol

OpenSource Framework
https://github.com/ggerganov/whisper.cpp: whisper.cpp, Port of OpenAI’s Whisper model in C&#x2F;C++
https://github.com/ggml-org/llama.cpp: llama.cpp, LLM inference in C&#x2F;C++

]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>aI</tag>
        <tag>aIGC</tag>
      </tags>
  </entry>
  <entry>
    <title>ollama</title>
    <url>/AI/AI/ollama/</url>
    <content><![CDATA[

Ollama本地启动并运行大型语言模型。
Ollama 是一个开源的大型语言模型服务工具，旨在帮助用户快速在本地运行大模型。通过简单的安装指令，用户可以通过一条命令轻松启动和运行开源的大型语言模型。 它提供了一个简洁易用的命令行界面和服务器，专为构建大型语言模型应用而设计。用户可以轻松下载、运行和管理各种开源 LLM。与传统 LLM 需要复杂配置和强大硬件不同，Ollama 能够让用户在消费级的 PC 上体验 LLM 的强大功能。
Ollama 会自动监测本地计算资源，如有 GPU 的条件，会优先使用 GPU 的资源，同时模型的推理速度也更快。如果没有 GPU 条件，直接使用 CPU 资源。
Ollama 极大地简化了在 Docker 容器中部署和管理大型语言模型的过程，使用户能够迅速在本地启动和运行这些模型。
思考
Ollama 后台是怎样启动的？使用了哪些技术？
HTTP 建立连接
心跳


工程中 Gin 是怎么使用的？
命令启动时，有点类似Docker的玩法，是怎样实现的？
Open-webUI 是怎样跑起来的，使用的是JavaScript，怎样写成网站的？;;
如何把多台电脑的CPU、GPU、RAM结合在一起跑大模型。


有数亿的人访问大模型，数万亿级别的请求，大模型要做成分布式的，提高并发速度。

部署安全策略，防止病毒或非法入侵。


References
Ollama 官网: https://ollama.com/

Ollama Github: https://github.com/ollama/ollama

动手学 Ollama 教程: https://github.com/datawhalechina/handy-ollama/blob/main/README.md

什么是 ollama: https://wiki.eryajf.net/pages/97047e/

An open-source, modern-design ChatGPT&#x2F;LLMs UI&#x2F;Framework : https://github.com/lobehub/lobe-chat

open-webui无法链接ollama 报错ERROR:apps.ollama.main:Connection error: Cannot connect: https://www.cnblogs.com/qumogu/p/18235298
问题：open-webui正常可以访问，但不能选择Ollama中的模型，解决方法：# WebUI与ollama在同一台机器：sudo docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main# WebUI与ollama不在同一台机器：docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main

]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>aI</tag>
        <tag>ollama</tag>
      </tags>
  </entry>
  <entry>
    <title>assembly</title>
    <url>/Assembly/Assembly/assembly/</url>
    <content><![CDATA[

Assemble Tutorial
Assembly language
x86 instruction set
memory hierarchy: DRAM, cache, address translation, virtual memory
instruction execution on a modern processor
compilation
linking
heap management

Knowing of Computer system organization

operating system
complier
network
computer architecture

1. instruction
DCD：指令可分配一个或多个字的内存，在四个字节的边界上对齐，并定义内存的运行时初值
DCDU&#96;：与之相同，不过内存对齐是任意的
分段：在实模式下通过偏移一个段寄存器的4位再加上16位偏移量，形成一个20位的物理地址

2. RegisterInter 8086架构有16个处理器，可供程序员使用的有14个16位的寄存器；有16位宽数据总线和地址总线，20位宽的外部地址总线。
Intel架构的处理器，指令集命令规则演变：最初的8086中有8个 16 bite 的寄存器，习惯命名为 %ax---%bp，然后扩展到IA32架构时，命名标号变为 %eax---%ebp，最后扩展到X86-64架构后，原来的8个寄存器由 32 bite变为 64 bite，标号也变为 %rax---%rbp，还新增了 8 个新的寄存器，标号按照新的命名规则制定的 %r8---%r15。

8个通用寄存器：

4个数据寄存器

EAX(Extended Accumulator X)	 累加寄存器
EBP(Extended Base Register X)	 基址寄存器
ECX(Extended Counting X	 )  计数寄存器
EDX(Extended Data Register)  数据寄存器


2个变址寄存器

EDI(Extended Destination Indexing)  目的变址寄存器
ESI(Extended Source Indexing)       源变址寄存器


2个指针寄存器

ESP(Extended Stack Pointer)	栈指针寄存器：用来指明运行时栈的结束位置。
EBP(Extended Base pointer )  基址指针寄存器




4个16位段寄存器 

段的起始地址称为段寄存器 


CS(Code Segment)  代码段寄存器 
DS(Data Segment)  数据段寄存器 
SS(Stack Segment) 堆栈段寄存器 
ES(Extra Segment) 附加段寄存器


EIP(Extended Instructions Pointer)	指令指针寄存器 

EFR(Extended Flag Register)          标志寄存器


3. Machine-Level Representation
Abbreviation
CISC(Complex Instruction Set Computer): 复杂指令集计算机
RISC(Reduced Instruction  Set Computer) ：精简指令集计算机
ARM：Acorn Risc Machine
OA(Offset Address)： 偏移地址
EA(Effective Address)：有效地址


反汇编器(disassembler): 根据机器代码产生一种类似于汇编代码的程序。
GCC和 Objdump 工具产生的汇编代码默认使用的是 AT&amp;T公司 拟定的格式。
在GCC中使用一些参数可以产生Intel公司拟定的汇编代码格式： gcc test.c -S  -masm=intel

3.1. Operand Specifiers(操作数指示符)大多数指令有一个或多个 Operand Specifiers，其中源数据(source values) 放置可执行的操作，目的位置(destination) 放置计算的结果。

Source values 支持的操作数(operand)格式
constants(常数，也叫立即数)
read from registers or memory(从寄存器或内存中读出的数)


Destination of Result 目的位置计算的结果支持的操作数格式
Register(寄存器)
Memory(内存)



各种不同的操作数可分为下面三种类型 

Immediate(立即数)：表示常数值
在AT&amp;T公司格式的汇编代码中，立即数的书写是 $ 后面跟一个用标准C表示法表示的整数。例如：$-577 或 $0x1F 


Register(寄存器)：表示某个寄存器中的内容
用符号 $r_a$ 表示任意寄存器 a，用引用 $R[r_a]$ 表示它的值，这是将寄存器集合看成一个数组 R，用寄存器标识符作为index(索引)。
可以把16个寄存器的低8位，16位，32位或64位中的一个来作为操作数。


memory reference(内存引用)：根据计算出来的地址去访问某个内存的位置。
可以将内存看成是一个很大的字节数组 (we view the memory as a large array of bytes)。 
用符号 $M_b[Addr]$ 表示：对存储在内存中从地址 Addr开始的 b 个字节值的reference(引用)。
汇编语言中常用的内存引用格式为 $Imm(r_{b}, r_{i}, s)$，因此有效地址的计算公式为：$Imm + R[r_b] + R[r_i]*s$
Imm: immediate offset (立即数偏移)
$r_b$: base register(64-bit基址寄存器)
$r_i$: index register(64-bit变址寄存器)
s: scale factor(比例因子，s必须是1、2、4或8)





3.2. Data Movement Instructions指令集的表示方式： [标号:] 操作码 [操作数] [;注释]，其中带有 [] 的部分为可选项。
注意：GNU汇编器默认采用 AT&amp;T 样式的语法，其中的源和目的操作数与 Intel 公司标准中拟定的格式顺序是相反的。

mov

Intel架构下的格式：mov dest, src；AT&amp;T公司规定的格式：mov source destination
功能：将source位置中的数据copy到destination位置中。注意：执行这个操作需要两条指令，第一条指令将源值(source value)加载到寄存器中，第二条指令将该寄存器值写入目的位置(destination)。
source operand(源操作数)支持以下几种类型
Immediate(立即数)
Register(寄存器)
Memory(内存)


destination operand(目的操作数)支持以下几种类型
Register(寄存器)
Memory address (内存地址)



注意： source与destination两个不能同时为 memory location(内存位置)。

几种简单的mov指令

movb: move byte(移动字节)
movw: move word(移动字)
movl: move double word(32 bit 数据被看成是long word，因此用后缀“l” 表示双字)
movq: move quad word(移动四字) 
> 常规的 `movq` 指令只能以表示为32位补码数字的立即数作为源操作数，然后把这个值符号扩展得到64位的值，放到目的(destination)位置。`movabsq` 指令能够以任意6位立即数值作为源操作数(source operand)，并且只能以寄存器(register)作为目的(destination)。


上面几个指令实现的例子


注意：大多数情况中，mov指令只会更新 destination operand 指定的寄存器字节和内存位置；但是当mov指令的destination 为寄存器时，它会把该寄存器的高位 4字节设置为0，原因是：任意的生成32 bit 值的指令都会将该register的高位设置为0。

两类数据移动指令：将较小的 source 拷贝到 destination中。MOVZ中的指令把destination中剩余的字节补充为 0，MOVS类中的指令通过符号扩充来填充，把source operand 的最高位进行拷贝。



注意：  cltq 指令：它没有操作数，总是以 %eax 为source；%rax 为destination，作为符号扩展的结果。
3.3. Pushing and Popping Stack Datastack的栈顶元素的地址是栈中元素地址最小的，因此栈具有向下增长的特性。

pushq: push quad word(每次压栈按4字为单位进行压栈)
pop ：从stack中弹出数据 
压栈和出栈指令
执行一条 pushq %rbp 等价于执行下面两条指令subq $8, %rsp                    // Decrement stack pointermovq %rbp, (%rsp)                // Store %rbp on stack执行一条 popq %rax 等价于执行下面两条指令movq (%rsp), %rax                // Read %rax from stackaddq $8, %rsp                    // Increment stack pointer

3.4. Arithmetic and Logical Operations(算术与逻辑运算)下面表中有四组操作(operations)：加载有效地址(load effective address)、一元操作(unary)、二元操作(binary)、移位(shifts)。其中一元操作只有一个操作数，二元操作有两个操作数(operand)
3.4.1. lea(load effective address)：加载有效地址
lea是mov指令的一个变形，从内存（memory）读数据到寄存器（register）。该指令并不是从指定的位置读入数据，而是将有效地址写入到目的操作数。
lea指令通常用来执行简单的算术操作，能执行加法和有限形式的乘法。
指令：leaq src dst
leaq 7(%rax, %rax, 4) %rdx：将 %rax 寄存器指向的地址中的值存储到 %rdx寄存器中，其中寄存器 %rdx 的值为x，寄存器 %rax 的值设置为：(x + 4*x) + 7



3.4.2. unary &amp;&amp; binary
只有一个操作数，既是source又是destination，这个操作数可以是register，也可以是memory location(内存位置)。
有两个操作数，第一个为source，第二个为destination 
第一个操作数可以是： immediate value(立即数)、register、memory location；
第二个操作数可以是：register、memory location
当第二个操作数为 memory location时，processor(处理器)必须从memory里读数据，执行操作，将结果写回入到memory(内存)中。




示例：subq %rax,%rdx：表示从 %rdx 寄存器中减去 %rax
示例：Address     Value   Register      Value-------------------------------------------0x100       0xFF    %rax          0x1000x108       0xAB    %rcx          0x10x110       0x13    %rdx          0x30x118       0x11incq(%rsp)           // 使栈顶指针的 8-byte 元素值加一incq 16(%rcx)        // 将源操作数 %rcx 的地址加上十进制的立即数 16，取出源操作数地址内的值并加一，其结果为目的操作数(0x14)并替换调原来的源操作数，。addq %rcx, (%rax)    // 源操作数%rcx的值，加上目的操作数 %rax寄存器的地址0x100中的内容0xFF，并将新的结果(0xFF + 1)存到目的操作数中imulq $16,(%rax,%rdx,8)   // 结果为：0x110subq %rdx,%rax            // 结果为：0xFD

3.4.3. shifts
移位操作中，第一位是移位量，第二位是要移位的数。
shift amount(移位量)：可以是immediate value(立即数)，或者是单字节的register %cl。
destination operand (目的操作数)可以是 register或者memory location。
左移
SAL：算术左移
SHL：逻辑左移


右移
SAR：算术右移
SHR：逻辑右移




一个字节的移位量使得移位量的编码范围可以达到 $2^8-1&#x3D;255$ 。x86-64中，移位操作对 w 位长的数据值进行操作，移位量是由 %cl 寄存器的低 m 位决定的，这里 $2^m &#x3D; w$，高位会被忽珞。所以，当寄存器 %cl 的十六进制值为0xFF时，指令 salb 会移7位，salw会移15位，sall会移31位，而会移63位。

3.5. Control Instruction
single-bit condition code registers(单个位的条件码寄存器)
CF(carry flag 进位标志): Set on high-order bit carry or borrow; cleared otherwise
PF(parity flag 奇偶校验标志): Set if low-order eight bits of result contain an even number of “1” bits; cleared otherwise
ZF(zero flags 零标志): Set if result is zero; cleared otherwise
SF(sign flag 符号标志): Set equal to high-order bit of result (0 if positive 1 if negative)
OF(overflow flag 溢出标志): Set if result is too large a positive number or too small a negative number (excluding sign bit) to fit in destination operand; cleared otherwise



3.6. Jump Instruction
je: 等于

jgt: 大于则跳（Jump if Greater Than）

jg:  大于（jump greater）

jge(或jgte): 大于等于（jump greater than or equal）

jl:  小于（jump less）

jle: 小于等于（jump less equal）

jne: 不等于（jump not equal）

add

格式：add dest src
功能：dest ← dest + src


sub

格式：sub dest src
功能：dest ← dest - src


xchg

格式：xchg dest src
功能：将src中的内容与dest内容经行交换。


test

格式：test dest src
功能：dest ^ src dest和src进行逻辑与运算


and

格式：and dest src
功能：dest ← dest ^ src dest和src进行逻辑与运算


dec

格式：add dest
功能：dest ← dest - 1


call


References
x86 Assembly Guide: https://www.cs.virginia.edu/~evans/cs216/guides/x86.html
Assembly language primer

]]></content>
      <categories>
        <category>Assembly</category>
      </categories>
      <tags>
        <tag>assembly</tag>
      </tags>
  </entry>
  <entry>
    <title>0_c_code_of_conduct</title>
    <url>/C/C/0_c_code_of_conduct/</url>
    <content><![CDATA[1、清晰第一清晰性是易于维护、易于重构的程序必需具备的特征。代码首先是给人读的,好的代码应当可以像文章一样发声朗诵出来。
2.、简洁为美简洁就是易于理解并且易于实现。代码越长越难以看懂，也就越容易在修改时引入错误。写的代码越多，意味着出错的地方越多，也就意味着代码的可靠性越低。
因此，我们提倡大家通过编写简洁明了的代码来提升代码可靠性。废弃的代码(没有被调用的函数和全局变量)要及时清除，重复代码应该尽可能提炼成函数。
3、选择合适的风格，与代码原有的风格保持一致产品所有人共同分享同一种风格所带来的好处，远远超出为了统一而付出的代价。在公司已有编码规范的指导下，审慎地编排代码以使代码尽可能清晰，是一项非常重要的技能。
如果重构&#x2F;修改其他风格的代码时，比较明智的做法是根据现有代码的现有风格继续编写代码,或者使用格式转换工具进行转换成公司内部风格。
一、头文件原则1.1 头文件中适合放置接口的声明,不适合放置实现。
说明:头文件是模块(Module)或单元(Unit)的对外接口。头文件中应放置对外部的声明,如对外提供的函数声明、宏定义、类型定义等。
原则1.2 头文件应当职责单一。
说明:头文件过于复杂，依赖过于复杂是导致编译时间过长的主要原因。很多现有代码中头文件过大，职责过多，再加上循环依赖的问题，可能导致为了在.c中使用一个宏，而包含十几个头文件。
原则1.3 头文件应向稳定的方向包含。
说明:头文件的包含关系是一种依赖，一般来说，应当让不稳定的模块依赖稳定的模块，从而当不稳定的模块发生变化时，不会影响(编译)稳定的模块。
规则1.1 每一个.c文件应有一个同名.h文件,用于声明需要对外公开的接口。
说明:如果一个.c文件不需要对外公布任何接口，则其就不应当存在，除非它是程序的入口，如main函数所在的文件。
规则1.2 禁止头文件循环依赖。
说明:头文件循环依赖，指a.h包含b.h，b.h包含c.h，c.h包含a.h之类导致任何一个头文件修改，都导致所有包含了a.h&#x2F;b.h&#x2F;c.h的代码全部重新编译一遍。
而如果是单向依赖，如a.h包含b.h，b.h包含c.h,而c.h不包含任何头文件，则修改a.h不会导致包含了b.h&#x2F;c.h的源代码重新编译。
规则1.3 .c&#x2F;.h文件禁止包含用不到的头文件。
说明:很多系统中头文件包含关系复杂，开发人员为了省事起见,可能不会去一一钻研，直接包含一切想到的头文件，甚至有些产品干脆发布了一个god.h,其中包含了所有头文件，然后发布给各个项目组使用，这种只图一时省事的做法，导致整个系统的编译时间进一步恶化,并对后来人的维护造成了巨大的麻烦。
规则1.4 头文件应当自包含。
说明:简单的说，自包含就是任意一个头文件均可独立编译。如果一个文件包含某个头文件，还要包含另外一个头文件才能工作的话，就会增加交流障碍，给这个头文件的用户增添不必要的负担。
规则1.5 总是编写内部#include保护符(#define 保护)。
说明:多次包含一个头文件可以通过认真的设计来避免。如果不能做到这一点，就需要采取阻止头文件内容被包含多于一次的机制。
注: 没有在宏最前面加上 _ ，即使用 FILENAME_H代替  FILENAME_H ，是因为一般以 _ 和  __ 开头的标识符为系统保留或者标准库使用，在有些静态检查工具中，若全局可见的标识符以 _ 开头会给出告警。
定义包含保护符时，应该遵守如下规则:
1)保护符使用唯一名称;
2)不要在受保护部分的前后放置代码或者注释。
规则1.6 禁止在头文件中定义变量。
说明:在头文件中定义变量，将会由于头文件被其他.c文件包含而导致变量重复定义。
规则1.7 只能通过包含头文件的方式使用其他.c提供的接口,禁止在.c中通过extern的方式使用外部函数接口、变量。
说明:若a.c使用了b.c定义的foo()函数，则应当在b.h中声明extern int foo(int input)；并在a.c中通过#include &lt;b.h&gt;来使用foo。禁止通过在a.c中直接写extern int foo(int input)；来使用foo，后面这种写法容易在foo改变时可能导致声明和定义不一致。这一点我们因为图方便经常犯的。
规则1.8 禁止在extern “C”中包含头文件。
说明:在extern “C”中包含头文件，会导致extern “C”嵌套，Visual Studio对extern “C”嵌套层次有限制，嵌套层次太多会编译错误。
建议1.1 一个模块通常包含多个.c文件,建议放在同一个目录下,目录名即为模块名。为方便外部使用者,建议每一个模块提供一个.h,文件名为目录名。
建议1.2 如果一个模块包含多个子模块,则建议每一个子模块提供一个对外的.h,文件名为子模块名。
建议1.3 头文件不要使用非习惯用法的扩展名,如.inc。
建议1.4 同一产品统一包含头文件排列方式。
二、函数原则2.1 一个函数仅完成一件功能。
说明:一个函数实现多个功能给开发、使用、维护都带来很大的困难。
原则2.2 重复代码应该尽可能提炼成函数。
说明:重复代码提炼成函数可以带来维护成本的降低。
规则2.1 避免函数过长,新增函数不超过50行(非空非注释行)。
说明:本规则仅对新增函数做要求，对已有函数修改时，建议不增加代码行。
规则2.2 避免函数的代码块嵌套过深,新增函数的代码块嵌套不超过4层。
说明:本规则仅对新增函数做要求，对已有的代码建议不增加嵌套层次。
规则2.3 可重入函数应避免使用共享变量;若需要使用,则应通过互斥手段(关中断、信号量)对其加以保护。
规则2.4 对参数的合法性检查,由调用者负责还是由接口函数负责,应在项目组&#x2F;模块内应统一规定。缺省由调用者负责。
规则2.5 对函数的错误返回码要全面处理。
规则2.6 设计高扇入,合理扇出(小于7)的函数。
说明:扇出是指一个函数直接调用(控制)其它函数的数目,而扇入是指有多少上级函数调用它。如下图：

规则2.7 废弃代码(没有被调用的函数和变量)要及时清除。
建议2.1 函数不变参数使用const。
说明:不变的值更易于理解&#x2F;跟踪和分析，把const作为默认选项，在编译时会对其进行检查，使代码更牢固&#x2F;更安全。
建议2.2 函数应避免使用全局变量、静态局部变量和I&#x2F;O操作,不可避免的地方应集中使用。
建议2.3 检查函数所有非参数输入的有效性,如数据文件、公共变量等。
说明:函数的输入主要有两种:一种是参数输入;另一种是全局变量、数据文件的输入，即非参数输入。函数在使用输入参数之前，应进行有效性检查。
建议2.4 函数的参数个数不超过5个。
建议2.5 除打印类函数外,不要使用可变长参函数。
建议2.6 在源文件范围内声明和定义的所有函数,除非外部可见,否则应该增加static关键字。
三、 标识符命名与定义目前比较常用的如下几种命名风格:
unix like风格：单词用小写字母,每个单词直接用下划线_分割,，例如text_mutex,kernel_text_address。
Windows风格：大小写字母混用，单词连在一起,每个单词首字母大写。不过Windows风格如果遇到大写专有用语时会有些别扭,例如命名一个读取RFC文本的函数，命令为ReadRFCText,看起来就没有unix like的read_rfc_text清晰了。
原则3.1 标识符的命名要清晰、明了,有明确含义,同时使用完整的单词或大家基本可以理解的缩写,避免使人产生误解。
原则3.2 除了常见的通用缩写以外,不使用单词缩写,不得使用汉语拼音。
建议3.1 产品&#x2F;项目组内部应保持统一的命名风格。
建议3.2 尽量避免名字中出现数字编号,除非逻辑上的确需要编号。
建议3.3 标识符前不应添加模块、项目、产品、部门的名称作为前缀。
建议3.4 平台&#x2F;驱动等适配代码的标识符命名风格保持和平台&#x2F;驱动一致。
建议3.5 重构&#x2F;修改部分代码时,应保持和原有代码的命名风格一致。
建议3.6 文件命名统一采用小写字符。
规则3.2 全局变量应增加“g_”前缀。
规则3.3 静态变量应增加“s_”前缀。
规则3.4 禁止使用单字节命名变量,但允许定义i、j、k作为局部循环变量。
建议3.7 不建议使用匈牙利命名法。
说明:变量命名需要说明的是变量的含义，而不是变量的类型。在变量命名前增加类型说明，反而降低了变量的可读性；更麻烦的问题是，如果修改了变量的类型定义，那么所有使用该变量的地方都需要修改。
建议3.8 使用名词或者形容词+名词方式命名变量。
建议3.9 函数命名应以函数要执行的动作命名,一般采用动词或者动词+名词的结构。
建议3.10 函数指针除了前缀,其他按照函数的命名规则命名。
规则3.5 对于数值或者字符串等等常量的定义,建议采用全大写字母,单词之间加下划线„_‟的方式命名(枚举同样建议使用此方式定义)。
规则3.6 除了头文件或编译开关等特殊标识定义,宏定义不能使用下划线„_‟开头和结尾。
四、变量原则4.1 一个变量只有一个功能,不能把一个变量用作多种用途。
原则4.2 结构功能单一;不要设计面面俱到的数据结构。
原则4.3 不用或者少用全局变量。
规则4.1 防止局部变量与全局变量同名。
规则4.2 通讯过程中使用的结构,必须注意字节序。
规则4.3 严禁使用未经初始化的变量作为右值。
建议4.1 构造仅有一个模块或函数可以修改、创建,而其余有关模块或函数只访问的全局变量,防止多个不同模块或函数都可以修改、创建同一全局变量的现象。
建议4.2 使用面向接口编程思想,通过API访问数据:如果本模块的数据需要对外部模块开放,应提供接口函数来设置、获取,同时注意全局数据的访问互斥。
建议4.3 在首次使用前初始化变量,初始化的地方离使用的地方越近越好。
建议4.4 明确全局变量的初始化顺序,避免跨模块的初始化依赖。
说明:系统启动阶段，使用全局变量前，要考虑到该全局变量在什么时候初始化，使用全局变量和初始化全局变量，两者之间的时序关系，谁先谁后，一定要分析清楚，不然后果往往是低级而又灾难性的。
建议4.5 尽量减少没有必要的数据类型默认转换与强制转换。
说明:当进行数据类型强制转换时，其数据的意义、转换后的取值等都有可能发生变化，而这些细节若考虑不周，就很有可能留下隐患。
五、 宏、常量规则5.1 用宏定义表达式时,要使用完备的括号。
说明:因为宏只是简单的代码替换，不会像函数一样先将参数计算后，再传递。
规则5.2 将宏所定义的多条表达式放在大括号中。
说明:更好的方法是多条语句写成do while(0)的方式。
规则5.3 使用宏时，不允许参数发生变化。
规则5.4 不允许直接使用魔鬼数字。
说明:使用魔鬼数字的弊端：代码难以理解；如果一个有含义的数字多处使用，一旦需要修改这个数值，代价惨重。使用明确的物理状态或物理意义的名称能增加信息，并能提供单一的维护点。
建议5.1 除非必要,应尽可能使用函数代替宏。
说明:宏对比函数，有一些明显的缺点：宏缺乏类型检查，不如函数调用检查严格。
建议5.2 常量建议使用const定义代替宏。
建议5.3 宏定义中尽量不使用return、goto、continue、break等改变程序流程的语句。
六、质量保证原则6.1 代码质量保证优先原则
(1)正确性，指程序要实现设计要求的功能。
(2)简洁性，指程序易于理解并且易于实现。
(3)可维护性，指程序被修改的能力，包括纠错、改进、新需求或功能规格变化的适应能力。
(4)可靠性，指程序在给定时间间隔和环境条件下，按设计要求成功运行程序的概率。
(5)代码可测试性，指软件发现故障并隔离、定位故障的能力，以及在一定的时间和成本前提下，进行测试设计、测试执行的能力。
(6)代码性能高效，指是尽可能少地占用系统资源，包括内存和执行时间。
(7)可移植性，指为了在原来设计的特定环境之外运行，对系统进行修改的能力。
(8)个人表达方式&#x2F;个人方便性，指个人编程习惯。
原则6.2 要时刻注意易混淆的操作符。比如说一些符号特性、计算优先级。
原则6.3 必须了解编译系统的内存分配方式,特别是编译系统对不同类型的变量的内存分配规则,如局部变量在何处分配、静态变量在何处分配等。
原则6.4 不仅关注接口,同样要关注实现。
说明:这个原则看似和“面向接口”编程思想相悖，但是实现往往会影响接口，函数所能实现的功能，除了和调用者传递的参数相关，往往还受制于其他隐含约束，如:物理内存的限制，网络状况，具体看“抽象漏洞原则”。
规则6.1 禁止内存操作越界。
坚持下列措施可以避免内存越界:

数组的大小要考虑最大情况，避免数组分配空间不够。
避免使用危险函数sprintf &#x2F;vsprintf&#x2F;strcpy&#x2F;strcat&#x2F;gets操作字符串，使用相对安全的函数snprintf&#x2F;strncpy&#x2F;strncat&#x2F;fgets代替。
使用memcpy&#x2F;memset时一定要确保长度不要越界
字符串考虑最后的’\0’， 确保所有字符串是以’\0’结束
指针加减操作时，考虑指针类型长度
数组下标进行检查
使用时sizeof或者strlen计算结构&#x2F;字符串长度,，避免手工计算

坚持下列措施可以避免内存泄漏:

异常出口处检查内存、定时器&#x2F;文件句柄&#x2F;Socket&#x2F;队列&#x2F;信号量&#x2F;GUI等资源是否全部释放
删除结构指针时，必须从底层向上层顺序删除
使用指针数组时，确保在释放数组时，数组中的每个元素指针是否已经提前被释放了
避免重复分配内存
小心使用有return、break语句的宏，确保前面资源已经释放
检查队列中每个成员是否释放

规则6.3 禁止引用已经释放的内存空间。

坚持下列措施可以避免引用已经释放的内存空间:
内存释放后，把指针置为NULL；使用内存指针前进行非空判断。
耦合度较强的模块互相调用时，一定要仔细考虑其调用关系，防止已经删除的对象被再次使用。
避免操作已发送消息的内存。
自动存储对象的地址不应赋值给其他的在第一个对象已经停止存在后仍然保持的对象(具有更大作用域的对象或者静态对象或者从一个函数返回的对象)

规则6.4 编程时,要防止差1错误。
说明:此类错误一般是由于把“&lt;&#x3D;”误写成“&lt;”或“&gt;&#x3D;”误写成“&gt;”等造成的,由此引起的后果，很多情况下是很严重的，所以编程时，一定要在这些地方小心。当编完程序后，应对这些操作符进行彻底检查。使用变量时要注意其边界值的情况。
建议6.1 函数中分配的内存,在函数退出之前要释放。
说明:有很多函数申请内存,，保存在数据结构中，要在申请处加上注释，说明在何处释放。
建议6.2 if语句尽量加上else分支,对没有else分支的语句要小心对待。
建议6.3 不要滥用goto语句。
说明:goto语句会破坏程序的结构性,所以除非确实需要,最好不使用goto语句。
建议6.4 时刻注意表达式是否会上溢、下溢。
七、 程序效率原则7.1 在保证软件系统的正确性、简洁、可维护性、可靠性及可测性的前提下,提高代码效率。
原则7.2 通过对数据结构、程序算法的优化来提高效率。
建议7.1 将不变条件的计算移到循环体外。
建议7.2 对于多维大数组,避免来回跳跃式访问数组成员。
建议7.3 创建资源库,以减少分配对象的开销。
建议7.4 将多次被调用的 “小函数”改为inline函数或者宏实现。
八、 注释原则8.1 优秀的代码可以自我解释,不通过注释即可轻易读懂。
说明:优秀的代码不写注释也可轻易读懂,注释无法把糟糕的代码变好,需要很多注释来解释的代码往往存在坏味道,需要重构。
原则8.2 注释的内容要清楚、明了,含义准确,防止注释二义性。
原则8.3 在代码的功能、意图层次上进行注释,即注释解释代码难以直接表达的意图,而不是重复描述代码。
规则8.1 修改代码时,维护代码周边的所有注释,以保证注释与代码的一致性。不再有用的注释要删除。
规则8.2 文件头部应进行注释,注释必须列出:版权说明、版本号、生成日期、作者姓名、工号、内容、功能说明、与其它文件的关系、修改日志等,头文件的注释中还应有函数功能简要说明。
规则8.3 函数声明处注释描述函数功能、性能及用法,包括输入和输出参数、函数返回值、可重入的要求等;定义处详细描述函数功能和实现要点,如实现的简要步骤、实现的理由、设计约束等。
规则8.4 全局变量要有较详细的注释,包括对其功能、取值范围以及存取时注意事项等的说明。
规则8.5 注释应放在其代码上方相邻位置或右方,不可放在下面。如放于上方则需与其上面的代码用空行隔开,且与下方代码缩进相同。
规则8.6 对于switch语句下的case语句,如果因为特殊情况需要处理完一个case后进入下一个case处理,必须在该case语句处理完、下一个case语句前加上明确的注释。
规则8.7 避免在注释中使用缩写,除非是业界通用或子系统内标准化的缩写。
规则8.8 同一产品或项目组统一注释风格。
建议8.1 避免在一行代码或表达式的中间插入注释。
建议8.2 注释应考虑程序易读及外观排版的因素,使用的语言若是中、英兼有的,建议多使用中文,除非能用非常流利准确的英文表达。对于有外籍员工的,由产品确定注释语言。
建议8.3 文件头、函数头、全局常量变量、类型定义的注释格式采用工具可识别的格式。
说明:采用工具可识别的注释格式,例如doxygen格式,方便工具导出注释形成帮助文档。
九、 排版与格式规则9.1 程序块采用缩进风格编写,每级缩进为4个空格。
说明:当前各种编辑器&#x2F;IDE都支持TAB键自动转空格输入,需要打开相关功能并设置相关功能。编辑器&#x2F;IDE如果有显示TAB的功能也应该打开,方便及时纠正输入错误。
规则9.2 相对独立的程序块之间、变量说明之后必须加空行。
规则9.3 一条语句不能过长,如不能拆分需要分行写。一行到底多少字符换行比较合适,产品可以自行确定。
换行时有如下建议:

换行时要增加一级缩进,使代码可读性更好;
低优先级操作符处划分新行;换行时操作符应该也放下来,放在新行首;
换行时建议一个完整的语句放在一行,不要根据字符数断行

规则9.4 多个短语句(包括赋值语句)不允许写在同一行内,即一行只写一条语句。
规则9.5 if、for、do、while、case、switch、default等语句独占一行。
规则9.6 在两个以上的关键字、变量、常量进行对等操作时,它们之间的操作符之前、之后或者前后要加空格;进行非对等操作时,如果是关系密切的立即操作符(如-&gt;),后不应加空格。
建议9.1 注释符(包括„&#x2F;*‟„&#x2F;&#x2F;‟„*&#x2F;‟)与注释内容之间要用一个空格进行分隔。
建议9.2 源程序中关系较为紧密的代码应尽可能相邻。
十、 表达式规则10.1 表达式的值在标准所允许的任何运算次序下都应该是相同的。
建议10.1 函数调用不要作为另一个函数的参数使用,否则对于代码的调试、阅读都不利。
建议10.2 赋值语句不要写在if等语句中,或者作为函数的参数使用。
建议10.3 赋值操作符不能使用在产生布尔值的表达式上。
十一、 代码编辑、编译规则11.1 使用编译器的最高告警级别,理解所有的告警,通过修改代码而不是降低告警级别来消除所有告警。
规则11.2 在产品软件(项目组)中,要统一编译开关、静态检查选项以及相应告警清除策略。
规则11.3 本地构建工具(如PC-Lint)的配置应该和持续集成的一致。
规则11.4 使用版本控制(配置管理)系统,及时签入通过本地构建的代码,确保签入的代码不会影响构建成功。
建议11.1 要小心地使用编辑器提供的块拷贝功能编程。
十二、 可测性原则12.1 模块划分清晰,接口明确,耦合性小,有明确输入和输出,否则单元测试实施困难。
说明:单元测试实施依赖于:

模块间的接口定义清楚、完整、稳定;
模块功能的有明确的验收条件(包括:预置条件、输入和预期结果);
模块内部的关键状态和关键数据可以查询,可以修改;
模块原子功能的入口唯一;
模块原子功能的出口唯一;
依赖集中处理:和模块相关的全局变量尽量的少,或者采用某种封装形式。

规则12.1 在同一项目组或产品组内,要有一套统一的为集成测试与系统联调准备的调测开关及相应打印函数,并且要有详细的说明。
规则12.2 在同一项目组或产品组内,调测打印的日志要有统一的规定。
说明:统一的调测日志记录便于集成测试,具体包括:

统一的日志分类以及日志级别;
通过命令行、网管等方式可以配置和改变日志输出的内容和格式;
在关键分支要记录日志,日志建议不要记录在原子函数中,否则难以定位;
调试日志记录的内容需要包括文件名&#x2F;模块名、代码行号、函数名、被调用函数名、错误码、错误发生的环境等。

规则12.3 使用断言记录内部假设。
规则12.4 不能用断言来检查运行时错误。
说明:断言是用来处理内部编程或设计是否符合假设;不能处理对于可能会发生的且必须处理的情况要写防错程序,而不是断言。
如某模块收到其它模块或链路上的消息后,要对消息的合理性进行检查,此过程为正常的错误检查,不能用断言来实现。
建议12.1 为单元测试和系统故障注入测试准备好方法和通道。
十三、 安全性原则13.1 对用户输入进行检查。
说明:不能假定用户输入都是合法的,因为难以保证不存在恶意用户,即使是合法用户也可能由于误用误操作而产生非法输入。用户输入通常需要经过检验以保证安全,特别是以下场景:

用户输入作为循环条件
用户输入作为数组下标
用户输入作为内存分配的尺寸参数
用户输入作为格式化字符串
用户输入作为业务数据(如作为命令执行参数、拼装sql语句、以特定格式持久化)

这些情况下如果不对用户数据做合法性验证,很可能导致DOS、内存越界、格式化字符串漏洞、命令注入、SQL注入、缓冲区溢出、数据破坏等问题。
可采取以下措施对用户输入检查:

用户输入作为数值的,做数值范围检查
用户输入是字符串的,检查字符串长度
用户输入作为格式化字符串的,检查关键字“%”
用户输入作为业务数据,对关键字进行检查、转义

规则13.1 确保所有字符串是以NULL结束。
说明: C语言中‟\0‟作为字符串的结束符,即NULL结束符。标准字符串处理函数(如strcpy()、 strlen())
依赖NULL结束符来确定字符串的长度。没有正确使用NULL结束字符串会导致缓冲区溢出和其它未定义的行为。
为了避免缓冲区溢出,常常会用相对安全的限制字符数量的字符串操作函数代替一些危险函数。如:

用strncpy()代替strcpy()
用strncat()代替strcat()
用snprintf()代替sprintf()
用fgets()代替gets()

这些函数会截断超出指定限制的字符串,但是要注意它们并不能保证目标字符串总是以NULL结尾。如果源字符串的前n个字符中不存在NULL字符,目标字符串就不是以NULL结尾。
规则13.2 不要将边界不明确的字符串写到固定长度的数组中。
说明:边界不明确的字符串(如来自gets()、getenv()、scanf()的字符串),长度可能大于目标数组长度,直接拷贝到固定长度的数组中容易导致缓冲区溢出。
规则13.3 避免整数溢出。
说明:当一个整数被增加超过其最大值时会发生整数上溢,被减小小于其最小值时会发生整数下溢。带符号和无符号的数都有可能发生溢出。
规则13.4 避免符号错误。
说明:有时从带符号整型转换到无符号整型会发生符号错误,符号错误并不丢失数据,但数据失去了原来的含义。
带符号整型转换到无符号整型,最高位(high-order bit)会丧失其作为符号位的功能。如果该带符号整数的值非负,那么转换后值不变;如果该带符号整数的值为负,那么转换后的结果通常是一个非常大的正数。
规则13.5:避免截断错误。
说明:将一个较大整型转换为较小整型,并且该数的原值超出较小类型的表示范围,就会发生截断错误,原值的低位被保留而高位被丢弃。截断错误会引起数据丢失。使用截断后的变量进行内存操作,很可能会引发问题。
规则13.6:确保格式字符和参数匹配。
说明:使用格式化字符串应该小心,确保格式字符和参数之间的匹配,保留数量和数据类型。格式字符和参数之间的不匹配会导致未定义的行为。大多数情况下,不正确的格式化字符串会导致程序异常终止。
规则13.7 避免将用户输入作为格式化字符串的一部分或者全部。
说明:调用格式化I&#x2F;O函数时,不要直接或者间接将用户输入作为格式化字符串的一部分或者全部。攻击者对一个格式化字符串拥有部分或完全控制,存在以下风险:进程崩溃、查看栈的内容、改写内存、甚至执行任意代码。
规则13.8 避免使用strlen()计算二进制数据的长度。
说明:strlen()函数用于计算字符串的长度,它返回字符串中第一个NULL结束符之前的字符的数量。因此用strlen()处理文件I&#x2F;O函数读取的内容时要小心,因为这些内容可能是二进制也可能是文本。
规则13.9 使用int类型变量来接受字符I&#x2F;O函数的返回值。
规则13.10 防止命令注入。
说明:C99函数system()通过调用一个系统定义的命令解析器(如UNIX的shell,Windows的CMD.exe)来执行一个指定的程序&#x2F;命令。类似的还有POSIX的函数popen()。
十四、 单元测试规则14.1 在编写代码的同时,或者编写代码前,编写单元测试用例验证软件设计&#x2F;编码的正确。
建议14.1 单元测试关注单元的行为而不是实现,避免针对函数的测试。
说明:应该将被测单元看做一个被测的整体,根据实际资源、进度和质量风险,权衡代码覆盖、打桩工作量、补充测试用例的难度、被测对象的稳定程度等,一般情况下建议关注模块&#x2F;组件的测试,尽量避免针对函数的测试。
尽管有时候单个用例只能专注于对某个具体函数的测试,但我们关注的应该是函数的行为而不是其具体实现细节。
十五、 可移植性规则15.1 不能定义、重定义或取消定义标准库&#x2F;平台中保留的标识符、宏和函数。
建议15.1 不使用与硬件或操作系统关系很大的语句,而使用建议的标准语句,以提高软件的可移植性和可重用性。
建议15.2 除非为了满足特殊需求,避免使用嵌入式汇编。
参考：编码规范——华为篇
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>0_c_code_of_conduct</tag>
      </tags>
  </entry>
  <entry>
    <title>10_const</title>
    <url>/C/C/10_const/</url>
    <content><![CDATA[ 


C90新增两个限定符：const  volatile
C99新增一个限定符：restrict 
C11新增一个限定符：_Atmoic
C语言中，用const类型限定符声明的是变量，不是常量
用于限定一个变量为只读,数值不能通过赋值或递增、递减来修改

例子
const float* pf;  pf 指向一个float类型的const值 
pf指向的值不能改变，指针本身可以改变


float* const pt;   pt 是一个const指针
pt本身的值不能改变，但它所指向的值可以改变


const float* const ptr; 表明ptr既不能指向别处， 它所指向的值也不能改变。
 const放在*左侧任意位置，限定了指针指向的数据不能改变；const放在*的右侧， 限定了指针本身不能改变



什么时候用？
如果一个指针仅用于给函数访问值， 应将其声明为一个指向const限定类型的指针。 
如果要用指针更改主调函数中的数据， 就不使用const关键字。
用const声明全局变量，可以创建const变量、 const数组和const结构
多个文件间共享const数据时遵循两个规则：
在一个文件中使用定义式声明，
在其他文件中使用引用式声明（用extern关键字），即只声明不能赋值



 注意： 在C语言中，const定义的值可以采用指针间接赋值的方法，改变指针本身const定义的值
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>10_const</tag>
      </tags>
  </entry>
  <entry>
    <title>11_restrict</title>
    <url>/C/C/11_restrict/</url>
    <content><![CDATA[ 

C99新增一个限定符：restrict 
作用
只用于限制指针。告诉编译器，想要修改当前指针指向内存的的数据，只能通过当前指针操作，不能通过除当前指针以外的变量或指针进行操作。



]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>11_restrict</tag>
      </tags>
  </entry>
  <entry>
    <title>12_extern</title>
    <url>/C/C/12_extern/</url>
    <content><![CDATA[

externC&#x2F;C++中使用 extern 声明的变量或函数，它们的作用域是全局的，告诉编译器使用该关键字声明的变量可以在本模块或其他模块中使用。只是 声明(declaration) 了变量，但是并没有 定义(definition) 该变量，需要在具体使用的地方去定义该变量。
// 在某个.h 文件中声明了变量extern int a;// 在某个具体的.c或.cpp文件中使用int a = 100;

extern “C”
extern &quot;C&quot; 的作用是为了能够正确在 C++ 代码中调用 C 语言代码。 加上 extern &quot;C&quot; 后指示编译器按 C 编译器编译这部分代码。使用它的本质原因是：C++ 函数的重载；C++ 中函数重载是C++编译器通过编译后生成的代码不止有函数名，还会带上参数类型，编译后生成的代码，会改变函数的名称，而 C 编译器编译函数时不会带上函数的参数类型，编译后生成的代码，函数的名称不会改变。

在混合编程中，如果我们不进行任何处理，而相互调用的话，在链接会出现找不到符号链接的情况。

extern &quot;C&quot; 是C++的特性，是一种链接约定，通过它可以实现兼容C与C++之间的相互调用，即对调用函数能够达成一致的意见，使用统一的命名规则，使得实现方提供的接口和调用方需要的接口经按照指定规则编译后，得到的都是一致的函数符号命名。

Ｃ++与c互相调用问题
C++中调用C函数：使用 extern &quot;C&quot; 关键字
// a.c 头文件内容#ifndef A_H#define A_Hint Test(int a, int b);#endif// 在xxx.cpp文件文件中调用 a.h 文件中的 Test() 函数#include &quot;a.h&quot;#include &quot;stdio.h&quot;extern &quot;C&quot;&#123;    int Test(int a, int b);&#125;  int func(int a, int b) &#123;  printf(&quot;result=%d/n&quot;, Test(a, b));  return 0;&#125;

C如何调用C++函数：需要使用 预处理宏 和 extern &quot;C&quot; 关键字
#ifdef __cplusplusextern &quot;C&quot;&#123;#endif......#ifdef __cplusplus&#125;#endif

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>12_extern</tag>
      </tags>
  </entry>
  <entry>
    <title>13_void</title>
    <url>/C/C/13_void/</url>
    <content><![CDATA[ 
1. Void Keywords1.1. 函数用法
使用规则
如果函数没有返回值，那么应声明为void类型；
如果函数无参数，那么应声明其参数为void；
如果函数的参数可以是 任意类型指针，那么应声明其参数为void * 
不能用 void 定义真实的变量。例如： 定义 void a; 会出错，因为无法确定类型，不同类型分配的空间不一样；


作用
对函数参数的限定
对函数返回的限定


含义
void的字面意思是“无类型”，void *则为“无类型指针”，void *可以指向任何类型的数据。 
void几乎只有“注释”和限制程序的作用



1.2. 注意
不能对 void 指针进行算法操作
void* 不能转化为其它类型的数据，否则会报错;但是其它类型的数据可以转化为 void* 类型
void 的出现只是为了一种抽象的需要，像在面向对象中，不能给 抽象基类 定义一个实例，因此不能定义一个void变量。

1.3. 参考
void与void*详解

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>13_void</tag>
      </tags>
  </entry>
  <entry>
    <title>14_memset</title>
    <url>/C/C/14_memset/</url>
    <content><![CDATA[ 
函数
定义 void *memset(void *s, int ch, size_t n);
函数解释：将s中当前位置后面的n个字节 （typedef unsigned int size_t ）用 ch 替换并返回 s 
该函数只能取ch的后八位赋值给你所输入的范围的每个字节，无论ch多大只有后八位二进制有效
ch的范围为：0~255
对字符数组操作时则取后八位赋值给字符数组，其八位值作为ASCII码。


函数原型：extern void *memset(void *buffer, int c, int count) 
buffer：为指针或是数组,
c：是赋给buffer的值
count： 要填充的 字节数。


作用
为新申请的内存按字节进行初始化。
对较大的结构体或数组进行清零，这种方法最快。
不能用它将int数组初始化为0和-1之外的其他值（除非该值高字   节和低字节相同）。



注意点

内存操作都是按照字节为单位进行处理，即 1字节
填充的数 count 按照字节为单位设置。
定义数组为int类型时，传入的数为sizeof(int)的整数倍，而不是数组的长度。

代码示例memset() 代码示例
参考
memset百度百科

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>14_memset</tag>
      </tags>
  </entry>
  <entry>
    <title>15_strncpy_memcpy</title>
    <url>/C/C/15_strncpy_memcpy/</url>
    <content><![CDATA[ 



1. strncpy()
2. memcpy()
3. strcpy()与memcpy()区别
4. 参考



1. strncpy()
定义char *strncpy(char *dest, const char *src, size_t count); 
dest：目标字符数组；
src：源字符数组；
count：要复制的最大字符数


功能
把src所指向的字符串中以src地址开始的前n个字节(不包括\0，\0得自己手动加在*dest被复制之后)复制到dest所指的数组中，并返回被复制后的dest


注意事项
src和dest所指内存区域不可以重叠，且dest必须有足够的空间来容纳src的字符长度 + \0&#39;
strcpy只是复制字符串，但不限制复制的数量，很容易造成缓冲溢出。strncpy要安全一些。
memcpy能够选择一段字符输出，strcpy复制全部的字符串。
执行完strncpy()后，会覆盖原先dest字符数组中的数据。



2. memcpy()
定义void *memcpy(void *dest, void *src, size_t count);
参数
dest: 指向用于存储复制内容的目标数组，类型强制转换为 void* 指针。
src: 指向要复制的数据源，类型强制转换为 void* 指针。
count: 要被复制的 字节数。


返回值
返回一个指向目标存储区dest的指针
成功时返回为零，错误时，返回非零值。




功能
从src内存地址拷贝 count 个字节到 dest内存中。


注意事项
指针src和指针dest所指的内存区域不能重叠
src和dest都不一定是数组，任意的可读写的空间均可。
两个不同的数组之间拷贝，用 sizeof() 得到 字节数 n，不是传入数组的长度len.
执行完 memcpy() 后，会覆盖原先 dest 字符数组中的数据。



3. strcpy()与memcpy()区别
复制的内容不同。
strcpy只能复制字符串，而memcpy可以复制任意内容，例如字符数组、整型、结构体、类等。


复制的方法不同。
strcpy不需要指定长度，它遇到被复制字符的串结束符”\0”才结束，所以容易溢出。memcpy则是根据其第3个参数决定复制的长度。


用途不同。
通常在复制字符串时用strcpy，而需要复制其他类型数据时则一般用memcpy


memcpy()是内存到内存之间拷贝最快的，相比strcpy() 和 memmove()
memmove() 函数也是将 src 指向的内存中的 count 个字符拷贝到 dest 指向的内存区域中。若目标区域(dest)和源区域(src)有重叠的话，memmove 能够保证源串(src)在被覆盖之前将 重叠区域 的字节拷贝到目标区域中，但 复制后源内容会被更改。但是当目标区域与源区域没有重叠则和 memcpy()函数功能相同。



4. 参考
百度百科strncpy讲解
百度百科memcpy讲解

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>15_strncpy_memcpy</tag>
      </tags>
  </entry>
  <entry>
    <title>16_memcmp_strcmp</title>
    <url>/C/C/16_memcmp_strcmp/</url>
    <content><![CDATA[ 




1. memcmp()
2. strcmp()
3. memcmp()与strcmp()区别
4. 参考



1. memcmp()
函数原型：int memcmp(const void *str1, const void *str2, size_t n));
参数
str1： 指向内存块的指针。
str2： 指向内存块的指针。
n： 要被比较的字节数


返回值
如果返回值 &lt; 0，则表示 str1 小于 str2。
如果返回值 &gt; 0，则表示 str1 大于 str2。
如果返回值 &#x3D; 0，则表示 str1 等于 str2


功能
把存储区 str1 和存储区 str2 的前 n 个字节进行比较。该函数是按字节进行比较，该函数位于string.h。



2. strcmp()
函数原型 intstrcmp(const char *s1,const char *s2)
返回值（比较结果返回整数）
s1小于s2则返回负数
s1等于s2则返回零
s1大于s2则返回正数。


功能
比较字符串s1和s2，对比是以 字符 为单位。
两个字符串自左向右逐个字符相比（按ASCII值大小相比较），直到出现不同的字符或遇’\0’为止



3. memcmp()与strcmp()区别
memcmp() 能比较除字符串以外其它复杂的数据类型，但不能判断两个结构体是否一定相等。
strcmp() 只能比较两个字符串的大小内容是否相等，以 字符 为单位进行比较，而 memcmp()是以内存的 字节数 进行比较的。

4. 参考
百度百科strcmp参考
百度百科memcmp参考

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>16_memcmp_strcmp</tag>
      </tags>
  </entry>
  <entry>
    <title>17_typedef</title>
    <url>/C/C/17_typedef/</url>
    <content><![CDATA[ 




1. Typedef Kyewords
1.1. 为什么使用typedef
1.2. 基本语法
1.3. typedef与数组
1.4. typedef与函数指针
1.5. 与#define比较
1.6. 参考






1. Typedef Kyewords1.1. 为什么使用typedef
使用 typedef来编写更美观和可读的代码。所谓美观，意指 typedef 能隐藏笨拙的语法构造以及平台相关的数据类型，从而增强可移植性和以及未来的可维护性。 
给变量取一个好记且意义明确的新名字，
简化一些比较复杂的类型声明。

1.2. 基本语法
typedef
typedef：为现有类型取一个新的名称
语法规则：typedef  现有数据类型名称 新类型名称
typedef a b;  给原类型a取一个别名为b



1.3. typedef与数组
定义相同类型和大小的数组typedef char arr[50];arr text, data;  // 声明了一个text数组和一个data数组

1.4. typedef与函数指针typedef void (*PrintHelloHandle)(int); PrintHelloHandle pFunc;  // 声明一个函数指针为 pFunc 的别名pFunc = printHello;      // 初始化函数指针，将 printHello 的函数的地址赋值给函数指针  pFunc(*pFunc)(110);           // 调用函数指针，两种方式：(*pFunc)(110) 或 pFunc(110)  //在其它地方的程序需要声明类似的函数指针，只需要简单使用 PrintHelloHandle pFuncOther; // 声明一个函数指针为 pFuncOther 的别名


为什么要用函数指针与typedef结合
在多个地方声明同一个类型的函数指针变量，简化代码



1.5. 与#define比较
#define只是简单的字符串替换而typedef则是为一个类型起新名字
通常讲，typedef要比#define要好，特别是在有指针的场合。

1.6. 参考
百度百科typedef用法

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>17_typedef</tag>
      </tags>
  </entry>
  <entry>
    <title>18_struct_bytealigned</title>
    <url>/C/C/18_struct_bytealigned/</url>
    <content><![CDATA[ 

1. 结构体定义（3种）
声明结构体包括两步

定义结构体
声明相应结构体类型的变量（结构体能包含C语言允许的所有类型变量）


法一：在定义结构体类型的同时说明结构体变量
struct 结构体标识符&#123;    成员变量列表;&#125;变量名列表;

法二:直接说明结构体变量
struct&#123;    成员变量列表;&#125;变量名列表;

法三：先定义结构体，再说明结构体变量
struct 结构体标识符&#123;    成员变量列表;&#125;;struct 结构体标识符 变量名列表;

2. 调用结构体
普通结构体 . 成员变量的引用  结构体变量名.成员名
结构体指针两种表示
(* 变量名).成员字段名 :点操作(.)比取值操作符(*)有更高的优先级，所以要加括号
 -&gt; 指针成员变量引用  结构体指针变量名字-&gt;成员名



3. 初始化结构体(两种方法)
在声明结构体类型时，不能指直接赋值，而是要定义结构体变量后才可以赋值。结构体是一种类型，而不是一个变量。
声明结构体变量后，单独初始化每个成员
通过集合符号对结构体变量进行初始化，使用花括号。变量之间用逗号隔开，成员字段按指定顺序查值并初始化。
使用结构体指针之前，必须对其进行初始化 
结构体只是一种 类型，不是变量。 

4. 结构体嵌套
一个结构体成员列表中嵌套另外一种数据类型的结构体，并声明该结构体类型的变量struct Student&#123;    char name[20];    char sex;    int age;    struct Teacher&#123;                    int num;                    char subject[20];                    char address[30];                &#125;teacher;            &#125;Stu;
定义一个结构体数据类型时候，成员列表中可以定义若干个其他数据类型的结构体，并同时声明该类型的结构体变量struct Student&#123;                char name[20];                char sex;                int age;                struct Teacher&#123;                                int num;                                char subject[20];                                char address[30];                                struct unit&#123;                                            char company[30];                                            char company_addr[30];                                           &#125;units;                              &#125;teacher;              &#125;Stu;

5. 结构体填充与数据对齐
结构变量的大小等于它包含所有变量的总大小。
结构体填充：是编译器用来对齐内存偏移数据。
字段填充：为了提高性能，编译器在结构体中利用 结构体填充 方法进行数据对齐。
数据对齐：当CPU读写内存时，它都在小块内（字长或4个字节）进行。这种安排增加了系统的性能，有效地将数据存放在字长整数倍的偏移地址。
结构体中每个数据类型都要对齐
联合体中按照最大长度的数据类型对齐
按照基本数据类型对齐



5.1. 为什么要字节对齐？
现代计算机中内存的存储理论上都是按照 byte 大小来存储的，但实际上是按照 字长（word size） 为单位存储的。这样做是减少CPU访问内存的次数，加大CPU访问内存的吞吐量。比如同样读取8个字节的数据，一次读取4个字节那么只需要读取2次。 

5.2. 字节对齐方法
C编译器中采用#pragma指令#pragma pack(n) 编译器将按照 n 个字节对齐
_packed: 按照一字节对齐。packed一般会以降低运行性能为代价，由于大多数cpu处理数据在合适的字节边界数的情况下会更有效，packed的使用会破坏这种自然的边界数。
GCC编译器中采用 attribute((aligned (n)))方式对齐。
让所作用的结构成员对齐在 n 字节自然边界上。如果结构体中有成员的长度大于 n，则按照最大成员的长度来对齐。


GCC编译器中采用attribute ((packed)) 取消结构在编译过程中的优化对齐，按照实际占用字节数进行对齐。
结构体字节对齐的细节和具体编译器实现相关，但一般而言满足三个准则
结构体变量的首地址能够被其最宽基本类型成员的大小所整除；
结构体每个成员相对结构体首地址的偏移量(offset)都是成员大小的整数倍，如有需要编译器会在成员之间加上填充字节 internal adding；
结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节 trailing padding。



5.3. 为什么要用传递结构体指针变量？
结构体中数据成员变量的数据非常大，采用 结构体指针变量 比 传递值 的效率要高，花费的时间少。

6. References
C语言#pragma预处理
百度百科字长解释
C语言字节对齐

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>18_struct_bytealigned</tag>
      </tags>
  </entry>
  <entry>
    <title>19_cdecl</title>
    <url>/C/C/19_cdecl/</url>
    <content><![CDATA[参考

调用约定__cdecl、__stdcall和__fastcall

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>19_cdecl</tag>
      </tags>
  </entry>
  <entry>
    <title>1_c_thinking</title>
    <url>/C/C/1_c_thinking/</url>
    <content><![CDATA[ 

如何看懂一个复杂的算法程序？
读懂流程
看懂每条语句
试数
调试
模仿改
不看代码写程序

C was developed from 1969 to 1973 by Dennis Ritchie(丹尼斯·里奇) of Bell Laboratories. 
References
GCC online documentation：GCC在线的官方文档，很权威。
2019年，CSDN有哪些值得学习的专栏？

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>1_c_thinking</tag>
      </tags>
  </entry>
  <entry>
    <title>20_byte_halfword_word</title>
    <url>/C/C/20_byte_halfword_word/</url>
    <content><![CDATA[

1.1. 概念
字定义：总线是一般设计用来传输固定大小的数据，这块数据被称为字（word）。一个字包含的字节数(即字的大小)是各种计算机系统里面的基本参数，而且这个参数在不同的操作系统里通常是不同的。

CPU按照其处理信息的字长可以分为：8位微处理器、16位微处理器、32位微处理器以及64位微处理器

CPU最大能查找多大范围的地址叫做寻址能力，CPU的寻址能力以字节为单位，如32位寻址的CPU可以寻址2的32次方大小的地址也就是4G，这也是为什么32位的CPU最大能搭配4G内存的原因，再多的话CPU就找不到了。

字长（word size）

字长也叫 字（word），CPU和内存之间的数据传送单位通常是一个字长。
字长 的大小取决于计算的 数据总线 是多少位的，现代计算机的字长通常为16、32、64位（bit）。
数据总线（data bus）：用于传输数据的，是双向三态的总线。可以把CPU的数据传送到存储器或I&#x2F;O接口等其它部件，也可以将其它部件的数据传送到CPU。
地址总线（address bus）：用于传输地址的，是单向三态的总线。地址只能从CPU传向外部存储器或I&#x2F;O端口。地址总线的位数决定了CPU可直接寻址的内存空间大小。
控制总线（control bus）：用来传送控制信号和时序信号。
控制信号中，有的是微处理器送往存储器和I&#x2F;O接口电路的，如读&#x2F;写信号，片选信号、中断响应信号等；也有是其它部件反馈给CPU的，比如：中断申请信号、复位信号、总线请求信号、限备就绪信号等。因此，控制总线的传送方向由具体控制信号而定，一般是双向的，控制总线的位数要根据系统的实际控制需要而定。实际上控制总线的具体情况主要取决于CPU。







1.2.  注意 
字的大小取决去具体系统的总线宽度，如果是32位的系统，则一个字(word)是4个字节(byte)，如果是64位，则是8个字节(byte)。

无论操作系统的 位宽 是多少，1byte=8bite，半字为字的一半，双字(double word)为字(word)的2倍永远不变。

一个ASCII字母占用 1 byte，一个汉字占用 2 byte

Intel公司中用术语 字(word) 表示16位数据类型，双字(double word) 表示32位数据类型，四字(quad word) 表示64位数据类型。Intel公司中无论是32位架构的机器还是64位架构的机器，它们都是从16位架构的基础上扩展的。


1.3. ARM架构
字节(byte)：在ARM体系结构和8位&#x2F;16位处理器体系结构中，字节的长度均为8位
半字(Half-Word) 
在ARM体系结构中，半字的长度为16位，2个字节。与8位&#x2F;16位处理器体系结构中字的长度一致


字(word)
在ARM体系结构中，字的长度为32位(bite)，4个字节(byte)
在8位&#x2F;16位处理器体系结构中，字的长度一般为16位(bite)，2个字节





1.4. References
对字的理解

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>20_byte_halfword_word</tag>
      </tags>
  </entry>
  <entry>
    <title>21_pointer</title>
    <url>/C/C/21_pointer/</url>
    <content><![CDATA[ 

1. 概念
地址：一片内存中，每个字节（Byte）的编号
地址，字节，位他们在内存中的关系：
内存是一栋大楼，字节（Byte）是大楼中的每一层，地址是楼层编号，位（bit）是每一层中的房间，每一层有8个房间。


变量内存：在内存中申请一块空间，该空间由多个字节组成
指针：是一种数据类型，是指它指向的内存空间的数据类型。（程序数据在内存中的地址）。在c语言当中，允许用一个变量来存放指针，这种变量称为指针变量。
不管是什么类型的指针变量，所存的值都是地址（int类型的值）。那么声明不同类型的作用是什么？
答案：通过声明指针类型，告诉指针每次移动多少字节，来获取变量的值。



2. 定义
指针定义：数据类型 *指针变量名;
符号*是定义指针变量的标志， 不是变量名的一部分
表示指针变量指向的数据类型。例如：int *P 表示指针变量指向int的数据类型
指针变量名：表示指向另一个数据地址的变量，本质是一个地址变量。
*指针变量名：表示指向另一个数据地址里面的值，本质是一个数据值变量。
*：取内容运算符；取出指针变量所指向地址的内容
&amp;：取地址运算符；获取变量在计算机内存中的存储地址。取地址运算符的操作对象（变量）一定是定义过的变量或数组元素。



3. 指针关键注意点
定义指针时，编译器并不为指针所指向的对象分配空间，它只是分配指针本身的空间，除非在定义时同时赋值给指针一个字符串常量进行初始化。
定义时不能为常量分配空间。例如：float *p = 3.14; 会导致编译不通过。
保存数据的地址，任何存入指针变量p 的数据都会被当作地址来处理。 p 本身的地址由编译器另外存储，存储在哪里，我们并不知道。
* 放在 = 的左边，给内存赋值，读内存；int *p = 10;
* 放在 = 的右边，取内存的值，往内存写；int q = *p;
指针变量与它指向的内存块是两个不同的概念
不允许向NULL和非法地址拷贝内存。
char *p = NULL; strcpy(p, &quot;abcdef&quot;);  会出错，空指针p不指向任何对象或函数。
char *p = 0x1234; strcpy(p, &quot;abcdef&quot;); 也出错，指针p没有指向一个内存地址。


向内存中写数据时，要保证指针所指向的内存块能修改。
char buf[] = &quot;abcdef&quot;; buf[2] = 2; 可以修改buf[2]的值，数组中的一般变量存放在内存的栈区。
char *buf = &quot;abcdef&quot;; buf[2] = 2; 不可以修改，*buf定义的变量存放在数据区。


空指针：定义一个指针变量后，没有指向一个确定的值。
例如：int* p=NULL; 指针p为一个空指针。
C语言中使用宏NULL表示空指针常量：#define  NULL  ((void *)0)
系统保证空指针不指向任何对象或函数。


初始化：数据类型 *指针变量名=内存地址； 
“内存地址”是地址常量或对变量取地址的运算表达式。



4. 应用
指针为形参，作为函数的参数，给变量间接赋值。（实际中应用很多）
通过形参来改变实参的内容，必须地址传递

5. 野指针
什么是野指针？

野指针不是 NULL指针，它是随机即指向一块内存的指针。


产生的原因？

野指针指向了一块没有访问权限的内存。（即指针没有初始化）
指针p被free或者delete之后，没有置为NULL。
指针操作超越了变量的作用范围。


如何避免野指针？

将指针初始化为NULL。 
用已有合法的可访问的内存地址对指针初始化char num[ 30] = &#123;0&#125;;char *p = num;
使用malloc分配内存。（在堆空间内分配）分配后要进行检查是否分配成功，最后要进行释放内存。malloc函数分配完内存后需注意：
检查是否分配成功（若分配成功，返回内存的首地址；分配不成功，返回NULL。可以通过if语句来判断）
清空内存中的数据（malloc分配的空间里可能存在垃圾值，用memset或bzero 函数清空内存）





6. 零值指针和 NULL 指针的区别
零值指针，是值为 0 的指针，可以是任何一种指针类型，可以是通用变体类型 void* 也可以是 char，int等。
空指针，其实空指针只是一种编程概念，就如一个容器可能有空和非空两种基本状态，而在非空时可能里面存储了一个数值是 0，因此空指针是人为认为的指针不提供任何地址讯息。

7. References
关于指针类型和指针类型转换的理解
C语言再学习 – 再论数组和指针
NULL指针、零指针、野指针

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>21_pointer</tag>
      </tags>
  </entry>
  <entry>
    <title>22_enumerations</title>
    <url>/C/C/22_enumerations/</url>
    <content><![CDATA[

1. Enum Keywords1.1. 定义概念： enum 关键字用于声明枚举，即一种由一组称为枚举数列表的命名常数组成的独特类型。每种枚举类型都有基础类型，该类型可以是除 char 以外的任何整型。枚举元素的默认基础类型为 int。默认情况下，第一个枚举数的值为 0，后面每个枚举数的值依次递增。

定义一： enum 枚举型名 &#123;枚举常量1， 枚举常量2…枚举常量n &#125;；
定义二：typedef enum 枚举型名 &#123;枚举常量1， 枚举常量2…枚举常量n &#125;枚举别名；

1.2. 初始化
定义枚举型的同时定义变量。
  // black和blue的值仍然分别是0和1，但green和其后的各项的值则为10， 11，12和13。enum color &#123; black, blue, green=10, cyan, red ,magenta &#125;;

不给初始值，变量的值从0开始依次增加一。
  // 枚举类型中的每个项都是一个整数值。 其中black的值为0， blue的值为1， green的值为2， cyan为3， 依次类推。enum color &#123; black, blue, green, cyan, red, magenta &#125;; 
先定义枚举型， 再定义枚举型变量，即用一个单独的变量类型说明语句来定义。


1.3. 用途
常用于定义编译器的符号表
作为字符串的索引(下标)、常量等，以加强程序的可读性。

1.4. 与结构体的区别结构体是将有限个不同类型的属性变量组合在一起，而枚举类型内的都是同类型的属性变量。
1.5. 存储空间枚举常量不会占用对象的存储空间，它们在编译时被全部求值。枚举常量的缺点是：它的隐含数据类型是整数，其最大值有限，且不能表示浮点数（如PI&#x3D;3.14159）。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>22_enumerations</tag>
      </tags>
  </entry>
  <entry>
    <title>23_state_machine</title>
    <url>/C/C/23_state_machine/</url>
    <content><![CDATA[

1. 为什么要用状态机？在单片机编程中，如果在不使用操作系统的情况下同时执行多个任务，一个任务的执行时间过长，导致其他任务无法及时执行在一些任务中大量使用 delay() 等函数进行软件延时，这些延时函数占用过多时间，影响其他任务的执行，一些复杂任务的程序逻辑不清晰，不便于以后对程序进行维护，或添加新功能。可以做到将一个耗时较多的复杂任务分解为多个简单任务，同时使代码逻辑更加清晰。
2. 应用
分解耗时过长的任务

单片机执行多任务也是类似的过程，但由于其资源有限，为了节省对 CPU 和存储空间的占用，在很多情况下没有使用操作系统。这时，单片机中运行的各个任务必须在一定时间内主动执行完毕，才能保证下一个任务能够及时执行。


避免软件延时对 CPU 资源造成浪费

对于一些简单的程序，可通过 delay(), delay_ms() 之类的函数进行软件延时。这些延时函数，一般是通过将某个变量循环递加或递加，递加或递减到一定值后跳出循环，从而通过消耗 CPU 时间实现了延时。这种方式虽然简单，但在延时函数执行的过程中，其他程序无法运行，消耗了大量 CPU 资源。而通过状态机，有助于减少软件延时的使用，提高 CPU 利用率。 


使程序逻辑更加清晰


3. References
有限状态机在单片机编程中的应用
Linux C 编程技巧–利用有限状态机模型编程
为Linux应用构造有限状态机

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>23_state_machine</tag>
      </tags>
  </entry>
  <entry>
    <title>25_atoi()</title>
    <url>/C/C/25_atoi()/</url>
    <content><![CDATA[
atoi (表示 ascii to integer)是把字符串转换成整型数的一个函数
函数原型：int atoi(const char *nptr);
函数会扫描参数 nptr字符串，会跳过前面的空白字符（例如空格，tab缩进）等
如果 nptr不能转换成 int 或者 nptr为空字符串，那么将返回 0



]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>25_atoi()</tag>
      </tags>
  </entry>
  <entry>
    <title>26_fprintf</title>
    <url>/C/C/26_fprintf/</url>
    <content><![CDATA[
函数原型：int fprintf (FILE* stream, const char*format, [argument])

stream: 指向FILE对象的指针
format: 这是 C 字符串，包含了要被写入到流 stream 中的文本。format 标签属性是%[flags][width][.precision][length]specifier
argment: 参数列表


函数功能

根据指定的格式，向输出流(stream)写入数据(argment)
fprintf( )会根据参数format 字符串来转换并格式化数据，然后将结果输出到参数stream 指定的文件中，直到出现字符串结束(‘\0’)为止



]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>26_fprintf</tag>
      </tags>
  </entry>
  <entry>
    <title>27_thrread_pool</title>
    <url>/C/C/27_thrread_pool/</url>
    <content><![CDATA[

参考
线程池原理及C语言实现线程池

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>27_thrread_pool</tag>
      </tags>
  </entry>
  <entry>
    <title>28___attribute__((packed))用法</title>
    <url>/C/C/28___attribute__((packed))%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[参考

attribute((packed))详解

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>28___attribute__((packed))用法</tag>
      </tags>
  </entry>
  <entry>
    <title>29-escape_string_ASCII</title>
    <url>/C/C/29-escape_string_ASCII/</url>
    <content><![CDATA[




说明
转义字符
十六进制(hex)
十进制(dec)



空字符(Null)
\0
0x00
0


空格

0x20
32


字符 0
0
0x30
48


回车(CR: carriage return)
\r
0x0D
13


换行(LF: NL line feed, new line)
\n
0x0A
10


退格符(BS)
\b
0x08
8



字符串结尾用空字符表示：\0
并不是所有的控制字符都可用相应的字母或者数字表示，不能表示的要用转义字符。任何一个转义字符都对应一个字符。

参考

百度百科–ASCII
C语言转义字符表和ASCII码表

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>29-escape_string_ASCII</tag>
      </tags>
  </entry>
  <entry>
    <title>2_character_encoding</title>
    <url>/C/C/2_character_encoding/</url>
    <content><![CDATA[ 

1. 基本概念
字符集：二进制编码到字符的映射
ASCII: (American Standard Code for Information Interchange，美国标准信息交换码)
规定了128个字符的编码
只占用了一个字节的后面7位，最前面的一位统一规定为0
在计算机的存储单元中，一个ASCII码值&#x3D;&#x3D;占一个字节&#x3D;&#x3D;(8个二进制位)，其最高位(b7)用作奇偶校验位。


ISO: 国际标准化组织（International Organization for Standardization）
ANSI: 美国国家标准协会(American National Standards Institute)
Unicode
通用多八位编码字符集(Universal Multiple-Octet Coded Character Set) ：简称UCS
Unicode是一个字符集，Unicode是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。
采用&#x3D;&#x3D;两个字节&#x3D;&#x3D;来表示一个字符，是一种16 位编码方式
在表示一个Unicode的字符时，通常会用“U+”然后紧接着一组十六进制的数字来表示这一个字符
在Unicode 3.0里使用“U-”然后紧接着八位数，而“U+”则必须随后紧接着四位数



中文编码: GB2312
采用两个字节表示一个汉字
理论上最多可以表示 256 x 256 &#x3D; 65536 个符号，收录了6763个汉字


UTF-8 (Unicode Transformation Format 8)
以字节为单位对Unicode进行编码
它是一种变长的编码方式,它可以使&#x3D;&#x3D;用1~6个字节&#x3D;&#x3D;表示一个符号，根据不同的符号而变化字节长度
编码规则
如果一个字节的第一位是0，则这个字节单独就是一个字符
如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节




UTF-16：编码以16位无符号整数为单位
对于编号在U+0000到U+FFFF的字符（常用字符集），直接用两个字节表示。 
编号在 U+10000到U+10FFFF之间的字符，需要用四个字节表示。


UFT-32：编码以32位(4字节)无符号整数为单位
每字符直接转化为对应的整数二进制，


BOM(Byte Order Mark: 字节序标记)
BOM是用来判断文本文件是哪一种Unicode编码的标记，其本身是一个Unicode字符（”\uFEFF”），位于文本文件头部。
不同的Unicode中，对应BOM不同的二进制字节
UTF-8编码的文件中，BOM占三个字节(EF BB BF UTF8)。UTF-8不需要BOM来表明字节顺序，用来表明编码方式。
FE FF UTF16BE(大端)
FF FE UTF16LE(小端)





2. 乱码怎样产生的？
编码与解码的方式不一致
在传输过程中，编码不一致，导致字节丢失。

3. 字节序
大头(Big endian)、小头(Little endian)编码方式
Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1
如果一个文本文件的头两个字节是FEFF，就表示该文件采用大头方式；如果头两个字节是FF FE，就表示该文件采用小头方式。
大小端是针对大于一个字节的数的存储问题而言的
大端法：低地址存储高字节
小端法：低地址存储低字节



3.1. References
弄清楚ASCII，Unicode和UTF-8
阮一峰 字符编码笔记：ASCII，Unicode和UTF-8
百度解释Unicode
详细讲解了 Unicode与UTF-8的区别

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>2_character_encoding</tag>
      </tags>
  </entry>
  <entry>
    <title>30_memory</title>
    <url>/C/C/30_memory/</url>
    <content><![CDATA[ 

1. 概念
内存：用于存储指令和数据序列，是一组以二进制存储信息的单元，存储容量取决于底层硬件、体系结构、位长(1、2、4、8、16、32、64、128)
永久存储
临时存储
寄存器：位于处理器连接的芯片上
段寄存器：支持段分区和多线程
系统寄存器：主要对系统的初始化和控制进行处理
CPU 优先读写寄存器，再由寄存器跟内存交换数据
寄存器不依靠地址区分数据，而依靠名称，每一个寄存器都有自己的名称，要哪个数据CPU直接去哪个寄存器取数据
容量：与CPU类型有关
速度：&lt;10ns




cache(缓存)：临时存储数据的高速内存（经常访问的数据）
L1cache：较快，距离CPU较近，容量小
L2cache：较慢，距离CPU较远，容量大
SRAM用作高速cache存储，比DRAM块。
专用指令cache
数据cache
容量：KB
速度：10~50ns


RAM(主存)，也叫物理内存
存储待执行的所有数据和指令 
主存的容量直接关系系统处理软件的能力
容量：MB、GB
速度：50~100ns





内存层次排列

  


  


  


  


  




内存：存储进程的相关数据；进程不能直接访问内存。

2. 分页，分段，逻辑地址，物理地址
内存模型分类
内存模型为进程建立物理内存映射，便于CPU访问内


实地址内存模型
分段：在实模式下通过偏移一个段寄存器的4位再加上16位偏移量，形成一个20位的物理地址


扁平内存模型
内存空间是连续的


分段内存模型
将线性地址空间分割为段的小部分，代码、数据、栈被放置在不同的段中
进程团通过逻辑地址从任意段访问数据
处理器将逻辑地址转换成线性地址，并使用线性地址访问内存







2.1. 物理地址(physical address)
定义：在存储器里以 byte 为单位存储信息，为正确地存放或取得信息，每一个 byte 单元给以一个唯一的存储器地址；也叫绝对地址（absolute address），是数据在内存中的实际位置。
用于内存芯片级的单元寻址，与处理器和CPU连接的地址总线相对应。
在地址总线上，以电子形式存在的，使得数据总线可以访问主存的某个特定存储单元的内存地址。
物理地址也叫实地址、二进制地址。

2.2. 逻辑地址(logical address)
定义：与当前数据在内存中的物理分配地址无关的一个地址，由CPU产生的地址，在执行对内存的访问之前，需要把它转换为物理地址。
另一种解释：从应用程序角度看到的内存单元（memory cell）、存储单元（storage element）、网络主机（network host）的地址。即由程序产生的与段相关的偏移地址部分。
逻辑区块地址(Logical Block Address, LBA)：指某个数据区块的地址或是某个地址所指向的数据区块
通过地址翻译器（address translator）或映射函数可以把逻辑地址转化为物理地址。
逻辑地址包括：页号、在该页中的偏移量

2.3. 相对地址相对地址是逻辑地址的一个特例，它是相对于某些已知点的存储单元。（系统采用运行时动态加载的方法把使用相对地址的程序加载到内存中）
2.4. Address(地址)
虚拟地址(Virtual address space)：标识一个虚拟（非物理地址）的实体地址

线性地址（Linear Address）：是逻辑地址到物理地址变换之间的中间层。

IP(Internet protocol：互联网协议)

由数据体头部和数据体数据区两部分组成。
数据体头部包括IP源地址和IP目标地址，以及其它信息
数据体的数据区包括用户数据协议（UDP），传输控制协议（TCP），还有数据包的其他信息。


随机存储：存储器的读取时间和数据所在位置无关

虚拟内存：进程能访问的地址，操作系统会把虚拟内存地址翻译成真实的内存地址

两个进程空间可以有相同的虚拟内存地址
虚拟内存地址与物理内存地址一一对应
应用程序只能通过虚拟内存地址进行数据的读写
C语言中表达式的地址，都是虚拟地址
进程对物理内存的访问，必须经过操作系统的审查。
借助虚拟内存地址，操作系统可以保障进程空间的独立性。
操作系统可以把同一物理内存区域对应到多个进程空间。这样，不需要任何的数据复制，多个进程就可以看到相同的数据。
所有进程共享一套内核数据：每个进程空间中，最初一部分的虚拟内存地址，都对应到物理内存中预留给内核的空间




  


从内核中查看虚拟内存：

  


虚拟地址组成：虚拟页号和页偏移字段 

  


虚拟地址转换成物理地址 

  


2.5. 帧(frame)
帧：将物理内存分为固定大小的块，物理内存使用的单元。(在计算机网络中的定义)
由帧头和帧数据两部分组成。
帧头包括接收方主机物理地址的定位以及其它网络信息。
帧数据区含有一个数据体


页：将逻辑内存分为同样大小的块，虚拟内存使用的单元。
页框：把可用的物理内存也划分为同样大小的连续的部分，称为块或页框。内核以页框为基本单位管理物理内存
内存分页：以更大尺寸的单位页（page）来管理内存。便于管理进程空间和物理页的对应关系
地址空间管理：负责分配和管理进程的地址空间
地址转换：在专用硬件的MMU(memory management unit)上完成。
MMU功能
设置CPU的访问级别
处理物理内存与虚拟内存之间的映射。



2.6. 分页(paging)
解决分区技术存在的缺陷；将内存分成许多大小相等且很小的页框，每个进程分成许多同样大小固定的页。

2.7. 分段(segmentation)
进程可以划分为许多的段，段的大小无须相等；调入另一个进程时，所有段都装入内存的可用区，并建立一个段表。

2.8. 内存共享
  


2.9. 页表(page table)页表是一种特殊的数据结构，放在系统空间的页表区，存放逻辑页与物理页帧的对应关系。每一个进程都拥有一个自己的页表
地址转换到内存物理地址时引用的一个页表

  



操作系统管理内存时，最小单元为内存页（page）而不是 byte。

32位操作系统的内存页一般是 4K
比如，初次申请1K内存，操作系统会分配1个内存页，也就是4K内存。
4K是一个折中的选择，因为：内存页越大，内存浪费越多，但操作系统内存调度效率高，不用频繁分配和释放内存；内存页越小，内存浪费越少，但操作系统内存调度效率低，需要频繁分配和释放内存。
嵌入式系统的内存内存资源很稀缺，其内存页会更小，因此在嵌入式开发当中需要特别注意。

动态分区采用的三种放置算法

最佳适配(Best fit): 选择与要求大小最接近的块
首次适配(First fit): 从头扫描内存，选择大小足够的第一个可用块
下次适配(Next fit): 从上一次放置的位置开始扫描内存，选择下一个大小足够的可用块

伙伴系统：在并行系统有很多的应用，为并行程序分配和释放内存。
2.10. References
内存管理笔记
Linux的内存分页管理
汇编语言入门教程

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>30_memory</tag>
      </tags>
  </entry>
  <entry>
    <title>31_sizeof_strlen</title>
    <url>/C/C/31_sizeof_strlen/</url>
    <content><![CDATA[

sizeof 是求数据类型所占的空间大小，而 strlen 是求字符串的长度，字符串以 \0 结尾。
sizeof()
sizeof() 是运算符，其值在编译时就计算好了，参数可以是数组、指针、类型、对象、函数等。因此 sizeof 不能用来返回使用动态内存分配空间的大小。

strlen()
strlen() 是一个函数，要在运行时才能计算，参数必须是字符型指针 char*。当数组名作为参数传入时，实际上数组就退化成指针了。
它的功能是：返回字符串的长度。该字符串可能是自己定义的，也可能是内存中随机的，该函数实际完成的功能是从代表该字符串的第一个地址开始遍历，直到遇到结束符 \0，返回的长度大小不包括 \0。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>31_sizeof_strlen</tag>
      </tags>
  </entry>
  <entry>
    <title>32_main</title>
    <url>/C/C/32_main/</url>
    <content><![CDATA[

main() 中参数传递一般编写的程序在 Linux 环境下运行时，主函数一般写成这种形式： int main(int argc, char* argv[])，为何 main() 函数中传递的参数值要写成 int argc, char* argv[] 下面我们来仔细的分析。

argc 表示数组中字符串的的数量
*argv[] 表示一个指针数组，也等价于 **argv
当使用argv中的形参时，需要从 argv[1] 开始，argv[0] 是保存程序的名字，而非用户的输入。

main()返回值
在 C&#x2F;C++ 中，将 main 函数写成 int main() &#123; return 0;&#125; 时，返回值是 int类型；若写成 void main()&#123;&#125; 时; 函数没有返回值，有些编译器器可能会报错。
函数的返回值如果等于 0，则代表程序正常退出，返回其它数字的含义则由系统决定，通常，返回非零代表程序异常退出。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>32_main</tag>
      </tags>
  </entry>
  <entry>
    <title>33_register_auto</title>
    <url>/C/C/33_register_auto/</url>
    <content><![CDATA[
register、auto关键字]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>33_register_auto</tag>
      </tags>
  </entry>
  <entry>
    <title>34_do_while(false)</title>
    <url>/C/C/34_do_while(false)/</url>
    <content><![CDATA[

为什么要使用 do {.. } while (false)?简化某些场景下 if else 的多级嵌套。 使用 do... while (false) 的用意就在于在 do &#123;&#125; 的过程中可以 break，使得函数唯一的出口就是最后一行的return，可以避免过多的嵌套括号，使结果更清晰，更容易理解。
没有使用  do... while (false)，if 语句之间多级嵌套。
if (condition1) &#123;    // some code that should execute if condition is not true        if (condition2) &#123;        //further code that should not execute if condition or condition2 are true        if (condition3) &#123;            //do some more stuff            break;        &#125;    &#125;&#125;

采用  do... while (false) 后，代码逻辑结构更简洁、清晰。
do &#123;    // some code that should always execute...    if (condition1)    &#123;        //do some stuff        break;    &#125;    // some code that should execute if condition is not true    if (condition2)    &#123;        //do some more stuff        break;    &#125;    //further code that should not execute if condition or condition2 are true    if (condition3)    &#123;        //do some more stuff        break;    &#125;&#125;while(false);

应用场景
在C&#x2F;C++ 的 library 中有很多的宏都使用了这种操作。

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>34_do_while(false)</tag>
      </tags>
  </entry>
  <entry>
    <title>35_snprintf</title>
    <url>/C/C/35_snprintf/</url>
    <content><![CDATA[

函数原型
  int snprintf(char *str, size_t size, const char *format, ...)
功能：将可变参数 … 按照 format 的格式格式化为字符串，然后再将其拷贝至 str中。

(1) 如果格式化后的 字符串长度 &lt; size，则将此字符串全部复制到 str 中，并给其后添加一个字符串结束符(&#39;\0&#39;)；
(2) 如果格式化后的 字符串长度 &gt;= size，则只将其中的 (size-1) 个字符复制到 str 中，并给其后添加一个字符串结束符(&#39;\0&#39;)，返回值为将要写入的字符串长度。


返回值：

若成功则返回 预写入的字符串长度。
若出错则返回 负值。



#include &lt;stdio.h&gt;   int main() &#123;     char buffer[50];     char* s = &quot;geeksforgeeks&quot;;       // Counting the character and storing      // in buffer using snprintf     int j = snprintf(buffer, 6, &quot;%s\n&quot;, s);       // Print the string stored in buffer and     // character count     printf(&quot;string:\n%s\ncharacter count = %d\n&quot;, buffer, j);       return 0; &#125; 

#include &lt;cstdio&gt;#include &lt;iostream&gt;using namespace std;int main()&#123;    char buffer[100];    int retVal, buf_size = 100;    char name[] = &quot;Max&quot;;    int age = 23;    retVal = snprintf(buffer, buf_size, &quot;Hi, I am %s and I am %d years old&quot;, name, age);    if (retVal &gt; 0 &amp;&amp; retVal &lt; buf_size) &#123;        cout &lt;&lt; buffer &lt;&lt; endl;        cout &lt;&lt; &quot;Number of characters written = &quot; &lt;&lt; retVal &lt;&lt; endl;    &#125;    else &#123;        cout &lt;&lt; &quot;Error writing to buffer&quot; &lt;&lt; endl;    &#125;        return 0;&#125;]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>35_snprintf</tag>
      </tags>
  </entry>
  <entry>
    <title>36_*_++_operate</title>
    <url>/C/C/36_*_++_operate/</url>
    <content><![CDATA[

在项目中遇见了 *p++ 这种操作，但不明白在 *p++中 ++ 和 * 是怎样执行的？现在我们来一一剖析它的运算过程。
C语言中取值运算符 * 与前置自增运算符++、后置自增运算符++都属于单目运算符，运算符的优先级顺序同为第2级，结合方向为 右到左。其中，* 使用形式为：*p，用于指针变量，前置自增使用形式为 ++i，后置自增使用形式为 ++i。

注意

同一优先级的运算符，运算次序由结合方向所决定。
简单记就是：！ &gt; 算术运算符 &gt; 关系运算符 &gt; &amp;&amp; &gt; || &gt; 赋值运算符



用一段代码来说明
#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;int main(int argc, char *argv[])&#123;    char ch[] = &quot;hello&quot;;    char* p = ch;    cout &lt;&lt; *p++ &lt;&lt; &quot; &quot;;        return 0;&#125;
运行调试过程：执行 cout &lt;&lt; *p++ &lt;&lt; &quot; &quot;; 这条语句时（不考虑标准库中cout的调用过程），开始时指针p指向字符串 hello 的首地址，即图中的 ch[0]:104 &#39;h&#39;。执行 *p++时，根据两者的优先级顺序在同一级，从右向左的结合性原则，先执行 ++，后执行 * 操作。p++ 是先执行当前的操作，然后再执行 ++ 操作。 这条语句执行完成后，指针p指向字符串的下一个位置 ch[1] 101 &#39;e&#39;。因此我们在终端看到的输出结果为字符 h，而程序中 *p 的值为 e。
运行结果：

References
百度百科解释运算符优先级

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>36_*_++_operate</tag>
      </tags>
  </entry>
  <entry>
    <title>37_callback_function</title>
    <url>/C/C/37_callback_function/</url>
    <content><![CDATA[

1. 什么是回调函数？
将函数指针作为一个参数传递给另一个函数。
把函数的指针（地址）作为另一个函数参数的入口地址传递，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。

2. 分类根据回调函数在运行时控制数据流的方式不同，可以为两种类型的回调函数。

阻塞回调(Blocking callbacks)，也叫同步回调(synchronous callbacks)或者直接叫回调函数(callbacks)。阻塞回调函数调用是发生在函数返回之前。阻塞回调通常不用于异步或将当前的工作委托给另外一个线程的情况。

延迟回调(Deferred callbacks)，也叫异步回调(asynchronous callbacks)。延时回调函数调用是发生在函数返回之后。延时回调函数常常使用在I&#x2F;O操作或事件处理(event handing)中,，通过中断或多线程来调用。


Windows系统中使用回调函数，应用程序提供一个特定的自定义回调函数给操作系统调用，然后这个应用程序需要实现特定的函数功能，像鼠标点击或键盘按下。
windows系统中外部应用程序与系统库函数之间通过 callback 函数实现的流程。
在这个调用的过程中最关心的是如何进行权限(privilege)与安全(security)管理，当这个函数被操作系统调用时，它不应该带有同操作系统一样的权限。解决的方案是使用 rings 保护。

rings: 操作系统如何实现特权管理的一种手段。

3. 用途
错误信号处理。当Unix系统收到 SIGTERM 信号时，不想让Terminal立刻收到它，为了确保terminal处理的是正确的，它会注册一个 cleanup 函数作为回调函数。回调函数也许被使用来控制 cleanup 函数是否被执行。
C++中 functor 普遍的使用就是 function pointer。
进程与线程之间进行通信。

4. 为什么要使用回调函数？
把调用者与被调用者分开进行实现。
开发者在库中封装了一套采用函数指针实现的接口，接口函数的参数就是用户实现函数的地址。
将回调函数（callback）传递给调用函数（calling function）的代码不需要知道将传递给调用函数的参数值有哪些。如果传递的是返回值，则需要公开暴露这些参数。

5. 代码实现实例一：
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;time.h&gt;/* The calling function takes a single callback as a parameter. */void PrintTwoNumbers(int (*numberSource)(void)) &#123;    int val1 = numberSource();    int val2 = numberSource();    printf(&quot;%d and %d\n&quot;, val1, val2);&#125;/* A possible callback */int overNineThousand(void) &#123;    return (rand()%1000) + 9001;&#125;/* Another possible callback. */int meaningOfLife(void) &#123;    return 42;&#125;/* Here we call PrintTwoNumbers() with three different callbacks. */int main(void) &#123;    time_t t;    srand((unsigned)time(&amp;t)); // Init seed for random function    PrintTwoNumbers(&amp;rand);    PrintTwoNumbers(&amp;overNineThousand);    PrintTwoNumbers(&amp;meaningOfLife);    return 0;&#125;

实例二：
#include &lt;stdio.h&gt;#include &lt;string.h&gt;typedef struct _MyMsg &#123;    int id;    char name[32];&#125; MyMsg;void myfunc(MyMsg *msg)&#123;    if (strlen(msg-&gt;name) &gt; 0 ) &#123;        printf(&quot;id = %d \name = %s \n&quot;,msg-&gt;id, msg-&gt;name);    &#125;    else &#123;        printf(&quot;id = %d \name = No name\n&quot;,msg-&gt;id);    &#125;&#125;/* * Prototype declaration */void (*callback)(MyMsg*);int main(void)&#123;    MyMsg msg1;    msg1.id = 100;    strcpy(msg1.name, &quot;This is a test\n&quot;);    /*     * Assign the address of the function &quot;myfunc&quot; to the function     * pointer &quot;callback&quot; (may be also written as &quot;callback = &amp;myfunc;&quot;)     */    callback = myfunc;    /*     * Call the function (may be also written as &quot;(*callback)(&amp;msg1);&quot;)     */    callback(&amp;msg1);    return 0;&#125;



6. references
英文Wikipedia解释什么是Callback
What is a callback function?
函数指针和指针函数用法和区别
C语言中函数指针和回调函数的详解
深入浅出剖析C语言函数指针与回调函数(一)

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>37_callback_function</tag>
      </tags>
  </entry>
  <entry>
    <title>38_static</title>
    <url>/C/C/38_static/</url>
    <content><![CDATA[

static 关键字static 修饰的全局变量和函数只能在本模块中使用，不能在其它的模块中使用。因此，当一个函数或变量只能在本模块中使用时，不能用 extern “C” 关键字修饰，用在其它的文件中调用。
当同时编译多个文件时，所有未加static前缀的全局变量和函数都具有全局可见性。其它的文件中可以调用该函数和变量。加了static关键字后，相当于做一个隐藏的作用，只对当前调用的文件有效。利用这一特性可以在不同的文件中定义同名函数和同名变量，而不必担心命名冲突。

比如 a.c 文件中定义了一个全局的 static int num = 100; 变量 和 static int add() 函数，此时变量和函数只能在 a.c 文件中调用，你要想在 b.c中调用变量和函数，你是行不通的，编译会出错。

那么你想在 b.c、d.c、m.c 等多个文件中调用全局变量和函数，要怎么办了？

办法就是：你需要将变量或函数用 extern 关键字进行声明，并且不用 static 关键字修饰。注意是声明，而不是定义。extern int num;和 extern int add()，这样操作过后，在b.c、d.c、m.c等多个文件中，你就能使用这个变量和函数了。



Tpis:看声明与定义的区别可以看我之前写的一篇文章。extern的用法

static修饰的变量在函数体内定义时，表明它的申请的内存是驻留在全局区，直到程序运行结束。但是它作用域仍为局部作用域，只能在函数体内使用定义的该变量，不能在函数体外使用。因此可以得出一个结论：把局部变量改变为static变量后改变了它的生存期。把全局变量改变为static变量后是改变了它的作用域， 限制了它的使用范围，仅仅只在拥有该变量的文件中使用，不能在其它的文件中调用。
static变量在函数体内使用情况
#include &lt;stdio.h&gt;#include &lt;string.h&gt;int sub()&#123;    static int count = 10;   // count变量在内存中位于全局区域，直到程序结束时，该变量才会被释放    // int count = 10;       // count变量申请的内存空间位于栈区，当前函数体执行完成后，变量就被释放了    return count--;&#125;int main(int argc, char *argv[])&#123;    for (int i = 0; i &lt; 10; i++) &#123;        printf(&quot;%d\n&quot;,sub());     &#125;    return 0;]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>38_static</tag>
      </tags>
  </entry>
  <entry>
    <title>39_static</title>
    <url>/C/C/39_static/</url>
    <content><![CDATA[
1. 字符串
字符串是一种特殊的 char 类型的数组，指向 char 类型数组的指针。

字符串与 char 数组的区别在于长度，字符会自动在尾部加上一个长度 \0，而 char 型数组的长度就是其字符的个数。

sizeof() 

遍历字符串，遇到 \0 就终止，返回的结果是第一个\0前字符元素的个数。指针声明 的字符串不能使用 sizeof() 方式求字符串的长度。


strlen() 

求字符串变量占用内存空间的大小，可以用来求字符串的长度；返回的是存储字符串的变量所占用的内存空间大小。



]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>39_static</tag>
      </tags>
  </entry>
  <entry>
    <title>3_big_endian_little_endian</title>
    <url>/C/C/3_big_endian_little_endian/</url>
    <content><![CDATA[ 
内存存放顺序原则
整数类型内部
低地址存储低位，高地址存储高位


栈
存放局部变量
先定义高地址，后定义低地址


类、结构体或数组的元素
先定义低地址，后定义高地址
数组内存地址分配的公式：base_address + index * data_size






参考
大端小端（Big- Endian和Little-Endian）
详解大端模式和小端模式

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>3_big_endian_little_endian</tag>
      </tags>
  </entry>
  <entry>
    <title>4-debug</title>
    <url>/C/C/4-debug/</url>
    <content><![CDATA[F8：step over 单步 遇到断点后，程序停止运行，按F8单步运行。
F7：step into 进入 配合F8使用。单步调试F8时，如果某行调用其他模块的函数，在此行F7，可以进入函数内部，如果是F8则不会进入函数内容，直接单步到下一行。
Alt+shift+F7：step into mycode, 个人理解F8和F7的综合。1、没遇到函数，和F8一样；2、遇到函数会自动进入函数内部，和F8时按F7类似的
shift+F8：跳出 调试过程中，F7进入函数内后，shift+F8跳出函数，会回到进入前调用函数的代码。不是函数地方shift+F8跳出
F9：resume program 按翻译是重启程序 ，实际是 下个断点，当打多个断点是，F9会到下一个断点

（1）Step into：遇见函数调用语句，进入函数内部
（2）Step over：遇见函数调用语句，但不进入函数内部，跳过该函数。调试时，如果不能确定这个函数是否有错，一般先跳过函数而不进入。
（3）Step out：从当前的函数中跳出，程序流程执行函数调用语句的下一步。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>4-debug</tag>
      </tags>
  </entry>
  <entry>
    <title>40_dynamic_library</title>
    <url>/C/C/40_dynamic_library/</url>
    <content><![CDATA[

动态库WindowsGetProcAddress()函数原型
FARPROC GetProcAddress(    HMODULE hModule, // DLL模块句柄    LPCSTR lpProcName // 函数名);



FreeLibrary()Linuxdlopen()dlopen 是一个Linux下的动态链接库操作函数，用于在运行时加载共享对象（动态链接库）并返回一个句柄（handle），以便在程序中使用。这个句柄可以用于后续的符号查找和符号解析，以及动态链接库的卸载。 dlopen 可以将一个共享对象加载到进程的地址空间中，从而允许程序在运行时动态地加载库。
dlopen 的函数原型如下：
cCopy codevoid *dlopen(const char *filename, int flag);

其中，filename 参数是一个字符串，表示要加载的共享对象的文件名。flag 参数用于指定加载库的行为，可以是以下值之一：

RTLD_LAZY：在程序首次访问动态链接库的符号时进行符号解析；
RTLD_NOW：在 dlopen 调用时立即解析动态链接库中的所有符号；
RTLD_GLOBAL：使动态链接库中定义的符号对其他动态链接库和程序的符号表可见；
RTLD_LOCAL：使动态链接库中定义的符号仅对该动态链接库的符号表可见。

dlopen 函数将返回一个指向句柄的指针。该句柄可用于调用 dlsym 函数来查找动态链接库中的符号，并且在程序结束时可以使用 dlclose 函数卸载动态链接库。
使用 dlopen 可以实现一些有趣的应用，如插件机制、动态库加载和更新、代码加密和混淆等。
dlclose()在 Linux 系统中，dlclose 是一个函数，它用于关闭动态链接库（也称为共享对象），释放该库在进程中占用的资源。
当程序使用 dlopen 函数打开一个动态链接库时，系统会将该库加载到进程的虚拟地址空间中，并在进程中创建一个动态链接库句柄（handle）。这个句柄可以被用于在程序中访问该库中定义的函数和变量。
当程序使用完这个动态链接库后，可以使用 dlclose 函数来释放该库占用的资源，并关闭该库。这可以释放进程中已分配的虚拟地址空间，同时释放库中定义的全局变量等资源。
dlclose 的语法如下：
int dlclose(void *handle);

其中，handle 是一个指向动态链接库句柄的指针。函数返回值为0表示成功，否则表示失败。注意，如果在使用该库的过程中，还存在指向该库中某个函数或变量的指针，那么在关闭该库之前，必须将这些指针置为NULL，否则可能导致程序崩溃。
总之，dlclose 是一个用于关闭动态链接库并释放占用资源的函数，它可以帮助程序更好地管理系统资源，从而提高程序的效率和稳定性。
dlsym()dlsym() 是 Linux 操作系统中的一个动态链接库函数，用于在运行时动态加载和使用共享库中定义的符号。它的作用是在共享库中查找一个符号，并返回该符号的地址。
dlsym() 函数的原型如下：
#include &lt;dlfcn.h&gt;void* dlsym(void*handle, const char*symbol);

其中，handle 参数是一个指向已打开共享库的句柄的指针，symbol 参数是要查找的符号的名称。
通过调用 dlsym() 函数，我们可以在程序运行时动态地加载共享库，并使用其中定义的符号。这使得我们可以编写模块化的程序，将不同的功能模块放在不同的共享库中，并在运行时根据需要加载这些库。
另外，dlsym() 还常用于编写插件系统。插件系统允许在程序运行时动态地加载和卸载插件，从而扩展程序的功能。在插件系统中，dlsym() 可以用来查找插件中定义的符号，并将其与主程序进行连接，从而实现插件的功能扩展。
总之，dlsym() 是 Linux 系统中一种非常有用的动态链接库函数，它允许程序在运行时动态地加载和使用共享库中定义的符号，从而使程序更加灵活和可扩展。
dlerror()在Linux操作系统中，dlerror 是一个用于动态链接库错误处理的函数。它被定义在 &#96;&#96; 头文件中。
dlerror 函数可以返回最近的动态链接库错误信息。在程序中使用动态链接库时，如果出现错误，可以使用 dlerror 函数获取错误信息并进行处理。
通常，当使用 dlopen 函数打开一个动态链接库时，如果出现错误，该函数会返回一个空指针，并且可以使用 dlerror 函数来获取错误信息。同样，当使用 dlsym 函数获取一个动态链接库中的符号时，如果出现错误，该函数也会返回一个空指针，并且可以使用 dlerror 函数获取错误信息。
dlerror 函数返回的错误信息是一个字符串，表示最近的错误信息。如果该函数返回空指针，则表示没有错误信息。
示例程序：
#include &lt;stdio.h&gt;#include &lt;dlfcn.h&gt;int main() &#123;    void* handle = dlopen(&quot;libtest.so&quot;, RTLD_NOW);    if (!handle) &#123;        printf(&quot;dlopen error: %s\n&quot;, dlerror());        return -1;    &#125;        void (*test_func)() = (void (*)())dlsym(handle, &quot;test&quot;);    if (!test_func) &#123;        printf(&quot;dlsym error: %s\n&quot;, dlerror());        return -1;    &#125;        test_func();        dlclose(handle);    return 0;&#125;

在上面的代码中，如果 dlopen 函数或者 dlsym 函数出现错误，就可以使用 dlerror 函数获取错误信息并输出。这样可以方便地调试程序，并解决动态链接库相关的问题。
References
百度百科 dlsym
百度百科 GetProcAddress

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>40_dynamic_library</tag>
      </tags>
  </entry>
  <entry>
    <title>41_fopen_open_</title>
    <url>/C/C/41_fopen_open_/</url>
    <content><![CDATA[

open() 函数open()是一个系统调用函数,用来打开或创建一个文件，通过不同的 flags 选项实现不同功能。
// 头文件#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;// 函数原型int open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);

fopen() 函数fopen() 是 C 语言中的库函数，在不同的操作系统中调用不同的内核 API， 返回的是一个指向 FILE 结构体的指针。
Linux 中实底层源码中的 FILE 结构体是 _IO_FILE 结构体的别名，其源码为：typedef struct _IO_FILE FILE;，最终调用的是 Linux 操作系统的 API 函数 open。其 _IO_FILE 结构体源码
struct _IO_FILE &#123;  int _flags;   /* High-order word is _IO_MAGIC; rest is flags. */#define _IO_file_flags _flags  /* The following pointers correspond to the C++ streambuf protocol. */  /* Note:  Tk uses the _IO_read_ptr and _IO_read_end fields directly. */  char* _IO_read_ptr; /* Current read pointer */  char* _IO_read_end; /* End of get area. */  char* _IO_read_base;  /* Start of putback+get area. */  char* _IO_write_base; /* Start of put area. */  char* _IO_write_ptr;  /* Current put pointer. */  char* _IO_write_end;  /* End of put area. */  char* _IO_buf_base; /* Start of reserve area. */  char* _IO_buf_end;  /* End of reserve area. */  /* The following fields are used to support backing up and undo. */  char *_IO_save_base; /* Pointer to start of non-current get area. */  char *_IO_backup_base;  /* Pointer to first valid character of backup area */  char *_IO_save_end; /* Pointer to end of non-current get area. */  struct _IO_marker *_markers;  struct _IO_FILE *_chain;  int _fileno;#if 0  int _blksize;#else  int _flags2;#endif  _IO_off_t _old_offset; /* This used to be _offset but it&#x27;s too small.  */#define __HAVE_COLUMN /* temporary */  /* 1+column number of pbase(); 0 is unknown. */  unsigned short _cur_column;  signed char _vtable_offset;  char _shortbuf[1];  /*  char* _save_gptr;  char* _save_egptr; */  _IO_lock_t *_lock;#ifdef _IO_USE_OLD_IO_FILE&#125;;

而 windows 中实底层源码中的 FILE 结构体是 _iobuf，最终调用的是 Windows 操作系统的 API 函数 CreateFile。其 _iobuf 源码为
typedef struct _iobuf&#123;    void* _Placeholder;&#125; FILE;

fopen 函数 API 接口使用说明
// 头文件#include &lt;stdio.h&gt;// 函数原型FILE *fopen(const char *path, const char *mode);// 返回值成功：获取文件信息，包括文件名、文件状态、当前读写位置等，并将这些信息保存到一个 FILE 类型的结构体变量中，然后将该变量的地址返回。错误：返回 NULL 或 errno

调用 fopen() 函数时必须指明读写权限，但是可以不指明读写方式（此时默认为&quot;t&quot;）。
文件打开方式由 r、w、a、t、b、+ 六个字符拼成，各字符的含义是：

r(read)：读
w(write)：写
a(append)：追加
t(text)：文本文件
b(binary)：二进制文件
+：读和写

示例
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(void)&#123;    FILE* fp = fopen(&quot;test.txt&quot;, &quot;r&quot;);    if(!fp) &#123;        perror(&quot;File opening failed&quot;);        return EXIT_FAILURE;    &#125;    int c; // 注意：int，非char，要求处理EOF    while ((c = fgetc(fp)) != EOF) &#123; // 标准C I/O读取文件循环       putchar(c);    &#125;    if (ferror(fp)) &#123;        puts(&quot;I/O error when reading&quot;);    &#125;    else if (feof(fp)) &#123;        puts(&quot;End of file reached successfully&quot;);    &#125;    fclose(fp);&#125;

fopen() 与 open() 区别
Windows 下 CreateFile 可以通过参数来制定，保证读写是否线程安全，而 fopen 则不可以。
fopen 工作在用户空间，open 是 Linux 的系统调用，所以工作在内核空间。

不同的进程同时访问一个文件，给文件加锁是有效的；而一个进程中的多个线程或协程同时对同一个文件进行加锁会互相覆盖掉，是无效的。
Reference
Windows API
关于C++：为什么std::fstreams这么慢？ | 码农家园
C&#x2F;C++读写文件的几种方法fstream fopen、fwrite()、fread()操作

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>41_fopen_open_</tag>
      </tags>
  </entry>
  <entry>
    <title>42_declaration_defination</title>
    <url>/C/C/42_declaration_defination/</url>
    <content><![CDATA[


术语（Terminology）
何为声明（declaration）？
告诉编译器某个东西的类型和名称，即不提供存储的位置和具体实现的细节。 
extern itn x;                   // 变量声明std::size_t func(int num);      // 函数声明class Widget;                   // 类声明template&lt;typename T&gt;            // 模板声明class Student;


何为定义（definition）？
编译器给变量分配内存空间，即提供存储的位置和具体实现的细节。
int x;          // 对象定义，编译器为对象分配内存；此处对象非面向对象中的对象// 对function 或function template而言，定义提供了代码的本体std::size_t func(int num)&#123;  std::size_t a;  return (a + 10);&#125;	// class 定义class Widget&#123;public:  Widget();  ~Widget();......&#125;;// 模板定义template&lt;typename T&gt;            class Student&#123;public:  Student();      ~Student();    &#125;;

注意：在程序中变量可以有多次声明，但只能 定义一次。

签名（signature）
C++ 官方定义中，签名就是函数的参数部分，不包括函数的返回类型。但习惯上一般把函数返回类型和参数都作为签名的部分。
例如函数声明中 std::size_t func(int num);，func 函数签名为 std::size_t 和 int


]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>42_declaration_defination</tag>
      </tags>
  </entry>
  <entry>
    <title>43_statistic_memory_usage</title>
    <url>/C/C/43_statistic_memory_usage/</url>
    <content><![CDATA[背景在程序中插入自定义的统计代码，来记录内存的使用情况。通过在关键位置调用操作系统提供的内存使用统计函数，如getrusage()或mallinfo()等，可以获取程序的内存使用情况，并将其记录下来。这样你就可以在程序运行过程中实时监测内存的使用情况。
getrusage()和mallinfo()是两个不同的函数，用于获取不同层面的内存使用情况。
getrusage()getrusage()函数用于获取系统级别的资源使用情况，包括进程的总体内存使用情况以及其他资源的统计信息。它返回的结构体struct rusage包含了多个字段，可以获取最大常驻内存集、页面错误次数等信息。这些信息是从操作系统的角度统计的，适用于整个进程的内存使用情况。
// 头文件#include &lt;sys/time.h&gt;#include &lt;sys/resource.h&gt;int getrusage(int who, struct rusage *usage);// 结构体struct rusage &#123;  struct timeval ru_utime; /* user CPU time used */  struct timeval ru_stime; /* system CPU time used */  long   ru_maxrss;        /* maximum resident set size */  long   ru_ixrss;         /* integral shared memory size */  long   ru_idrss;         /* integral unshared data size */  long   ru_isrss;         /* integral unshared stack size */  long   ru_minflt;        /* page reclaims (soft page faults) */  long   ru_majflt;        /* page faults (hard page faults) */  long   ru_nswap;         /* swaps */  long   ru_inblock;       /* block input operations */  long   ru_oublock;       /* block output operations */  long   ru_msgsnd;        /* IPC messages sent */  long   ru_msgrcv;        /* IPC messages received */  long   ru_nsignals;      /* signals received */  long   ru_nvcsw;         /* voluntary context switches */  long   ru_nivcsw;        /* involuntary context switches */&#125;;

示例
#include &lt;iostream&gt;#include &lt;sys/resource.h&gt;// 获取当前进程的内存使用情况，并打印相关信息void PrintMemoryUsage()&#123;    struct rusage usage;    if (getrusage(RUSAGE_SELF, &amp;usage) == 0)    &#123;        std::cout &lt;&lt; &quot;内存使用情况：&quot; &lt;&lt; std::endl;        std::cout &lt;&lt; &quot;最大常驻内存集：&quot; &lt;&lt; usage.ru_maxrss &lt;&lt; &quot; KB&quot; &lt;&lt; std::endl;        std::cout &lt;&lt; &quot;页面错误次数：&quot; &lt;&lt; usage.ru_majflt &lt;&lt; std::endl;        std::cout &lt;&lt; &quot;不可恢复的页面错误次数：&quot; &lt;&lt; usage.ru_minflt &lt;&lt; std::endl;    &#125;    else    &#123;        std::cerr &lt;&lt; &quot;无法获取内存使用情况&quot; &lt;&lt; std::endl;    &#125;&#125;int main()&#123;    // 在合适的位置调用 PrintMemoryUsage() 来记录内存使用情况    // 示例：打印程序开始时的内存使用情况    PrintMemoryUsage();    // 在这里添加你的代码    // 示例：打印程序结束时的内存使用情况    PrintMemoryUsage();    return 0;&#125;

mallinfo()mallinfo()函数是GNU C库提供的一个函数，用于获取堆内存的使用情况。它返回的结构体struct mallinfo包含了堆内存的统计信息，如总分配空间、空闲空间、空闲块数量等。这些信息是从堆内存管理器的角度统计的，适用于特定的堆内存使用情况。
// 头文件#include &lt;malloc.h&gt;struct mallinfo mallinfo(void);// 结构体struct mallinfo &#123;  int arena;     /* Non-mmapped space allocated (bytes) */  int ordblks;   /* Number of free chunks */  int smblks;    /* Number of free fastbin blocks */  int hblks;     /* Number of mmapped regions */  int hblkhd;    /* Space allocated in mmapped regions (bytes) */  int usmblks;   /* Maximum total allocated space (bytes) */  int fsmblks;   /* Space in freed fastbin blocks (bytes) */  int uordblks;  /* Total allocated space (bytes) */  int fordblks;  /* Total free space (bytes) */  int keepcost;  /* Top-most, releasable space (bytes) */&#125;;

实例：
#include &lt;iostream&gt;#include &lt;malloc.h&gt;int main()&#123;    // 调用 mallinfo() 函数获取堆内存的使用情况    struct mallinfo info = mallinfo();    std::cout &lt;&lt; &quot;总分配空间：&quot; &lt;&lt; info.arena &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl;    std::cout &lt;&lt; &quot;空闲空间：&quot; &lt;&lt; info.fordblks &lt;&lt; &quot; bytes&quot; &lt;&lt; std::endl;    std::cout &lt;&lt; &quot;空闲块数量：&quot; &lt;&lt; info.ordblks &lt;&lt; std::endl;    // 其他字段...    return 0;&#125;

用法总结所以，getrusage()和mallinfo()函数提供了不同层面和不同粒度的内存使用统计信息。具体选择哪个函数取决于你想要获取的内存使用情况的精度和范围。
如果你想获取整个进程的内存使用情况，包括堆内存以外的资源使用情况，例如最大常驻内存集和页面错误次数等，那么getrusage()函数是一个更合适的选择。
如果你主要关注堆内存的使用情况，例如总分配空间、空闲空间等，那么mallinfo()函数可能更适合你的需求。
需要注意的是，mallinfo()函数是GNU C库特有的函数，在某些平台上可能不可用。另外，它仅适用于使用GNU C库的程序。如果你的程序不使用GNU C库，那么mallinfo()函数将不可用。在这种情况下，你可以考虑使用其他方法来获取堆内存的使用情况，如使用第三方内存分析工具或自定义统计代码。
]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>43_statistic_memory_usage</tag>
      </tags>
  </entry>
  <entry>
    <title>6_volatile</title>
    <url>/C/C/6_volatile/</url>
    <content><![CDATA[ 




1. Volatile关键字
1.1. 编译器的优化介绍
1.2. 概念
1.3. 为什么使用 volatile 关键字修饰的语句会影响编译器的优化？
1.4. 什么情况下使用 volatile？
1.5. 注意点
1.6. Reference





1. Volatile关键字1.1. 编译器的优化介绍
高速缓存：处理器读取程序里面的数据时，把一些访问频率比较高的数据，临时存储到寄存器(register)中，当需要取数据时，就会从 register 中取，而不是直接去从 memory(内存)中取，节约了时间，像这样的过程，叫做高速缓存。


硬件级别的优化：内存访问速度远不及CPU处理速度，为提高机器整体性能，在硬件上引入硬件高速缓存(Cache)，加速对内存的访问。另外在现代CPU中指令的执行并不一定严格按照顺序执行，没有相关性的指令可以乱序执行，以充分利用CPU的指令流水线(Instruction pipeline)，提高执行速度。

软件级别的优化：一种是在编写代码时由程序员优化，另一种是由编译器进行优化。编译器优化常用的方法有：将内存变量缓存到寄存器；调整指令顺序充分利用CPU指令流水线，常见的是重新排序读写指令。对常规内存进行优化的时候，这些优化是透明的，而且效率很好。

由编译器优化或者硬件重新排序引起的问题的解决办法是在从硬件（或者其他处理器）的角度看必须以特定顺序执行的操作之间设置内存屏障（memory barrier），linux 提供了一个宏解决编译器的执行顺序问题。 

void Barrier(void) 这个函数通知编译器插入一个内存屏障，但对硬件无效，编译后的代码会把当前CPU寄存器中的所有修改过的数值存入内存，需要这些数据的时候再重新从内存中读出。



1.2. 概念volatile 关键字(keywords)是一种类型修饰符(Type Qualifiers)，volatile 的英文翻译过来是 “易变的” 。用volatile 声明类型变量的时候，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用 volatile 进行声明，则编译器将对所声明的语句进行优化。即 volatile 关键字影响编译器编译的结果，用 volatile 声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错。
1.3. 为什么使用 volatile 关键字修饰的语句会影响编译器的优化？
当使用 volatile 声明变量值的时候，编译器总是重新从它所在的原内存读取数据，即使它前面的指令刚刚从该处读取过数据。

1&gt; 告诉compiler不能做任何优化
比如要往某一地址送两指令：int *ip =...; //设备地址*ip = 1; //第一个指令*ip = 2; //第二个指令以上程序被compiler可能做优化为：int *ip = ...;*ip = 2;结果第一个指令丢失。如果用volatile, compiler就不允许做任何的优化，从而保证程序的原意：volatile int *ip = ...;*ip = 1;*ip = 2;即使你要compiler做优化，它也不会把两次付值语句间化为一，它只能做其它的优化。

2&gt; 用 volatile 定义的变量会在程序外被改变，每次都必须从内存中读取，而不能重复使用放在cache(高速缓存)或寄存器中的备份。
1.4. 什么情况下使用 volatile？一般说来，volatile用在如下的几个地方：
一、 中断服务程序中修改的供其它程序检测的变量需要加 volatile；
static int i=0;int main(void)&#123;  ...  while (1) &#123;    if (i) &#123;      dosomething();    &#125;  &#125;｝/* Interrupt service routine. */void ISR_2(void)&#123;      i=1;&#125;
程序的本意是希望ISR_2中断产生时，在main当中调用do_something函数，但是，由于编译器判断在main函数里面没有修改过i，因此可能只执行一次对从i到某寄存器的读操作，然后每次if判断都只使用这个寄存器里面的“i副本”，导致do_something永远也不会被调用。如果变量加上volatile修饰，则编译器保证对此变量的读写操作都不会被优化（肯定执行）。此例中i也应该如此说明。
二、多任务环境下各任务间共享的标志 应该加 volatile；

在编写多线程的程序时，同一个变量可能被多个线程修改，而程序通过该变量同步各个线程。

DWORD __stdcall threadFunc(LPVOID signal) &#123;   int* intSignal=reinterpret_cast&lt;int*&gt;(signal);   *intSignal=2;   while(*intSignal!=1)       sleep(1000);   return 0; &#125;

该线程启动时将intSignal 置为2，然后循环等待直到intSignal 为1 时退出。显然intSignal的值必须在外部被改变，否则该线程不会退出。但是实际运行的时候该线程却不会退出，即使在外部将它的值改为1，看一下对应的伪汇编代码就明白了： 
mov ax,signal   label:   if(ax!=1)   goto label

对于C编译器来说，它并不知道这个值会被其他线程修改。自然就把它cache在寄存器里面。记住，C 编译器是没有线程概念的！这时候就需要用到volatile。volatile 的本意是指：这个值可能会在当前线程外部被改变。也就是说，我们要在threadFunc中的intSignal前面加上volatile关键字，这时候，编译器知道该变量的值会在外部改变，因此每次访问该变量时会重新读取，所作的循环变为如下面伪码所示： 
label:  mov ax,signal  if(ax!=1)  goto label 3、Memory 


三、 存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能有不同意义；
XBYTE[2]=0x55;XBYTE[2]=0x56;XBYTE[2]=0x57;XBYTE[2]=0x58;

对外部硬件而言，上述四条语句分别表示不同的操作，会产生四种不同的动作，但是编译器却会对上述四条语句进行优化，认为只有XBYTE[2]&#x3D;0x58（即忽略前三条语句，只产生一条机器代码）。如果键入volatile，则编译器会逐一地进行编译并产生相应的机器代码（产生四条代码）。


注意： 以上这几种情况经常还要同时考虑数据的完整性（相互关联的几个标志读了一半被打断了重写），在1中可以通过关中断来实现，2 中可以禁止任务调度，3中则只能依靠硬件的良好设计了。



1.5. 注意点
频繁地使用 volatile 很可能会增加代码尺寸和降低性能，因为它频繁的访问内存，而非缓存或寄存器，因此要合理的使用 volatile。
作为指令关键字，确保本条指令不会因编译器的优化而省略，且要求每次直接读值，volatile处理结果：直接存取原始内存地址的值。

1.6. Reference
C语言中volatile关键字的作用
volatile关键字的使用
C语言的volatile关键字

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>6_volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>7_segment_fault</title>
    <url>/C/C/7_segment_fault/</url>
    <content><![CDATA[
Segmentation Fault1. C语言中常见的问题
内存重叠的处理
临时变量太多或 new 的内存没有安全释放
没有测试内存越界
指针操作不熟悉

2. 概念
什么是段错误(segmentation fault)？
程序发生了越界访问，cpu就会产生相应的异常保护，于是segmentation fault就出现了。



3. 产生的原因
什么时候会发生 segmentation fault?

访问了不可访问的内存，这个内存区要么是不存在的，要么是受到系统保护的。
错误的访问类型引起
访问了不属于进程地址空间的内存
内存越界，数组越界，变量类型不一致等,访问到不属于你的内存区域
试图把一个整数按照字符串的方式输出
栈溢出了，有 SIGSEGV 有时却啥都没发生


为什么访问 null pointer会发生 segmentation fault？

进程(process) 运行时生成了一个虚拟地址(virtual address)0，硬件尝试在TLB(Translation Lookaside Buffer)中查找VPN(virtual page number)0，在TLB中没有找到，则查询页表(page table)，发现 VPN为0 的 entry 被标记为无效。遇到无效的访问，将控制权交给OS(operation system)，OS可能会使终止进程。



4. return返回
return 语句返回时，不可指向 栈内存 的 指针 或者 引用，因为该内存在函数体结束时被自动销毁。

5. 参考
C语言再学习 段错误（核心已转储）
C语言再学习

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>7_segment_fault</tag>
      </tags>
  </entry>
  <entry>
    <title>8-c_basic_knowledge</title>
    <url>/C/C/8-c_basic_knowledge/</url>
    <content><![CDATA[
1. 理解面向对象和面向过程编程
面向对象
本质是以建立模型体现出来的抽象思维过程和面向对象的方法；
把构成问题事务分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个事物在整个解决问题的步骤中的行为


面向过程
一种以过程为中心的编程思想，分析出解决问题所需要的步骤，然后用函数把这些步骤一步一步实现，使用的时候一个一个依次调用就可以了



2. whilewhile ( expression )  statement;

expression为真执行，为假则跳出
所有非零的值都为真，只有0被视为假


单独的; 表示空语句，应该独占一行，可读性更好

3. 赋值语句 =
数据对象(Data Object):  用于储存值的数据存储区域
可修改的左值(modifiable Lvalue)：用于标识可修改的对象。或者叫对象定位值(object locator value)

4. do … whiledo &#123;    statement;&#125; while (expresion);

先执行后判断，为真则执行，为假则跳出
while() 和for()先判断后执行
一般而言， 当循环涉及初始化和更新变量时， 用for循环比较合适， 而在其他情况下用while循环更好

5. if…elseif ( expression )  statement1;else &#123;    statement2;&#125;

expression为真（非0）,则执行statement1；如果expression为假或0， 则执行else后面的statement2
if和else之间只允许有一条语句（简单语句或复合语句）

6. continue
用作占位符：在使用while循环时，后边语句部分采用;可以从continue代替
让程序跳过循环体的余下部分

7. 文件流
C语言处理的是流(stream),不直接处理文件。流（stream） 是一个实际输入或输出映射的理想化数据流。 
windows操作系统可以使用内嵌的Ctrl+Z字符来标记文件结尾。而Linux中的文件结尾结尾标志为：Ctrl+D
用 getchar()读取文件检测到文件结尾时将返回一个特殊的值， 即EOF（end of file）,在C语言中定义为EOF=-1
scanf()函数检测到文件结尾时也返回EOF。

8. 动态内存分配
calloc函数
void *calloc(size_t m,size_tsize);m个大小为size字节的对象分配存储空间，把已分配的空间所有位都初始化为0


malloc函数：
void *malloc(size_t,size) 大小为size字节的对象分配存储空间，存储空间的初始值不确定



9. 条件编译(precompilation)
#if

#if 表达式    程序段1[# else    程序段2]#enif


#ifndef

#ifndef 标识符    程序段1[# else    程序段2]#enif


为什么要用预编译？
不同的源码文件，可能会引用同一个头文件（比如stdio.h）。编译的时候，头文件必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。用来声明宏定义的#define命令，就不会被预编译 



10. 双引号与单引号区别
单引号&#39; :  代表一个整数，数值对应于该字符在ASCII字符集中的序列值；一个字符就是一个字节。
双引号&quot;: 表示一个字符串，进行指针运算，代表字符指针；其中一个字符也是一个字符串，大小为两个字节(后面为\0)。
 注意:  
C编译器接受字符和字符串的比较，无任何意义
C编译器允许字符串对字符变量赋值，只能得到错误



11. 其它知识点b &#x3D; ++a 先对a加一后赋值为b
b &#x3D; a++ 先赋值后a加一
% 求余数运算符结果的符号与 % 左边的操作符号相同

例如：-45 % 8 结果为-5

大写字母与小写字母ASCII码相差32（小写字母大）
指针运算通常只有减法没有加法，差值是两个指针变量之间相差的元素个数
12. References
C语言

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>8-c_basic_knowledge</tag>
      </tags>
  </entry>
  <entry>
    <title>9_pointer_function_function_pointer</title>
    <url>/C/C/9_pointer_function_function_pointer/</url>
    <content><![CDATA[ 

1. 指针函数1.1. 定义指针函数是返回结果的类型为指针的一个函数。其本质是一个函数，与普通函数的区别是，指针函数的返回值是一个指针，函数返回的数据是一个地址。
1.2. 格式函数的定义格式如下：

类型说明符  *函数名(参数表)
格式： int *fun(x, y)

1.3. 代码实现#include &quot;stdio.h&quot;int *complare(int *x, int *y);int main()&#123;    int a = 5;    int b = 10;    int *p;    p = complare(&amp;a, &amp;b);    printf(&quot;%d \n&quot;, *p);    getchar();    return 0;&#125;int *complare(int *x, int *y)&#123;    if(*x &gt; *y)    &#123;        printf(&quot;较大值: %x \n&quot;, x);        return x;    &#125;    else    &#123;        printf(&quot;较小值的memory为: 0X=%x \n&quot;, y);         return y;    &#125;&#125;


2. 函数指针2.1. 什么是函数指针？函数的名称是一个指针，表示一个函数的入口地址。将函数名赋给一个指针变量，然后通过这个指针变量对其函数进行操作。
2.2. 函数指针定义格式
 类型标识符 (*指针变量名)() 
格式：int (*p)()

2.3. 特点
函数指针 本质 是一个指针变量，该指针指向这个函数。
指针变量p，只能指向函数的入口地址，不能指向一般变量或数组。
一个函数指针变量可以先后指向不同的函数，但是函数的类型应该与函数指针的类型一样。

2.4. 使用步骤1、先声明函数指针类型或变量  int (*pointerFunc)(int a, int b);pointerFunc ret;2、将变量指向函数的首地址   ret = func;3、使用变量调用函数       ret(11, 22)
2.5. 代码实现#include &quot;stdio.h&quot;int add(int x, int y)&#123;    return x + y;&#125;int sub(int x, int y)&#123;    return x -y;&#125;int multiple(int x, int y, int z)&#123;    return (x * y * z);&#125;// 定义函数指针 int (*func)(int, int);// 函数指针做函数参数int funcPointerParam(int (*funcPointer)(int, int, int))  &#123;    int val = funcPointer(3, 4, 5);  // 直接调用定义的函数指针    printf(&quot;multi val: %d\n&quot;, val);    return val;&#125;int main()&#123;    func = add;   //func指向函数的地址    printf(&quot;add 函数地址: 0x%p\n&quot;, &amp;add);    printf(&quot;add 指向的数据: %x\n&quot;, add);    printf(&quot;func指针的地址: %x\n&quot;, &amp;func);    printf(&quot;func指向函数add的地址: %x\n&quot;, func);    int a = func(1, 3);    printf(&quot;carry add operation: %d\n&quot;, a);    func = &amp;sub;    printf(&quot;sub address: %x\n&quot;, &amp;sub);    printf(&quot;func指针的地址: %x\n&quot;, &amp;func);    printf(&quot;func指向函数sub的地址: %x\n&quot;, func);    int b = func(4, 1);    printf(&quot;carry add operation: %d\n&quot;, b);   // 调用函数指针做函数参数   funcPointerParam(multiple);   // multiple 指向函数的入口地址    return 0;&#125;

2.6. 常见的函数指针声明
结构体函数指针
用typedef来定义一个指针函数
直接声明一个函数指针

2.7. 为什么使用函数指针：
可以将实现同一功能的多个模块统一起来标识，更容易后期维护，系统结构更加清晰。
便于分层设计、利于系统抽象、降低耦合度以及使接口与实现分开。函数指针约定了函数的返回值和函数的参数这套协议，留下了一套接口，以便兼容新增的代码。
实现面向对象编程中的多态性。
通过函数指针做函数的参数，可以实现回调函数。任务调用者和任务的实现者可以分开编写。
在程序运行的时候根据数据的具体状态来选择相应的处理方式

2.8. 其它指针声明int board[8][8];     // 声明一个内含int数组的数组int ** ptr;          // 声明一个指向指针的指针， 被指向的指针指向intint * risks[10];     // 声明一个内含10个元素的数组， 每个元素都是一个指向int的指针int (* rusks)[10];   // 声明一个指向数组的指针， 该数组内含10个int类型的值int * oof[3][4];     // 声明一个3×4 的二维数组， 每个元素都是指向int的指针int (* uuf)[3][4];   // 声明一个指向3×4二维数组的指针， 该数组中内含int类型值int (* uof[3])[4];   // 声明一个内含3个指针元素的数组， 其中每个指针都指向一个内含4个int类型元素的数组


2.9.  []、()、* 优先级比较 
[] 、()属于基本运算符，优先级相同，结合方向为：从左到右
* 属于单目运算符，比[]、()的优先级低
各类优先级：单目 &gt; 算数运算 &gt; 移位 &gt; 关系 &gt; 位逻辑 &gt; 逻辑 &gt; 条件 &gt; 赋值 &gt; 逗号

2.10. 函数指针数组格式
typedef int (*p)(void *);p pArray[arraySize];

]]></content>
      <categories>
        <category>C</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>9_pointer_function_function_pointer</tag>
      </tags>
  </entry>
  <entry>
    <title>Actor</title>
    <url>/CloudNative/CloudNative/Actor/</url>
    <content><![CDATA[

1. Actor Model1.1. 带着问题思考1.1.1. Actors是如何发送和接收消息的？在Actor模型中，消息是唯一的通信机制。Actors通过消息进行相互通信，它们不直接共享内存。以下是Actors如何发送和接收消息的基本概念：

发送消息：

Actors可以发送消息给其他Actors，也可以发送消息给自己。当一个Actor想要与另一个Actor通信时，它创建一个消息并将其发送给目标Actor的地址（通常称为PID，即Process ID）。
在发送消息时，Actor系统负责将消息传递给正确的接收者。发送消息通常是异步的，这意味着发送者Actor不会等待接收者Actor处理消息。发送消息的过程通常是非阻塞的，这样可以提高系统的并发性能。

接收消息：

当一个Actor接收到消息时，它会将消息放入自己的邮箱（Mailbox）中。邮箱是一个消息队列，用于存储Actor接收到的消息。接收者Actor从邮箱中获取消息，并根据消息的内容执行相应的操作。
接收消息的过程通常是同步的，即当Actor正在处理一个消息时，它会等待该消息处理完成，然后再处理下一个消息。这确保了消息的顺序处理，避免了竞态条件和数据一致性问题。

消息处理：

当Actor接收到消息后，它会调用预定义的消息处理函数（也称为处理器）来处理消息。处理器是Actor定义的一部分，用于指定接收到特定类型消息时应该执行的操作。处理器可以是Actor的方法，这样当Actor接收到特定类型的消息时，它会调用相应的方法来处理消息。

消息传递的特性：

在Actor模型中，消息传递具有以下特性：

封装性（Encapsulation）： 每个Actor都有自己的状态和行为，其他Actor无法直接访问其状态，只能通过消息传递来与其通信。

并发性（Concurrency）： 多个Actor可以并发地执行，处理各自的消息，从而实现系统级的并发性。

位置透明性（Location Transparency）： 发送消息时，发送者无需知道接收者Actor的具体位置，只需知道接收者的PID即可。


1.1.2. 它们是如何并发地工作的？1.1.3. 理解代码中的设计模式和结构1.2. 模型介绍Proto.Actor-go 是一个用于构建分布式应用程序的框架，它基于 Go 语言开发，旨在简化并发和分布式系统的开发。这个框架使用 Actor 模型作为基础，允许开发者将应用程序拆分成独立的 Actor，并通过消息传递进行通信。
Actor模型是一个概念模型，用于处理并发计算。Actor由3部分组成：状态（State）+行为（Behavior）+邮箱（Mailbox），State是指actor对象的变量信息，存在于actor之中，actor之间不共享内存数据，actor只会在接收到消息后，调用自己的方法改变自己的state，从而避免并发条件下的死锁等问题；Behavior是指actor的计算行为逻辑；邮箱建立actor之间的联系，一个actor发送消息后，接收消息的actor将消息放入邮箱中等待处理，邮箱内部通过队列实现，消息传递通过异步方式进行。
1.3. Actor1.3.1. 特点
Actor 之间是彼此隔离的，不会共享内存，只能通过邮箱方式去和对方打交道。

邮箱（MailBox）：本质上是一个队列。每个Actor都有一个邮箱，邮箱接收并缓存其他Actor发过来的消息。


彼此之间异步发送消息和处理的。

Actor一次只能同步处理一个消息，处理消息过程中，除了可以接收消息外不能做任何其他操作。

多个 Actor 之间通过发信息进行交流，actor与actor之间可以交流，但是不会产生数据竞争。

一个Actor可以响应消息、退出新Actor、改变内部状态、将消息发送到一个或多个Actor。

Actor可能会堵塞自己但Actor不应该堵塞自己运行的线程

多个actor向同一actor发送消息，按照时间顺序投递进对方MailBox

actor 能够根据到来的消息通过行为修改自己的状态，可以发送信息给其他actor，可以创建新的actor或者新的子actor。

actor需要知道接收方的地址，需要知道将消息传递给谁


1.3.2. 缺点
Actor 没有拒绝交流的能力。当消息到达时，必须对其进行处理，或者将其放入缓冲区，以便稍后处理。

1.3.3. Spawn(生成)在Proto Actor中，**Spawn是用于创建新的Actor实例**的操作，并返回该 Actor 的 PID。当你想要创建一个新的Actor时，你会调用Spawn函数，并且提供一个Props对象作为参数，该对象描述了将要生成的Actor的行为。Spawn会返回一个PID（Process ID）——一个用于唯一标识Actor实例的标识符。
pid, err := actor.Spawn(props) // 通过Props对象生成一个新的Actor实例，并返回其PID

1.3.4. Props(属性)Props是一个用于配置Actor实例的对象。它定义了Actor的行为、状态和消息处理逻辑。当你调用Spawn函数时，你需要提供一个Props对象，以告诉Proto Actor系统你希望创建的Actor的特性。
Props对象通常包含以下信息：

Actor类型（Actor Type）： 描述Actor的类型，指定Actor实例所属的类型。
消息处理器（Message Handler）： 定义了Actor如何处理接收到的消息。
监督策略（Supervision Strategy）： 定义了当Actor失败时，如何处理该Actor的策略。
初始化参数（Initialization Parameters）： 用于在Actor实例创建时传递给Actor构造函数的参数。

在Proto Actor中，Props对象可以按需定制，以创建不同类型的Actor实例。以下是一个示例：
props := actor.PropsFromFunc(func(ctx actor.Context) &#123;    // 消息处理逻辑    switch msg := ctx.Message().(type) &#123;    case string:        ctx.Respond(&quot;Received: &quot; + msg)    &#125;&#125;)pid, err := actor.Spawn(props)

在上述示例中，PropsFromFunc函数创建了一个Props对象，它指定了一个简单的消息处理器，该处理器能够处理接收到的字符串消息并回复。
1.3.5. statector本身的属性信息，state只能被actor自己操作，不能被其他actor共享和操作，有效的避免加锁和数据竞争
1.3.6. behaviorActor的处理逻辑。定义在该时间点对消息作出反应时要采取的行动的功能，例如，如果客户端得到授权，则转发请求，否则拒绝请求。此行为可能会随着时间的推移而改变
1.3.7. mailbox
actor 存储消息是 fifo队列，每个actor只有一个信箱，所有发送者都将他们的消息队列排队。

actor与actor之间发送消息，消息只能发送到邮箱，等待拥有邮箱的actor 去处理，这个过程是异步的。


1.3.8. PID
创建一个 Actor 时，不能直接向另一个 Actor 发送者消息，而是用开发者暴露出消息传递的一个引用（reference），这个引用就叫 PID，是 process id的简称。

PID 是一个序列化标识，被使用发送 messages 到 Actor 的 mailbox。

通过 PID 就知道了实际 actor instance 位于哪儿以及是怎样通信的。


1.3.9. children1.3.10. supervisor Strategy
每个actor都有一个监督者。
Proto.Actor实现了一种称为“家长监督”的特定形式。actor只能由其他actor创建，其中顶级actor由库提供，每个创建的actor由其父级监控。
两类监管策略
ForOneStrategy：将获得的指令应用于失败的子级，没有明确指定，这就是默认值。
AllForOneStrategy：适用于child actor 之间存在紧密依赖关系的情况，即一个child的失败会影响其他child的功能，他们之间存在着不可分割的联系。



1.3.11. messages
Actor 可以运行在本地进程，也可以在不同机器的远程Actor上运行。
消息是不可变的，因此是线程安全的。
消息是异步的，

1.3.12. 用法Actor是ProtoActor的核心组件，它是一个可以处理消息的实体。每个Actor都有一个唯一的PID（Process ID）来标识。Actor通过消息进行通信，不共享状态，因此可以避免并发编程中的许多问题。
ReceiveDefault 是 UserActor 接口中定义的一个方法。在 ProtoActor 的设计中，这个方法的主要作用是处理 Actor 接收到的未被明确处理的消息。
在 Actor 模型中，Actor 通过消息进行通信。当 Actor 接收到一个消息时，它会在其 Receive 方法中查找对应的处理逻辑。如果 Receive 方法中没有找到对应的处理逻辑，那么这个消息就会被传递给 ReceiveDefault 方法。
package mainimport (	&quot;fmt&quot;	&quot;time&quot;	console &quot;github.com/asynkron/goconsole&quot;	&quot;github.com/asynkron/protoactor-go/actor&quot;)type (	hello      struct&#123; Who string &#125;	helloActor struct&#123;&#125;)func (state *helloActor) Receive(context actor.Context) &#123;	switch msg := context.Message().(type) &#123;	case *actor.Started:		fmt.Println(&quot;Started, initialize actor here&quot;)	case *actor.Stopping:		fmt.Println(&quot;Stopping, actor is about shut down&quot;)	case *actor.Stopped:		fmt.Println(&quot;Stopped, actor and its children are stopped&quot;)	case *actor.Restarting:		fmt.Println(&quot;Restarting, actor is about restart&quot;)	case *hello:		fmt.Printf(&quot;Hello %v\n&quot;, msg.Who)	&#125;&#125;func main() &#123;	system := actor.NewActorSystem()	props := actor.PropsFromProducer(func() actor.Actor &#123; return &amp;helloActor&#123;&#125; &#125;)	pid := system.Root.Spawn(props)	system.Root.Send(pid, &amp;hello&#123;Who: &quot;Roger&quot;&#125;)	// why wait?	// Stop is a system message and is not processed through the user message mailbox	// thus, it will be handled _before_ any user message	// we only do this to show the correct order of events in the console	time.Sleep(1 * time.Second)	system.Root.Stop(pid)	_, _ = console.ReadLine()&#125;

1.3.13. RouterRouter 是用于管理一组Actor并将消息路由到这些 Actor 的组件。ProtoActor提供了几种路由策略，如RoundRobin（轮询）、Random（随机）等。
package mainimport (	&quot;log&quot;	console &quot;github.com/asynkron/goconsole&quot;	&quot;github.com/asynkron/protoactor-go/actor&quot;	&quot;github.com/asynkron/protoactor-go/router&quot;)type workItem struct&#123; i int &#125;const maxConcurrency = 5func doWork(ctx actor.Context) &#123;	if msg, ok := ctx.Message().(*workItem); ok &#123;		// this is guaranteed to only execute with a max concurrency level of `maxConcurrency`		log.Printf(&quot;%v got message %d&quot;, ctx.Self(), msg.i)	&#125;&#125;func main() &#123;	system := actor.NewActorSystem()	pid := system.Root.Spawn(router.NewRoundRobinPool(maxConcurrency).Configure(actor.WithFunc(doWork)))	for i := 0; i &lt; 1000; i++ &#123;		system.Root.Send(pid, &amp;workItem&#123;i&#125;)	&#125;	_, _ = console.ReadLine()&#125;

1.3.14. Persistence of actor’s state文献：Proto.Persistence module: https://proto.actor/docs/persistence-proto-persistence/
有场景需要存储 actor 的 state 时，可用 protoactor-go 中 persistence 模块的 events（事件） 和 snapshots（快照）。
1.4. RemoteRemote 是ProtoActor的分布式组件，它允许Actor跨网络节点进行通信。你可以创建一个Remote Actor，然后在另一个节点上通过PID发送消息给它。
学习 remote 可以清楚知道 actor 之间是如何通信的。
package mainimport (	&quot;fmt&quot;	&quot;log&quot;	&quot;runtime&quot;	&quot;sync&quot;	&quot;time&quot;	&quot;remoterouting/messages&quot;	console &quot;github.com/asynkron/goconsole&quot;	&quot;github.com/asynkron/protoactor-go/actor&quot;	&quot;github.com/asynkron/protoactor-go/remote&quot;	&quot;github.com/asynkron/protoactor-go/router&quot;)var (	system      = actor.NewActorSystem()	rootContext = system.Root)func main() &#123;	cfg := remote.Configure(&quot;127.0.0.1&quot;, 8100)	r := remote.NewRemote(system, cfg)	r.Start()	runtime.GOMAXPROCS(runtime.NumCPU())	runtime.GC()	p1 := actor.NewPID(&quot;127.0.0.1:8101&quot;, &quot;remote&quot;)	p2 := actor.NewPID(&quot;127.0.0.1:8102&quot;, &quot;remote&quot;)	remotePID := rootContext.Spawn(router.NewConsistentHashGroup(p1, p2))	messageCount := 1000000	var wgStop sync.WaitGroup	props := actor.		PropsFromProducer(newLocalActor(&amp;wgStop, messageCount),			actor.WithMailbox(actor.Bounded(10000)))	pid := rootContext.Spawn(props)	log.Println(&quot;Starting to send&quot;)	t := time.Now()	for i := 0; i &lt; messageCount; i++ &#123;		message := &amp;messages.Ping&#123;User: fmt.Sprintf(&quot;User_%d&quot;, i)&#125;		rootContext.RequestWithCustomSender(remotePID, message, pid)	&#125;	wgStop.Wait()	rootContext.Stop(pid)	fmt.Printf(&quot;elapsed: %v\n&quot;, time.Since(t))	console.ReadLine()&#125;

1.5. SchedulerScheduler是ProtoActor的定时任务组件，它可以让你在指定的时间后或者按照指定的间隔重复发送消息。
package mainimport (	&quot;log&quot;	&quot;math/rand&quot;	&quot;sync&quot;	&quot;time&quot;	console &quot;github.com/asynkron/goconsole&quot;	&quot;github.com/asynkron/protoactor-go/actor&quot;	&quot;github.com/asynkron/protoactor-go/scheduler&quot;)var HelloMessages = []string&#123;	&quot;Hello&quot;,	&quot;Bonjour&quot;,	&quot;Hola&quot;,	&quot;Zdravstvuyte&quot;,	&quot;Nǐn hǎo&quot;,	&quot;Salve&quot;,	&quot;Konnichiwa&quot;,	&quot;Olá&quot;,&#125;func main() &#123;	var wg sync.WaitGroup	wg.Add(5)	rand.Seed(time.Now().UnixMicro())	system := actor.NewActorSystem()	log.SetFlags(log.LstdFlags | log.Lmicroseconds)	count := 0	props := actor.PropsFromFunc(func(ctx actor.Context) &#123;		switch t := ctx.Message().(type) &#123;		case []string:			count++			log.Printf(&quot;\t%s, counter value: %d&quot;, t[rand.Intn(len(t))], count)			wg.Done()		case string:			log.Printf(&quot;\t%s\n&quot;, t)		&#125;	&#125;)	pid := system.Root.Spawn(props)	s := scheduler.NewTimerScheduler(system.Root)	cancel := s.SendRepeatedly(1*time.Millisecond, 1*time.Millisecond, pid, HelloMessages)	wg.Wait()	cancel()	wg.Add(100) // add 100 to our waiting group	cancel = s.RequestRepeatedly(1*time.Millisecond, 1*time.Millisecond, pid, HelloMessages)	// the following timer will fire before the	// wait group is consumed and will stop the scheduler	time.Sleep(10 * time.Millisecond)	cancel()	s.SendOnce(1*time.Millisecond, pid, &quot;Hello Once&quot;)	// this message will never show as we cancel it before it can be fired	cancel = s.RequestOnce(500*time.Millisecond, pid, &quot;Hello Once Again&quot;)	time.Sleep(250 * time.Millisecond)	cancel()	_, _ = console.ReadLine()&#125;

 Plugin：Plugin是ProtoActor的插件系统，你可以通过实现Plugin接口来创建自定义的插件。
package pluginimport (	&quot;github.com/asynkron/protoactor-go/actor&quot;)type plugin interface &#123;	OnStart(actor.ReceiverContext)	OnOtherMessage(actor.ReceiverContext, *actor.MessageEnvelope)&#125;func Use(plugin plugin) func(next actor.ReceiverFunc) actor.ReceiverFunc &#123;	return func(next actor.ReceiverFunc) actor.ReceiverFunc &#123;		fn := func(context actor.ReceiverContext, env *actor.MessageEnvelope) &#123;			switch env.Message.(type) &#123;			case *actor.Started:				plugin.OnStart(context)			default:				plugin.OnOtherMessage(context, env)			&#125;			next(context, env)		&#125;		return fn	&#125;&#125;



1.6. ClusterProto.Actor的集群（Cluster）是一种分布式Actor系统，它允许在多个节点上运行Actor，并通过网络进行通信。集群的主要目标是提供高可用性和容错性。
以下是Proto.Actor集群的一些核心API：

Cluster.Start：这个函数用于启动一个集群节点。它需要一个ClusterConfig对象，该对象包含了集群的配置信息，如节点的地址、端口、种子节点列表等。

Cluster.GetCluster：这个函数返回一个Cluster对象，你可以通过这个对象进行集群的操作，如获取集群成员、注册或注销事件处理器等。

Cluster.SpawnNamed：这个函数用于在集群中创建一个Actor。它需要一个Props对象和一个名字，返回创建的Actor的PID。

Cluster.PID：这个函数用于获取集群中的一个Actor的PID。你可以通过这个PID向Actor发送消息。


以下是一个简单的使用Proto.Actor集群的例子：
package mainimport (	&quot;log&quot;	&quot;time&quot;	&quot;github.com/asynkron/protoactor-go/actor&quot;	&quot;github.com/asynkron/protoactor-go/cluster&quot;	&quot;github.com/asynkron/protoactor-go/remote&quot;)type HelloActor struct&#123;&#125;func (state *HelloActor) Receive(ctx actor.Context) &#123;	switch msg := ctx.Message().(type) &#123;	case *actor.Started:		log.Println(&quot;Started, initialize actor here&quot;)	case *actor.Stopping:		log.Println(&quot;Stopping, actor is about shut down&quot;)	case *actor.Stopped:		log.Println(&quot;Stopped, actor and its children are stopped&quot;)	case *actor.Restarting:		log.Println(&quot;Restarting, actor is about restart&quot;)	case string:		log.Printf(&quot;Hello %v\n&quot;, msg)	&#125;&#125;func main() &#123;	system := actor.NewActorSystem()	remoteConfig := remote.Configure(&quot;localhost&quot;, 8080)	remote := remote.NewRemote(system, remoteConfig)	remote.Start()	clusterConfig := cluster.Configure(&quot;mycluster&quot;, remote, nil)	c := cluster.NewCluster(system, clusterConfig)	c.Start(&quot;node1&quot;, &quot;localhost:8080&quot;)	props := actor.PropsFromProducer(func() actor.Actor &#123; return &amp;HelloActor&#123;&#125; &#125;)	pid, err := c.SpawnNamed(props, &quot;hello&quot;)	if err != nil &#123;		log.Fatalf(&quot;Failed to spawn named actor: %v&quot;, err)	&#125;	c.PID(&quot;hello&quot;).Tell(&quot;Hello World&quot;)	time.Sleep(1 * time.Second)	c.Shutdown(true)&#125;

在这个例子中，我们首先创建了一个Actor系统和一个远程配置，然后启动了一个远程节点。接着，我们创建了一个集群配置，并使用它启动了一个集群节点。然后，我们在集群中创建了一个名为”hello”的Actor，并向它发送了一个消息。最后，我们关闭了集群。
1.6.1. grain在Proto.Actor中，Grain是一种特殊的Actor，它提供了一种更高级的抽象，使得开发者可以更加专注于业务逻辑，而不是并发和分布式计算的细节。
virtual actor model 借鉴了 Microsoft Orleans 的概念。一个Grain 就是一个 virtual actors
Grain是一种虚拟Actor，它的生命周期由Proto.Actor框架自动管理。Grain可以在集群中的任何节点上运行，当它收到消息时，Proto.Actor框架会自动激活它；当它一段时间没有收到消息时，框架会自动将它停用，释放资源。使用虚拟 Actor 模型，一个 Actor 被特别称为 “grain”。然而，grain 的实现与任何其他 Actor 的实现非常相似。一个显著的区别是，proto.actor 在初始消息接收时会自动启动 grain。
Grain 的这种特性使得它非常适合用于构建大规模的分布式系统。开发者只需要关注业务逻辑，而无需关心Grain的位置、生命周期和并发问题。
在Proto.Actor的集群中，Grain、Remote和Actor之间的关系如下：

Grain：Grain是一种特殊的Actor，它的生命周期由框架自动管理。Grain可以在集群中的任何节点上运行，它的状态可以持久化，也可以在内存中保存。

Remote：Remote是Proto.Actor的分布式组件，它允许Actor跨网络节点进行通信。Grain就是通过Remote在集群中的节点之间进行通信的。

Actor：Actor是Proto.Actor的核心组件，它是一个可以处理消息的实体。Grain实际上就是一种特殊的Actor，它提供了更高级的抽象，使得开发者可以更加专注于业务逻辑。


在实际使用中，你可以根据需要选择使用Actor或Grain。如果你需要更高级的抽象和自动的生命周期管理，可以选择使用Grain；如果你需要更细粒度的控制，可以选择使用Actor。
1.6.2. EventStream在Proto.Actor中，发布-订阅模式是通过EventStream组件实现的。EventStream是一个全局的消息通道，你可以在任何地方向它发布消息，也可以订阅它的消息。
以下是使用EventStream进行发布-订阅的基本步骤：

订阅消息：你可以通过EventStream.Subscribe函数订阅某种类型的消息。这个函数需要一个消息处理函数，当有消息发布时，这个函数会被调用。例如：

system.EventStream.Subscribe(func(msg *MyMessage) &#123;  *// 处理消息*&#125;)


发布消息：你可以通过EventStream.Publish函数发布消息。这个函数需要一个消息对象，这个消息会被发送给所有订阅了这种类型消息的处理函数。例如：

system.EventStream.Publish(&amp;MyMessage&#123;Value: &quot;Hello, World!&quot;&#125;)


取消订阅：你可以通过EventStream.Unsubscribe函数取消订阅。这个函数需要一个之前通过Subscribe函数返回的订阅对象。例如：

subscription := system.EventStream.Subscribe(func(msg *MyMessage) &#123;  // 处理消息&#125;)system.EventStream.Unsubscribe(subscription)


以上就是Proto.Actor中发布-订阅模式的基本使用方法。在实际使用中，你可能需要处理更复杂的场景，如在Actor之间进行发布-订阅、处理订阅失败等。
1.6.3. Pub-SubProto.Actor的集群 Pub-Sub（发布-订阅）模式是通过EventStream组件实现的。EventStream是一个全局的消息通道，你可以在任何地方向它发布消息，也可以订阅它的消息。
1.6.4. cluster providercluster 的核心是 cluster provider。
集群提供者（cluster provider）：通常是指一种软件或服务，负责管理和提供集群的基础设施。一个集群是由多个计算机节点组成的集合，这些节点协同工作以完成共同的任务。Cluster Provider 为创建、监控和维护这个集群提供了支持，使得节点能够了解集群中其他节点的状态、可用性以及成员身份等信息。
以下是一些 Cluster Provider 的功能和解释：

集群管理： Cluster Provider 负责创建、配置和管理整个集群。它可能提供用户界面或命令行工具，用于定义集群的规模、节点配置和其他相关属性。
节点协调： 集群中的节点需要协同工作以执行任务。Cluster Provider 负责确保节点之间的通信和协作，并在需要时自动进行节点的发现和注册。
资源分配和负载均衡： Cluster Provider 可能会处理集群中资源的分配和负载均衡，以确保任务在集群中均匀分布，并最大程度地利用集群中的计算资源。
故障恢复： 集群中的节点可能会因故障而失效，Cluster Provider 需要具备故障检测和自动恢复的机制，以保持集群的可靠性和稳定性。
扩展性： Cluster Provider 应该支持集群的动态扩展，允许根据需求添加或移除节点，以适应工作负载的变化。
安全性： 提供对集群中数据和通信的安全性管理，包括身份验证、授权和加密等方面的功能。
监控和日志： 提供集群性能和健康状态的监控功能，同时记录有关集群操作和事件的日志信息，以便进行故障排除和性能分析。

在这里，”cluster provider” 是负责维护和提供集群状态信息的组件。它允许应用程序中的节点通过与集群提供者进行交互，获取有关整个集群拓扑结构、节点状态的更新，并且使得集群中的节点能够协同工作。
“topology” 指的是拓扑结构，特指集群的结构或组织方式。在计算机科学和网络领域，拓扑结构描述了系统中各个节点之间的连接方式和关系。
1.6.4.1. Kubernetes Provider1.6.4.2. Consul Provider1.6.4.3. AWS ECS Provider1.6.4.4. Seed Provider - Experimental1.6.5. gossip在分布式系统中，gossip协议是一种用于在网络中传播信息的分散式通信方法。它基于随机选择的节点之间的互相交流，以便将信息传播到整个网络。Gossip协议通常用于处理集群中的成员关系、状态同步、故障检测等问题。
在Proto Actor的Golang实现中，gossip协议用于实现分布式系统中的Actor之间的通信和协作。Proto Actor提供了一种称为gossip.Gossip的模块，其中包含了一些用于在Actor之间传播信息的功能。
在这个上下文中，”gossip” 是指在分布式系统中，Actor之间相互交换信息的一种机制。它允许不同的Actor之间共享状态信息，从而实现集群中的协作和协调。通过使用gossip协议，系统中的Actor可以更容易地了解其他Actor的状态，帮助实现一致性、容错性和可扩展性等特性。
理解gossip的关键概念包括：

随机选择的节点交流信息：Gossip协议中的节点（这里是指Actor）随机选择其他节点进行信息的交流。这种随机性确保了信息在整个网络中的分布。
信息的传播：通过节点之间的交流，信息被传播到整个网络。这种方式使得系统中的所有节点逐渐了解到所有其他节点的状态。
自我修复性：Gossip协议通常设计成具有自我修复性。如果某个节点长时间不可达，它的信息仍然可以通过其他节点传播，从而防止信息的丢失。

在Proto Actor中，gossip机制帮助实现了集群中的Actor之间的信息传递和状态同步，使得系统更具弹性，能够应对网络分区、故障和动态的集群成员变化等情况。通过这种方式，Proto Actor系统可以更好地适应复杂的分布式环境。
1.6.6. identity lookup在Proto Actor框架中，”identity lookup” 是指根据Actor的标识（identity）查找特定Actor实例的过程。在Proto Actor中，每个Actor都有一个唯一的标识符，通常是一个字符串。通过这个标识符，你可以在系统中查找并与特定的Actor进行交互。
在Proto Actor的Golang实现中，有一个 actor.PID 结构表示一个Actor的标识符，其中 PID 是 “Process ID” 的缩写。PID 包含了用于定位Actor的信息，比如Actor的地址（Address）、ID等。你可以使用 actor.PID 来发送消息给特定的Actor实例。
1.6.7. autoMangment
Actor kind 是一种 actor 的类型，它定义了 actor 处理消息的方式。

Kind 表示一个集群可以管理的 Actor 种类。

重启期间事件的详细顺序如下所示：

挂起actor，在这之间将不能处理普通消息直到恢复过来
调用实例的PreRestart钩子(默认发送终止请求给所有的孩子，同时调用 postStop)
等待所有请求终结的孩子在PreRestart之间(使用context.Stop()真正的停止; 像所有children actor 终结一样, 上一次终结child 的提示 将会影响下一步的处理
通过原来actor的创建函数创建一个新的actor。
新实例调用 PostRestart，默认已经调用了PreStart。
发送重启消息给所有在步骤三被杀死的孩子，重启孩子将会递归的遵循同一个 步骤2 的process 。
恢复actor。

2. References
offical website: https://proto.actor/docs/

cluster: https://proto.actor/docs/cluster/

offical golang package API: https://pkg.go.dev/github.com/asynkron/protoactor-go

[Golang] protoactor-go 101:

How actors communicate with each other: https://blog.oklahome.net/2018/09/protoactor-go-messaging-protocol.html

How actor.Future works to synchronize concurrent task execution: https://blog.oklahome.net/2018/11/protoactor-go-how-future-works.html

How proto.actor’s clustering works to achieve higher availability: https://blog.oklahome.net/2021/05/protoactor-clustering.html



How virtual actor frameworks deal with cluster topology change: https://www.etteplan.com/stories/how-virtual-actor-frameworks-deal-cluster-topology-change

Microsoft Orleans: https://learn.microsoft.com/en-us/dotnet/orleans/overview

知乎深入解析actor 模型（一)： actor 介绍及在游戏行业应用：https://zhuanlan.zhihu.com/p/427806717

知乎深入解析actor 模型（二)： actor 在go 实践proto.Actor 源码解析：https://zhuanlan.zhihu.com/p/427817175

Chat Example Using Proto.Actor: https://aneshas.medium.com/chat-example-using-proto-actor-5b42864c2d70

微软 Orleans 教程：https://orleans.azurewebsites.net/docs/index.html


]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>actor</tag>
      </tags>
  </entry>
  <entry>
    <title>CloudNative</title>
    <url>/CloudNative/CloudNative/CloudNative/</url>
    <content><![CDATA[


Cloud Native LandscapeCNCF Cloud Native Interactive Landscape
]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
      </tags>
  </entry>
  <entry>
    <title>Influxdb</title>
    <url>/CloudNative/CloudNative/Influxdb/</url>
    <content><![CDATA[1. InfluxDBInfluxDB 是一个高性能的时序数据库，专门用于处理高写入负载的数据存储，尤其是时间序列数据，比如物联网传感器数据、性能监控数据和实时分析数据等。以下是InfluxDB的一些基本概念和操作介绍：
什么是InfluxDB？InfluxDB 是由InfluxData公司开发的一款开源时序数据库（Time Series Database，TSDB），设计用于高性能的写入和查询操作，特别是针对时间序列数据。它的主要特点包括：

高性能写入和查询：适用于高吞吐量的数据写入和快速的查询操作。
Schemaless（无模式）：不需要预定义数据模式，数据可以灵活地添加。
内置的数据压缩和持久化：有效地存储和管理大量数据。
丰富的查询语言（InfluxQL）：提供类SQL的查询语言，便于数据操作和分析。

基本概念
Database（数据库）：InfluxDB中数据的集合，每个数据库包含多个测量、序列和数据点。
Measurement（测量）：相当于传统数据库中的表，用来存储一类数据。
Tag（标签）：用于数据的元数据，类似于数据库中的索引，帮助快速查询和过滤数据。标签是字符串类型。
Field（字段）：存储实际数据，字段可以是多种类型（整数、浮点数、字符串等）。
Timestamp（时间戳）：每个数据点都有一个时间戳，表示数据记录的时间。

2. 连接InfluxDBinflux --username &#x27;admin&#x27; --password &#x27;password&#x27;

2.1. 用户权限管理
创建管理员用户

首先，你需要创建一个具有管理员权限的用户。这通常是在首次设置InfluxDB时完成的。如果你还没有创建管理员用户，可以使用以下命令：
CREATE USER admin WITH PASSWORD &#x27;adminpassword&#x27; WITH ALL PRIVILEGES


启用认证

确保在InfluxDB配置文件中启用了认证。配置文件通常位于 /etc/influxdb/influxdb.conf（Linux）或 /usr/local/etc/influxdb.conf（MacOS）。
找到 [http] 部分，并确保以下行被设置：
[http]  auth-enabled = true

重启InfluxDB服务：
service influxdb restart


创建普通用户并授予权限

如果你已经有一个普通用户，例如 iottest，你需要为该用户授予特定的权限。例如，授予 iotdata 数据库的读写权限：
CREATE USER iottest WITH PASSWORD &#x27;password&#x27;GRANT ALL ON iotdata TO iottest

如果用户已经存在，只需要授予权限：
GRANT ALL ON iotdata TO iottest


连接并使用认证

确保你在连接InfluxDB时使用了正确的用户名和密码。如果你使用的是CLI，可以在连接时指定用户：
influx -username &#x27;admin&#x27; -password &#x27;adminpassword&#x27;

然后选择数据库并执行查询：
USE iotdataSHOW GRANTS FOR &quot;iottest&quot;


验证权限

你可以检查用户的权限设置是否正确：
SHOW USERS

这会显示所有用户及其管理员状态。你还可以使用以下命令来查看特定用户的权限：
SHOW GRANTS FOR &quot;iottest&quot;

2.2. influxdb 账户密码忘记如果你忘记了InfluxDB的账户密码，可以通过以下几种方式解决问题，具体取决于你是否能够直接访问InfluxDB的配置文件和数据文件。
停用认证临时修改密码
这是最常用的解决方案，适用于你能够访问InfluxDB的配置文件并且可以重启InfluxDB服务。
步骤：

编辑配置文件： 打开InfluxDB的配置文件，通常位于 /etc/influxdb/influxdb.conf（Linux）或 /usr/local/etc/influxdb.conf（MacOS）。
找到 [http] 部分，并将 auth-enabled 设置为 false：
[http]  auth-enabled = false

重启InfluxDB服务：
service influxdb restart

修改用户密码： 现在你可以不使用认证直接连接到InfluxDB：
influx

然后修改用户密码：
USE _internalSET PASSWORD FOR &quot;admin&quot; = &#x27;newpassword&#x27;

如果你想修改其他用户的密码：
SET PASSWORD FOR &quot;iottest&quot; = &#x27;newpassword&#x27;

重新启用认证： 编辑配置文件，将 auth-enabled 设置为 true，然后重启InfluxDB服务：
[http]  auth-enabled = true

service influxdb restart

2. 数据库操作2.1. 创建数据库CREATE DATABASE mydb

查看所有数据库：
SHOW DATABASES

使用数据库
use mydb



2.2. 插入数据在InfluxDB中，数据是以时间序列的形式存储的，每条数据称为一个点（point）。一个点包含以下几个部分：

measurement（测量）：相当于数据库中的表。
tags（标签）：用于存储元数据，类似于数据库中的索引列。
fields（字段）：用于存储实际的数据。
timestamp（时间戳）：记录数据的时间。

插入数据的基本语法如下：
INSERT measurement,tag_key=tag_value field_key=field_value timestamp

例如，插入一条温度数据：
INSERT temperature,location=office value=23.5 1622547800000000000

2.3. 查询数据你可以使用InfluxQL（类似于SQL的查询语言）来查询数据。基本查询语法如下：
SELECT field_key FROM measurement WHERE tag_key=&#x27;tag_value&#x27;

例如，查询办公室的温度数据：
SELECT value FROM temperature WHERE location=&#x27;office&#x27;

你可以进一步限制时间范围，例如查询最近的温度数据：
SELECT value FROM temperature WHERE location=&#x27;office&#x27; AND time &gt; now() - 1h

常用查询语法

根据条件查询
可以使用 WHERE 子句根据条件查询数据。例如，查询办公室温度高于24度的数据：
SELECT * FROM temperature WHERE location = &#x27;office&#x27; AND value &gt; 24

限制返回结果的数量
使用 LIMIT 子句限制返回结果的数量。例如，只返回最近的5条记录：
SELECT * FROM temperature LIMIT 5

按时间范围查询
使用 time 字段按时间范围查询数据。例如，查询过去1小时的数据：
SELECT * FROM temperature WHERE time &gt; now() - 1h

按时间先后顺序排列查询
-- 从最早到最新SELECT * FROM temperature ORDER BY time ASC-- 从最新到最早SELECT * FROM temperature ORDER BY time DESC

5.你可以结合其他查询条件一起使用 ORDER BY time，例如限制返回的记录数：
SELECT * FROM temperature WHERE location = &#x27;office&#x27; ORDER BY time ASC LIMIT 10

2.4. 删除数据如果你需要删除数据，可以使用以下命令：
删除整个测量的数据：
DROP MEASUREMENT measurement_name

删除数据库
DROP DATABASE database_name

2.5. 操作MEASUREMENTS(表)2.5.1. 所有表
显示所有表
SHOW MEASUREMENTS

显示某个测量（表）的所有字段
SHOW FIELD KEYS FROM measurement_name

显示某个测量（表）的所有标签：
SHOW TAG KEYS FROM measurement_name

显示标签值
SHOW TAG VALUES FROM measurement_name WITH KEY = tag_key

2.5.2. 表结构为了确保你了解测量中的字段和标签，可以使用以下命令查看表结构：
SHOW FIELD KEYS FROM measurement_nameSHOW TAG KEYS FROM measurement_name

References
InfluxDB（一）初探时序数据库

]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>influxdb</tag>
      </tags>
  </entry>
  <entry>
    <title>Mqtt</title>
    <url>/CloudNative/CloudNative/Mqtt/</url>
    <content><![CDATA[

EMQX PortEMQX 是一个高性能的 MQTT 消息中间件，通常用于物联网和实时消息应用。为了确保 EMQX 可以正常运行并允许客户端连接，你需要在防火墙上开放一些特定的端口。
Port
MQTT 协议端口
**默认端口：1883 (TCP)**：这是 MQTT 协议的默认端口，用于客户端与服务器之间的非加密通信。
**加密 MQTT（MQTT over TLS&#x2F;SSL）：8883 (TCP)**：如果你使用加密的 MQTT（通过 TLS&#x2F;SSL），需要开放此端口。


MQTT WebSocket 协议端口
**默认端口：8083 (TCP)**：用于 WebSocket 连接的 MQTT 通信（未加密）。
**加密 WebSocket：8084 (TCP)**：用于加密的 WebSocket 连接（MQTT over WebSocket with TLS&#x2F;SSL）。


管理界面端口
**默认端口：18083 (TCP)**：这是 EMQX 的管理控制台端口，通过浏览器访问 Web UI 进行管理和配置。


用于集群通信的端口
4371 (TCP)：用于 Erlang 节点间通信。
5371 (TCP)：备用端口用于集群通信。


CoAP 协议端口（可选）
**默认端口：5683 (UDP)**：如果你启用了 CoAP 协议（用于 IoT 设备），需要开放此端口。


HTTP API 端口（可选）
**默认端口：8080 (TCP)**：用于 EMQX HTTP API 的端口，如果你使用 EMQX 提供的 REST API 进行集成，可以开放此端口。


用于 MQTT Bridge 的端口（可选）
**默认端口：1883 或 8883 (TCP)**：如果你配置了 MQTT Bridge（用于连接不同的 EMQX 实例或第三方 MQTT 服务器），你需要确保桥接端口也被开放。



开放防火墙端口假设你在 CentOS 或 RHEL 上使用 firewalld 作为防火墙工具，可以通过以下命令开放这些端口：
# 开放 MQTT 协议端口sudo firewall-cmd --zone=public --add-port=1883/tcp --permanentsudo firewall-cmd --zone=public --add-port=8883/tcp --permanent# 开放 MQTT WebSocket 协议端口sudo firewall-cmd --zone=public --add-port=8083/tcp --permanentsudo firewall-cmd --zone=public --add-port=8084/tcp --permanent# 开放管理界面端口sudo firewall-cmd --zone=public --add-port=18083/tcp --permanent# 开放集群通信端口sudo firewall-cmd --zone=public --add-port=4371/tcp --permanentsudo firewall-cmd --zone=public --add-port=5371/tcp --permanent# 开放 CoAP 协议端口（可选）sudo firewall-cmd --zone=public --add-port=5683/udp --permanent# 开放 HTTP API 端口（可选）sudo firewall-cmd --zone=public --add-port=8080/tcp --permanent# 重新加载防火墙规则sudo firewall-cmd --reload

检查防火墙端口是否开放你可以使用以下命令检查防火墙端口是否已经开放：
firewall-cmd --list-ports

总结对于 EMQX，你至少需要开放以下端口：

1883（TCP Port）
8883（SSL&#x2F;TLS Port）
8083（WebSocket Port）
8084（Secure WebSocket Port）
18083（EMQX 管理控制台）
4371 和 5371（集群通信）

根据你的部署和需求，你可能还需要开放其他端口（如 CoAP、HTTP API 等）。
EMQX env将 EMQX 添加到系统的环境变量中，可以让你在任何位置执行 EMQX 的命令，而不需要每次都进入其安装目录。以下是将 EMQX 添加到环境变量的步骤。
1. 查找 EMQX 安装目录首先，确认你的 EMQX 安装目录。假设你是按照标准方式安装的 EMQX，那么默认情况下，EMQX 应该安装在 /opt/emqx 或 /usr/local/emqx 目录下。
如果你不确定安装路径，可以通过以下命令查找 EMQX 的路径：
whereis emqx

或者，如果你是通过源码安装的，可以根据安装时指定的路径来确认。
2. 编辑环境变量假设你的 EMQX 安装目录为 /opt/emqx，并且你想将其添加到环境变量中，使得你可以在任何地方通过命令行启动 EMQX。

打开 shell 配置文件：
根据你使用的 shell 类型（bash、zsh 等），编辑相应的配置文件。假设你使用的是 bash，配置文件通常是 ~/.bashrc 或 /etc/bash.bashrc（对于系统级别的环境变量）。
打开 ~/.bashrc 文件：
vim ~/.bashrc

或者使用 vim 编辑器：
vim ~/.bashrc

**添加 EMQX 的路径到 PATH**：
在 .bashrc 文件的末尾添加 EMQX 的路径。假设 EMQX 的安装目录为 /opt/emqx，你可以添加如下内容：
export PATH=$PATH:/opt/emqx/bin

这样就将 EMQX 的 bin 目录添加到了环境变量中。/opt/emqx/bin 目录包含了 EMQX 的可执行文件，例如 emqx 命令。

使改动生效：
修改完成后，保存并退出编辑器。如果你是用 nano 编辑的，可以按 Ctrl+X 保存并退出。
使环境变量更新生效，执行以下命令：
source ~/.bashrc

或者，你也可以关闭当前终端并重新打开一个新的终端窗口。


3. 验证是否生效现在，你可以在任何地方通过以下命令启动 EMQX 或检查其版本，来验证是否已经成功添加到环境变量：
emqx version

如果命令返回 EMQX 的版本号，说明环境变量已经成功配置。
4. 系统级环境变量（可选）如果你想要让所有用户都能够访问 EMQX 命令，你可以将路径添加到系统级环境变量中。对于所有用户，可以编辑 /etc/profile 或 /etc/bash.bashrc 文件：
sudo nano /etc/profile

在文件末尾添加：
export PATH=$PATH:/opt/emqx/bin

然后执行：
source /etc/profile

或者重启系统。
总结
确定 EMQX 的安装目录。
将 EMQX 的 bin 目录路径添加到 ~/.bashrc 文件中的 PATH 环境变量。
使更改生效，并验证是否可以通过命令行访问 EMQX。

这样，你就可以方便地在任何地方通过命令行启动 EMQX，而无需进入其安装目录。
ClientIDClientID 是MQTT连接的唯一标识符。在IoTCore中，不同实例之间是隔离的，故实际上 CoreID + ClientID 唯一标识了一个客户端连接。
如果多个客户端使用相同的 ClientID 连接到MQTT服务器，那么只有最后一个连接会被保留，其他连接会被强制断开。
在使用MQTT连接时，客户端ID应该是唯一的，并且应该易于识别。一个通常的做法是，使用固定前缀加上随机生成的UUID作为ClientID：前缀可以用来标识客户端的身份或分组，UUID保证了唯一性。
参数设置在 MQTT 协议中，retain 和 retainHandling 是两个不同的概念，分别与消息保留和消息传递策略有关。
1. retain
作用：决定发布的消息是否被保留在 MQTT 服务器上。
范围：仅在发布消息时有效。
取值：true 或  false
**retain = true**：消息被保留，新的订阅者会立即收到此消息。
**retain = false**：消息不被保留，新的订阅者不会收到过去发布的消息。



2. retainHandling
作用：控制 MQTT 客户端在订阅时如何处理保留消息。
范围：仅在订阅消息时有效。
取值 ：retainHandling是 MQTT v5 引入的新特性，取值有三种：
0（默认）：当客户端订阅主题时，接收服务器上的保留消息。
1：当客户端订阅主题时，如果客户端以前没有订阅过该主题，才接收保留消息。
2：客户端永远不会接收保留消息。



区别总结：
retain 是在发布消息时设置的，用于决定服务器是否应保留该消息。
retainHandling 是在订阅时设置的，用于控制客户端是否接收服务器上已经保留的消息。

例如，在某些场景中，用户可能希望只接收新的消息（不包括以前保留的消息），那么可以在订阅时将 retainHandling 设置为 2。
TroubleShoots冲突的 MQTT 客户端 ID
问题描述
多个设备使用同一客户端 ID 连接，导致每次有新的数据发送时，原来的连接被断开后重连。

分析：
多个设备使用同一客户端 ID 连接，使用同一客户端 ID 建立了多个连接，从而导致已连接的设备断开连接。MQTT 规范只允许每个客户端 ID 有一个活动连接，因此当另一个设备使用同一客户端 ID 连接时，它会使前一个连接断开。

导致的问题：
ID 相冲突的设备将被迫不断重新连接，这可能导致消息丢失或致使设备无法连接。
这可能表示设备或设备的凭证已遭破坏，并可能是 DDoS 攻击的一部分。也有可能是设备未在账户中得到正确配置，或者设备连接效果不佳，被迫每分钟重新连接多次。

解决方式：

MQTT 连接设备时使用 UUID 作为客户端 ID。
将每个设备注册为唯一的 客户端ID。



References
Eclipse Paho offical: https://eclipse.dev/paho/downloads
Eclipse Paho offical documentation: https://eclipse.dev/paho/documentation
MQTT 教程: https://www.emqx.com/zh/blog/category/mqtt-protocol
MQTT control packet: https://www.emqx.com/zh/blog/introduction-to-mqtt-control-packets
centos7设置emqx开机自启动: http://iotts.com.cn/blog/2023/06/28/centos7%E8%AE%BE%E7%BD%AEemqx%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8/
https://bifromq.io/zh-Hans/docs/2.0.0/best_practices/mqtt_parameters/

]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>mqtt</tag>
      </tags>
  </entry>
  <entry>
    <title>ProtoActor-go</title>
    <url>/CloudNative/CloudNative/ProtoActor-go/</url>
    <content><![CDATA[

Actorcontext.go// Context contains contextual information for actorstype Context interface &#123;	infoPart	basePart	messagePart	senderPart	receiverPart	spawnerPart	stopperPart	extensionPart&#125;type ExtensionContext interface &#123;	extensionPart&#125;type SenderContext interface &#123;	infoPart	senderPart	messagePart&#125;type ReceiverContext interface &#123;	infoPart	receiverPart	messagePart	extensionPart&#125;type SpawnerContext interface &#123;	infoPart	spawnerPart&#125;



message.go// Actor is the interface that defines the Receive method.//// Receive is sent messages to be processed from the mailbox associated with the instance of the actortype Actor interface &#123;	Receive(c Context)&#125;

Receive 方法是 Actor 接口的核心，它处理所有发送给 actor 的消息。
Receive 方法是由 ProtoActor 框架自动调用的。当一个 Actor 收到消息时，框架会自动调用该 Actor 的 Receive 方法，并将消息作为参数传递。
在 ProtoActor 的内部，这是通过消息调度器（dispatcher）和邮箱（mailbox）来实现的。当一个消息被发送到 Actor 时，它首先被放入 Actor 的邮箱。然后，调度器会从邮箱中取出消息，并调用相应 Actor 的 Receive 方法。
因此，开发者不需要手动调用 Receive 方法，只需要实现它，定义 Actor 如何响应各种消息即可。
dispatcher.go消息调度器
type Dispatcher interface &#123;	Schedule(fn func())	Throughput() int&#125;

timer.goTimerScheduler
func (s *TimerScheduler) SendRepeatedly(initial, interval time.Duration, pid *actor.PID, message interface&#123;&#125;) CancelFunc &#123;	return startTimer(initial, interval, func() &#123;		s.ctx.Send(pid, message)	&#125;)&#125;

上面的代码是一个TimerScheduler结构体中的方法SendRepeatedly的实现。这个方法的功能是创建一个定时器，定期地向指定的PID发送特定的消息。
让我解释一下这个方法的参数和功能：

initial：表示定时器第一次触发的延迟时间。
interval：表示定时器之后每次触发的间隔时间。
pid：是一个指向特定Actor实例的PID（Process ID），消息将会发送给这个Actor。
message：是要发送的消息内容。

这个方法的作用是在定时器到期时，使用ctx.Send(pid, message)向指定的Actor发送消息。定时器在创建后，会在经过initial时间段后触发第一次，之后每隔interval时间触发一次，每次触发都会向指定的Actor发送特定的消息。
返回值是一个CancelFunc类型的函数，它可以用来取消定时器。通过调用这个函数，你可以停止后续的定时触发。
这种定时器的功能通常用于在分布式系统中实现定期的任务调度、周期性的状态检查或者执行一些周期性的清理操作。它使得在Actor模型中实现定时任务变得非常方便和直观。
protoc-gen-gograinv2template.go 模板文件分析
template.go 文件是 ProtoActor 项目中的一部分，它用于生成 Go 语言的代码。这个文件主要包含一个字符串常量 code，这个常量是一个模板，用于生成服务的代码。
这个模板主要包含以下部分：

包的导入和日志设置：这部分代码导入了一些必要的包，并设置了日志的级别。

服务工厂的设置和获取：对于每一个服务，都生成了一个工厂函数的设置和获取方法。工厂函数用于生成服务的实例。

GrainClient 的获取：对于每一个服务，都生成了一个获取 GrainClient 的方法。GrainClient 是用于与服务进行通信的客户端。

Kind 的获取：对于每一个服务，都生成了一个获取 Kind 的方法。Kind 是用于在集群中注册服务的类型。

服务接口的定义：对于每一个服务，都生成了一个接口。这个接口定义了服务的所有方法。

GrainClient 的定义和方法：对于每一个服务，都生成了一个 GrainClient 的结构体和对应的方法。这些方法用于向服务发送请求。

Actor 的定义和方法：对于每一个服务，都生成了一个 Actor 的结构体和对应的方法。这些方法用于处理接收到的消息。


这个模板的主要作用是根据 protobuf 文件生成对应的 Go 语言代码，这些代码可以用于创建服务、处理请求等。
]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>protoActor-go</tag>
      </tags>
  </entry>
  <entry>
    <title>TechnicalChoose</title>
    <url>/CloudNative/CloudNative/TechnicalChoose/</url>
    <content><![CDATA[技术选型Kafka &amp;&amp; RocketMQReferences
知乎技术选型 RocketMQ or Kafka : https://zhuanlan.zhihu.com/p/60196818
RocketMQ与kafka的区别：https://blog.csdn.net/shijinghan1126/article/details/104724407
三分钟了解RocketMQ与Kafka的异同：https://juejin.cn/post/6844903920058236936

]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>technicalChoose</tag>
      </tags>
  </entry>
  <entry>
    <title>modbus</title>
    <url>/CloudNative/CloudNative/modbus/</url>
    <content><![CDATA[


References
modbus tools
www.modbus.org
Complete Modbus Guide
Modbus_Application_Protocol_V1
Frequently Asked Questions
doc: MinimalModbus
Manual_Modbus
Modbus仿真器 Modbus Poll 和Modbus Slave详细图文教程
Modbus调试软件–ModbusPoll、ModbusSlave使用详解

]]></content>
      <categories>
        <category>CloudNative</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>modbus</tag>
      </tags>
  </entry>
  <entry>
    <title>01-C++Novice</title>
    <url>/Cpp/Cpp/01-C++Novice/</url>
    <content><![CDATA[

1. concept(概念)c++ 是一种倾向于系统编程的通用编程语言，在 C 语言的基础上发展起来的，支持的特性。

supports data abstraction
supports object-oriented programming
supports generic programming  
Compile-Time (constexpr and template metaprogramming)

2. c++ basics(C++基础)
C 语言中，表达式的返回值是一个数值。C++ 中，表达式的返回值是变量的本身，可以作为左值，作为左值需要开辟一个内存空间。

endl 与 \n 区别

endl：换行和清除缓冲区到输出屏幕上
\n：仅仅只是换行


float：有效数字是 6~7 位

double：有效数字是 15 位

char：8 个 bit，占一个字节（byte）空间

取模场景

取一个数的个位数
多少天是一个月的第几天


&lt;&lt; 左移运算符：右侧空位补 0

&gt;&gt; 右移运算符：左侧空位补符号位，符号位正数部 0，符号位为负数补 1。

switch 语句后的表达式只能为整型或字符类型。break 语句：执行循环体后，调出循环。可用于 switch 结构或者循环结构。
switch (expression)&#123;case /* constant-expression */:    /* code */    break;default:    break;&#125; 
continue：只能用于循环结构，调出循环。

计算数组大小：对基本类型（不包括 String 类型）
sizeof(array_var) / sizeof(array_type)sizeof(nums) / sizeof(int) 

指针

所有的指针都要初始化
int *ptr  整型指针，结果是一个值
int *ptr  int*：指向整型的指针，结果是一个地址
void*  指针存放的是一个内存地址，地址的内容是什么类型不能确定



3. namespace(命名空间)C 中的命名空间

只有一个全局的作用域，所有的全局标识符共用一个作用域。同名的标识符之间会发生冲突。

C++的命名空间

将全局的作用域分成不同的部分，不同命名空间的标识符可以同名而不会发生冲突。// 使用标准库中封装的内容。标准库中定义的所有名字都在命名空间 std 中using namespace std&#123;  .....&#125;
全局作用域也叫默认命名空间。
命名空间之间可以相互嵌套。
:: 叫作用域运算符。std::out 从标准库中输出读取的内容，即编译器从操作符左侧名字的作用域中去寻找右侧的名字。
一般有三种方式去实现命名空间
全部打开标准库中的内容。using namespace std;
只打开标准库的部分内容。using std::cout;int main()&#123;  cout &lt;&lt; ...;  std::cin &gt;&gt; ...;  return 0;&#125;
在使用的时候根据需要打开int main()&#123;  std::cout &lt;&lt; ...;  std::cin  &gt;&gt; ...;  return 0;&#125;


使用 using 定义别名与 typedef 的用法一样。using uint64 = unsigned long long;

C++编译器不支持使用 typedef 关键词为模板类设置别名，但是使用 using 的方式声明一个关键词却是允许的，只是这个是 C++11 标准才有的，如果在编译时不加上 --std=c++11 使用新的标准的话，编译器一样会报错。

优美的命名空间名积累
internal
metal



4. header file(头文件)头文件采用防御式声明 
#ifndef __TEST_H#define __TEST_H  ...#endif

头文件名包含在尖括号 &lt;&gt; 中，则 C++ 编译器将在存储标准头文件的主机系统的文件系统中查找；但如果文件名包含在双引号 &quot;&quot; 中，则编译器将首先查找当前的工作目录或源代码目录（或其他目录，这取决于编译器）。
类的声明和实现时分开的。通常 .h 文件只作类的声明，.cpp 文件进行类的实现。
5. reference(引用)5.1. ordinary reference(普通引用)在 C++ 中采用 &amp; 符号表示引用，只是给对象起了一个别名。引用的功能主要是传递函数的参数和返回值。从使用者的角度，引用类似是一个别名，没有自己的内存空间，这是因为 C++为了实用性，隐藏了相关细节。实质上引用有自己的内存空间。
引用初始化

引用被创建的同时必须被初始化，而指针则可以在任何时候被初始化。 一旦引用被初始化，就不能改变引用的关系，而指针则可以随时改变所指的对象。
单独定义引用时，必须要 初始化。
引用作为函数的参数声明时，不 需要进行初始化。
不能有 NULL 引用，引用必须与合法的存储单元关联，而指针则可以是NULL。

引用使用时注意点

传引用的效率比指针高，传递的直接是对象，而不是把对象复制。
函数内部的引用参数值可能会改变，一般需要加 const 解决。
不要返回局部变量的引用，全局变量和静态变量可以作为返回值的引用。 
C++编译器在编译时使用一个常量指针作为引用的内部实现。因此，引用占用的内存空间大小与指针占用空间大小相同。type&amp; name &lt;==&gt; type* const name

指针的引用 

格式 const int* &amp;a
指针的引用做函数参数
函数二级指针作为输出变量






5.2. lvalue reference(左值引用)左值就是一个能够被修改的变量。

引用 作为 左值时，返回的是变量的本身，是变量而不是值（value）。变量只能是全局变量或静态变量，不能是局部变量，否则会出现 Segmentation fault。
函数的返回值作为一个 左值时，应该返回的是一个引用(reference)。
左值表达式表示的是一个对象的身份。
变量表达式是一个左值，作用的时间比较长，右值的作用时间比较短暂。

5.3. rvalue reference(右值引用)何为右值引用？

必须绑定到右值的引用，采用 &amp;&amp; 来获得右值引用，而不是 &amp; 
右值表达式表示的是对象的值。
右值引用只能绑定到一个将要被销毁的对象，该对象没有其它的用户。

std::move()

显式的将左值转化为对应的右值引用类型。
使用 move() 函数时告诉编译器，处理左值时像右值一样去处理它；对左值进行赋值或销毁外，不再使用它。

5.4. const reference(常量引用)让变量的引用拥有只读 (read-only) 的属性。
int x = 10;const int &amp;y = x;   // 不能通过y去修改x的值 

初始化

用变量初始化常引用。int x = 10; const int &amp;y = x;
用自变量初始化常引用。const int &amp;a = 100; 
使用常量引用进行初始化时，C++编译器会为常量值分配空间，并将引用名作为当前分配空间的别名。

6. function(函数)C++ 对函数的检查更严格。C++ 支持 bool 类型：C++中的 bool，只占 1 个字节。
6.1. inline(内联函数)函数定义时，加 inline 关键字，例如 inline void func()&#123;&#125;。内联函数的关键字 inline 与函数体的实现在一起，不需额外的声明。 
实现机制

C++编译器直接将函数体插入函数调用的地方。

什么时候可以用 inline？

函数体不能过大。
函数声明必须在调用之前声明。
不能对函数进行取值地址操作。 
不能存在任何形式的循环语句（for、while）。
内联函数省去了普通函数调用时的压栈、跳转、返回操作。

6.2. function parameter(函数参数)默认参数

函数的参数有一个默认的值。
函数带有参数列表，参数列表的右边必须有默认的值，左边可以不给默认参数赋值。

占位参数

只有函数类型声明，没有函数变量声明。int func(int a, int b, int)

6.3. template function(模板函数)什么是模板函数？

函数定义时不指定具体的数据类型，建立一个通用函数。函数调用时，根据实际的参数反推数据类型，即类型的参数化。

6.4. conversion function(转换函数)函数没有返回值，没有参数，函数的类型为需要转换的类型。通常转换函数中的内容都是不应该改变的，可以设置为 const。



6.5. functor(仿函数)什么是仿函数？

一个 class 类中重载了函数调用操作运算符 ()，任何一个东西能接受 () 操作运算符，这个东西就叫 像函数 或者叫 仿函数。



思考：为什么 C++ 中要把 class 设计成 pointer(智能指针)和 function(仿函数)？
7. Special member function (类中特别的成员函数)7.1. constructor(构造函数)为什么要用构造函数？

被用来初始化类的对象。  
类对象被创建时，编译器为对象(object)分配内存空间，并自动调用构造函数，完成成员的初始化

构造函数特征 

构造函数的 函数名称 与 类的名称 一样。
函数没有返回值
函数参数值
创建的对象有默认值时，应传入创建对象的默认值。
创建的对象没有默认值时，编译器传入的默认值为 0



构造函数注意点

构造函数是一个 成员函数，函数内有一个 this 指针
构造函数的访问属性可以放在 private 中。在单例模式（singleton）中就采用这种用法。
构造函数 与 析构函数 在类中声明了 ，必须要通过类的方法去实现，即声明了必须要用，否则编译时会报错。
多线程编程中，构造函数不能保证线程的安全。

类中默认的构造函数

默认无参数构造：当类中没有定义构造函数时，C++编译器会默认提供一个无参数构造函数，构造函数的函数体为空。
默认拷贝构造：当类中没有定义拷贝构造函数时，C++编译器会默认提供一个拷贝构造函数（浅拷贝），简单的进行成员变量的值拷贝操作。

构造函数分类

无参构造：一般为栈内存空间，自动释放内存空间。调用时不用 加括号。

带参数构造(重载了构造函数)

一般为堆内存空间，需要使用delete释放内存空间；使用 new 关键字创建空间

一般需要初始化构造的参数

有默认值参数的构造函数，需要在类的声明中指定默认参数值，一般只能指定一次，在构造函数实现时不需要再给出默认值，否则会报错。
// 有参构造函数三种调用方法Test t1(10);         // 括号法Test t2 = t1;         // 等号法Test t3 = Test(30);  // 直接调用构造函数


拷贝构造
// 声明一个类class String()&#123;  private:    ...  public:    ...&#125;// 实例化一个对象String st_one;// 拷贝构造String st_two = st_one;   // 方法一：等号(=)是拷贝一个对象不是赋值运算String st_three(st_one)   // 方法二：初始化拷贝构造

构造函数在继承中的用法

构造函数与父类的其它成员(成员变量和成员方法)不同，它不能被子类继承。因此，在创建子类对象时，为了初始化从父类中继承来的成员变量，编译器需要调用其父类的构造函数。如果子类的构造函数没有显示地调用父类的构造函数，则默认调用父类的无参构造函数。 


子类与父类均没有声明构造函数时，C++编译器会默认生成构造函数去调用。 
子类继承父类的方法，默认会调用父类的无参数构造函数，再调用子类的无参或有参构造函数。
当父类为有参构造函数时
父类的有参构造函数有默认的值时，子类中不需要显式地调用父类的构造，C++编译器会默认的调用父类的有参构造函数。
父类的有参构造函数没有默认的值时，子类中需要显式地调用父类的构造class Parent&#123; private: public:   Parent(int a, int b)&#123;&#125;;&#125;class Child:public Parent&#123;private:public:  Child(int m, int n):Parent(a, b)     // 显示的调用父类的构造函数&#125;
父类中既有无参默认构造又有带参默认构造函数时，子类继承父类时，需要子类显示的指定到底该调用哪一个构造函数。





Initialization(初始化)
  类中成员的初始化
struct Widget&#123;    int a;        // 没有初始化，获得一个任意的值    string s;     // 默认初始化为 empty string    int* ptr;     // 没有初始化，指向任意的地址&#125;;int main(int argc, char *argv[]) &#123;    Widget w;    return 0;&#125;

struct Widget&#123;    int a;        // 初始化为 0    string s;     // 默认初始化为 empty string    int* ptr;     // 初始化为 n&#125;;int main(int argc, char *argv[]) &#123;    Widget w&#123;&#125;;    return 0;&#125;

struct Widget&#123;    Widget()    &#123;        a = 10;        s = &quot;hello&quot;;        ptr = nullptr;    &#125;    int a;            string s;         int* ptr;     &#125;;

构造函数中初始化，都是属于赋值操作（assignment operator）,
7.2. copy constructor(拷贝构造)
拷贝构造函数是由普通构造函数和赋值操作符共同实现的。
拷贝构造函数必须以 引用(reference)的形式传递(参数为引用值)。
拷贝构造函数使程序更有效率，因为它不用再构造一个对象的时候改变构造函数的参数列表
当某对象是按值传递时（无论是类的对象作为函数参数，还是作为函数返回值），编译器都会先建立一个此对象的临时拷贝，而在建立该临时拷贝时就会调用类的拷贝构造函数。



浅拷贝（shallow copy）

当类的对象发生复制过程的时候，类的对象自己有资源（堆或者是其它系统资源），但复制过程中并未复制资源，只是改变了指针的指向，这种称为浅拷贝。

只是将类的成员值进行拷贝，类指针没有进行拷贝，两个指针同时指向一块内存空间。
// 没有做任何的说明，C++编译默认使用的是浅拷贝。People obj_2 = obj_1;   将obj_1对象的内容拷贝到obj_2对象中，不是拷贝的指针。
浅拷贝完成后，在释放资源的时候会产生资源归属不清的情况，导致一个指针指向已经被删除的内存空间，使程序运行出错。即销毁对象时，两个对象的析构函数将对同一个内存空间释放两次。



深拷贝（deep copy）

当类的对象发生复制过程的时候，类的对象自己有资源（堆或者是其它系统资源），但拷贝过程中复制了资源，这种将一个对象的资源完整的拷贝到另一个对象的过程，称为深拷贝。
不仅拷贝了类的 成员变量值，还拷贝了类的指针，两个指针指向两块不同的内存空间。


什么时候用深拷贝和浅拷贝？

类中没有自定义拷贝构造函数时，编译器会默认调用浅拷贝，完成成员的复制。
当类的成员中没有指针时，浅拷贝是可行的。
当类的成员中有指针时，如果采用简单的浅拷贝，则两类中的两个指针将指向同一个地址，当对象快结束时，会调用两次析构函数，而导致指针悬挂现象，因此必须要用深拷贝。



参考

c++拷贝构造函数详解

7.3. copy assignment operator(拷贝赋值)// 将对象s1拷贝赋值给对象s2，内部处理过程分3步：class MyString&#123;private:    char* m_data;public:    MyString(const char* cstr = 0) &#123;&#125;             // 带有初始值的构造函数    MyString(const MyString&amp; str) &#123;&#125;              // 深拷贝构造    MyString&amp; operator=(const MyString&amp; str);     // 操作符重载，拷贝赋值    ~MyString() &#123;&#125;    char* getStr() const &#123;return m_data;&#125;&#125;;MyString&amp; MyString::operator=(const MyString&amp; str) &#123;  if (this == &amp;str)   // 进行自我赋值检测  &#123;    return *this;  &#125;  delete[] m_data;                           // 1、释放原先数据m_data的内存空间  m_data = new char[strlen(str.m_data) + 1]; // 2、重新给m_data 分配内存空间  strcpy(m_data, str.m_data);                // 3、执行拷贝操作  return *this;&#125;// 在拷贝之前需要进行自我赋值检测。即自己把值赋给自己，保证在执行第二步操作时，指针有指向的位置。// 若不进行自我检测步骤，先释放原先数据m_data的内存空间后，此时指针m_data没有一个确定的指向，// 不能重新分配内存空间，导致程序出错。


7.4. Move constructor(移动构造)7.5. Move assignment operator(移动赋值操作)7.6. destructor(析构函数)析构函数就是一个函数，只不过这个函数的函数名称与类名一样，在函数名之前还多了一个波浪号 ~。例如：string::~string()，就是 string 类的析构函数。
析构函数作用：类的对象离开作用域后释放对象使用的资源，在类死亡之前的前一刻调用，用于清除类中的资源（比如：释放内存）。
析构函数注意点：

一个类只能有一个析构函数，若有多个类则有多个析构函数。如果没有显式的定义析构函数，编译器会自动生成一个默认的析构函数。
析构函数不能 重载。每有一次构造函数的调用就会有一次析构函数的调用。
只有当一切的构造动作都完成时，析构函数才有可能会被调用。因为在构造函数中可能会抛出异常从而导致程序结束。

什么时候析构函数被调用？

对象生命周期结束，对象被销毁时，编译器自动调用析构函数。
手动去释放内存，用 delete 关键字时，先执行 delete，释放掉在堆上申请的内存后，再调用析构析构函数。

8. empty class若 C++ 中一个 class 中什么也没有写，就是一个空的类（empty class），形如 class Stu &#123;&#125;; 这样。程序编译时，C++ 编译器会给这个 empty class 提供默认构造函数（constructor）、析构函数（destructor）、拷贝构造函数（copy constructor）、拷贝赋值函数（copy assignment），并且这些函数的默认属性都是 public 且内联（ inline）。

思考：为什么 C++ 中一个空类的大小为 1byte ？
空类中没有函数和数据成员，但可以实例化类；一个类能被实例化，编译器就要给他分配空间，来指示类实例化的地址，通常编译器分配为 1 个字节（char类型），这样分配同时也保证了 空类占用的空间最小。


通常情况下，编译器生成一些函数
class Widget&#123;  public:     Widget();                                  // Default constructor     Widget(Widget const&amp;);                     // copy constructor      Widget&amp; operator= (Widget const&amp;);         // Copy assignment operator     Widget(Widget&amp;&amp; ) noexcept;                // Move constructor     Widget&amp; operator= (Widget&amp;&amp;) noexcpet;     // Move asignment operator     ~Widget();                                 // destructor&#125;;


9. class object &amp;&amp; class pointer类对象与类指针的区别
// 定义一个类class Stu&#123;private:public:&#125;


类对象
格式：Stu s1;
定义之后就已经为 s1 这个对象在栈上分配了内存


类指针
格式：Stu *s2 = new Stu;
定义 *s2 的时候没有分配内存，只有执行 new 后才会在堆上分配内存，是个永久的变量，需要用 delete 关键字手动去释放它。



10. new &amp;&amp; deletewindows 下内存显示总是 16 的倍数，若果不是 16 的倍数，则填充为最靠近 16 的倍数的大小。 
new 动态分配内存 

先分配 memory，再调用构造函数 

new 创建一维动态数据
// 普通类型根据哪种数据类型来分配内存？根据数据类型来确定分配多少内存？找到这样的内存，并返回其地址。格式：typeName* pointer_name = new typeName 例如：int *p = new int;指针 p 指向的内存没有名称，那么要如何称呼它呢？我们说指针 p 指向一个数据对象， 这里的“对象”不是“面向对象编程”中的对象， 而是一种“东西”，它指的是为数据项分配的内存块。 数据对象：可以是复杂的结构类型，也可以是基本类型。// 一维数组typeName* pointer_name = new typeName[num_elements];例如：int *p = new int[10];注意：将数组的元素类型和元素数目告诉new即可。 必须在类型名后加上方括号， 其中包含元素数目。new运算符返回第一个元素的地址。

创建二维数组
格式：typeName (*ptr)[col_num] = new typeName[row_num][col_num];例子：int (*ptr)[2] = new int[4][2];
创建对象
class Airplane&#123;  ...&#125;Airplane *ap = new Airplane;

delete 释放内存，与 new 配对使用。

先调用析构函数，再释放 memory  
注意
不要使用 delete 释放同一个内存块两次。
不是用 new 分配的动态内存空间，不能用 delete 释放
对空指针使用 delete 是安全的。
采用 array new 的方式创建一块内存空间，则一定要采用  array delete 方式去释放内存，否则在涉及指针的时候可能会导致内存泄漏。泄漏的并不是整个分配的内存空间，而是分配的空间中数组没有被释放的部分。
不配对地使用 new 和 delete，将发生内存泄漏(memory leak)，被分配的内存再也无法使用了，如果内存泄漏严重，则程序将由于不断寻找更多内存而终止。





class member operator new()






标准库中使用 placement arguments new 的例子 


11. overload(重载)函数重载是指函数名相同，参数表列个数或顺序、类型不同的函数。注意：不能靠函数返回类型来判断，因为函数的返回值不是判断函数重载的标准。
函数重载的特点

在同一个作用域中（C++中构造函数也可以重载）。
函数名字相同。
参数不同。
virtual 关键字可有可无。
返回值可以不同。
子类无法重载父类的函数。如果子类与父类的函数名称相同，则发生函数名称覆盖，不会发生函数重载。若想在子类和父类中分别调用具有相同名称的函数，则需要使用域分符号 ::
当子类中没有与父类相同参数的函数，只有名称相同的函数时，而子类去调用父类中重载的函数，则 C++ 编译器会将子类中有相同函数名称的函数去覆盖掉父类中相同名称的函数，从而将当前子类调用父类的函数当做子类中一个新的重载函数，但是编译器发现子类中并没有该函数的重载，因此会报错。

函数重载底层实现原理：编译器在编译时，根据函数的参数列表进行重命名。
12. override(重写)重写（也称为覆盖 override）是指派生类重新定义基类的虚函数。必须发生在子类与父类之间，并且父类与子类的函数具有完全相同的原型。使用 virtual 关键字声明后，能够产生多态，没有使用 virtual 关键字，只能叫重定义，不叫虚函数重写。

不在同一个作用域，分别位于派生类与基类。
函数名字相同。
参数相同。
基类函数必须有 virtual 关键字，不能有 static。
返回值相同，否则会报错。
重写函数的访问修饰符可以不同。若基类中函数的修饰符是 private，派生类中重写的函数可以是 public，protected。


 
    重载与重写的区别
1. 作用域不同：重载是在同一区域，子类无法重载父类，父类同名函数的将被覆盖，重写 是在父类与子类之间。
2. 重载是静态多态性，在编译期间确定执行的函数或运算符。
3. 重写是动态多态性，运行期间确定执行的函数，根据对象的实际类型调用相应的函数。




13. const
C 语言中，const 是只读的变量，有自己的存储空间。
C++ 中，const 可能分配存储空间，也可能不分配存储空间。
当 const 作为全局变量，并在其它的文件中到调用时，会分配存储空间。
采用 &amp; 地址运算符去取 const 变量的地址时，会分配存储空间。


加 const 后，不会改变数据的内容，不加const，则会改变数据的内容，一般数据的内容定义在 private中。

const 放在函数声明前表明函数的 返回值是 const 类型，不能修改。
const int add(int x, int y)&#123;  return x+y;&#125;

定义 const 成员函数时，把 const 关键字放在函数的参数表和函数体之间作用：表用该函数的数据成员不能被改变，const 修饰的是 this 指针指向的内存空间。如果在编写 const 成员函数时，不慎修改了数据成员，或者调用了其它非 const 成员函数，编译器则将报错。
class Complex&#123;public:  double real(int a, int b) &#123;    return re;  &#125;  // 不加const时，C++编译器简单编译等价为，不允许我们手动去改变this指针，否则会编译器会报错  double real(Complex* const this, int a, int b) &#123;    return re;  &#125;  double real(int a, int b) const &#123;    return re;  &#125;  // 在编写代码时，隐藏了this指针，不用书写；但实际上C++编译器已经帮我们做好了this指针的处理，加const后，上面的成员函数等价于下面的函数  double real(const Complex* const this, int a, int b) &#123;    return re;  &#125;&#125;;

 
注意：void test() const {}; 这样定义的函数只能作为类的成员函数，不能作为一个全局的函数，即非类的外部这样使用，编译器会报错。


在类中采用 const修饰函数，需要在类调用时必须加 const
// definitionconst class complex&#123;&#125;;// 调用：const complex fx(1, 2);


const 对象只能调用 const 成员函数，const 类对象成员的数据在类对象的生命周期内不能改变。
const 成员函数是对 const 对象的限制；const 成员函数只能读类对象成员的数据，不能修改类对象成员的数据。



Tips：const 常量与 宏定义 用法比较
（1）编译器处理方式不同。
宏定义（#define） 是在 预处理 阶段展开的，仅仅只是单纯的文本替换，不做计算，不做表达式求解，不能对宏定义进行调试，生命周期结束在编译时期；而 const常量 是在程序运行阶使用的，类似于一个只读的数据。
（2）类型和安全检查不同。
 const常量 有具体的数据类型，在编译阶段提供作用域检查和类型检查；而 宏定义 没有类型，不做任何类型检查，仅仅是展开。
（3）定义域不同。

宏定义可以通过 #undef 来使之前的宏定义失效
const 常量定义后将在定义域内永久有效。const 不能重定义，而 #define 可以通过 #undef 取消某个符号的定义，再重新定义。

（4）存储方式不同。
宏定义 仅仅是展开，有多少地方使用，就展开多少次，不会分配内存；const常量 可以在堆或栈中分配内存。
（5）const  可以节省空间，避免不必要的内存分配。
const定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象 #define 一样给出的是立即数，所以，const 定义的常量在程序运行过程中只有一份拷贝（因为是全局的只读变量，存在静态区），而 #define定 义的常量在内存中有若干个拷贝，每使用一次宏就拷贝一次。
#define PI 3.14159       // 常量宏，作用域为全局const doulbe Pi=3.14159; // 此时并未将Pi放入ROM中double i=Pi;             // 调用 const 常量，此时为Pi分配内存，以后不再分配 double I=PI;             // 调用宏，编译期间进行宏替换，分配内存 double j=Pi;             // 调用 const 常量，没有内存分配 double J=PI;             // 调用宏，再进行宏替换，又一次分配内存

（6） 提高了效率。 
编译器通常不为普通 const常量 分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。
14. staticstatic 成员定义

一个 static 数据成员只能被定义一次。static 数据成员类似于全局变量，定义在任何的函数之外，一旦被定义，就一直存在与程序的整个生命周期内。
既可以在类的外部定义又可以在类的内部定义 static 成员，但是在类的外部定义时，不能重复 static 关键字，static 只出现在类的内部。

static 成员初始化

若在类的内部提供了一个初始值，则在成员的定义时，不能再赋初值了。
不能在类的内部初始化静态成员，必须在类的外部初始化每个静态成员。
不能在构造函数或初始化列表中初始化静态成员。


static 修饰的成员函数是属于 class 本身，在类加载的时候就会分配内存，可以通过类名直接去访问；而非 static 修饰的成员函数是属于 类的对象，只有在类的对象产生（创建类的实例）时才会分配内存，然后通过类的对象（实例）去访问。


非静态成员初始化

const 类型的成员变量只能在初始化列表中初始化。
非 const 类型的成员变量可以在构造函数或初始化列表中初始化。

继承中的 static

需要在类的外部进行初始化，并且C++编译器在外部初始化的同时还给变量分配内存空间，只有在使用时才分配内存空间，不调用不分配内存空间。

类模板中的 static

每个类模板中都有自己的类模板 static 数据成员副本。
与非类模板的 static 数据成员一样，类模板中的 static 数据成员也需要进行定义和初始化。

static 成员与非 static 成员的区别?

一个类的成员变量为 static 成员变量时，这个类中无论有多少个对象被创建，这些对象都共享这个 static 成员；即静态成员独立于任何的对象。
静态成员可以作为默认的参数，而非静态成员不能作为默认的参数，因为它本身的值属于对象的一部分。

为什么要用 static 成员函数？

由于没有 this 指针，可以把某些系统 API 的回调函数以静态函数的形式封装到类的内部。因为系统 API 的回调函数通常都是那种非成员函数，没有 this 指针的。比如你可以在类的内部写一个线程函数供 CreateThread 创建线程用，如果没有静态函数，那么这种回调函数就必须定义成 全局函数（非静态成员函数指针无法转换成全局函数指针），从而影响了OOP的“封装性”。
封装某些算法，比如数学函数，如 ln，sin，tan等等，这些函数本就没必要属于任何一个对象，所以从类上调用感觉更好，比如定义一个数学函数类Math，调用Math::sin(3.14);如果非要用非静态函数，那就必须：Math math;math.sin(3.14); 行是行，只是不爽：就为了一个根本无状态存储可言的数学函数还要引入一次对象的构造和一次对象的析构，当然不爽。而且既然有了对象，说不得你还得小心翼翼的定义拷贝构造函数、拷贝赋值运算符等等，对于一些纯算法的东西显然是不合适的。

静态对象（static object）：在作用域（scope）结束后，生命周期还存在，即没有结束，一直到整个程序结束了，它的生命周期也就结束了。

静态的函数没有 this pointer，只能去处理静态的数据如何去调用？ 1、使用 object 调用。Account a.state(10);2、通过 class name 来调用。Account::state(10);

全局对象（global object）：整个程序结束了，它的生命周期也就结束了。
15. this
C++中的成员函数和成员变量是分开存储的。
什么叫成员函数：在类（class）中声明的函数。
什么叫非成员函数：没有在类（class）中声明的函数，非成员函数也叫全局函数。

什么是 this?
this 是C++中的一个关键字，是一个指针（pointer）。在面向对象中，哪个对象调用非静态成员函数，this 指针就指向哪个对象。静态成员函数中不包含 this 指针，非静态成员函数中包含 this 指针。
成员函数中 const 修饰的是谁？
class TT&#123;private:  ......public:  void func(int a, int b) const  &#123;&#125;&#125;// 由C++面向对象模型知，上面的函数等价于void func(TT *this, int a, int b) const&#123;&#125;// const 修饰的是this指针指向的内存空间。

类名后直接加括号，表示是一个临时对象(local object)。
//声明类class Complex&#123;public:    // 主要放置函数    ........private:    // 定义数据    ........&#125;// 调用临时对象Complex();

匿名对象什么时候留下？什么时候被析构？

用匿名对象初始化一个同类型的对象，则匿名对象转化为有名字的对象。
用匿名对象赋值给另外一个对象，则匿名对象被析构。

16. mutable16.1. mutable是什么？mutable的中文译为 “可变的，易变的”，是 constant（即 C++ 中的 const ）的反义词。C++ 中为了突破 const 的限制而采用的，被 mutable 修饰的变量将永远处于可变的状态。
16.2. 为什么要用mutable？
我们知道，如果类的成员函数不会改变对象的状态，那么这个成员函数一般会声明成 const 的。但是，有些时候，我们需要在 const 的函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被 mutable 来修饰。
mutable 常用于指定不影响类的外部可观察状态的成员（通常用于互斥体[mutexes]、记忆缓存 [memo caches]、惰性求值 [lazy evaluation]和访问指令 [access instrumentation] 等）。

class ThreadsafeCounter &#123;mutable std::mutex m; // mutable 和 mutex 用在一起情况int data = 0;public:int get() const &#123;    std::lock_guard&lt;std::mutex&gt; lk(m);    return data;&#125;void inc() &#123;    std::lock_guard&lt;std::mutex&gt; lk(m);    ++data;&#125;&#125;;


16.3. 使用 mutable 的注意事项mutable只能作用于类的非静态和非常量数据成员。mutable不能修饰static数据成员，因为static数据成员存储在Data段或BSS段，属于类，不属于类对象，因此类的static数据成员不需要 mutable 的修饰。但常对象和常函数可以对其任意地修改，对于常对象的数据成员一般不可以被修改，若想修改，则需要 mutable 的修饰。
在一个类中，应尽量或者不用 mutable，大量使用 mutable表示程序设计存在缺陷。
class Student&#123;string name;mutable int getNum;             // okmutable const int test;         // 编译出错//mutable static int static1;   // 编译出错&#125;


16.4. 常函数
什么是常函数？常函数就是带 const 修饰的函数。
为什么要有常函数这个概念？为了封装的良好性，有时我们用到的一些函数并不需要我们去改变类中的参数和成员变量，仅仅只是为了显示和输出的作用，因此才引进常函数。

参考

cpp reference官网解释mutable关键字: https://en.cppreference.com/w/cpp/language/cv
C++ mutable 的用法: https://blog.csdn.net/K346K346/article/details/48030597
C++中的mutable关键字

17. pass by value &amp;&amp; pass by reference参数传递与返回值传递的区别

传值(pass by value)是将整个的数据传递给调用者
传引用(pass by reference)本质是 传指针。
采用一个 &amp; 符号表示。
希望调用者对传递的数据不能进行修改，在数据前加 const 限制。


参数传递时：在能使用传reference的前提下，一般优先使用 传引用 而尽量少使用传值，并不是必须的。传引用 的速度比 传值 速度快。
函数返回 值传递 时：在能使用传reference的前提下，一般优先使用 传引用 而尽量少使用传值，并不是必须的。 
什么情况下不能使用 引用传递（reference）？
当一个函数参数的变量为局部变量时，不能使用传引用。因为变量在函数结束时，变量就被销毁了，不存在，若再传递引用，调用者则不能得到值，会出错。



18. friend(友元)友元函数

在一个类中使用 friend 关键字时，不是当前类的成员函数可以去访问当前类的私有成员或 protect成员 数据。
重载运算符 &lt;&lt; 和 &gt;&gt; 一般使用友元函数，其它的函数一般定义为 类的成员函数。
类模板 中一般不要滥用友元函数，使用会很复杂，若将 .h 文件与 .cpp 文件分开实现，将会更加的复杂。

同一个 class 中的各个对象(object) 互为友元。
// 函数定义：int func(const complex&amp; param)&#123;    return param.value;&#125;// 声明对象:complex c1;complex c2;c2.func(c1);   // 采用友元的方式实现，通过对象参数访问私有成员数据

友元类

若B类是A类的友元类，则B类的所有成员函数都是A类的友元函数。
通常是为设计一种数据操作或类之间传递消息的辅助类。

采用友元的优缺点

优点
可以灵活地实现需要访问若干类的私有或受保护的成员才能完成的任务；
便于与其他不支持类概念的语言(如C语言、汇编等)进行混合编程；
通过使用友元函数重载可以更自然地使用C++语言的IO流库。


缺点
一个类将对其非公有成员的访问权限授予其他函数或者类，会破坏该类的封装性，降低该类的可靠性和可维护性。



19. operator overloading(操作运算符重载)为什么要操作符重载？
普通的运算规则不能满足复杂的数据类型，像类（class）数据类型，需要编程人员自定义运算规则去实现。操作运算符重载的本质是个 函数。
操作符重载有两种实现的方式

非成员函数方式，即全局函数（全域）的方式。
通常与 friend 友元函数结合在一起使用。
应用场景：重载不同类之间的操作符。例如，重载 &lt;&lt; 和 &gt;&gt;，编程人员自定义的类与C++编译器中 ostream 或 istream 类中的数据进行操作符重载。


成员函数方式。
函数的参数有一个隐藏的 this 指针，可以在函数里面去调用。



分析重载的步骤？

确定函数名称
确定函数参数
根据业务，确定函数的返回值类型（是返回引用还是返回值？）以及函数体的实现。

= 赋值操作符重载。= 赋值操作只是将成员变量的值相应复制。若对象内包含指针，将造成不良后果：指针的值被丢弃了，但指针指向的内容并未释放。 
20. smart pointer(智能指针)自 C++11 起 C++ 标准库提供了两种类型的智能指针：shared_ptr 和 unique_ptr。而所有的智能指针都被封装在标准库的 &lt;memory&gt; 头文件中，要使用智能指针必须引入 #include &lt;memory&gt; 头文件。
20.1. 为什么要使用智能指针？
动态分配内存时可能会出现一些问题
忘记释放内存，会造成内存泄漏
有指针引用内存的情况下，释放了内存，产生引用非法内存的指针。


需要更加安全的来管理动态内存。动态内存分配常用 new 和 delete 来分配内存。不使用 smart pointer 时，用动态内存分配时，可能会忘记 delete，导致内存泄漏；也可以使用异常捕获，但是会导致代码比较臃肿，不易阅读和维护。因此智能指针可以很好的解决这个问题。
负责自动释放所指向对象的内存资源。智能指针就是一个类（class），当智能对象超出了类的作用域时，类会自动调用析构函数，释放资源。

20.2. 智能指针原理智能指针底层源码采用类模板（class template）来实现的，并不是一个简单的普通指针。可以用下面的模型来简单的表示
20.3. 使用智能指针的优点在函数结束时自动释放内存空间，不需要手动释放内存空间。
20.4. auto_ptr
auto_ptr 智能指针采用所有权模式。
已被 C++11弃用，潜在内存崩溃问题。
存在非法的申请内存时，在编译期时可能通过，但程序在运行时可能会出错。

20.5. unique_ptr20.5.1. 概述unique_ptr 实现的是一种独一无二拥有权 (exclusive ownership) 的概念。保证一个对象和其相应资源同一时间内只能被一个智能指针拥有(ownership)。当 unique_ptr 被销毁时，它所指向的对象也就自动销毁。
20.5.2. 为什么要用 unique_ptr它对于避免资源泄露，例如以 new 创建对象后因为发生异常而忘记调用 delete特别有用。 
20.5.3. 初始化unique_ptr 智能指针提供三种方式进行对象的初始化。构造函数中初始化、移动构造函数中初始化 std::move()、采用 reset() 成员函数进行初始化。

unique_ptr 不允许执行 copy(拷贝) 和 assignment(赋值) 操作。但是可以用 std::move() 语义将对象的拥有权转移。
// initialize a unique_ptr with a new objectstd::unique_ptr&lt;ClassA&gt; up1(new ClassA);// copy the unique_ptrstd::unique_ptr&lt;ClassA&gt; up2(up1);  // ERROR// assign the unique_ptr, transfer ownership from up1 to up3std::unique_ptr&lt;ClassA&gt; up3(std::move(up1));    // OK

当程序试图将一个 unique_ptr 赋值给另一个时，如果源 unique_ptr 是个临时右值，编译器允许这么做；如果源 unique_ptr 将存在一段时间，编译器将禁止这么做。
unique_ptr&lt;string&gt; pu1(new string (&quot;hello world&quot;)); unique_ptr&lt;string&gt; pu2; pu2 = pu1;                                      // 不允许拷贝构造unique_ptr&lt;string&gt; pu3; pu3 = unique_ptr&lt;string&gt;(new string (&quot;You&quot;));   // 允许
想要执行  pu2 = pu1; 的操作，又要保证指针的安全。可以用C++有一个标准库函数 std::move()，让你能够将一个 unique_ptr赋给另一个。

尽管转移所有权后 还是有可能出现原有指针调用（调用就崩溃）的情况。但是这个语法能强调你是在 转移所有权，让你清晰的知道自己在做什么，从而不乱调用原有指针。


unique_ptr 可以转移对象的拥有权。使unique_ptr 不必一定拥有对象，它也可以是 empty；例如：当它被默认构造函数创建时。
std::unique_ptr&lt;std::string&gt; ip;ip = nullptr;ip.reset();

20.5.4. 成员函数
move(): 转移对象的拥有权
reset(): 销毁内部对象并接受新对象的所有权并将该智能指针被置为空，等价于 up &#x3D; nullptr
release(): 放弃内部对象的拥有权
swap(): 交换两个指针指向的对象(即交换所拥有的对象)。
get(): 获得内部对象的指针

20.5.5. unique_ptr 删除器unique_ptr 也有自己的 删除器。
// 但lambda 表达式中没有写捕获参数时，要实现自己的删除器，需要在模板参数中指定其参数类型using func = void(*)(Stu*);    // void 类型的函数指针unique_ptr&lt;Stu, func&gt; s1(new Stu(100), [](Stu* p)&#123;      delete p;&#125;);// 有捕获参数时，unique_ptr 模板参数类型为 仿函数的返回类型unique_ptr&lt;Stu, std::function&lt;void (Stu*)&gt;&gt; s2(new Stu(200), [&amp;](Stu* p)&#123;      delete p;&#125;);// 申请的内存为数组类型时，模板参数为数组类型unique_ptr&lt;Stu[]&gt; ptr1(new Stu[3]);

独占的智能指针能管理数组类型的地址，能够自动释放。
unique_ptr&lt;Stu[]&gt; ptr1(new Stu[3]);

C++11 中 shared_ptr 不支持下面的语法，自C++11之后的版本，开始支持下面的语法。
shared_ptr&lt;Stu[]&gt; ptr1(new Stu[3]); 

注意点unique_ptr 智能指针创建对象时，在 C++11 版本没有提供 std::make_unique() 的方式去创建对象，只能用 new 关键字创建对象。 
std::unique&lt;Employee&gt; employee(new Employee);// 不需要显示去调用delete，智能智能自动去调用delete

std::make_unique 在 C++14 中引入，可用下面的方式去创建对象。
auto employee = std:make_unique&lt;Employee&gt;();

若编译器版本只支持 C++11，可以自己封装一个 std::make_unique 函数去实现。
template&lt;typename T, typename ...Args&gt;std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp; ...args) &#123;  return std::unique_ptr&lt;T&gt;(new T( std::forward&lt;Args&gt;(args)... ));&#125;


20.6. shared_ptr20.6.1. 概述share_ptr 实现的是一种共享所有权 (shared ownership)的概念。多个智能指针可以指向同一个对象，该对象和它的相关资源会在最后一个指针的指向 (reference) 被销毁时，得到释放。
20.6.2. 为什么要使用 shared_ptrshared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性(auto_ptr 是独占的)，在使用引用计数的机制上提供了可以共享所有权的智能指针。  
20.6.3. 成员函数
use_count() 返回引用计数的个数
unique() 返回指针对象的拥有者是否唯一(等价于 use_count&#x3D;1)
swap() 交换两个 shared_ptr 对象(即交换所拥有的对象)
reset() 放弃内部对象的所有权或拥有对象的变更, 会引起原有对象的引用计数的减少。简单来说，主要有两个作用：1、让指针指向另一块内存；2、重置指针，即让引用计数变为 0。
get() 获得被 shared_ptr 包裹的内部对象, 即获得原始的指针，类似 *p 这样的。
get_deleter() 返回删除器 (deleter) 的地址。

20.6.4. 底层原理采用 引用计数 的方法，记录当前内存资源被多少个智能指针引用，该引用计数的内存在堆上分配。当新增一个指针时，引用计数 加1，当释放时 引用计数 减一。只有引用计数为0时，智能指针才会自动释放引用的内存资源。
20.6.5. 初始化shared_ptr 有四种初始化方式。

通过构造函数初始化。

通过移动构造函数或者拷贝构造函数初始化。

通过 reset() 函数进行初始化。

通过 make_shared 初始化。用 shared_ptr 进行初始化时不能将一个普通指针直接赋值给智能指针，因为一个是指针，一个是类。但可以通过 make_shared 函数或者通过构造函数传入普通指针，并可以通过 get() 函数获得普通指针。 
shared_ptr&lt;string&gt; p = new string(&quot;hello&quot;);               // ERRORshared_ptr&lt;string&gt; p(new string(&quot;hello&quot;));                // OKshared_ptr&lt;string&gt; p = make_shared&lt;string&gt;(&quot;hello&quot;));     // OK

20.6.6. 用法直接使用智能指针对象。
shared_ptr&lt;Stu&gt; st5 = make_shared&lt;Stu&gt;(9527);st6-&gt;setValue(777);st6-&gt;getValue();

获取智能指针对象的原始指针。
shared_ptr&lt;Stu&gt; st1(new Stu(007));Stu* p = st1.get();p-&gt;setValue(100);p-&gt;getValue();


20.6.7. shared_ptr 删除器shared_ptr 默认的删除器函数不能自动析构申请的是数组类型对象的内存，因此需要手动实现一个删除器；当申请的内存不是数组类型时，不需要手动实现删除器。
shared_ptr&lt;Stu&gt; st(new Stu(10), [](Stu* p)&#123;    delete p;&#125;);

其中对象中的第二个参数是匿名对象，这个匿名对象可以对象的外部实现后再传入进来，也可以在对象中使用 lambda 表达式，例如：[](Stu* p)&#123;&#125;。
// 定义一个自己的删除器：deleter,可以选择自己不手动实现shared_ptr&lt;string&gt; str(new string(&quot;Implement my deleter&quot;),                       [](string* p) &#123;                           cout &lt;&lt; &quot;deleter: &quot; &lt;&lt; *p &lt;&lt; endl;                           delete p;                       &#125;);str = nullptr;// 必须要手动实现删除器// shared_ptr&lt;Stu&gt; St7(new Stu[5]);   // 执行 5 次 构造函数，析构函数执行一次，造成内存泄漏shared_ptr&lt;Stu&gt; St7(new Stu[5], [](Stu* t)&#123;  // 改进版    delete []t;&#125;);

在删除数组内存时，除了自己编写删除器，也可以使用 C++ 提供的 std::default_delete() 函数作为删除器，这个函数内部的删除功能也是通过调用 delete 来实现的，要释放什么类型的内存就将模板类型 T 指定为什么类型即可。具体处理代码如下：
shared_ptr&lt;Stu&gt; st8(new Stu(5), default_delete&lt;Stu&gt;());

自己封装一个 make_shared_array 方法来让 shared_ptr 支持数组。
template&lt;typename T&gt;shared_ptr&lt;T&gt; make_shared_array(size_t len)&#123;    return shared_ptr&lt;T&gt;(new T[len], default_delete&lt;T[]&gt;());&#125;void test05()&#123;    shared_ptr&lt;Stu&gt; t = make_shared_array&lt;Stu&gt;(4);    cout &lt;&lt; t.use_count() &lt;&lt; endl;&#125;

完整的代码可在仓库中查看：shared_ptr实现
20.6.8. 注意点
shared_ptr 还有可能导致内存泄漏。两个对象相互使用一个 shared_ptr 成员变量指向对方，会造成循环引用，从而导致内存泄漏。
不能使用一个原始地址值初始化多个 shared_ptr。
函数不能返回管理了 this 指针的 shared_ptr 对象。
shared_ptr 只提供 operator* 和 operator-&gt;，没有提供 operator[] 和指针运算。

20.7. weak_ptr20.7.1. 概述weak_ptr 是弱引用指针，是一种不控制对象生命周期的智能指针，指向一个 shared_ptr 管理的对象。weak_ptr 只提供一种访问手段，它不共享指针，不能操作资源。
20.7.2. 为什么要使用 weak_ptr
配合 shared_ptr 智能指针来进行工作，解决 shared_ptr 智能指针相互引用时死锁的问题。当两个 shared_ptr智能指针相互引用时，这两个指针的引用数永远不可能减到 0 ，导致资源永远不会释放。
它是对 对象的一种弱引用，不会增加对象的 引用计数。
weak_ptr  与 shared_ptr之间可以相互转化。shared_ptr 可以直接赋值给 weak_ptr；而 weak_ptr 通过调用 lock() 函数来获得 shared_ptr。

20.7.3. 初始化weak_ptr 提供三种初始化的方式：构造函数中初始化、拷贝构造函数初始化、通过隐式类型转换，shared_ptr 对象直接赋值给 weak_ptr 对象来初始化。
shared_ptr&lt;int&gt; st(new int()); // Create a objectweak_ptr&lt;int&gt; wt1;cout &lt;&lt; &quot;wt1.use_count = &quot; &lt;&lt; wt1.use_count() &lt;&lt; endl;weak_ptr&lt;int&gt; wt2(st);cout &lt;&lt; &quot;wt2.use_count = &quot; &lt;&lt; wt2.use_count() &lt;&lt; endl;weak_ptr&lt;int&gt; wt3(wt1);cout &lt;&lt; &quot;wt3.use_count = &quot; &lt;&lt; wt3.use_count() &lt;&lt; endl;weak_ptr&lt;int&gt; wt4 = st; // 通过隐式类型转换，shared_ptr 对象直接赋值给 weak_ptr 对象cout &lt;&lt; &quot;wt4.use_count = &quot; &lt;&lt; wt4.use_count() &lt;&lt; endl;


20.7.4. 底层原理weak_ptr 底层主要依赖于 counter 计数器类和 shared_ptr 赋值、构造等手段实现的。

counter 对象的目地就是用来申请一个块内存来存引用基数。
share_ptr 给出的函数接口为：构造，拷贝构造，赋值，解引用。

20.7.5. 成员函数
expired() 检测所管理的对象是否已经释放, 如果已经释放, 返回 true; 否则返回 false。
lock() 获取所管理的对象的强引用 shared_ptr；如果 expired 为 true, 返回一个空的 shared_ptr; 否则返回一个 shared_ptr, 其内部对象指向与 weak_ptr 相同。
reset() 放弃被拥有物的拥有权，重新初始化为一个空的 weak_ptr。
use_count() 返回所监测的 shared_ptr 共享对象的引用计数。

代码用例实现在工程库中：Weak_ptr 智能指针用法
20.7.6. 注意点
weak_ptr 没有重载 * 和-&gt;  但可以使用 lock 获得一个可用的 shared_ptr 对象。weak_ptr 在使用前需要检查合法性。
weak_ptr 支持 拷贝或赋值, 但不会影响对应的 shared_ptr 内部对象的计数。

参考

详解C++11智能指针: https://www.cnblogs.com/WindSun/p/11444429.html
C++智能指针详解: https://blog.csdn.net/flowing_wind/article/details/81301001
C++ 智能指针类: https://blog.csdn.net/heyabo/article/details/8791410

21. typename21.1. 概念从属名称(dependent names)：类模板中出现的名称依赖于某个参数。
template&lt;typename T&gt;void show(const T&amp; var)&#123;    T::const_iterator iter(var.begin());  // T::const_iterator 为从属名称&#125;

嵌套从属名称(nested depended name)：从属名称在 class 内嵌套。
21.2. 为什么要用 typename ?typename 是C++中的一个关键字。当类模板中使用指针类型去定义变量时，编译并不知道 T::const_iterator* 是个类型还是一个变量，编译的时候会产生歧义，撰写C++解析的人员必须要考虑到所有可能出现的问题，因此引入了 typename 关键字。
template&lt;typename T&gt;void show(const T&amp; var)&#123;    T::const_iterator* x;&#125;

在类模板中 class 关键字与 typename 关键字的用法一样，都是定义一个类。
// 两者声明的效果一样template&lt;typename T&gt; class Stu&#123;&#125;;template&lt;class T&gt; class Stu&#123;&#125;;

typename 用于嵌套从属名称(nested depended name)。

任何时候你要在 template 模板类中使用一个嵌套从属类型名称，就必须在它的前边放置 typename 关键字。
C++编译器有个解析的规则：如果解析器在 template 中遇到一个嵌套从属名称，它便假设这个名称不是类型，除非你要告诉编译器，这是一个类型。

// 未使用typename，可能在编译时出现问题template&lt;typename T&gt;void show(const T&amp; var)&#123;  if (var.size() &gt;= 2)&#123;    // 默认情况下编译器认为 T::const_iterator 这个不是类型名，可能是个变量    T::const_iterator iter(var.begin());      &#125;&#125;// 改进情况template&lt;typename T&gt;void show(const T&amp; var)&#123;  if (var.size() &gt;= 2)&#123;    typename T::const_iterator iter(var.begin());      &#125;&#125;


21.3. 注意点typename 不可以出现在 base classes list 内的嵌套从属名称之前，也不可以在 member initialization list(成员初值列) 中作为 base class 修饰符。例如：
template&lt;typename T&gt;class Derived : public Base&lt;T&gt;::Nested &#123;  // base class list 中不允许 typename    public:    explicit Derived (int x)        : Base&lt;T&gt;::Nested(x)                    // mem.init.list中不允许typename        &#123;            // 嵌套从属类型名称既不在base class list 中也不在 mem.init.list 中，            // 作为一个 base class 修饰符则需要加上 typename            typename Base&lt;T&gt;::Nested temp;                   ...        &#125;&#125;;


22. explicit conversions(显示类型转换)C++中的类型转换有4种。
22.1. static_cast&lt;&gt;()static_cast 是一种静态类型转换。编译时，编译器会做类型转换。C 语言中能使用隐式转换的类型均可以用 static_cast 类型转换。
static_cast&lt;&gt;()，例如：double a1 = 12.0;int a2 = static_cast&lt;int&gt;(a1);  


22.2. reinterpret_cast&lt;&gt;()reinterpret_cast&lt;&gt;() 是一种重新解释类型转换。
22.3. dynamic_cast&lt;&gt;()dynamic_cast&lt;&gt;() 是一种动态类型转换，用于父类与子类之间的多态类型转换。
22.4. const_cast&lt;&gt;()const_cast&lt;&gt;() 是一种 const 类型转换，去除类型的只读属性。常常用于有函数重载的上下文中。
23. exception(异常处理)C++ 中使用 throw 抛出异常，try...catch 等关键字来捕获异常。
// 语法try &#123;    program-statements&#125;catch (exception-declaration) &#123;    handler-statements&#125;catch (exception-declaration) &#123;    handler-statements&#125;// throw语法throw 需要处理的表达式;

注意：空的 throw 语句只能出现在 catch 语句或者被 catch 语句调用的函数体内，如果空的 throw 语句出现在处理代码以外，则编译器将执行 terminate。
异常的特性

异常严格按照类型进行匹配，不会进行隐式的类型转换。
C++的异常处理机制使 异常的检测 与 异常的处理 不必在同一个函数中，很好的实现了软件的分层机制。
异常是一种 跨越函数 的机制。
栈解旋：类中的抛出异常会执行析构函数。

23.1. 异常变量的生命周期
异常接收时的变量是元素，且为 类的类型 时，则执行的是拷贝构造。
异常接收时的变量为 类的引用 时，使用 throw 去抛那个对象。
指针和引用或元素可以同时执行 catch 捕获，但引用和元素不能同时执行 catch 捕获。

23.2. 异常的层次结构标准库中常常在继承中处理。按照 引用 传递异常，在异常中使用虚函数。
标准程序库中所有基类的异常为 Exception() 



23.3. 异常的优缺点
优点

函数的返回值可以忽略，但异常不可忽略。如果程序出现异常，但是没有被捕获，程序就会终止，这多少会促使程序员开发出来的程序更健壮一点。而如果使用C语言的error宏或者函数返回值，调用者都有可能忘记检查，从而没有对错误进行处理，结果造成程序莫名其面的终止或出现错误。
整型返回值没有任何语义信息，而异常却包含语义信息，有时你从类名就能够体现出来。整型返回值缺乏相关的上下文信息。异常作为一个类，可以拥有自己的成员，这些成员就可以传递足够的信息。
异常处理可以在调用时跳级。这是一个代码编写时的问题：假设在有多个函数的调用栈中出现了某个错误，使用整型返回码要求你在每一级函数中都要进行处理。而使用异常处理的栈展开机制，只需要在一处进行处理就可以了，不需要每级函数都处理。


缺点

C++没有垃圾回收机制，资源需要自己管理。C++中异常经常会导致资源泄漏的问题，比如在new和delete中抛出了异常，导致内存泄漏，在lock和unlock之间抛出了异常导致死锁。
异常会在程序运行出错时抛出异常，程序会乱跳，导致调试程序比较困难。
异常会有一些性能的开销。 
构造函数中不能抛异常，抛异常可能导致对象定义不完整。析构函数不能抛异常，可能导致内存泄漏。



23.4. 构造函数中的异常处理构造函数中初始值异常的唯一方法：将构造函数写成 try函数语句块
24. Meaningful aphorisms (隽永警句)
编程—-写出大家风范。
吾道一以惯之。—&gt;出自孔子的《论语》
胸中自有丘壑。—&gt;出自叶圣陶的《苏州园林》
勿在浮沙筑高楼。
山高月小，水落石出。—&gt;出自宋代苏轼的《后赤壁赋》
当你发现自己的才华撑不起野心时，就请安静下来学习吧！
Don’t reinvent the wheel.


StyleGuide(规范)

每个独立的类应单独放在一个文件里
变量一般声明为 private，采用间接访问


25. References by website(学习参考)
cppreference: 新版C++标准官方参考文档。
cplusplus: 旧版的C++学习参考文档
GCC, the GNU Compiler Collection: GCC编译器的官网
C++ Core Guidelines: Bjarne Stroustrup 与 Herb Sutter 联合编写的 C++ 教程。Github 地址：https://github.com/isocpp/CppCoreGuidelines
open-std.org: C++标准委员会列出的C++中某项技术如何被采纳到标准中？
isocpp.org: 标准委员会官方站点，近期的会议、行程、活动、计划等等都会发布在这里。这里也会推荐一些比较好的文章、教程、书籍等等内容，供C++程序员阅读。
C++ FAQ: 指出了C++编程中可能出现的一些问题，值得推荐阅读，中文网址 C++11 FAQ。
cpprocks.com：查看C++11支持哪些编译，里面还有许多优质的东西，值得挖掘。
stroustrup.com: C++之父的主页，确定不来看看吗？好东西贼多。
http://scottmeyers.blogspot.com/：Scott Meyers 个人博客网址，长期更新，从 1999 年开始，每年都有文章更新，一直坚持到现在。
Microsoft C++ 语言文档: 微软官方写的C++参考技术文档，用于Visual Studio 中。
microsoft cppblog: 微软C++团队的博客，没事的话也可以看看。 
geeksforgeeks.org: GeeksforGeeks 是一个主要专注于计算机科学的网站。 它有大量的算法，解决方案和编程问题。
reddit cpp版块: reddit的cpp版块也不错，可以了解最新的C++消息，也可以提问题，也有人在这里写一些文章教程。
herbsutter.com: Herb Sutter的博客，Herb Sutter是C++核心人物之一，早期The Free Lunch Is Over这篇文章就出自他手，他还写过Exceptional系列C++图书.
stepanovpapers.com: 收录了泛型编程的祖师Alex Stepanov的论文网站，STL便是其杰作。可以说没人比他更懂泛型编程，而且这位大牛中的大牛竟然还仿照欧几里得的《几何原本》写了本《编程原本》，试图以公理化方法演绎编程。
modernescpp.com: 一个开发者个人的网站，网站上的文章质量很高。值得一读。
Preshing on Programming: 自由开发者撰写的博客，内容质量很不错。
arne-mertz.de: 同样是自由开发者撰写的博客，内容质量很不错。
learncpp: 该网站主要是叫你如何使用C++，成为一个master。
TutorialsPoint: 网站上有许多关于编程语言学习的教程，可以看看。
C++ shell: 在线的C++编译器，在线编辑代码。
herbsutter: ISO C++标准委员会主席，C++&#x2F;CLI首席架构师 的个人主页。
cppreference 列出的 C++ compiler support 
官方在线 The GNU C++ Library 文档
open source C++ libraries：cppreference 官方列出的一些开源的 C++ 库。
https://www.fluentcpp.com：博客作者Jonathan Boccara 是C++软件工程负责人、博客作者和作家，专注于如何使代码具有表现力，顶级C++高手。

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>01-C++Novice</tag>
      </tags>
  </entry>
  <entry>
    <title>02-C++Advanced</title>
    <url>/Cpp/Cpp/02-C++Advanced/</url>
    <content><![CDATA[

1. Object Oriented Programming(面向对象编程)Object Oriented Programming(OOP)叫面向对象编程。

class without pointer members：类中的成员不带有指针。
class with pointer members：类中的成员带有指针。

1.1. Encapsulation(封装)封装这个术语用来描述在过程接口后面隐藏实现细节的概念。
C++ 中对类的设计时，封装了属性和方法。若直接访问类的数据成员就违反了封装原则。设计原则应保持数据成员的私有性。
访问限定符

public  修饰类的成员变量和函数，既能在 类的内部 使用又能在 类的外部 使用
private 修饰类的成员变量和函数，只能在 类的内部 使用，不能在 类的外部 使用
protect 修饰类的成员变量和函数，只能在 类的内部 使用，不能在 类的外部 使用，可以在 继承的子类 中使用。

C++ 中类与类之间的关系主要归为三大类：复合、委托、继承。
1.2. Composition(复合)什么是复合？

每当一个类的对象作为另一个类的成员变量时，就实现了复合。当一个类中包含(has-a)另一个类时，将其它类的对象作为当前类的成员使用，当前类的成员变量不再是简单的基础类型，而是变为复杂的其它类的对象。


// queue类中包含deque类Template &lt;class T&gt;class queue &#123;  ...  protected:    deque&lt;T&gt; C;  public:    ...&#125;;

内存角度理解复合中的构造与析构

构造（由内而外）：编译器默认先调用当前类中包含的类的默认构造函数，然后再调用当前类的构造函数。

析构（由外而内）：编译器默认先调用调用当前类的析构函数，然后再调用当前类中包含的类的析构函数。





类与类之间的生命周期两者是同步的。

1.3. Delegation(委托)什么是delegation？

委托(delegation)也叫Composition by reference。两个类之间通过指针相连。


  


// MyString类指向Stu类class MyString&#123;private:    Stu* st;       // 采用委托的方式public:    MyString(/* args */) &#123;&#125;    ~MyString() &#123;&#125;&#125;;class Stu&#123;private:    char* m_data;    int n;public:    Stu(/* args */) &#123;&#125;    ~Stu() &#123;&#125;&#125;;


类与类之间的生命周期两者是不同步的。

1.2.1. copy on write
MyString类对象的三个实例a，b, c 同时共享Stu类中的整数 n，指针 rep 指向数据 hello。如果实例 a 想要修改 hello 这个数据，则需要先拷贝一份，然后再修改拷贝的数据，这种实现的方法称为 copy on write(写时复制)


  


1.2.2. pImpl IdiomPImpl（Pointer to implementation，指向实现的指针，也叫handle/body或者叫防火墙编译）是一种常用来对类的接口与实现进行解耦的方法。《Effective Modern C++》第四章 Iterm 22 条的对 Pimpl Idiom 的用法做了非常详细的解释说明。
这个技巧可以避免在头文件中暴露私有细节，是促进 API 接口与实现保持完全分离的重要机制。但是 pImpl 并不是严格意义上的设计模式（它是受制于 C++ 特定限制的变通方案），这种惯用法可以看作桥接设计模式的一种特例。

优点
降低耦合。
信息隐藏。
降低编译依赖，提高编译速度。采用 Pimpl 风格，通过减少类的声明与实现之间的依赖关系来减少编译的时间。
接口与实现分离。



《Effective Modern C++》中对  Pimpl Idiom 使用做出的建议：

The Pimpl Idiom decreases build times by reducing compilation dependencies between class clients and class implementations.
For std::unique_ptr pImpl pointers, declare special member functions in the class header, but implement them in the implementation file. Do this even if the default function implementations are acceptable. 
The above advice applies to std::unique_ptr, but not to std::shared_ptr.

1.3. Inheritance(继承)什么是Inheritance？

继承（英语：inheritance）是面向对象软件技术当中的一个概念。如果一个类 B “继承自”另一个类 A，就把这个 B 称为 “ A 的子类”，而把 A 称为 “B的父类” 也可以称 “A是B的超类”。继承可以使得子类具有父类别的各种属性和方法，而不需要再次编写相同的代码。在令子类别继承父类别的同时，可以重新定义某些属性，并重写某些方法，即覆盖父类别的原有属性和方法，使其获得与父类别不同的功能。另外，为子类追加新的属性和方法也是常见的做法。 一般静态的面向对象编程语言，继承属于静态的，意即在子类的行为在编译期就已经决定，无法在运行期扩展。

C++中常见的三种继承方式：public、private、protected。也支持多继承的方式。

public继承  

父类成员在子类中保持原有的访问级别。
类的对象的公共数据成员可以使用直接成员访问运算符 . 来访问；但私有的成员和受保护的成员不能使用直接成员访问运算符 . 来直接访问。


protected继承 

父类中为 public 成员属性，在子类中变为 protected
父类中为 protected 成员属性，在子类中仍为 protected
父类中为 private 成员属性，在子类中仍为 private


private继承 

父类成员在子类中的访问级别都变为 private

子类无法访问父类中 private 属性的成员。





public、protect、private 三个关键字的访问范围

public: 能被类成员函数、子类函数、友元、类的对象访问。

protected: 只能被类成员函数、子类函数及友元访问，不能被其它任何的数据访问，本身的类对象也没有访问权限。  

为什么要引入 protected 访问权限？

引入 protected 成员的理由：基类的成员本来就是派生类的成员，对于那些隐藏的、不宜设为公有的，但又确实需要在派生类的成员函数中经常访问的基类成员，则将它们设置为 protected 成员，既能起到 隐藏 的目的，又避免了派生类成员函数要访问它们时只能间接访问所带来的麻烦。 


子类（派生类）的成员函数只能访问所作用的那个对象（即 this 指针指向的对象）的基类 protected 成员，不能访问其他基类对象的父类 protected 成员。  

类的对象只能调用其 public 部分的成员，而不能调用 protected 和 private 部分的成员。




private: 只能被类成员函数及友元访问，不能被其它任何的数据访问，本身的类对象也没有访问权限。


三种继承之间的关系用一张表来清楚的表示


子类（派生类）可以从父类（基类）继承哪些方法和成员?

数据：子类继承的是父类内存中的数据。
函数：从内存的角度去看待，子类函数继承的是父类的调用权，而不是父类的内存大小。
子类不能继承父类中以下几种的数据
基类的构造函数、析构函数和拷贝构造函数。
基类的重载运算符。
基类的友元函数。



如何判断继承中的访问控制权限

看类的调用语句，是在类的内部还是在类的外部？
看子类如何从父类中继承？
看父类的访问级别？

1.3.1. 父类与子类的关系
子类是特殊的父类。

基类(base)的指针或引用 直接指向 子类(derived)的对象。

指针做函数参数
class Parent&#123;&#125;class Child&#123;&#125;Parent *p1 = NUll;Child c1;p = &amp;c1;     // 父类的指针直接指向子类的对象

引用做函数参数



子类对象直接初始化 父类对象。

子类对象直接 赋值 给父类对象。

子类对象可以 当做父类对象使用。


1.3.2. 继承中的构造与析构调用原则
内存角度探讨调用原则



构造：由内而外。先调用 base (父类)的默认构造函数，然后才执行自己。
析构：由外而内。先执行自己，然后再调用 base(父类)的析构函数。



1.3.3. 继承中同名成员变量处理方法子类与父类中的成员变量和成员函数有相同的名称时，采用作用域的方式调用。
class Parent&#123;public:    int m;    void shoe();&#125;class child&#123;public:    int m;    void shoe();&#125;Parent p1;Child c1;// 调用p1.Parent::m = 100;c1.Child::m = 200;p1.Parent::shoe();c1.Child::shoe();

参考

Stack Overflow: Difference between private, public, and protected inheritance
Public, Protected and Private Inheritance in C++ Programming
C++：继承访问属性（public&#x2F;protected&#x2F;private）

1.3.4. Composite, Inheritance 和 Delegation 对比
继承

类继承允许你根据其他类的实现来定义一个类的实现。在继承方式中，父类的内部细节对子类可见。
类继承是在编译时刻静态定义的，且可直接使用，因为程序设计语言直接支持类继承。类继承可以较方便地改变被复用的实现。当一个子类重定义一些而不是全部操作时，它也能影响它所继承的操作，只要在这些操作中调用了被重定义的操作。
类继承也有一些不足之处。首先，因为继承在编译时刻就定义了，所以无法在运行时刻改变从父类继承的实现。更糟的是，父类通常至少定义了部分子类的具体表示。因为继承对子类揭示了其父类的实现细节，所以继承常被认为“破坏了封装性”。子类中的实现与它的父类有如此紧密的依赖关系，以至于父类实现中的任何变化必然会导致子类发生变化。
使用继承时，被继承的操作总能引用接受请求的对象，C++ 中通过 this 成员变量。委托方式为了得到同样的效果，接受请求的对象将自己传给被委托者（代理人），使被委托的操作可以引用接受请求的对象。


组合

对象组合要求被组合 的对象具有良好定义的接口，对象的内部细节是不可见的。  
对象组合是通过获得对其他对象的引用而在运行时刻动态定义的。组合要求对象遵守彼此的接口约定，进而要求更仔细地定义接口，而这些接口并不妨碍你将一个对象和其他对象一起使用。这还会产生良好的结果：因为对象只能通过接口访问，所以我们并不破坏封装性；只要类型一致，运行时刻还可以用一个对象来替代另一个对象；更进一步，因为对象的实现是基于接口写的，所以实现上存在较少的依赖关系。
优先使用对象组合有助于你保持每个类被封装，并被集中在单个任务上。这样类和类继承层次会保持较小规模，并且不太可能增长为不可控制的庞然大物。另一方面，基于对象组合的设计会有更多的对象 (而有较少的类)，且系统的行为将依赖于对象间的关系而不是被定义在某个类中。


委托

委托(delegation)是一种组合方法，它使组合具有与继承同样的复用能力。在委托方式下，有两个对象参与处理一个请求，接受请求的对象将操作委托给它的代理者(delegate)。类似于子类将请求交给它的父类处理。
优缺点
优点：便于运行时刻组合对象操作以及改变这些操作的组合方式。
缺点： 动态的、高度参数化的软件比静态软件更难于理解。还有运行低效问题，不过从长远来看人的低效才是更主要的。只有当委托使设计比较简单而不是更复杂时，它才是好的选择。要给出一个能确切告诉你什么时候可以使用委托的规则是很困难的。因为委托可以得到的效率是与上下文有关的，并且还依赖于你的经验。





1.3.5. Inheritance and virtual function在 C++ 中，在基类的成员函数声明前加上关键字 virtual 即可让该函数成为 虚函数，派生类中对此函数的不同实现都会继承这一修饰符，允许后续派生类覆盖，达到迟绑定的效果。
为什么会有虚继承

解决多个继承可能产生的二义性。 
二义性：若果一个派生类（子类）由多个基类（父类）继承，这些基类都有一个共同的基类，则在对该基类中声明的变量进行访问时，可能会出现二义性。

为什么要用虚函数

相同的接口，实现不同的功能。
有了虚函数，程序能够调用编译期还不存在的函数。
虚函数是动态生成的，普通成员函数是静态生成的。

几种混淆的 virtual function

non-virtual: 不希望子类（derived）重写。
virtual: 希望子类重写（override）父类，父类已有默认值。
pure-virtual: 子类（derived）中必须重写(override)父类，父类没有默认值。

1.4. Polymorphism(多态)多态（英语：polymorphism）指为不同数据类型的实体提供统一的接口。

实现多态的三个条件

要有继承
子类中有虚函数重写
父类指针或引用指向子类的对象。


多态实现的效果：同一种调用语句，有多种表现形态。

链编(bind)：一个程序模块，代码之间相互关联的过程。

静态链编：程序的匹配、链接的过程在编译阶段中实现。重载函数使用的是静态链编。
动态链编：程序的匹配、链接的过程在运行时实现。switch、if 语句都是采用的动态链编。


多态的内部原理探究

当类中声明虚函数时，编译器自动创建了一个虚函数表，每个类的对象都有一个虚函数表。
虚函数表：存储多个虚函数的开始地址。虚函数表由编译器自动创建和维护。
有 virtual 关键字的成员函数会被编译器放入虚函数表中。
存在虚函数时，用类实例化一个对象的过程中，C++编译器会在类的对象中添加一个 vptr 指针，每个对象中都有一个指向虚函数表的 vptr 指针。
通过虚函数表的虚指针 vptr 调用重写函数是在程序运行时进行的，需要通过寻址操作才能确定调用的是哪个函数。
虚函数的效率比普通成员的效率要低。因为函数所有的调用都是动态绑定的，只有在运行的时候，才知道具体调用哪个。



1.4.1. 虚析构函数为什么要虚析构函数？

通过父类指针将子类的所有资源都释放，即把子类的所有析构函数都执行一遍。

函数格式
virtual ~People()&#123;&#125;

1.4.2. vptr虚指针)和vtbl(虚函数表)虚表是属于类的，而不是属于某个具体的对象，一个类只有一个虚表，同一个类的所有对象都使用同一个虚表。
为了指定对象的虚表，对象内部包含一个虚表的指针，来指向自己所使用的虚表。为了让每个包含虚表类的对象都拥有一个虚表指针，编译器在类中添加了一个指针 *__vptr，用来指向虚表。这样，当类的对象在创建时便拥有了这个指针，且这个指针的值会自动被设置为指向类的虚表。




构造函数中调用虚函数


函数的静态绑定


函数的动态绑定


虚表是一个指针数组，其元素是虚函数的指针，每个元素对应一个虚函数的函数指针。普通的函数不是虚函数，其调用并不需要经过虚表，所以虚表的元素并不包括普通函数的函数指针。虚函数指针的赋值发生在编译器的编译阶段，即代码在编译阶段，虚表就构造出来了。

结论：多态是实现框架的基础。在使用框架结构去设计程序的时候，常常结合 Template Method 和其它的设计模式去实现。C++通过虚函数表，实现了虚函数与对象的动态绑定，从而构建了C++面向对象程序设计的基石。

参考 

C++编译期多态与运行期多态

1.4.3. 纯虚函数和抽象类纯虚函数
// 语法virtual int func() = 0;

含有纯虚函数的类叫抽象类。在父类中只定义一套通用的接口，在子类中去实现。
// 抽象类class People&#123;private:  ....public:   ....virtual int func(int a) = 0;&#125;

虚函数注意点

静态函数没有虚函数，内联函数不可能是虚函数，构造函数不能是虚函数。
抽象类不能实例化对象，可以声明抽象类的指针。
抽象类不能作为函数的参数类型。 void fg(People)  // error, People为抽象类
抽象类不能作为函数返回的类型。People eat();  // error，People为抽象类
抽象类可以声明类的引用。People&amp; run(People&amp;); // People为抽象类

继承与虚函数在工程中的应用

由于多继承的二义性，很少使用多继承，一般采用单继承。
C++ 中没有真正的类似Java中接口的方法，但可以使用虚继承来模拟接口的方法。
虚继承中可以使用多继承的方式，来实现复杂的业务。

1.5. 耦合与解耦
C++中采用抽象类，提前布局 vptr 指针，虚函数表，调用动态链编，实现与第三方产品的解耦合。
动态库—–函数的首地址—-调用函数指针—-调用函数
常常采用函数指针将任务的调用者与任务的实现者进行分开，两者互不依赖。

Aggregation: 聚合

聚合意味着一个对象拥有另一个对象或对另一个对象负责。一般我们称一个对象包含另一个对象或者是另一个对象的一部分。聚合意味着聚合对象和其所有者具有相同的生命周期。


C++中，聚合可以通过定义表示真正实例的成员变量来实现，但更通常的是将这些成员变量定义为实例指针或引用。

Acquaintance: 相识

相识意味着一个对象仅仅知道另一个对象。有时相识也被称为“关联”或“引用”关系。相识的对象可能请求彼此的操作，但是它们不为对方负责。相识是一种比聚合要弱的关系，它只标识了对象间较松散的耦合关系。


通过指针或引用来实现。

聚合关系使用较少且比相识关系更持久；而相识关系则出现频率较高，但有时只存在于一个操作期间，相识也更具动态性，使得它在源代码中更难被辨别出来。
2. Generic Programming(泛型编程)Generic Programming(泛型编程): 操作(operations)使用相同的接口，但是其类型(type)不相同，即使用模板(template)将泛型操作公式化。其中STL是泛型编程(GP)最成功的一个作品。
泛型编程在程序编译时就能获知其类型。而面向对象编程处理的类型在程序运行之前都是未知的情况。
模板是泛型编程的基础。C++语言既有类模板（class template），也有函数模板（function template），只有对C++语言有了相当深入的理解后才能写出模板。模板本身不是类或函数，可以将模板看作是：编译器为生成类或函数编写的一份说明，或认为一个模板就是为创建类或函数的公式。 编译器根据模板创建类或函数的过程称为实例化（Instantiation），当使用模板时，编译器需要明确应该吧类或函数实例化成何种类型。
面向对象编程与泛型编程的区别？

OOP是将类中的data与methods组合在一起的，而泛型编程(GP)则是将类中的data与methods分开来的。采用泛型编程可以实现容器(Containers)与算法(Algorithms)的各自分离与实现。

2.1. Parameterized Type(参数化类型)参数化类型（parameterized type）也就是泛型编程（generic）和模板（templates）。
2.2. 模板编译当编译器遇到一个模板定义时，它并不生成代码。只有当我们实例化出模板的一个特定版本时，编译器才会生成代码。当我们使用（而不是定义）模板时，编译器才生成代码，这一特性影响了我们如何去组织代码以及错误何时被检测到。
通常，当我们调用一个函数时，编译器只需要掌握函数的声明。类似的，当我们使用一个类类型的对象时，类定义必须是可用的，但成员函数的定义不必己经出现。因此，我们将类定义和函数声明放在头文件中，而普通函数和类的成员函数的定义放在源文件中。
模板则不同：为了生成一个实例化版本，编译器需要掌握函数模板或类模板成员函数的定义。因此，与非模板代码不同，模板的头文件通常既包括声明也包括定义。
2.3. Function Template(函数模板)模板函数语法
实例一：
template &lt;typename T&gt;   void Show(T arrNum[], int len);

实例二：
// 声明template &lt;typename T&gt;void func(T a, T b)// 调用func&lt;int&gt;(x, y);      // 显示调用func(x, y);           // 调用时自动类型推导，不需要写出具体的函数类型 int，编译器会对                      // function template 进行实参推导


两种方式调用

显示类型调用
自动类型推导


函数模板与函数重载

函数模板的调用严格按照类型进行匹配，不会进行类型的自动转换。
普通函数 的调用可以进行 隐式 的类型转换。
调用规则
函数模板与普通函数都符合调用时，C++编译器优先考虑普通函数
函数模板可以像普通函数一样被重载。
若函数模板可以产生一个更好的匹配，那么选择模板
通过空模板 &lt;&gt; 实参数列表的语法限定编译器只通过模板匹配。




函数模板调用的机制

编译器并不是把函数模板处理成能够匹配任意类型的函数，而是根据函数模板中的具体类型产生不同的函数。
编译器会对 函数模板进行两次编译。第一次在声明 的地方对模板进行编译，第二次在实际调用 的地方将参数替换后，再对代码进行编译。


函数模板当函数参数与函数指针当函数参数的情况类似。


2.4. Class Template(类模板)对类模板来说，我们通过提供一些额外信息来指定模板到底实例化成什么样的类，需要提供哪些信息由模板决定。在模板名字后面跟一对尖括号，尖括号内放上需要提供的信息。
与函数模板不同之处是，编译器不能自动为类模板推断模板参数类型，需要显示的指定传入的参数类型。
为什么要使用类模板？

让 算法 和 数据类型 进行各自的分离。

代码示例：
// 定义类模板template &lt;typename T&gt;class Complex&#123;public:  Complex(T r = 0, T i = 0)    : re(r), im(i)    &#123;&#125;  Complex&amp; operator += (const Complex&amp;);  T real() const &#123;retuen re;&#125;  T image() const &#123;return im;&#125;private:  T re;  T im;&#125;&#123;  // 具体使用类模板  Complex&lt;double&gt; c1(5.5, 10.8);  Complex&lt;int&gt; c2(4, 6);&#125;


要实现不同类型的复数类进行加、减、乘的运算，其中进行运算的规则都是一样的，只是传入的类型不同而已，这时类模板就很好的解决了这个问题。


单个类中的类模板

模板类型参数化


继承中的类模板

从模板类派生普通的类时，需要具体化模板类（即指定类的参数类型），C++编译器需要知道父类的数据类型具体是怎样的。 
类模板可以派生 类模板


注意

一个类模板的每个实例都形成一个独立的类。



2.4.1. Specialization(模板特化)什么是模板特化？

模板特化也叫模板全特化。使用时，给类模板指定具体的参数类型，这样使用类模板的方式就叫模板特化。



2.4.2. Class Partial Specialization(类模板偏特化)类模板偏特化也叫类模板局部特化。只指定一个类模板中的部分参数，不全部在类模板调用时传入，对某个 template 参数进行特化工作。
所谓 partial specialization 的意思是提供另一份 template 定义，而其本身仍然为 templatized。例如，假设有一个类模板：
template &lt;typename T, typename U, typename T&gt;  class test&#123; &#125;;

针对模板参数类型 T 做一个偏特化版本
template &lt;typename T&gt;  class test&lt;T*&gt;&#123; &#125;;

类模板偏特化按照模板参数的个数和参数类型的范围，分为模板个数偏特化和模板范围偏特化。
1. 模板个数的偏特化

只指定类模板中部分的参数个数

2. 类模板范围的偏特化
下图中类模板传入的是一种通用的 T 类型，而另外一个相同的类模板，传入的参数 是 T* 类型，类模板的类型从 T 缩小为 T* 类型，这种的方式的类模板就是类模板范围的偏特化。
2.5. Member Template(成员模板)为什么要使用 member template?

STL 标准库中很多的构造函数都使用了，为了让模板类更加有弹性，支持更多的数据类型。



2.6. template template parameter什么是模板参数模板？

模板参数列表里面可以存在模板，称之为模板参数模板。





参考

【C++】template template argument 模板参数模板

3. IOStream(输入输出流)输入流 cin

getline() 终端输入缓冲区中时可以输入 空格。
ignore() 忽略缓冲区指定的数据
peek() 读缓冲区的数据，若有数据，则读出缓冲区的一个数据；没有数据，则读出无数据。
putback()

输出流 cout

flush() 刷新缓冲区的数据
put() 将字符一个一个地输出到标准输出上
write()
width()
fill()

文件IO流

ofstream建立一个输出流对象，将数据输出到指定文件中。
ifstream 建立一个输入流对象，将从文件中读到的数据输出到终端上。

4. std::move()有利于编译器对程序做更多的优化。英文名叫 move assignment，又称为移动赋值函数。与早期版本中的复制赋值函数对应。在 c++11 以后，可以直接将临时变量b中的内存指针直接传递给 a，由于避免了多余的内存分配操作，因此大大提高了程序效率。、
class MyString&#123;public:    MyString() &#123;&#125;    ~MyString() &#123;&#125;    // move constructor    MyString(MyString&amp;&amp; str) noexcept    : _data(str._data), _len(str._len)    &#123;&#125;    // move assignment    MyString&amp; operator=(MyString&amp;&amp; str) noexcept    &#123;        return *this;    &#125;private:    char* _data;    size_t _len;&#125;;

5. Meata Programming(元编程)元编程针对类型进行操作。而一般的编程是对 变量或对象 进行操作。
tuple 标准库的底层是采用递归的方式去实现的。 
三个核心 API 接口

td::make_tuple: 构造元组
std::get: 获得元组某个位置的值
std::tie: 元组拆包

#include &lt;tuple&gt;#include &lt;iostream&gt;auto get_student(int id)&#123;// 返回类型被推断为 std::tuple&lt;double, char, std::string&gt;if (id == 0)    return std::make_tuple(3.8, &#x27;A&#x27;, &quot;张三&quot;);if (id == 1)    return std::make_tuple(2.9, &#x27;C&#x27;, &quot;李四&quot;);if (id == 2)    return std::make_tuple(1.7, &#x27;D&#x27;, &quot;王五&quot;);    return std::make_tuple(0.0, &#x27;D&#x27;, &quot;null&quot;);    // 如果只写 0 会出现推断错误, 编译失败&#125;int main()&#123;    auto student = get_student(0);    std::cout &lt;&lt; &quot;ID: 0, &quot;    &lt;&lt; &quot;GPA: &quot; &lt;&lt; std::get&lt;0&gt;(student) &lt;&lt; &quot;, &quot;    &lt;&lt; &quot;成绩: &quot; &lt;&lt; std::get&lt;1&gt;(student) &lt;&lt; &quot;, &quot;    &lt;&lt; &quot;姓名: &quot; &lt;&lt; std::get&lt;2&gt;(student) &lt;&lt; &#x27;\n&#x27;;    double gpa;    char grade;    std::string name;    // 元组进行拆包    std::tie(gpa, grade, name) = get_student(1);    std::cout &lt;&lt; &quot;ID: 1, &quot;    &lt;&lt; &quot;GPA: &quot; &lt;&lt; gpa &lt;&lt; &quot;, &quot;    &lt;&lt; &quot;成绩: &quot; &lt;&lt; grade &lt;&lt; &quot;, &quot;    &lt;&lt; &quot;姓名: &quot; &lt;&lt; name &lt;&lt; &#x27;\n&#x27;;&#125;

6. Resource acquisition is initialization(RAII)Resource acquisition is initialization 简写为 RAII，翻译为：资源获取即初始化。RAII要求，资源的有效期与持有资源的对象的生命期严格绑定，即由对象的构造函数完成资源的分配(获取)，同时由析构函数完成资源的释放。在这种要求下，只要对象能正确地析构，就不会出现资源泄露问题。
]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>02-C++Advanced</tag>
      </tags>
  </entry>
  <entry>
    <title>03-C++Standard</title>
    <url>/Cpp/Cpp/03-C++Standard/</url>
    <content><![CDATA[

C++ 新特性演化整体概览。

1. C++11 新特性1.1. Template of  Space在 C++11 之后，对一些语法做了一些优化（Important Minor Syntax Cleanups）。比如，优化了 template（模板）中的尖括号的问题，中间是否需要加空格。
vector&lt;list&lt;int&gt; &gt; ;  // C+11 之前版本，必须要加一个空格，否则编译器会报错vector&lt;list&lt;int&gt;&gt; ;   // C++11 之后，不用加空格，语法得到了优化


1.2. Initializer listsC++11 引入了初值列 (initializer list) 和一致性初始化 (Uniform Initialization)。即采用 &#123;&#125; 去初始化需要初始化的参数，引入新特的同时也兼容原版本的 () 初始化操作。



initializer list 的底层是采用 initializer_list&lt;T&gt; 这个类模板实现的，其中这个类模板下层采用 array&lt;T, n&gt; 的方式去实现的。
初值列 赋值是在对象创建成功之前完成的，而 函数体内赋值 是你的对象成员都已经创建好后再对成员进行赋值。初值列 是在带参构造函数的函数体外面，第一行进行初始化。

初值列初始化语法//  将成员变量设置为 m_re=re, m_im=imclass Stu(int re, int im)  : m_re(re), m_im(im)&#123;public:      ...private:  int m_re;  int m_im;&#125;;
这种初始化并不是必须的，但是在以下几种情况时是必须进行初始化的
成员是 const 类型。
成员是 引用类型。
有一个成员是类型的对象（不是默认的构造函数）。
初始化列表的顺序并不限定初始化的执行顺序，成员的初始化顺序是与类中定义的顺序保持一致。最好让构造函数初始值的顺序与成员声明的顺序保持一致。





1.3. nullptrC++11 开始让你使用 nullptr 关键字去替代老版本中 0 或 NULL 的值。nullptr 不是整型也不是一个指针类型，你可以把它认为是 所有类型的指针。它表示一个指针指向的值是没有值的，这个特性可以避免当一个 NULL 指针被当做一个整型解释时，程序产生的错误。
nullptr 的真正的类型是 std::nullptr_t，位于标准库的 &lt;stddef.h&gt; 头文件中。在源码中，std::nullptr_t 被重定义（define）为 nullptr。因此 std::nullptr_t 可以隐式转换为任意的原生指针（raw pointer）类型，这也是为什么 nullptr 表现得像所有类型的指针。
标准库中源码实现
#if defined(__cplusplus) &amp;&amp; __cplusplus &gt;= 201103L#ifndef _GXX_NULLPTR_T#define _GXX_NULLPTR_Ttypedef decltype(nullptr) nullptr_t;#endif#endif /* C++11.  */

推荐优先考虑 nullptr 而非 0 和 NULL 的原因

如果 C++ 发现在当前上下文只能使用指针，它会很不情愿地把 0 解释为指针（pointer），但那是最后的办法。一般情况下，C++ 的解析策略是把 0 看做 int 而非指针类型，把 NULL 解析成 integral(int 或 long 类型)，而非指针类型。

避免函数重载（overload）解析产生的歧义。若使用 nullptr 替代 0 或 NULL 可以避免函数重载解析时一些意想不到的问题。在 C++98 中，对指针类型和整型进行函数重载可能会导致意想不到的错误。比如下面的代码，函数重载中传递参数 0 或 NULL，调用时，前两种重载的函数会调用，但不会调用指针版本的重载函数。
// 三个重载函数 f()void f(int);void f(bool);void f(void*);f(0);               // 调用 f(int) 重载函数而不是 f(void*)f(NULL);            // 可能不会被编译，一般来说调用 f(int)，                    // 绝对不会调用 f(void*) 重载函数

f(NULL) 函数调用的不确定行为是因为参数 NULL 的实现不同造成的。若 NULL 被定义为 0 ，其类型为 long 时，函数调用是有歧义的。因为从 long 转化为 int，long 转化为 bool 和 0 转化为 void* ，都要进行类型转化。代码中认为调用 f(NULL) 函数，传递的参数就是 null 指针，而实际上调用 f(NULL) 函数，传递的参数是 integral，并不是 null 指针。由于这种违反直觉的行为，导致以 C++98 风格编写代码的程序员，要避免函数重载时，传指针和整型的情形。
调用时，若函数传递的参数为 nullptr，将会调用 void* 版本的重载函数，因为 nullptr 不能被看做任何的整形。
f(nullptr); // calls f(void*) overload

特别是与 auto 声明的变量一起使用时，使代码表意更明确。比如：你在代码库中遇到了这样的代码
auto result = findRecord(/* arguments */);if (result == 0) &#123;    ...&#125;

如果你不知道 findRecord 函数返回类型是什么，那么你也许不清楚 result 是一个指针类型还是一个整型。毕竟 0 也可以解析为 指针类型或整型，容易引发歧义。
若将 0 替换为 nullptr 后，函数返回的结果不会产生歧义（ambiguity），因为 result 的类型一定为指针类型。
auto result = findRecord(/* arguments */);if (result == nullptr) &#123;    ...&#125;

模板类型推导将 0 和 NULL 推导为一个错误的类型（即它们的实际类型，而不是作为空指针的隐含意义），这就导致在当你想要一个空指针时，它们的替代品 nullptr 很吸引人。
假如你有一些函数只能被合适的已上锁的 mutex 调用，且每个函数的形参都是指针类型。
// 只能被以上锁合适的 mutex 调用int f1(std::shared_ptr&lt;Widget&gt; spw);double f2(std::unique_ptr&lt;Widget&gt; upw);bool f3(Widget* pw);

调用代码传递的是 null 指针
std::mutex f1m, f2m, f3m; // mutexes for f1, f2, and f3using MuxGuard = // C++11 typedef; see Item 9std::lock_guard&lt;std::mutex&gt;;    …&#123;    MuxGuard g(f1m);     // lock mutex for f1    auto result = f1(0); // pass 0 as null ptr to f1&#125;                        // unlock mutex…&#123;    MuxGuard g(f2m);        // lock mutex for f2    auto result = f2(NULL); // pass NULL as null ptr to f2&#125;                           // unlock mutex…&#123;    MuxGuard g(f3m);           // lock mutex for f3    auto result = f3(nullptr); // pass nullptr as null ptr to f3&#125;                              // unlock mutex

上面的代码中，前两个的调用没有使用 nullptr，但代码可以正常工作。但是代码中有重复的调用，会多次执行 lock mutex, call function, unlock mutex 这些步骤，让代码很臃肿。模板的使用会减少代码量，上面的代码很臃肿，因此可用模板来执行上面的流程。
template&lt;typename FuncType,         typename MuxType,         typename PtrType&gt;auto lockAndCall(FuncType func,                 MuxType&amp; mutex,                 PtrType ptr) -&gt; decltype(func(ptr))&#123;    MuxGuard g(mutex);    return func(ptr);&#125;


调用 lockAndCall 模板函数可用下面的代码
auto result1 = lockAndCall(f1, f1m, 0);         // error!...auto result2 = lockAndCall(f2, f2m, NULL);      // error!...auto result3 = lockAndCall(f3, f3m, nullptr);   // fine

代码中的前两个是不能通过编译的。第一个调用的问题是：当 0 被传递给 lockAndCall 模板函数时，模板类型推导会尝试去推导实参类型，将 lockAndCall 模板函数的 ptr 形参被推导为 int 类型。与 f1 函数期待的 std::shared_ptr&lt;Widget&gt; 类型不符。因为传递 0 给 lockAndCall 模板函数本来想表示空指针，但  f1 函数得到的却是 int 类型。把 int 类型看做 std::shared_ptr&lt;Widget&gt; 类型传递给 f1 函数，编译时会产生类型错误（type error）。
第二个调用的问题是：当 NULL 被传递给 lockAndCall 模板函数时，形参 ptr 被推导为整型（integral）。即当形参 ptr 的类型为 int 或者类似 int 的类型时，传递给  f2 函数的时候就会发生类型错误（type error），因为 f2 函数期待的是 std::unique_ptr&lt;Widget&gt; 类型。
第三个调用是没有问题的。当 nullptr 传给 lockAndCall 模板函数时，形参 ptr 被推导为 std::nullptr_t 类型。当 ptr 被传递给 f3 函数时，隐式的将 std::nullptr_t 转换为 Widget 类型，因为 std::nullptr_t 可以隐式转换为任何指针类型。


准则

优先考虑 nullptr 而非 0 和 NULL
避免重载指针和整型

1.4. range based for statement引入了一种崭新的 for 循环：逐一迭代给定的某个区间、数组、集合、表达式、初始值列表内的每一个元素。
for (auto&amp; i : &#123;1, 3, 5, 7&#125;)   // 注意: &#123;&#125; 表示是一个容器，初始值列表&#123;    cout &lt;&lt; i &lt;&lt; endl;&#125;




1.5. LambdaLambda 表达式是现代 C++ 中最重要的特性之一，而 Lambda 表达式，实际上就是提供了一个类似匿名函数的特性， 而匿名函数则是在需要一个函数，但是又不想费力去命名一个函数的情况下去使用的。这样的场景其实有很多很多， 所以匿名函数几乎是现代编程语言的标配。
lambda 表达式是 C++11 新引进的一种新特性，允许内联函数的定义（inline functionality）作为 parameter（参数） 或者 local object（局部对象），它改变了 C++ 标准库使用的方式。
lambda 是一份功能性的定义，定义在语句（statement）和表达式（expression）中，可以使用 lambda 作为内联函数。
基本语法
[捕获列表](参数列表) mutable(可选) 异常属性 -&gt; 返回类型 &#123;// 函数体&#125;

&lt;img title&#x3D;””src&#x3D;”.&#x2F;figures&#x2F;1-lambda.png”alt&#x3D;”” width&#x3D;”704”&gt;
上面的语法规则除了 [捕获列表] 内的东西外，其他部分都很好理解，只是一般函数的函数名被略去， 返回值使用了一个 -&gt; 的形式进行。
所谓捕获列表，其实可以理解为参数的一种类型，lambda 表达式内部函数体在默认情况下是不能够使用函数体外部的变量的， 这时候捕获列表可以起到传递外部数据的作用。根据传递的行为，捕获列表也分为以下几种：

[=]: 以传值的方式捕获外部作用域之外的所有变量，若 lambda 中有被定义的内容时。不能修改外部作用域中的数据，只有 read 的权限。

[&amp;]: 以传引用的方式捕获外部作用域之外的所有变量，若 lambda 中有被定义的内容时，可以修改外部作用域中的数据，具有 write 的权限。
int x = 100;int y = 200;auto val = [x, &amp;y]()&#123;    cout &lt;&lt; &quot;x:&quot; &lt;&lt; x &lt;&lt; endl;    cout &lt;&lt; &quot;y:&quot; &lt;&lt; y &lt;&lt; endl;    ++y;&#125;;// 当前 x，y 分别捕获的值是 100，200x = y = 300;// 当前 x，y 分别捕获的值是 100，300，// 当 x 为值传递，外部值的改变不会改变 lambda 中原先以捕获的值，其中 x 原来捕获的值为 x=100val();val();cout &lt;&lt; &quot;final y:&quot; &lt;&lt; y &lt;&lt; endl// 输出结果为：x: 100y: 300x: 100y: 301final y: 302

[]：表示不捕获任何外部变量

[this]：捕获外部的 this 指针

[&#x3D;，&amp;a]：以传值的方式捕获外部的所有变量，但是 a 变量以传引用的方式捕获

[a，b]：以传值的方式捕获外部变量 a 和 b

[a, &amp;b]：a 以传值方式捕获，b 以传引用的方式捕获




当 lambda 说明中有 mutable 关键字修饰时，表明在 lambda 中可以改变捕获的值。上图中的第一个案例表明，开始时捕获的 id&#x3D;0, 当运行至 id=42 这一行时，由于是按照 值传递，且 lambda 还没有执行，因此，lambda 中的 id 捕获的还是为 0 ，当执行 lambda 后，id 值每次 ++，改变了 lambda 表达式中捕获的内容。



 注意：

lambda 没有默认的构造和赋值操作函数（ default constructor 和 assignment operator）。
捕获变量中没有加 = 或 &amp; 时，编译器默认按照是值传递 =；在捕获变量时，一边建议使用 传引用，而非传值。

优点

C++ 编译器对 lambda 的优化效果高于普通的函数。

缺点

根据 C++ 语言规定，lambda 没有默认的构造函数，也没有 assignment 操作符。

1.6. decltypedecltype 是 C++11 增加的一个关键字，作为类型推导，操作过程是在编译时进行的。
decltype 通常有以下几种用法：

常常与 typdef/using 关键字结合起来使用。
可以处理匿名的类型。比如：union, struct  结构中出现的匿名数据，可以使用这个来解决。
最重要的一个作用：推导函数的返回类型 (used to declare return types)。template&lt;typename T1, typename T2&gt;auto add(T1 + T2)-&gt;decltype(x + y);   // 自动推导 x + y 结果的返回类型
元编程中使用 (use it in metaprogramming)template&lt;typename T1, typename T2&gt;struct common_type&lt;T1, T2&gt; &#123;typedef decltype(true ? declval&lt;T1&gt;() : declval&lt;T2&gt;()) type;&#125;;
lambda 表达式作为类型参数传入 (use to pass the type of the a lambda)class Person &#123;...&#125;;auto cmp = [](const Person1&amp;, const Person2) &#123;    ...&#125;;std::set&lt;Person, decltype(cmp)&gt; p(cmp);

1.7. explicit大部分情况下 explicit 关键字用在构造函数中，只有少部分用在模板中。注意：被 explicit 关键字修饰的构造函数，不能进行自动地进行隐式 (implicit) 类型转换，只能显式 (explicit) 地进行类型转换。

当类的声明和定义分别在两个文件中时，explicit 只能写在在声明 (declaration) 中，不能写在定义 (definition) 中。
被声明为 explicit 的构造函数通常比它的兄弟 non-explicit 更受欢迎，因为它们禁止编译器执行非预期（往往也不被期望）的类型转换。除非我有一个好的理由允许构造函数被用于隐式类型转换，否则我会把它声明为 explicit 。我鼓励你遵循相同的政策。

1.8. autoC++11 中新增的一个关键字，让编译器通过初始值去分析所属类的类型。auto 关键字会完成类型自动推导 (Automatic Type Deduction with auto)：根据初始值自动推导变量的类型，因此，在使用这个关键字之前，必须需要将变量初始化。

auto 一般会忽略掉顶层的 const，但底层的 const 会保留下来。从变量声明的初始化表达式处获得变量的类型。const int ci = i;const auto f = ci;  // ci 的推演类型是 int，f 是 const int

1.9. noexceptC++11 引入了该关键字 noexcept。该关键字告诉编译器，指定的某个函数不会抛出异常。通常有两种不同的方式来使用这个关键字。

第一种方式，简单地将 noexcept 关键字放在函数声明的后面，这样该函数便会被标记为不会抛出异常。void add(int) noexcept;   // 表明 add() 函数不会抛出异常
第二种方式：为 noexcept 关键字额外提供一个常量表达式作为其参数，若这个常量表达式的值为 “true”，那么函数就会被标记为不会抛出异常，反之亦然。constexpr bool suppressExcept = true;void excpt_func() noexcept (suppressExcept);


注意：



若当前函数抛出来的异常没有被立即处理，则一直通过 throw 关键往上抛，直到被标准库中的 std::terminal() 捕获，再去处理，其中 std::terminal() 内部默认调用的是 std::abort()。
C++ 中的异常处理是在程序运行时检测，而不是编译时检测的。为了实现运行时检测，编译器会创建额外的代码，然而这会妨碍程序优化。
函数指针的声明和定义中可以指定 noexcept
typedef 或类型的别名  中不能使用 noexcept
成员函数中，noexcept 需要跟在 const 或引用  限定符之后，但是跟在 final、override 或虚函数 = 0 这些限定符之前。
移动构造函数 (move constructor)：在对象进行 copy 时，直接拷贝对象所保有的一些资源。比如，已经在原对象中分配的堆内存、文件描述符，以及 IO 流等。
移动分配函数 (move assignment)
析构函数 (destructor)。在新版本的编译器中，析构函数是默认加上关键字 noexcept 的。

参考

C++ 中的移动构造与 noexcept

1.10. constexpr常量表达式 (const expression)：表示值不会改变，并且在编译过程中就能得到计算的结果的表达式。

为什么要使用 constexpr？

提高程序的执行效率，允许一些计算发生在编译时，而不是在运行的时候，因而采用常量表达式。constexpr 关键字在 C++11 中引入，而在 C++14 中得到改善，使用更加灵活。constexpr 表示允许将变量声明为 constexpr 类型，让编译器来验证变量的值是否是一个常数表达式。


const 与 constexpr 的区别：

const 变量的初始化可以延迟到程序运行时
constexpr 变量的初始化必须在编译时进行，但不能作为函数的参数。
constexpr 指针：限定符 constexpr 仅对指针有效，与指针所指向的对象无关。const int* p = nullpter;      // p 是一个指向整型常量的指针constexpr int* q = nullptr;   // q 是一个指向整数的常量指针



利用 constexpr 可以修饰函数。修饰的函数可是：普通成员函数、构造函数、模板函数。

修饰函数时，函数体必须要有返回值，且返回的表达式必须是常量表达式，非常量表达式就编译报错。constexpr int func()&#123;  return 100;&#125;
整个函数的函数体中不能出现非常量表达式之外的语句，例如 for 循环。但 using 语句，typedef 语句，static_assert 断言以及 return 语句等这些语句除外。
constexpr 修饰构造函数时，类中的变量初始化必须放在初始值列表，且构造函数中必须是空的。class Animal&#123;  Animal(int id) : m_id(id)  &#123;  &#125;private:  int m_id;&#125;;
C++11 语法中，constexpr 可以修饰函数模板，但由于模板中类型的不确定性，因此函数模板实例化后的模板函数是否符合常量表达式函数的要求也是不确定的。如果 constexpr 修饰的模板函数实例化结果不满足常量表达式函数的要求，则 constexpr 会被自动忽略，即该函数就等同于一个普通函数。// initializer list 中的一段源码template&lt;class _Tp&gt;  constexpr const _Tp*  begin(initializer_list&lt;_Tp&gt; __ils) noexcept  &#123;return __ils.begin(); &#125;


在编译时，被 constexpr 修饰的函数会隐式的被指定为内联函数。其中内联函数一般定义在头文件中。

参考: https://subingwen.cn/cpp/constexpr/#2-1-%E4%BF%AE%E9%A5%B0%E5%87%BD%E6%95%B0
1.11. overrideoverride 是 C++11 引进的一个说明符，翻译为 覆盖、重写 的意思。C++11 中的 override 关键字，可以显式的在派生类（子类）中声明，看哪些成员函数需要被重写。

override 有什么用?
一般在继承中，涉及到虚函数时，需要在子类中重新改写函数的内容，去实现父类的方法，这时 override 关键字就派上用场了。


注意事项
在派生类的成员函数中使用 override 时，如果基类中无此函数或基类中的函数并不是虚函数，编译器会给出相关错误信息。



1.12. finalfinal 是 C++11 引进的一个说明符，有两种使用方式。

第一种：用在 class 类名之后，表示当前的类是一个类的最终继承者，不能再被额外的类继承了。若还有子类继承自用 final 关键字修饰的父类，编译器则会报错。
第二种：虚函数中用于修饰函数。若父类中有用 final 关键字修饰的虚函数，则表明该虚函数不能再被其子类重写了，即它是一个最终的虚函数；否则编译器会报错。

1.13. New Function Declaration SyntaxNew Function Declaration Syntax 是新的函数声明语法。
1.14. Scoped EnumerationsScoped Enumerations 英文可翻译为带作用域的枚举。
1.15. New Template Features1.15.1. variadic templatesvariadic templates(参数数量不定的模板) 是 C++ 新增的一个非常重要的特性。



代码部分#include &lt;iostream&gt;#include &lt;bitset&gt;using namespace std;/** * @description: 当包 ... 中 的个数等于 0 时就会执行下面这个空的函数 * @param &#123;*&#125; * @return &#123;*&#125; */void my_print()&#123;&#125;template&lt;typename T, typename... Types&gt;void my_print(const T&amp; firstAgs, const Types&amp;... args)&#123;    cout &lt;&lt; firstAgs &lt;&lt; endl;    my_print(args...);&#125;int main(int argc, char *argv[])&#123;    my_print(100, &quot;hello&quot;, bitset&lt;16&gt;(377), 50);    return 0;&#125;





使用这个的好处是帮助我们解决递归。递归的过程就是把不定参数的个数一一分解出来。
1.15.2. Alias Templates (Template Typedef)Alias Templates 是一个别名模板。

简单用法
// declarationtemplate&lt;typename T&gt;using Vec = std::Vector&lt;T, MyAlloc&lt;T&gt;&gt;;// callVec&lt;int&gt; coll;

上面的代码等价于
std::vector&lt;int, MyAlloc&lt;int&gt;&gt; coll;




alias template 不可能用作 偏特化 或 全特化。

从上面的代码看，using 使用的效果与 #define 或 typedef 的用法似乎是一样的，其实并不是一样的，反而使用 #define 或 typedef 不能实现 alias template 所达到的效果。







1.15.3. Type AliasType Alias 是一个类型别名。

第一种用法与 typedef 的用法是一样的。typedef void(*func)(int, int);using func = void(*)(int, int);  // 两者实现的用法是等同的void example(int, int) &#123;&#125;func f = example;
第二种用法：type alias 用在 member typedef name(成员类型名字)。template&lt;typename T&gt;struct Container &#123;  using value_type = T;  // 等同于 typedef T value_type;&#125;;// 泛型编程中使用template&lt;typename Cntr&gt;void f2(const Cntr&amp; ct)&#123;  typename Cntr::value_type n;&#125;

1.15.4. Function template1.16. using哪些地方会用到 using 关键字？

第一种： namespace 用在命令空间中： using namespace std;
第二种：为类成员做声明 (using-declarations for class members)。可用于子类继承于父类的成员或函数。// vector 容器中的一段源码protected:  using _Base::_M_allocate;  using _Base::_M_deallocate;  using _Base::_M_impl;

有一篇博客写得很好可以值得参考：委托构造和继承构造函数，可以看我自己用代码实现的例子：using 用法


第三中：C++11 起引入了 type alias 和 alias template，可使用 using 关键字作为类型或模板的别名。类模板中使用template&lt;typename T&gt;struct Container &#123;  // 类型别名  using value_type = T;  // 等同于 typedef T value_type;&#125;;// 模板别名template &lt;class CharT&gt; using mystring = std::basic_string&lt;CharT, std::char_traits&lt;CharT&gt;&gt;;

普通类型中使用// 函数指针中使用，给类型起个别名typedef int(func1*)(int, string);  // 法一：使用 typedefusing func2 = int(*)(int, string);  // 法二：使用 using


using 关键字的代码实现可参考：using 用法

1.17. Move Semantics and Rvalue ReferencesRvalue 只能出现在左边。常见的右值： 临时对象 (temp object)。
STL 中更好的解决 perfect forward 问题的的源码部分。
/** *  @addtogroup utilities *  @&#123; *//** *  @brief  Forward an lvalue. *  @return The parameter cast to the specified type. * *  This function is used to implement &quot;perfect forwarding&quot;. */template&lt;typename _Tp&gt;  constexpr _Tp&amp;&amp;  forward(typename std::remove_reference&lt;_Tp&gt;::type&amp; __t) noexcept  &#123;return static_cast&lt;_Tp&amp;&amp;&gt;(__t); &#125;/** *  @brief  Forward an rvalue. *  @return The parameter cast to the specified type. * *  This function is used to implement &quot;perfect forwarding&quot;. */template&lt;typename _Tp&gt;  constexpr _Tp&amp;&amp;  forward(typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp; __t) noexcept  &#123;    static_assert(!std::is_lvalue_reference&lt;_Tp&gt;::value, &quot;template argument&quot;          &quot;substituting _Tp is an lvalue reference type&quot;);    return static_cast&lt;_Tp&amp;&amp;&gt;(__t);  &#125;/** *  @brief  Convert a value to an rvalue. *  @param  __t  A thing of arbitrary type. *  @return The parameter cast to an rvalue-reference to allow moving it.*/template&lt;typename _Tp&gt;  constexpr typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp;  move(_Tp&amp;&amp; __t) noexcept  &#123;return static_cast&lt;typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp;&gt;(__t); &#125;

1.18. &#x3D;delete &amp;&amp; &#x3D;default构造函数后面加上 =default 关键字，告诉编译器要显式的将哪个作为默认构造函数，而不去调用空类型参数的构造函数。比如：下面的类中，将拷贝赋值函数作为默认的构造函数，而不是 Pro() 这个构造函数。
class Pro&#123;public:  Pro();                                  // constructor  Pro(const pro&amp;) = delete;               // copy constructor  Pro(Pro&amp;&amp;) = default;                   // move constructor  Pro&amp; operator= (const Pro&amp;) = default;  // copy assignment  Pro&amp; operator= (const Pro&amp;&amp;) = delete;  // move assignment  virtual ~Pro();                         // deconstructor&#125;;

类中有拷贝构造函数或拷贝赋值函数后，不能再在拷贝构造函数或拷贝赋值函数后面加 =default 或 =delete 关键字修饰了。





1.19. Chrono通用术语

duration 时间段：指的是在某时间单位时间上的一个明确的 tick（片刻数）。
timepoint（时间点）：表示某个特定的时间点，是一个 duration 和 epoch 的组合。关联至某个 clock 的某个正值或负值 duration。
epoch（时间段的起点）。1970 年 1 月 1 日是 UNIX 和 POSIX 系统时钟（system clock）的起点。

1.19.1. durationclass duration 类 API 接口

d.count() 返回 duration d 的 tick 数量，即打印 tick 数。
duration::zero() 获得一个长度为 0 的时间段（duration）。
duration::min() 和 duration::max() 则分别获得一个 duration 所拥有的最小和最大值。
duration::rep 获得 ticks 的类型。
duration::period 获得 unit type 的类型。

1.19.2. timepoint and clock2. C++14 新特性C++14 引入了一些新特性，以下是其中一些：

泛型 lambda 表达式：允许 lambda 表达式具有自动类型推导和通用的参数列表。

constexpr 函数的扩展：C++11 中，constexpr 函数只允许包含单个 return 语句。C++14 中允许 constexpr 函数中有多个 return 语句，也可以包含局部变量。

返回类型推导：C++14 允许使用 auto 来推导函数的返回类型，如下所示：
 auto add(int x, int y) &#123;  return x + y;&#125;
字符串字面量的改进：C++14 支持 R”delim(…)delim” 的原始字符串字面量，其中 delim 可以是任何字符序列。这种类型的字符串字面量可以包含换行符和反斜杠字符。

二进制字面量：C++14 允许使用 0b 或 0B 前缀来表示二进制数字。

数组初始化的简化：C++14 允许在花括号中使用 “等号” 来表示“全部初始化为指定值”，如下所示：
 int arr[10] = &#123; 0 &#125;; // 所有元素初始化为 0
sizeof() 的变量模板：C++14 允许使用变量模板来获取对象的大小，如下所示：
 template &lt;typename T&gt;constexpr std::size_t size = sizeof(T);
常量表达式 if 语句：C++14 允许在常量表达式中使用 if 语句。

容器的 emplace_back() 函数的改进：C++14 允许使用可变参数模板来调用 emplace_back() 函数。

引入了 std::make_unique 创建 unique_ptr  对象，可以使用 std::make_unique() 函数来创建。


3. C++17 新特性
结构化绑定（Structured Binding）：
 #include &lt;tuple&gt;#include &lt;iostream&gt;using namespace std;int main() &#123;    auto [x, y, z] = make_tuple(1, 2, 3);    cout &lt;&lt; x &lt;&lt; &quot;&quot; &lt;&lt; y &lt;&lt;&quot; &quot; &lt;&lt; z &lt;&lt; endl;    return 0;&#125;

 输出：
 1 2 3

if 语句中的初始化（if with initializer）：
 #include &lt;iostream&gt;using namespace std;int main() &#123;    if (int x = 42; x&gt; 0) &#123;        cout &lt;&lt; x &lt;&lt; endl;    &#125;    return 0;&#125;

 输出：
 42

折叠表达式（Fold Expressions）：
 #include &lt;iostream&gt;using namespace std;template&lt;typename... Args&gt;auto sum(Args... args) &#123;    return (args + ...);&#125;int main() &#123;    cout &lt;&lt;sum(1, 2, 3, 4, 5) &lt;&lt; endl;    return 0;&#125;

 输出：
 15

constexpr if：
 #include &lt;iostream&gt;using namespace std;template&lt;typename T&gt;void foo(T t) &#123;    if constexpr (is_same_v&lt;T, int&gt;) &#123;        cout &lt;&lt; &quot;int:&quot; &lt;&lt; t &lt;&lt; endl;    &#125; else if constexpr (is_same_v&lt;T, double&gt;) &#123;        cout &lt;&lt; &quot;double:&quot; &lt;&lt; t &lt;&lt; endl;    &#125; else &#123;        cout &lt;&lt; &quot;unknown type&quot; &lt;&lt; endl;    &#125;&#125;int main() &#123;    foo(42);    foo(3.14);    foo(&quot;hello&quot;);    return 0;&#125;

 输出：
 int: 42double: 3.14unknown type

结构化绑定与 tuple 的整合使用：
 #include &lt;tuple&gt;#include &lt;iostream&gt;using namespace std;struct Point &#123;    int x;    int y;&#125;;int main() &#123;    Point p&#123;1, 2&#125;;    auto [x, y] = tie(p.x, p.y);    cout &lt;&lt; x &lt;&lt; &quot; &quot; &lt;&lt; y &lt;&lt; endl;    return 0;&#125;

 输出：
 1 2

[[nodiscard]] 属性：
 #include &lt;iostream&gt;using namespace std;[[nodiscard]] int foo() &#123;    return 42;&#125;int main() &#123;    foo();    return 0;&#125;

 编译时会提示：
 warning: ignoring return value of function declared with &#x27;nodiscard&#x27; attribute

constexpr lambda：
 #include &lt;iostream&gt;using namespace std;int main() &#123;    constexpr auto f = [] (int x) &#123; return x * 2; &#125;;    constexpr int x = f(3);    cout &lt;&lt; x &lt;&lt; endl;    return 0;&#125;

 输出：
 6

嵌套命名空间：
 #include &lt;iostream&gt;using namespace std;namespace ns1 &#123;    namespace ns2 &#123;        int x = 42;    &#125;&#125;int main() &#123;    cout &lt;&lt; ns1::ns2::x &lt;&lt; endl;    return 0;&#125;

 输出：
 42

if constexpr 中的变量声明：
 #include &lt;iostream&gt;using namespace std;template&lt;typename T&gt;void foo(T t) &#123;    if constexpr (bool b)&#125;

4. C++20 新特性4.1. Coroutines协程（Coroutines）是 C++20 引进的一种新技术。
4.2. Concepts4.3. Modules4.4. Ranges5. References
C++ standard: https://isocpp.org/std/the-standard 标准委员会官方站点，近期的会议、行程、活动、计划等等都会发布在这里。这里也会推荐一些比较好的文章、教程、书籍等等内容，供C++程序员阅读。
modern C++ 讲解：http://www.modernescpp.com/index.php

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>03-C++Standard</tag>
      </tags>
  </entry>
  <entry>
    <title>04-STL</title>
    <url>/Cpp/Cpp/04-STL/</url>
    <content><![CDATA[

1. Thinking(思考)
使用它是一件很愉快的事。
使用一个东西，却不明白它的道理，不高明！—林语堂
源码之前了无秘密。
天下大事，必作于细。
高屋建瓴，细致入微。
所谓剖析源码，其目的在于明理、解惑，提高自身水平，并不是要穷经皓首，倒背如流。

STL学习境界：会用，明理，能扩展。

会用：熟练使用 STL 的各种 API 接口。
明理：明白 STL 设计的思想，各种 API 的底层实现原理。
能扩展：对 STL 添加自己实现的各种接口，扩充 STL 的功能。


目标
Level 0: 使用C++标准库
Level 1: 深入认识C++标准库(胸中自有丘壑)
Level 2: 良好使用C++标准库
Level 3: 扩充C++标准库

源码版本：GNU 2.91, GNU 4.9

2. History(历史)C++创始人：比尼亚·斯特鲁斯特鲁普（Bjarne Stroustrup）
STL创始人：Alexander Stepanov(亚历山大·斯蒂芬诺夫)
GPL(General Public licence): 广泛开放授权。使用者可以自由阅读与修改GPL软件的源代码，但如果使用者要传播借助GPL软件而完成的软件，他们必须也同意GPL规范。这种精神主要是强迫人们分享并回馈他们对GPL软件的改善。得之于人，舍于人。
3. STL(Standard Template Library)标准模板库Generic Programming(泛型编程): 操作(operations)使用相同的接口，但是其类型(type)不相同，即使用模板(template)将泛型操作公式化。其中STL是泛型编程(GP)最成功的一个作品。

STL所实现的是依据泛型思维架设起来的概念结构。STL的核心思想：算法和数据结构的实现是分离的。

STL六大部件

算法 (Algorithm)
容器 (Container）
迭代器 (Iterator)
仿函数 (Functor)
适配器 (Adaptor)
分配器 (Alloctor)



从语言实现的层面分析，Algorithm 采用 function template 实现的，而 Container、Iterator、Functor、Adaptor、Alloctor 都是采用 class template 实现的。

六大部件之间的关系

Container 通过 Allocator 取得数据存储的空间；

Algorithm 通过 Iterator 访问 Container 中的内容，Container 与 Algorithm 之间不能直接访问，需要借助 iterator，可以把 Iterator 看做是算法与容器之间沟通的桥梁；

Functor 协助 Algorithm 完成不同的策略变化；

Adaptor 修饰或套接 Functor；




使用六大部件的例子


常用的容器

Vector(向量)
Deque(双队列)
List(链表)
Map&#x2F;Multimap(映射&#x2F;多重映射)
Set&#x2F;Multiset(集合&#x2F;多重集合)



4. Container(容器)容器是一个一个的类模板 (class template)，里面放的是元素。
STL标准库中 容器** 内存储的元素都必须能够拷贝，而 C++ 编译器默认提供的是浅拷贝，程序在执行时，则会出现问题。因此需要 重写构造函数 和重载 &#x3D; 操作运算符，执行深拷贝。
4.1. Sequence containers(有序容器)4.1.1. Array(数组)Array 是 C++11 标准之后新增的一个容器，表示固定数量的元素(fixed number of elements)。为了模拟数组的相关特性。
其内部结构如下图所示


Array会把元素复制到其内部的 static C-style array中。这些元素总是拥有一个明确次序。因此 array 是一种有序(ordered)集合。Array允许随机访问，也就是你可以在常量时间内直接访问任何元素，前提是你知道元素位置。Array的迭代器属于随机访问（random-access)迭代器，所以你可以对它运用任何 STL 算法。
如果你需要一个有固定元素量的序列，classarray&lt;&gt; 将带来最效能，因为内存被分配下stack中（如果可能的话），绝不会被重分配(reallocation)，而且你拥有随机访问能力。
注意点：STL 源码中实现，没有构造和析构函数。
4.1.1.1. 优点支持 [] 和 at() 操作。at() 函数带范围检查，超出范围，就会抛出 range-error异常；而 [] 操作是不做范围检查的。 
4.1.1.2. 缺点
不能扩容。
Array 不允许你指定分配器(Allocator)。

4.1.1.3. 源码分析

4.1.2. vector(单端的动态数组)vector 是 C++ 标准模板库中的部分内容，它是一个多功能的，能够操作多种数据结构和算法的模板类和函数库。vector 之所以被认为是一个容器，是因为它能够像容器一样存放各种类型的对象，简单地说 vector 是一个能够存放任意类型的动态数组，能够增加和压缩数据。
动态数组实现机制：

先为数组开辟较小的空间，然后往数组里面添加数据，当数组中元素的数量超过数组的容量时，重新分配一块更大的空间（STL 中 vector 每次扩容时，新的容量都是前一次的两倍），再把之前的数据复制到新的数组中，再把之前的内存释放。

发生内存的重分配（realloc）操作通常有 4 个步骤

分配一个新的内存块，它是容器当前容量的一些倍数，常常为 2 倍。
将容器旧内存中的所有元素复制到新内存中。
销毁旧内存中的对象（object）。
销毁（Deallocate）旧内存。

 注意：

使用动态数组时，尽量减少改变数组容量大小的次数，可以减少时间性能的消耗。 一般每次扩容为原来的  2 倍。
当 vector 扩容时，会调用 move constructor 和 move destructor，并且移动构造和移动析构函数在执行期间不会抛出异常，是用 noexcept 关键字修饰。因为它不能确保异常发生后，移动构造和移动析构函数还能满足标准库的要求，所以是禁止抛异常的。
 标准库中成长型的容器（需要发生 memory reallocation）有：vector 、deque、string。

内部结构图




4.1.2.1. API接口
size(): 返回容器中元素的个数
get(r): 获取索引为 r 的元素
put(r, e): 用 e 替换索引为 r 元素的数值
insert(r, e): 向索引为 r 的元素处插入数值 e，后面元素依次后移
remove(r): 移除索引为 r 的元素，返回全元素中原存放的对象
disordered(): 判断所有元素是否已按升序序排列
sort(): 调整各元素癿位置，使按照升序序排列
deduplicate(): 删除重复元素   —向量
uniquify(): 删除重复元素 —有序向量
traverse(): 遍历向量幵统一处理所有元素，处理斱法由函数对象指定
empty(): 判断容器是否为空
at(index): 返回索引为 index 的元素
erase(p): 删除指针p指向位置的数据，返回下指向下一个数据位置的指针（迭代器）
erase(beg, end):删除区间[beg, end)的数据
pop_back(): 删除最后一个元素
push_back(): 在容器末尾插入一个元素
back(): 获取尾部元素
front(): 获取首部元素
begin(), end(): 返回容器首尾元素的迭代器
clear(): 移除容器中所有的元素
swap(): 交换两个容器的内容，交换两个 vector 的内容后，两者的容量也交换了，这是一个间接缩短 vector的小窍门。
shrink_to_fit(): 缩短 vector 的大小到合适的空间，为实现特定的优化保留了回旋的余地。
resize(size_t n): 强制容器将其容纳的元素数更改为 n。
若 n 小于当前容器的 size，原容器里超过 n 后面的值被销毁。
若 n 大于当前容器的 size，容器里超过 size 后面的内容，编译器将默认构造函数中的数据写入到容器里面。
若 n 大于当前容器的 capacity ，向容器中增加元素之前会发生 reallocation。


reserve(size_t n): 强制将容器的容量重新设置为 n。
若 n 大于当前容器的 capacity，发生 reallocation。
若 n 小于当前容器的 capacity，vector 忽略调用，什么也不会做；string 会将其容量减少到 size ()和 n 的最大值，但 string 的大小（size）肯定保持不变。



4.1.2.2. 优点
不指定一块内存大小的数组的连续存储，即可以像数组一样操作，但可以对此数组进行动态操作，运行阶段执行。
随机访问快，支持随机迭代访问器。即支持 [] 操作符和 at()操作。
节省空间。

4.1.2.3. 缺点
向容器中插入元素时，内部的元素必须能够执行 拷贝（必须提供拷贝构造） 操作。
在内部进行插入删除操作效率低。
只能在vector的最后进行push和pop，不能在vector的头进行push和pop。
当动态添加的数据超过vector默认分配的大小时要进行整体的重新分配、拷贝与释放。

4.1.2.4. 源码分析GNU 2.9版源码UML图


GNU 4.9版源码UML图


Vector类与其基类之间的关系


Vector_base内部类与其它类之间的关系


迭代器之间的关系


4.1.3. deque(双端数组)deque 是在功能上合并了 vector 和 list。与 vector 容器类似，但是可以在 Deque 的两端进行操作。
deque 的内部结构图如下






4.1.3.1. API接口
push_back(): 在容器末尾插入一个元素
push_front() 容器头部插入一个元素
pop_front(): 容器头部删除一个元素
pop_back(): 删除最后一个元素

4.1.3.2. 优点
支持随机访问，即支持 []操作符和 at()。
在内部方便的进行插入和删除操作。
可在两端进行 push、pop。

4.1.3.3. 缺点
每次扩容的大小为一个 buffer。
占用内存多，采用多个内存区块来存储元素。

4.1.4. list(双向链表)list是一个双向链表的容器，可以高效的进行 插入 和 删除 元素。每一个结点都包括一个信息快 Info、一个前驱指针 Pre、一个后驱指针 Post。可以不分配固定的内存大小，方便的进行添加和删除操作，使用的是非连续的内存空间进行存储。
4.1.4.1. list insert链表的插入操作：在 pos 位置插入新的节点，新插入的数据存放在 pos 位置之前。
4.1.4.2. list delete
clear() 移除容器中所有的数据
erase(begin, end) 删除区间 [begin, end) 的数据，返回下一个元素的位置。
erase(pos) 删除指定 pos 位置的数据，返回下一个元素的位置。
remove(element) 删除容器中所有与 element 值匹配的数据。

4.1.4.3. 内部结构图



4.1.4.4. 优点
不使用连续内存完成动态操作。
在内部方便的进行插入和删除操作
可在两端进行push、pop

4.1.4.5. 缺点
每次只能扩充一个结点，效率低，但空间浪费是最小的。
不能进行内部的随机访问，即不支持 at.(pos) 函数和 [] 操作符。
相对于verctor占用内存多。

4.1.4.6. API接口4.1.4.7. 源码分析    _Self&amp;    operator++() _GLIBCXX_NOEXCEPT      // 前置++    &#123;_M_node = _M_node-&gt;_M_next;             // 移动结点return *this;    &#125;    _Self    operator++(int) _GLIBCXX_NOEXCEPT   // 后置++    &#123;_Self __tmp = *this;                    // 记录原值_M_node = _M_node-&gt;_M_next;             // 执行操作return __tmp;                           // 返回原值，执行的是拷贝构造    &#125;

通过两者传入的参数值不同来区分是前置++还是后置++。
_M_node = _M_node-&gt;_M_next; 这一行为++操作的具体实现过程：

移动结点。过程：将当前结点next域的值取出来赋给_M_node，而_M_node本身指向当前的结点，_M_node-&gt;_M_next 指到下一个结点的prev域。此时_M_node 与_M_node-&gt;_M_next指向的内容是一样的，所以把_M_node移动到 _M_node-&gt;_M_next 指向的位置，这一过程就是结点的++操作。



思考：为什么前置++与后置++两者的返回值是不一样的？

为了与整数的 ++ 操作保持一致，操作运算符重载持有的操作应该向整数的操作看起，拥有类似的功，保证不能进行两次的 ++ 运算操作。



源码中list的UML图分析




4.1.5. forword list(单向链表)forword list 链表是 C++11 新加的功能，比 list 的效率要快，是单向的链表。
使用 forword_list，必须添加头文件 #include &lt;forword_list&gt;。头文件中 forward list 是命名空间 std 内的 class template 。
namespace std &#123;    template &lt;typename T,              typename Allocator = allocator&lt;T&gt; &gt;    class forward_list;&#125;



4.1.5.1. 内部结构图

4.1.5.2. API 接口
insert()
front() 返回容器中的第一个元素，但并不检查是否存在第一元素。

4.1.5.3. 优缺点
优点
内存占用量比 list 少，运行速度（runtime）略快。


缺点
扩容是时，只能扩充一个结点。



4.1.5.4. 注意点forword list 不提供 size()操作。原因是不可能在固定的时间内存储或计算当前元素的数量。同时也反应出 size() 是一个费时间的操作。若必须要计算元素的个数，可用 distance() 函数。
$include &lt;iostream&gt;#include &lt;forward_list&gt;#include &lt;iterator&gt;    int main () &#123;    std::forward_list&lt;int&gt; l;    std::cout &lt;&lt; &quot;l.size(): &quot; &lt;&lt; std::distance(l.begin(),l.end())    &lt;&lt; std::endl;&#125;



4.1.5.5. 源码分析

4.2. Associative containers(关联性容器)关联式容器并不提供元素的直接访问，需要依靠迭代器访问。map 是个例外，提供了subscript(下标)操作符，支持元素的直接访问。
4.2.1. setset 是一个 集合 容器，包含的元素是唯一的，集合中的元素按照一定的顺序排列，不能随意指定位置插入元素。
4.2.1.1. 内部结构图



4.2.1.2. API 接口
insert() 函数的返回值类型为 pair&lt;iterator, bool&gt;，结果是一对数据类型。
pair&lt;T1, T2&gt; 存放两个不同类型的数值

set 查找接口

find() 返回查找元素的迭代器，查找的元素默认是区分大小写的。
count() 返回容器中查找元素的个数
upper_bound 返回容器中大于查找元素的迭代器位置
lower_bound 返回容器中小于查找元素的迭代器位置
equal_range(ele)返回容器中等于查找元素的两个上下限的迭代器位置（第一个：大于等于ele元素的位置，第二个：大于 ele元素的位置）



4.2.1.3. 优点4.2.1.4. 缺点4.2.2. multisetmultiset 也是一个容器集合，但它支持容器中的 key 可以重复。
4.2.3. set 与 multiset 对比
set 与 multiset 底层都是采用红黑树的数据结构实现的。
set 支持唯一的键值，容器里面的元素值只能出现一次，而 multiset 集合容器中同一个元素值可以出现多次。
不可以直接修改 set 和 multiset 集合容器中元素的值，因为集合容器是自动排序的。修改集合容器中元素的值，必须先删除原先元素的值，再插入新元素的值。

4.2.4. mapmap 是关联式容器，一个 map 就是一个键值对。map 中的 key 值唯一，容器中的元素按照一定的顺序排列，不能在任意指定的位置插入元素。
4.2.4.1. map与multimap内部结构图



4.2.4.2. map insert// 四种map容器的插入方法map&lt;int, string&gt; mp;mp.insert(pair&lt;int, string&gt;(101, &quot;赵云&quot;));                   // 法一mp.insert(make_pair&lt;int, string&gt;(102, &quot;关羽&quot;));              // 法二mp.insert(map&lt;int, string&gt;::value_type(103, &quot;曹操&quot;));        // 法三mp[104] = &quot;张飞&quot;;                                            // 法四// 方法一到方法三向容器中插入相同的键值时，不会插入成功。// 采用法四向容器中插入相同的键值时，会覆盖原先相同键值的数据。

注意: 

map的查找操作需要做异常判断处理
key 与 value 两个值必须是可拷贝的(copyable)和可移动的(movable)。
指定的排序准则下，key 必须是可比较的(comparable)。

4.2.4.3. at() &amp;&amp; []
at() 函数会根据它收到的 key 得到元素的 value，如果不存在这样的元素，则抛出 out_of_range 异常。
operator []
operator [] 的索引就是 key，其类型可能属于任何的类型，不一定是整数。
如果你选择某 key 作为索引，容器内没有相应的元素，那么 map 会自动安插一个新元素，其 value 将被其类型的 default 构造函数初始化。因此你不可以指定一个 不具 default 构造函数的 value 类型。一般基础类型都有一个 default 构造函数，设初值为 0。



4.2.4.4. 优点插入键值的元素不允许重复，只对元素的键值进行比较，元素的各项数据可以通过 key 值进行检索。 
4.2.4.5. 缺点4.2.5. mutimapmultimap (collection of key-value pairs, sorted by keys.)
4.2.6. map 与 multimap 对比
map 的底层原理是按照平衡二叉树的数据结构来实现的，在插入和删除的操作上比 vector 容器快。
map 支持唯一的键值，每个 key 只能出现一次，支持 [] 操作，形如：map[key] = value。 multimap 不支持唯一的键值，容器中的每个 key 可以出现相同的多次，不支持 [] 操作。
map 和 multimap 会根据元素的 key 自动对元素排序。这么一来，根据已知的 key 查找某个元素时就能够有很好的效率，而根据己知 value 查找元素时，效率就很糟糕。“自动排序”这一性质使得 map 和 multimap 本身有了一条重要限制：你不可以直接改变元素的 key。因为这样做会损坏正确的次序。想要修改元素的 key ，必须先移除拥有该 key 的元素，然后插人拥有新 key/value 的元素。从迭代器的视角看，元素的 key 是常量。然而直接修改元素的 value 是可能的，提供的值的类型不能是 constant。

4.2.7. 与其它容器对比set 和 map 中的 key 不能重复，而 multiset 和 multimap 中的 key 却能重复的原因：set 和 map 底层调用的是红黑树的 insert_unique()，而 multiset 和 multimap 底层调用的是红黑树中的 insert_equal() 去进行 insert 操作的。
4.3. Unordered associative containers(无序关联容器)4.3.1. unordered_setunordered_set 是一种无序的容器集合。底层采用哈希表实现的。
STL无序容器存储状态，hash 表存储结构图




unordered_set 模板类中的定义
template&lt;typename _Value,                        // 容器中存储元素的类型        typename _Hash = hash&lt;_Value&gt;,           // 确定元素存储位置的哈希函数        typename _Pred = std::equal_to&lt;_Value&gt;,  // 判断各个元素是否相等        typename _Alloc = std::allocator&lt;_Value&gt;, // 指定分配器对象的类型        typename _Tr = __uset_traits&lt;__cache_default&lt;_Value, _Hash&gt;::value&gt;&gt;


注意：此容器模板类中没有重载 [] 运算符，也没有提供 at() 成员方法，unordered_set 容器内部存储的元素值不能被修改，可以使用迭代器遍历容器中的数，但不能修改容器中元素的值。

4.3.2. unordered_multiset4.3.3. unordered_map内部结构图


4.3.4. API 接口
count(key) : 对 multimap 而言，返回 key 在 multimap 中出现的次数；对 map 而言，返回结果为：当前key在map中，返回结果为 1，没在返回结果就为 0；

4.3.5. unordered_multimap4.3.6. hashtable4.3.6.1. 什么是hashtable？哈希表（hashtable）又叫散列表，是一种根据设定的映射函数f(key)将一组关键字映射到一个有限且连续的地址区间上，通过哈希函数把key转成哈希值来定位数据存储位置的一种数据结构。这个映射过程称为哈希造表或者散列，这个映射函数f(key)即为哈希函数也叫散列函数，通过哈希函数得到的存储位置称为哈希地址或散列地址
简单来说哈希表就是通过一个映射函数f(key)将一组数据散列存储在数组中的一种数据结构。
哈希集合（hashset），也是一种通过哈希值来定位存储位置的数据结构，只是它不是键-值对结构，而是储存key本身，相当于只有哈希表（hashtable）中的key部分，即用key算出的哈希值来定位存储位置，在该位置上存储内容为key本身。 简单来说就是，hashset是不能存储重复元素的数据结构（集合），而哈希表（hashtable）是存储键-值对（key-value），其中键key不能重复。
用一张图来说明hashtble的数据结构


用一张图来说明hashset的数据数据


在哈希表中，每一个元素的key和key所对应的value值都存在一个映射函数f(key)与它们一一相对应，通过这个映射函数f(key)，我们可以快速的查找到这个元素在表中所对应的位置。


4.3.6.2. 为什么要用 hashtable?如何在一个无序的线性表中查找一个数据元素？
注意，这是一个无序的线性表，也就是说要查找的这个元素在线性表中的位置是随机的。
对于这样的情况，想要找到这个元素就必须对这个线性表进行遍历，然后与要查找的这个元素进行比较。 这就意味着查找这个元素的时间复杂度为o(n)。
对于o(n)的时间复杂度，在查找海量数据的时候也是一个非常消耗性能的操作。那么有没有一种数据结构，这个数据结构中的元素与它所在的位置存在一个对应关系，这样的话我们就可以通过这个元素直接找到它所在的位置，而此时查找这个元素的时间复杂度就变成了o(1),可以大大节省程序的查找效率。


hash table有什么用？利用哈希表可以快速判断一个元素是否出现集合里。
4.3.6.3. 什么是哈希冲突？对于不同的key，可能得到同一个哈希地址，即key1≠key2,而 f(key1)&#x3D;f(key2)，对于这种现象我们称之为哈希冲突，也叫哈希碰撞。
一般情况下，哈希冲突只能尽可能的减少，但不可能完全避免。
因为哈希函数是从key集合到地址value集合的映射，通常来说key集合比较大，它的元素理论上包括所有可能的key，而地址value集合的元素仅为哈希表中的地址值。
这就导致了哈希冲突的必然性。
4.3.6.4. 如何解决哈希冲突？常用的构造哈希函数的方法有以下几种：
（1）除留取余法
这个方法我们在上边已经有接触过了。取关键字被某个不大于哈希表长m的数p除后所得余数为哈希地址。即：f(key)&#x3D;key % p, p≤m;
（2）直接定址法
直接定址法是指取关键字或关键字的某个线性函数值为哈希地址。即：f(key)&#x3D;key 或者 f(key)&#x3D;a*key+b、
（3）数字分析法
假设关键字是以为基的数（如以10为基的十进制数），并且哈希表中可能出现的关键字都是事先知道的，则可以选取关键字的若干位数组成哈希表。
虽然我们可以通过选取好的哈希函数来减少哈希冲突，但是哈希冲突终究是避免不了的。那么，碰到哈希冲突应该怎么处理呢？接下来我们来介绍几种处理哈希冲突的方法。
4.3.6.4.1. 链地址法hash table 为了解决冲突采用 separate chaining 的方式。
链地址法是指在碰到哈希冲突的时候，将冲突的元素以链表的形式进行存储。也就是凡是哈希地址为i的元素都插入到同一个链表中，元素插入的位置可以是表头（头插法），也可以是表尾（尾插法）。
是一中比较常用的方法。比如Java中的HashMap就是基于链地址法的哈希表结构。虽然链地址法是一种很好的处理哈希冲突的方法，但是在一些极端情况下链地址法也会出现问题。
4.3.6.4.2. 开发定址法开放定址法是指当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。
4.3.6.4.3. 再哈希法再哈希法即选取若干个不同的哈希函数，在产生哈希冲突的时候计算另一个哈希函数，直到不再发生冲突为止。


4.3.6.4.4. 建立公共溢出区专门维护一个溢出表，当发生哈希冲突时，将值填入溢出表。
4.3.6.5. 优点
无论数据有多少，处理起来都特别的快
能够快速地进行 插入修改元素 、删除元素 、查找元素 等操作
代码简单，只需要把哈希函数写好，之后的代码就很简单了。

4.3.6.6. 缺点
哈希表中的数据是没有顺序的
数据不允许重复

4.3.6.7. 复杂度时间复杂度：最好情况下是 $\Omicron(1)$，最坏情况下是 $\Omicron(n)$，n 是 hash table 的长度。
Hashtable 其实是综合了数组和链表的优点，当 Hashtable 对数值进行搜索的时候，首先用该数值与Hashtable的长度做了取模的操作，得到的数字直接作为hashtable中entry 数组的 index,因为 hashtable 是由 entry 数组组成的，因此，可以直接定位到指定的位置，不需要搜索，当然，这里还有个问题，每个entry其实是链表，如果entry有很多值的话，还是需要挨个遍历的，因此可以这样讲Hashtable的时间复杂度最好是O(1)但是最差是 O(n) 最差的时候也就是hashtable中所有的值的hash值都一样，都分配在一个entry里面。
4.4. Containers Difference(容器之间的差异性)和其他所有关联式容器一样，map/multimap 底层是以平衡二叉树完成的。C++ standard 并未明定这一点，但是从 map 和 multimap 各项操作的复杂度自然可以得出这一结念。
通常 set、multiset、map 和 multimp 都使用相同的内部结构，因此，你可以把 set 和 multiset 视为特殊的 map 和 multimp，只不过 set 元素的 value 和 key 是同一对象。因此，map 和 multimap 拥有 set 和 multiset 的所有能力和所有操作。当然，某些细微差异还是有的：首先，它们的元素是 key&#x2F;value pair，其次，map 可作为关联式数组(associative array)来使用。
容器如何选择？

Array 和 vector 的区别在于容器的长度是否固定。若要随机访问，且容器的长度固定，则用 array，反之用 vector。
List 和 vector 最主要的区别在于 vector 是使用连续内存存储的，它支持 [] 运算符，而 list 底层用链表数据结构实现的，不支持 [] 。
Vector 内部结构简单，对元素随机访问的速度很快，但是在头部插入元素速度很慢，在尾部插入速度很快。所以数据的访问十分灵活方便，数据的处理也很快。
List 对于随机访问速度慢得多，因为需要遍历整个链表才能做到，但是对元素的插入就快的多了，不需要拷贝和移动数据，只需要改变指针的指向就可以了。
Map、Set 属于关联性容器，底层是采用红黑树实现的，它的插入、删除效率比其他序列容器高，因为它不需要做内存拷贝和内存移动，而是改变指向节点的指针。
Set 和 Vector 的区别在于 Set 容器不包含重复的数据。Set 和 Map 的区别在于 Set 只含有 Key，而 Map有一个 Key 和 Key 所对应的 Value 两个元素。
Map 和 HashMap 的区别是 HashMap 使用了 Hash 算法来加快查找过程，但是需要更多的内存来存放这些 Hash 桶元素，因此可以算得上是采用空间来换取时间策略。

简单选择容器的准则

若需要高效的随机存取，而不在乎插入和删除的效率，使用 vector。 
经常需要元素大量的插入、删除和移动，而不关心随机存取，则应使用 list。
若需要随机存取，而且经常在两端对数据进行插入和删除，则应使用 deque；若希望元素从容器中被移除时，容器能自动缩减内部的内存用量，那么也用 deque。
若需要字典结构或者处理 key&#x2F;value 这样的键值对时，应采用 unordered map(multimap)；若元素的顺序很重要，则用 map(multimap)。
经常根据某个准则去查找元素，则应根据该准则进行 hash 的 unordered_set 或 unordered_multiset；若元素的顺序很重要，则用 set 或 multiset。

4.5. Container adaptors(容器适配器)容器适配器为有序的容器提供了不同的接口。queue 和 stack 底层完全借助 deque 实现的。
4.5.1. stack4.5.1.1. 内部结构图

4.5.1.2. API 接口
push() 入栈
pop() 出栈
top() 获取栈顶元素
size() 获取栈大小
empty() 栈为空

4.5.2. queue4.5.2.1. 内部结构图

4.5.2.2. API 接口
push() 入队列
pop() 出队列
empty() 对列为空
front() 队列头部元素

4.5.3. priority_queue(优先级队列)4.5.3.1. 什么是优先级队列4.5.3.2. 标准库接口// 最大或最小优先级队列变量的声明 priority_queue&lt;int&gt; g_priq;                            // 默认为最大值优先队列priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; l_priq; // 最小值优先队列

5. StringString 类是 C++ 标准库接对 char* 字符串一系列操作的封装，位于头文件 #include &lt;string&gt; 中。
5.1. string 与 char* 转换1、const char* 与 string 之间的转换。
char* 是 C 语言形式的字符串，string 类是 C++ 的字符串，C++ 为了要兼容 C 语言的字符串，两者之间需要进行转换。string 转 const char*，直接调用 string 类的 c_str() 接口。
string str = “abc”;const char* c_str = str.c_str();

2、const char* 转 string，直接赋值即可。
const char* c_str = “abc”;string str(c_str);

3、string 转 char*
char* c = “abc”;string s(c);const int len = s.length();c = new char[len+1];strcpy(c,s.c_str());

4、char* 转 string，直接赋值即可。
char* c = “abc”;string s(c);

5、 const char* 转 char*
const char* cpc = “abc”;char* pc = new char[strlen(cpc)+1];strcpy(pc,cpc);

6、char* 转 const char*，直接赋值即可
char* pc = “abc”;const char* cpc = pc;

5.2. API 接口string 是一个随机存储容器。

constructors: 构造函数。Create or copy a string
destructor: 析构函数。Destroys a string
= : 对 string 赋一个新值，新值可以是 string，C-string 形式的字符或单一字符。
assign(): 给 string 赋单个或多个值。
swap(): 交换两个 string 内容。
+=, append(), push_back(): 追加字符。
insert()：插入字符。
erase(), pop_back(): 删除字符。pop_back() 自 C++ 开始。
clear(): 移除所有字符。
resize(): 改变字符数量，在尾部删除或添加字符。
replace(): 替换字符
data(), c_str(): 将 string 字符串中内容作为字符数组（C-string形式）返回 。C++11 之前，data() 不是一个有效的 C-string，返回的结果中不包含 \0，C++11 之后，两者的方式是相同的。
size(), length(): 返回 string 中当前的字符数量。
empty(): 检查 string 中的字符数量是否为 0。检查 string 是否为空时，C++ STL 中建议用 empty() 替代 size()、length()，因为 empty() 比较快。
max_size(): 返回一个 string 中包含的最大字符数量。若操作 string 时，它的长度 length 大于 max_szie，后，STL 会抛出 length_error异常。
capacity() : 未重新分配 string 内部内存之前，返回 string 包含的最大字符数量。
重新分配后，所有字符串字符指向的 reference、pointer、Iterator 均无效了。
重新分配是很耗费时间的。
reverse(): 避免重新分配，保留一定容量，确保该容量用尽之前，reference 一直有效。
getline(): 逐行读取所有字符，包括开头的空白字符，直到遇到指定的分行符或 end of file 结束，默认情况下分行符为 换行符。

5.3. 底层实现Scott Meyers 在《Effective STL》第 15 条中提到 std::string 底层实现有多种方式，归纳起来有 3 类。

eager copy（无特殊处理）。采用类似 std::vector 的数据结构，现在很少采用这种形式。
Copy-on-Write（COW，写时复制）。
Small String Optimization（SSO，短字符串优化）。利用 string 对象的本身空间来存储短字符串。

C++ GCC std::string 在 C++11 之前与之后实现是完全不同的。c++11 之前实现的是 COW string。C++11之后实现的就是实时拷贝，因为 C++11 标准规定：不允许 [] 导致之前的迭代器失效，这就使得 COW 的string 不再符合C++规范了。
重要区别：COW 的 basic_string 有一个 RefCnt 变量，用于引用计数；而自 C++11开始，采用引用计数（reference counted）实现的 basic_string  不在被允许。因为让 string 的内部缓冲区共享被共享（ share internal buffers），在多线程环境中是行不通的。
空 string 大小源码
// C++11 及其以上static const size_type	npos = static_cast&lt;size_type&gt;(-1);size_type		_M_string_length;enum &#123; _S_local_capacity = 15 / sizeof(_CharT) &#125;;union&#123;    _CharT           _M_local_buf[_S_local_capacity + 1];    size_type        _M_allocated_capacity;&#125;;

size_type 由机器决定。
5.3.1. 数据类型( Type Definitions and Static Values)
string::traits_type
string::value_type
string::size_type
string::difference_type
string::reference
string::const_reference
string::pointer
string::const_pointer
string::iterator
string::const_iterator
string::reverse_iterator
string::const_reverse_iterator
static const size_type string::npos
string::allocator_type

6. Functor(仿函数)6.1. 什么是仿函数？仿函数(Functor)也叫函数对象(Function object)或者叫伪函数。它是在 struct 结构体中定义一种新的函数，它只为算法 (Algorithms) 服务。从实现的角度看，仿函数是一种重载了 operator() 的 class 或 class template，让对象也具有像函数一样的功能。一般函数指针可视为狭义的仿函数。 


6.2. 分类按操作数个数划分

一元运算 (unary_function)
二元运算 (binary_function)

按功能划分

算术运算 (Arithmetic)

加：plus

减: minus

乘: multiplies

除: divides

取模: modulus  

否定: negate 

negate 属于一元运算，其余的都属于二元运算。




关系运算 (Ratioanl)

等于: equal_to 

不等于: not_equal_to

大于: greater

大于等于: greater_equal

小于: less

小于等于: less_equal

六种都属于二元运算。




逻辑运算 (Logical)

逻辑 And: logical_and 

逻辑 Or: logical_or

逻辑 Not: logical_not

And, Or 属于二元运算，Not 属于一元运算。





6.3. 可调用对象哪些可以是可调用对象？

函数指针 (function pointer)
带有成员函数 operator() 创建的 object。
带有转换函数，可将自己转换为函数指针的 类 所创建的 object。
lambda 表达式。

6.4. 函数对象调用
函数对象可以做函数参数。 

函数对象可以做返回值。 

函数对象的调用与 回调函数 的调用类似。 
class Stu&#123;  private:  public:    void operator() (Stu&amp; T) &#123;&#125;&#125;

6.5. 可调用对象包装器包含头文件：#include &lt;functional&gt;
语法
std::function&lt;返回值类型(参数列表)&gt; obj_name = 可调用对象

包装器可包装哪些东西？

包装类的普通成员函数
包装类的静态函数
包装仿函数
包装转化为函数指针的函数对象

类的成员函数不能直接使用可调用对象包装器，还需要结合绑定器一起使用。
6.6. 可调用对象绑定器std::bind()
绑定器作用

将可调用对象与其参数一起绑定成为仿函数。
将多元可调用转化为一元可调用对象

两种方式

绑定非类的成员变量。
绑定类的成员变量或成员函数。

6.7. Predefined Function Objects (预定义函数对象)标准STL模板库中提前预定义了很多的函数对象。任何应用程序想要使用 STL 内建的仿函数，都必须包含标准库预定义函数对象的头文件 &lt;functional&gt;。
仿函数的主要作用就是为了搭配 STL 算法，在算法中进行使用。
6.8. 其它
证同函数(identity_function): 任何数值通过此函数后，不会有任何改变。标准库 stl_function.h 中用 identity 来指定 RB-tree 所需的 KeyOfValue。

选择函数(selection_function)，标准库 stl_function.h 中用 select1st 和 select2nd 来指定 RB-tree 所需的 KeyOfValue。

select1st: 接受一个pair，传回它的第一个元素。
select2nd: 接受一个pair，传回它的第二个元素。


投射函数

project1st: 传回第一参数，忽略第二参数。
project2nd: 传回第二参数，忽略第1参数。



7. Algorithm从实现的角度来看，STL算法是一种 function template。而所有的 Algorithms 内部最本质的操作无非就是比大小。
标准库中大约封装了有 80 多种算法。
STL算法的核心思想

STL通过类模板技术，实现了数据类型与容器模型的分离。
通过函数对象实现了自定义数据类型与底层算法的分离。
通过迭代器的方式统一的去遍历容器，向容器中读数据和写数据。

7.1. Heap(堆)heap（堆）的 STL 库中函数

make_heap(first, last, comp); 建立一个空堆；
push_heap(first, last, comp); 向堆中插入一个新元素；
top_heap(first, last, comp);  获取当前堆顶元素的值；
sort_heap(first, last, comp); 对当前堆进行排序；

7.2. API 接口
std::for_each() 遍历容器中的所有元素。

std::transform() 将容器中的数据进行某种转换的运算。

两个算法的区别

std::for_each() 使用的函数对象可以没有 返回值，参数一般传 reference，因此速度较快，不是很灵活。
std::transform() 使用的函数对象必须要有 返回值，参数一般传 value，因此速度较慢，但是很灵活。



std::adjacent() 查找一对相邻位置重复的元素，找到则返回指向这对元素的第一个元素的迭代器值。

std::distance() 返回两个迭代器之间的距离，两个迭代器必须指向同一个容器。

std::binary_search() 采用二分法在有序序列中查找 value，找到则返回 true。在无序的序列中不能使用。

std::count() 计数容器中指定元素的个数。

std::count_if() 使用 谓词 计数容器中指定条件元素的个数。

std::find() 

std::find_if() 

std::merge()  合并两个有序的序列，并存放到另一个序列中。

std::sort() 默认按照升序的方式重新排列指定范围内元素的元素。

std::random_shuffle() 对指定范围内的元素随机进行排序。

std::reverse() 对指定范围内的元素进行倒叙排序。

std::copy() 将一个容器中的元素值拷贝到另一个容器中

std::replace() 将指定范围内的 oldValue 替换为 newValue

std::replace_if() 将指定范围内的 oldValue 替换为 newValue，需要指定 函数对象（是自定义的函数对象或STL预定义的函数对象）。

std::swap()  交换两个容器

std::accumulate() 累加遍历容器中指定范围内的元素，并在结果上加一个指定的值。

std::stable_partition()

std::upper_bound() 

std::lower_bound() 

std::floor() 和 std::ceil()都是对变量进行四舍五入，只不过四舍五入的方向不同。 

std::floor() –&gt;向下取整数。5.88   std::floor(5.88) = 5;
std::ceil() –&gt;向上取整数。std::ceil(5.88)   = 6;


std::rotate()

std::max()

std::min()

std::sample


8. Adaptor(适配器)8.1. 什么是适配器适配器是一种用来修饰容器(containers)或仿函数(functor)或迭代器(iterators)接口的东西。改变 functor 接口者，称为 function adaptor；改变 container 接口者，称为 container adaptor；改变 iterator 接口者，称为 iterator adaptor。
8.2. 分类8.2.1. function adaptor(函数适配器)8.2.2. bind adaptor(绑定适配器)8.2.3. composite adaptor(组合适配器)8.2.4. pointer adaptor(指针适配器)8.2.5. member function adaptor(成员函数适配器)predicate: 判断这个条件是真还是假
9. Traits(萃取机)trait 中文译为：特点、特征、特性。
Traits 有很多的类型。
9.1. iterator_traits iterator_traits 即为迭代器的特征。这个有点不好理解，可以把它理解成一个 萃取机，用来区分传入迭代器中的类型是 class iterators 还是 non class iterators，即 native pointer。可以利用类模板中的 partial specialization可以得到目标。


根据经验，最常用到的迭代器相应型别有五种：value type，difference type，pointer，reference，iterator_category。如果你希望你所开发的容器能与 STL 水乳交融，一定要为你的容器中的迭代器定义这五种相应类型。“特性萃取机” traits 会很忠实地将原汁原味榨取出来：


其中，iterator_traits 位于 ../C++/bits/stl_iterators.h&gt; 头文件里。
public:  typedef _Iterator					                iterator_type;  typedef typename __traits_type::iterator_category iterator_category;  typedef typename __traits_type::value_type  	    value_type;  typedef typename __traits_type::difference_type 	difference_type;  typedef typename __traits_type::reference 	    reference;  typedef typename __traits_type::pointer   	    pointer;


value_type: 迭代器所指对象的类型。
difference_type: 两个迭代器之间的距离。也可以用来表示一个容器的最大容量，因为对于连续空间的容器而言，最大容量就是头尾之间的距离。
reference: 迭代器所指向的内容是否允许改变。
pointer: 迭代器指向的内容为指针。
iterator_category: 迭代器的类别。查看 迭代器章节的分类部分。

9.2. type traits位于 ../C++/type_traits.h&gt; 头文件中。
9.3. char traits位于 ../C++/bits/char_traits.h&gt; 头文件中。
9.4. allocator traits位于 ../C++/bits/alloc_traits.h&gt; 头文件中。
9.5. pointer traits位于 ../C++/bits/ptr_traits.h&gt; 头文件中。
9.6. array traits位于 ../C++/array&gt; 头文件中。
10. Iterators(迭代器)10.1. 什么是迭代器表示元素在容器中的位置，这种对象的概念就称为迭代器。（STL标准库中的解释：we need a concept of an object that represents positions of elements in a container. This concept exists. Objects that fulfill this concept are called iterators.）
迭代器就是一种泛化的指针，是一个可遍历 STL 容器中全部或部分元素的对象。从实现的角度看，迭代器是一种将 operator*, operator-&gt;, operator++, operator-- 等指针操作给予重载的 class template。
10.2. 迭代器设计思维不论是泛型思维或 STL 的实际运用，迭代器（iterators）都扮演着重要的角色。STL 的中心思想在于：将数据容器（containers）和算法（algorithms）分开，彼此独立设计，最后再以一帖胶着剂将它们撮合在一起。容器和算法的泛型化，从技术角度来看并不困难，C++ 的 class templates 和 function templates 可分别达成目标。如何设计出两者之间的良好胶着剂，才是大难题。
10.3. 基本操作
operator *: 返回当前位置上元素的值。
operator ++ 或 operator --: 让迭代器指向下一个或上一个元素。
operator == 或 operator !=: 判断两个迭代器是否指向同一个位置。
operator =: 赋值给迭代器

不同的迭代器也许是 smart pointers，具有遍历复杂数据结构的能力，其内部运作机制取决于所遍历的数据结构。每一种容器都必须提供自己的迭代器。事实上每一种容器的确都将其迭代器以嵌套方式定义与 class 内部，因此各种迭代器的接口（interface）虽然相同，但类型（type）却是各不相同。
10.4. 迭代运算迭代器的区间是一个前闭后开区间（half-open range）。

begin: 返回一个迭代器，指向容器中第一个元素的位置。
end: 返回一个迭代器，指向容器的终点，终点位于最后一个元素的下一个位置。



采用半开区间的优点？

给遍历元素时，循环（loop）结束的时候，提供一个简单的判断依据。只要尚未达 end()，loop就继续执行。
避免对空区间（empty ranges）采取特殊的处理。对于 empty ranges 而言，begin() 就等于 end()。

10.5. iterator遵循的原则iterator 是算法（Algorithms）与容器 （containers）之间的桥梁。


10.6. Iterator 分类根据移动特性和施行特性，迭代器分为五类：

input iterator: 这种迭代器所指的对象，不允许外界去改变，属于只读的。
output iterator: 属于只能写的迭代器。
forward iterator: 允许”写入型“算法（例如：replace()）在此迭代器所形成的区间上进行读写操作。l
bidirectional iterator: 双向移动迭代器。
random access iterator: 随机访问迭代器，涵盖所有指针运算的能力。



源码位于标准库的 stl_iterator_base_types.h 文件中。
// stl_iterator_base_types.h/**   *  @defgroup iterator_tags Iterator Tags   *  These are empty types, used to distinguish different iterators.  The   *  distinction is not made by what they contain, but simply by what they   *  are.  Different underlying algorithms can then be used based on the   *  different operations supported by different iterator types.  *////  Marking input iterators.struct input_iterator_tag &#123; &#125;;///  Marking output iterators.struct output_iterator_tag &#123; &#125;;/// Forward iterators support a superset of input iterator operations.struct forward_iterator_tag : public input_iterator_tag &#123; &#125;;/// Bidirectional iterators support a superset of forward iterator/// operations.struct bidirectional_iterator_tag : public forward_iterator_tag &#123; &#125;;/// Random-access iterators support a superset of bidirectional/// iterator operations.struct random_access_iterator_tag : public bidirectional_iterator_tag &#123; &#125;;

istream_iterator 的 iterator_category
ostream_iterator 的 iterator_category
父类中没有data 和 function，子类继承于父类的 typedef。
Iterator分类对算法的影响








10.7. 迭代器失效
为什么迭代器会失效？
STL 容器中元素整体“迁移”导致存放原容器元素的空间不再有效，使原本指向某元素的迭代器不再指向希望指向的元素，从而使得指向原空间的迭代器失效。 

对于序列式容器，比如vector，删除当前的iterator会使后面所有元素的iterator都失效。因为序列式容器中内存是连续分配的（分配一个数组作为内存），删除一个元素导致后面所有的元素会向前移动一个位置。删除了一个元素，该元素后面的所有元素都要挪位置，所以，删除一个数据后，其他数据的地址发生了变化，之前获取的迭代器根据原有的信息就访问不到正确的数据。

数组型数据结构的元素是分配在连续的内存中，insert 和 erase 操作，会使删除点和插入点之后的元素挪位置。所以，插入点和删除掉之后的迭代器全部失效，也就是说 insert(*iter)(或erase(*iter))，然后再 iter++，是没有意义的。

解决方法：erase(*iter)的返回值是下一个有效迭代器的值 iter =cont.erase(iter);


list型的数据结构，使用了不连续分配的内存，删除运算使指向删除位置的迭代器失效，但是不会失效其他迭代器。

解决办法两种，erase(*iter) 会返回下一个有效迭代器的值，或者erase(iter++)。


红黑树存储的数据，插入操作不会使任何迭代器失效；删除操作使指向删除位置的迭代器失效，但不会失效其他迭代器。erase 迭代器只是被删元素的迭代器失效，但是返回值为 void，所以要采用 erase(iter++)的方式删除迭代器。


注意：  经过 erase(iter) 之后的迭代器完全失效，该迭代器 iter 不能参与任何运算，包括 iter++和*ite。
参考

迭代器失效的几种情况总结 
聊聊map和vector的迭代器失效问题
C++ STL 迭代器失效问题

11. Allocators(分配器)11.1. 什么是分配器分配器（Allocator）负责内存空间的分配与管理。分配器是一个实现了动态空间配置、空间管理、空间释放的 class template。分配器我们一般不直接使用它，它是给容器使用的。容器的内存分配是通过分配器来管理的。
C++ 标准库在许多地方使用特殊的对象（objects）处理内存的分配（allocation）和归还（deallocation），像这样的对象（objects）就称为分配器allocators。
Allocator 代表的是一种特殊内存模型（memorymodel），并提供一种抽象的概念，将需要使用的内存（need to use memory）转变为对内存的直接调用（raw call for memory）。 如果在相同的时间使用不同的分配器（allocato）对象，允许你在程序中使用不同的内存模型（memory models）。
最初，allocator 只是作为 STL 的一部分而引人的，用来处理像 PC 上不同类型的指针（例如near、far、huge指针）这一类乱七八艚的问题；现在则是作为“运用某种内存模型”技术方案的基础，使得像共享内存（shared memory）、垃圾回收（garbagecollection）、面向对象数据库（object-oriented database）等解决方案能保特一致接。
11.2. 默认分配器C++标准定了一个 default allocator 如下：
namespace std &#123;  template &lt; typename T&gt;  class allocator;&#125;

这个默认分配器（default allocator）可在 allocator 得以被当作实参使用的任何地方允许当默认值，它会执行内存分配和回收。也是说，它会调用 new 和 delete 操作符。但 C++ 并没有对在什么时候以什么方式调用这些操作符给予明确规定。因此，default allocator 甚至可能在内部对分配内存采用缓存（cache）的手法。
绝人多数程序都使用 default allocator，但有时其它程序库也可能提供些 allocator 满足特定需求。这种情况下只需简单地将它们当做实参即可。只有少数情况下才需要自行写一个 allocator，现实中最常使用的还是 default allocator。
allocator 底层的操作都是采用 malloc() 和 free()来分配和释放内存。malloc 分配内存时，会有额外的外开销（overhead），使程序变慢。若要提高内存分配的效率，需要减少 cookie（用以记录内存的大小） 的开销
11.3. Allocator 标准接口
allocator::value_type 
The type of the elements. 
It is usually equivalent to T for an allocator&lt;T&gt;，传递一个模板参数类型。


allocator::size_type
allocator::difference_type
有符号整数值的类型，它可以表示分配模型中任意两个指针之间的差异。


allocator::pointer
allocator::const_pointer
allocator::void_pointer
allocator::const_void_pointer
allocator::reference
allocator::const_reference
allocator::rebind
allocator::propagate_on_container_copy_assignment
allocator::propagate_on_container_move_assignment
allocator::propagate_on_container_swap
allocator::allocator ()
allocator::allocator (const allocator&amp; a)
allocator::allocator (allocator&amp;&amp; a)
allocator::˜allocator ()
pointer allocator::address (reference value) 
const_pointer allocator::address (const_reference value)
size_type allocator::max_size ()
pointer allocator::allocate (size_type num) 
pointer allocator::allocate (size_type num, allocator::const_pointer hint)
void allocator::deallocate (pointer p, size_type num)
void allocator::construct (U* p, Args&amp;&amp;... args)
void allocator::destroy (U* p)
bool operator == (const allocator&amp; a1, const allocator&amp; a2)
bool operator != (const allocator&amp; a1, const allocator&amp; a2)
allocator select_on_container_copy_construction ()

12. Reference
面试官：哈希表都不知道，你是怎么看懂HashMap的？ 
c++ list, vector, map, set 区别与用法比较

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>04-STL</tag>
      </tags>
  </entry>
  <entry>
    <title>C++MemoryManagement</title>
    <url>/Cpp/Cpp/C++MemoryManagement/</url>
    <content><![CDATA[

History(历史)Doug Lea自1986年开始研究malloc算法，他的作品被称为 DL Malloc，目前linux中的glibc的malloc算法就是直接来自Doug Lea，其它平台的malloc的实现或多或少受到DL的影响。
内存管理层级
OS（操作系统），Windows 系统的的 HeapAlloc 和 VirtualAlloc；
GUNC++&#x2F;CRT 编译器的 malloc()
C++ 标准库的 Allocator
C++ 应用程序层面的内存 API 函数。

内存库作品
tcmalloc：稳定，占用内存更低。
jemalloc性能更高，占用内存更高

Bibliography(书目)
STL源码剖析(侯捷)
Small Memory Software(James Noble &amp; Charles Weir)
Modern C++ Design General Programming and Design Patterns Applied(Andrei Alexandrescu)

Reference(参考)
Doug Lea’s Home Page: Malloc算法的发明者网站。
Wikipedia Malloc: 很权威的Wikipedia解释Malloc的用法。

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>c++MemoryManagement</tag>
      </tags>
  </entry>
  <entry>
    <title>C++Optimization</title>
    <url>/Cpp/Cpp/C++Optimization/</url>
    <content><![CDATA[
开销来自哪里
函数之间的调用。用模板和内联函数去解决。

编写高效的 C++ 程序让编写的程序提高运行效率的方式：

高效的算法。
避免不必要计算和步骤。
选择恰当的优化设计策略。

References
Software optimization resources
《Optimized C++》Kurt Guntheroth 大师编写的 C++ 优化书籍。
《Effective STL》
《Effective C++》
《Effective Modern C++》

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>c++Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>C++SoftDesign</title>
    <url>/Cpp/Cpp/C++SoftDesign/</url>
    <content><![CDATA[

1. C++ 软件设计1.1. 简单就是最好的 —&gt; 大道至简。API 是软件组件的接口，隐藏了实现这个接口所需的内部细节。
API 必须拥有良好的设计、文档、回归测试、并且保证发布之间的稳定性。
1.2. 重用哲学设计自己和其它程序员可以重复使用的代码。重用设计的准则：

编写一次，经常使用。
尽量避免代码重复。
不要重复写在自己写过的代码（Don’t repeat yourself）。

为什么要重用设计代码？

重用设计可以节约金钱和时间。
缺乏重用性会导致代码重复。

1.3. 如何设计可重用代码对于设计可重用代码而言，最重要的策略是抽象。设计代码时，需要考虑将    接口和实现进行分离，使代码更容易使用，程序员使用时不需要理解其内部实现细节。
​ 抽象将代码分为接口和实现，因此设计可重用代码会关注这两个领域。代码实现时思考：如何做到恰到好处的设计代码结构？考虑使用什么样的类层次结构？需要使用模板吗？如何将代码切分割为子系统？设计接口时思考：设计分接口是库还是代码的“入口“，程序员使用这个接口时，应该给提供什么样的功能。
1.4. 软件设计考虑的原则
可扩展性（scalability）：代码之间耦合低。
可移植性（portability）：不同平台上运行。
安全性：产品发布后，有没有做相关保护的措施。例如，当前发布的产品有问题，如何快速回滚到原来的版本，最大限度减少产品发布的风险。
可维护性：方便组内其它的成员和后续维护代码的人员的快速理解和熟悉你的代码。
可复用性

1.5. 优美命名
launch
wrapper
crontab：定时器
schedule
task
helper
register
register_keybord_callback


callback
start
cancel
detail
grace-period：宽限期
spin

1.5.1. 管理类命名
starter、bootstrap
一般作为程序启动器使用，或者作为启动器的基类。通俗来说，可以认为是main函数的入口。
AbstractBootstrapServerBootstrapMacosXApplicationStarterDNSTaskStarter

processor
某一类功能的处理器，用来表示某个处理过程，是一系列代码片段的集合。
CompoundProcessorBinaryComparisonProcessorDefaultDefaultValueProcessor

manager
对有生命状态的对象进行管理，通常作为某一类资源的管理入口。
AccountManagerDevicePolicyManagerTransactionManager

holder
表示持有某个或者某类对象的引用，并可以对其进行统一管理。
QueryHolderInstructionHolderViewHolder

provider
Provider &#x3D; Strategy + Factory Method。它更高级一些，把策略模式和方法工厂揉在了一块，让人用起来很顺手。Provider一般是接口或者抽象类，以便能够完成子实现。
AccountFeatureProviderApplicationFeatureProviderImplCollatorProvider

registrar
注册并管理一系列资源。
ImportServiceRegistrarIKryoRegistrarPipelineOptionsRegistrar

Engine
一般是核心模块，用来处理一类功能。引擎是个非常高级的名词，一般的类是没有资格用它的。
ScriptEngineDataQLScriptEngineC2DEngine

Task
某个任务，通常是个runnable
WorkflowTaskFutureTaskForkJoinTask

1.5.2. 传播类命名
context
如果你的程序执行，有一些变量，需要从函数执行的入口开始，一直传到大量子函数执行完毕之后。这些变量或者集合，如果以参数的形式传递，将会让代码变得冗长无比。这个时候，你就可以把变量统一塞到Context里面，以单个对象的形式进行传递。
AppContextServletContextApplicationContext

propagator
传播，繁殖。用来将context中传递的值进行复制，添加，清除，重置，检索，恢复等动作。通常，它会提供一个叫做propagate的方法，实现真正的变量管理。
TextMapPropagatorFilePropagatorTransactionPropagator

1.5.3. 回调类命名
callback：用于响应某类消息，进行后续处理。

handler：表示持有真正消息处理逻辑的对象，它是有状态的。

trigger：代表某类事件的处理，属于 handler。通常不会出现在类的命名中。

listener：通常在观察者模式中用来表示特定的含义
ChannelHandlerSuccessCallbackCronTriggerEventListener

aware
Aware就是感知的意思，一般以该单词结尾的类，都实现了Aware接口。
ApplicationContextAwareApplicationStartupAwareApplicationEventPublisherAware

1.5.4. 监控类命名
metric
表示监控数据，比用 Monitor 要优雅点。
TimelineMetrichistogramMetric

estimator
估计 、统计。用于计算某一类统计数值的计算器。
ConditionalDensityEstimatorFixedFrameRateEstimatorNestableLoadProfileEstimator

accumulator
用来缓存累加的中间计算结果，并提供读取通道。
AbstractAccumulatorStatsAccumulatorTopFrequencyAccumulator

tracker
一般用于日志记录的追踪。
VelocityTrackerRocketTrackerMediaTracker

1.5.5. 内存管理类命名
allocator
分配器，表示内存的分配。
AbstractByteBufAllocatorArrayAllocatorRecyclingIntBlockAllocator

chunk
表示一块内存。
EncryptedChunkChunkFactoryMultiChunk

arena
英文是舞台、竞技场的意思。由于Linux把它用在内存管理上发扬光大，它普遍用于各种存储资源的申请、释放与管理。为不同规格的存储chunk提供舞台，好像也是非常形象的表示。
关键是，这个词很美，作为后缀让类名显得很漂亮。
BookingArenaStandaloneArenaPoolArena

pool
池子，用于内存池、连接池、线程池等。
ConnectionPoolObjectPoolMemoryPool

1.5.6. 过滤检测类命名程序收到的事件和信息是非常多的，有些是合法的，有些需要过滤扔掉。根据不同的使用范围和功能性差别，过滤操作也有多种形式。你会在框架类代码中发现大量这样的名词。

pipeline, chain
PipelineChildPipelineDefaultResourceTransformerChainFilterChain

filter
过滤器，用来筛选某些满足条件的数据集，或者在满足某些条件的时候执行一部分逻辑。
FilenameFilterAfterFirstEventTimeFilterScanFilter

interceptor
拦截器。
HttpRequestInterceptor

evaluator
评估器。可用于判断某些条件是否成立，一般内部方法 evaluate 会返回 bool 类型。比如你传递进去一个非常复杂的对象，或者字符串，进行正确与否的判断。
ScriptEvaluatorSubtractionExpressionEvaluatorStreamEvaluator

detector
探测器。用来管理一系列探测性事件，并在发生的时候能够进行捕获和响应。比如Android的手势检测，温度检测等
FileHandlerReloadingDetectorTransformGestureDetector ScaleGestureDetector

1.5.7. 结构类命名
cache
大块的缓存。常见的缓存算法有LRU、LFU、FIFO等。
LoadingCacheEhCacheCache

buffer
buffer是缓冲，不同于缓存，它一般用在数据写入阶段。
ByteBufferRingBufferDirectByteBuffer

composite
将相似的组件进行组合，并以相同的接口或者功能进行暴露。
CompositeDataCompositeMapScrolledComposite

wrapper
用来包装某个对象，做一些额外的处理，以便增加或者去掉某些功能。
IsoBufferWrapperResponseWrapperMavenWrapperDownloader 

tuple
元组。
Tuple2Tuple3

aggregator
聚合器，做一些聚合计算。如分库分表中的sum，max，min等聚合函数的汇集。
BigDecimalMaxAggregatorPipelineAggregatorTotalAggregator

iterator
迭代器。在数据集很大的时候，需要进行深度遍历，迭代器可以说是必备的。使用迭代器还可以在迭代过程中安全的删除某些元素。
BreakIteratorStringCharacterIterator

batch
批量执行请求或对象。
SavedObjectBatchBatchRequest

limiter
限流器，使用漏桶算法或者令牌桶来完成平滑的限流。
DefaultTimepointLimiterRateLimiterTimeBasedLimiter

1.5.8. 解析类命名
converter, resolver
转换和解析。一般用于不同对象之间的格式转换，把一类对象转换成另一类。注意它们语义上的区别，一般特别复杂的转换或者有加载过程的需求，可以使用Resolver。
DataSetToListConverterLayoutCommandLineConverterInitRefResolverMustacheViewResolver

parser
用于非常复杂的解析器。比如解析 DSL。
SQLParserJSONParser

customizer
表示对某个对象进行特别的配置。由于这些配置过程特别的复杂，值得单独提取出来进行自定义设置。
ContextCustomizerDeviceFieldCustomizer

formatter
格式化类。主要用于字符串、数字或者日期的格式化处理工作。
DateFormatterStringFormatter

1.5.9. 网络命名
packet
用于网络编程中的数据包。
DhcpPacketPacketBuffer

protocol
表示某个协议。
RedisProtocolHttpProtocol

Encoder、Decoder、Codec
编码解码器。
RedisEncoderRedisDecoderRedisCodec

Request，Response
网络的请求与响应。


1.5.10. 其它
util：表示工具类，一般是无状态的。

helper：创建实例时才使用
HttpUtilTestKeyFieldHelperCreationHelper

invoker, invocation
invoker是一类接口，通常会以反射或者触发的方式，执行一些具体的业务逻辑。通过抽象出invoke方法，可以在invoke执行之前对入参进行记录或者处理；在invoke执行之后对结果和异常进行处理，是AOP中常见的操作方式。
MethodInvokerInvokerConstructorInvocation

selector
根据一系列条件，获得相应的同类资源。
X509CertSelectorNodeSelector

reporter
用来汇报某些执行结果。
ExtentHtmlReporterMetricReporter

accessor
封装了一系列get和set方法的类。但Accessor类一般是要通过计算来完成get和set，而不是直接操作变量。这适合比较复杂的对象存取服务。
ComponentAccessorStompHeaderAccessor

generator
生成器。一般用于生成代码，生成id等。
CodeGeneratorCipherKeyGenerator

1.6. 实践经验指导
代码一定要做单元测试，测试代码尽量覆盖所有的分支（覆盖率尽量高），可以采用 GoogleTest 单元测试框架。
代码最好用 valgrind 等工具跑一遍，检查代码有没有内存泄漏风险和异常。
尽量使用现代 C++（C++11 以上）进行C++编程，开发效率，性能，安全性都有极大提高。
尽量使用智能指针，用 RAII 模式管理对象生命周期，静态 GC（智能指针，RAII，move语义）。
理解C++对象的内存模型和布局，方便定位和解决各种C++内存问题。
异常是一个即安全又危险的特性，请谨慎使用。
熟悉常见的设计模式和C++特有的设计范式（C++Idioms），帮助自己设计构建更好的系统，对代码进行必要的重构。

2. References
微信公众号 优雅的代码命名：https://mp.weixin.qq.com/s/-Se0olV03HLGy-Y_-60lOw

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>c++SoftDesign</tag>
      </tags>
  </entry>
  <entry>
    <title>C++StyleGuide</title>
    <url>/Cpp/Cpp/C++StyleGuide/</url>
    <content><![CDATA[ 

1. 编程规范笔记1.1. 不同操作系统
Linux一般采用小写和 _  组合；
Windows一般采用大小写组合的方式

1.2. 四大命名规范
匈牙利法
开头字母用变量类型的缩写，其余部分用变量的英文或英文的缩写，要求单词第一个字母大写。
int iMyAge; “i”是int类型的缩写； 
char cMyName[10]; “c”是char类型的缩写；


驼峰式法
第一个单词首字母小写，后面其他单词首字母大写。
int myAge; 
char myName[10]; 


帕斯卡法
每个单词的第一个字母都大写
int MyAge;
char MyName[10];


下划线法
采用下划线命名方法，小写加下划线，在pyhton中使用比较多



1.3. 个人风格命名规范遵循原则：易于阅读，优美，简洁。
1.3.1. 代码格式
if/for/while/switch/do 等保留字与括号之间都必须加 空格，函数或者方法名称与括号之间不用加空格。

任何二目、 三目运算符的左右两边都需要加一个 空格。



说明： 包括赋值运算符&#x3D;、逻辑运算符&amp;&amp;、加减乘除符号等。


注释的双斜线与注释内容之间有且仅有一个空格。

在进行类型强制转换时，右括号与强制转换值之间不需要任何空格隔开。
 long first = 1000000000000L;int second = (int)first + 2;

单行字符数限制不超过 80 个，超出需要换行。逗号处执行换行，不要在括号前换行。

IDE 的 text file encoding 设置为 UTF-8; IDE 中文件的换行符使用 Unix 格式，不要使用 Windows 格式。

没有必要增加若干空格来使变量的赋值等号与上一行对应位置的等号对齐

不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开来以提升可读性。



说明： 任何情形， 没有必要插入多个空行进行隔开。


指针符号 *，引用符号&amp; 的位置，写在靠近类型的地方。

1.3.2. 文件名
一般为名词性的词。
全部小写，多个单词之间使用破折号 - 隔开，不采用下划线 _。
同一级下有多个文件，属于同一内容时，文件开头添加数字00 01 ...等，以便区分。

1.3.3. 变量名
普通变量名，个人习惯单词与单词之间采用下划线 _ 的方式。若公司有编码规范，需遵守公司的编码规范（例如：全部采用小写式的驼峰法命名）。

在 long 或者 Long 赋值时， 数值后使用大写的 L，不能是小写的 l，小写容易跟数字混淆，造成误解。

常量命名

全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。一般为名词性的变量。
C语言中常用宏定义。表示 类型的名词 放在词尾，以提升辨识度。


bool 类型添加上 is。isEmpty, isOK, isDoorOpened等等，读起来就是一个询问句。

类成员变量

成员变量，访问权限只分成两级，private 和 public，不要用 protected。 私有的成员变量，前面加下划线。
公有的成员变量前面不用加下划线。


静态成员变量：统一加 s_ 前缀，并尽可能的详细命名。例如：static ColorTransformStack s_colorTransformStack;

全局变量：加上前缀 g_，并尽可能的详细命名

嵌入式中，包含有外围设备的变量每个字母大写，后面加_，下划线后面每个单词的首字母大写。


1.3.4. 结构体和枚举类型
结构体和枚举类型，词性一般为名词或者形容词。

枚举类名

结尾带上 Enum 后缀，枚举成员名称需要全大写，单词间用下划线隔开。
枚举其实就是特殊的常量类，且构造方法被默认强制是私有。
例子：枚举名字为 ProcessStatusEnum 的成员名称： SUCCESS / UNKNOWN_REASON


嵌入式单片机中，包含有外围设备的变量每个字母大写，后面加_，下划线后面每个单词的首字母大写，结构体结尾添加 _TypeDef，枚举结尾添加 _Type。 例如： CAN_TxMailBox_TypeDef   IRQn_Type


1.3.5. 方法名（函数名）
整体上，应该是个动词或者是形容词(返回bool的函数)，但不要是名词。

名称尽量短并且保持原子性。

C++、C中首字母小写，其它的单词首字母大写，没有下划线。

统一使用 lowerCamelCase 风格。

例如：localValue / getHttpMessage() / inputUserId


嵌入式单片机中，包含有外围设备的变量每个字母大写，后面加 _，下划线后面每个单词的首字母大写。例如：ADC_GetResetCalibrationStatus()


1.3.6. 类名（class）
类型命名每个单词以大写字母开头，不包含下划线 MyExcitingClass、 MyExcitingEnum

如果模块、 接口、类、方法使用了设计模式，在命名时需体现出具体模式。

说明： 将设计模式体现在名字中，有利于阅读者快速理解架构设计理念



1.3.7. 抽象类、异常、测试名
抽象类命名使用 Abstract 或 Base 开头；
异常类命名使用 Exception 结尾； 
测试类命名以它要测试的类的名称开始，以 Test 结尾。

1.3.8. 包名
统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。
包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。
应用工具类包名为 com.alibaba.ei.kunlun.aap.util、类名为 MessageUtils（此规则参考 spring 的框架结构）

1.3.9. Include与Define
#define

所有的头文件，都应该使用 #define 来防止头文件被重复包含。
#define宏，的名字全部都为大写。不要出现大小写混杂的形式。// 格式#ifndef __GEO_POINT_H__#define __GEO_POINT_H__namespace geo&#123;  class Point  &#123;      .....  &#125;;&#125;#endif


#include

C++代码使用 #include 来引入其它的模块的头文件。尽可能，按照模块的稳定性顺序来排列#include的顺序，按照稳定性从高到低排列。



1.4. OOP规约(Object Oriented Programming)
任何货币金额，均以最小货币单位且 整型类型 来进行存储
浮点数之间的等值判断，基本数据类型不能用 ==来比较，计算机在内部进行差值计算的时候，因为精度的问题，导致判断的两个结果可能不相等。

1.5. 时间约定
年份统一使用小写的 y
月份是大写的 M
分钟则是小写的 m
24 小时制的是大写的 H
12 小时制的则是小写的 h
不要在程序中写死一年为 365 天，避免在公历闰年时出现日期转换错误或程序逻辑错误。
使用枚举值来指代月份。

1.6. 控制语句
在一个 switch 块内，每个 case 要么通过 continue&#x2F;break&#x2F;return 等来终止，要么注释说明程序将继续执行到哪一个 case 为止；在一个 switch 块内，都必须包含一个 default语句并且放在最后，即使它什么代码也没有。

说明： 注意 break 是退出 switch 语句块，而 return 是退出方法体


在 if&#x2F;else&#x2F;for&#x2F;while&#x2F;do 语句中必须使用大括号。

说明： 即使只有一行代码， 禁止不采用大括号的编码方式： if (condition) statements;


表达异常的分支时， 少用 if-else 方式， 这种方式可以改写成：
if (condition) &#123;...return obj;&#125;// 接着写 else 的业务逻辑代码;说明： 如果非使用 if()...else if()...else...方式表达逻辑， 避免后续代码维护困难， 请勿超过 3 层。
不要在其它表达式（尤其是条件表达式）中，插入赋值语句。

说明： 赋值点类似于人体的穴位，对于代码的理解至关重要，所以赋值语句需要清晰地单独成为一行


避免采用取反逻辑运算符。

说明： 取反逻辑不利于快速理解，并且取反逻辑写法必然存在对应的正向逻辑写法。



1.7. 注释规约
所有的类都必须添加创建者和创建日期。日期的设置统一为 yyyy&#x2F;MM&#x2F;dd 的格式。
/**  * @author yangguanbao  * @date 2016/10/31  */
方法内部单行注释，在被注释语句上方另起一行，使用&#x2F;&#x2F;注释。方法内部多行注释使用&#x2F;* *&#x2F;注释，注意与代码对齐

所有的枚举类型字段必须要有注释，说明每个数据项的用途。

与其“半吊子” 英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可。

代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改。

说明： 代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了导航的意义。


对于注释的要求：

第一、能够准确反映设计思想和代码逻辑
第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路； 注释也是给继任者看的，使其能够快速接替自己的工作。


对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(&#x2F;&#x2F;&#x2F;)
public static void hello() &#123;/// 业务方通知活动暂停// Business business = new Business();// business.active();System.out.println(&quot;it&#x27;s finished&quot;);&#125;

1.8. 单元测试
A： Automatic（自动化）
I： Independent（独立性）
R： Repeatable（可重复）

1.9. Code Review对于代码格式规范，100% 严格执行，严重容不得一点沙。

文件绝不能超过 800 行，超过，一定要思考怎么拆文件。工程思维，就在于拆文件的时候积累。

函数对决不能超过 80 行，超过，一定要思考怎么拆函数，思考函数分组，层次。工程思维，就在于拆文件的时候积累。

代码嵌套层次不能超过 4 层，超过了就得改。多想想能不能 early return。工程思维，就在于拆文件的时候积累。

从目录、package、文件、struct、function 一层层下来 ，信息一定不能出现冗余。比如 file.FileProperty 这种定义。只有每个定语只出现在一个位置，才为做好逻辑、定义分组&#x2F;分层提供了可能性。

多用多级目录来组织代码所承载的信息，即使某一些中间目录只有一个子目录。

随着代码的扩展，老的代码违反了一些设计原则，应该立即原地局部重构，维持住代码质量不滑坡。比如:拆文件；拆函数；用 Session 来保存一个复杂的流程型函数的所有信息；重新调整目录结构。

基于上一点考虑，我们应该尽量让项目的代码有一定的组织、层次关系。我个人的当前实践是除了特别通用的代码，都放在一个 git 里。特别通用、修改少的代码，逐渐独立出 git，作为子 git 连接到当前项目 git，让 goland 的 Refactor 特性、各种 Refactor 工具能帮助我们快速、安全局部重构。

自己的项目代码，应该有一个内生的层级和逻辑关系。flat 平铺展开是非常不利于代码复用的。怎么复用、怎么组织复用，肯定会变成人生难题。T4-T7 的同学根本无力解决这种难题。

如果被 review 的代码虽然简短，但是你看了一眼却发现不咋懂，那就一定有问题。自己看不出来，就找高级别的同学交流。这是你和别 review 代码的同学成长的时刻。

日志要少打。要打日志就要把关键索引信息带上。必要的日志必须打。

有疑问就立即问，不要怕问错。让代码作者给出解释。不要怕问出极低问题。

不要说建议，提问题，就是刚，你 pk 不过我，就得改！

请积极使用 trpc。总是要和老板站在一起！只有和老板达成的对于代码质量建设的共识，才能在团队里更好地做好代码质量建设。

消灭重复！消灭重复！消灭重复！


1.10. 代码写的优美的特征
命名规范，风格统一。给变量取名称时，为什么人家（Google的工程师）就能想到那么多、那么优雅、恰到好处的名字？
行间距恰到好处。
整体布局合理，让人一看感觉就很舒适。看代码就像看诗歌一样，甚至比诗歌还要优美。
合理的注释。

1.11. References
CSDN：Google的C++编程规范总结
Google Style Guides：Google 所有编程语言编程规范文档。

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>c++StyleGuide</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/Cpp/Cpp/README/</url>
    <content><![CDATA[记录C++语言学习的知识点。
有些文章我并不是从0到1创建一门新的学问、新的概念或新的知识，是在前人分享的基础上进行学习，从而加入自己对知识的理解和思考，形成自己的一套学习方法，来简单、容易的理解和阐述知识。此过程中我参考了很多的书籍、博客、官网链接等，通过不同的渠道来辅助我加强对知识点的理解，每篇文章我都有参考文献。我认为这是很重要的一个点，在传递知识的途中，需要尊重他人知识构建的成果。只因有了这些默默爱分享的作者，自己才能借助他人分享的知识作为佐证，阐述对知识的学习和理解。
]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
        <tag>cpp</tag>
      </tags>
  </entry>
  <entry>
    <title>ThreadPool</title>
    <url>/Cpp/Cpp/ThreadPool/</url>
    <content><![CDATA[

维基百科解释线程池

线程池（英语：thread pool）：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。可用线程数量应该取决于可用的并发处理器、处理器内核、内存、网络 sockets 等的数量。 例如，线程数一般取 cpu 数量 +2 比较合适，线程数过多会导致额外的线程切换开销。
任务调度以执行线程的常见方法是使用同步队列，称作任务队列。池中的线程等待队列中的任务，并把执行完的任务放入完成队列中。
线程池模式一般分为两种：HS&#x2F;HA 半同步&#x2F;半异步模式、L&#x2F;F 领导者与跟随者模式。

半同步&#x2F;半异步模式又称为生产者消费者模式，是比较常见的实现方式，比较简单。分为同步层、队列层、异步层三层。同步层的主线程处理工作任务并存入工作队列，工作线程从工作队列取出任务进行处理，如果工作队列为空，则取不到任务的工作线程进入挂起状态。由于线程间有数据通信，因此不适于大数据量交换的场合。
领导者跟随者模式，在线程池中的线程可处在3种状态之一：领导者 leader、追随者follower 或工作者 processor。任何时刻线程池只有一个领导者线程。事件到达时，领导者线程负责消息分离，并从处于追随者线程中选出一个来当继任领导者，然后将自身设置为工作者状态去处置该事件。处理完毕后工作者线程将自身的状态置为追随者。这一模式实现复杂，但避免了线程间交换任务数据，提高了 CPU cache 相似性。在 ACE（Adaptive Communication Environment）中，提供了领导者跟随者模式实现。


线程池的伸缩性对性能有较大的影响。

创建太多线程，将会浪费一定的资源，有些线程未被充分使用。
销毁太多线程，将导致之后浪费时间再次创建它们。
创建线程太慢，将会导致长时间的等待，性能变差。
销毁线程太慢，导致其它线程资源饥饿。


组成部分

任务队列：存储需要处理的任务，由工作的线程来处理这些任务。

通过线程池提供的 API 函数，将待处理的任务添加到任务队列，或者从任务队列中删除。
将已处理的任务从任务队列中删除。
线程池的使用者，也就是调用线程池函数往任务队列中添加任务的线程就是生产者线程。


工作线程：任务队列任务的消费者，N个。

线程池中维护了一定数量的工作线程，他们的作用是不停的读任务队列，从任务队列里取出任务并处理。
工作线程相当于是任务队列里的消费者角色。
如果任务队列为空，工作的线程将会被阻塞 (使用条件变量 &#x2F; 信号量阻塞)。
如果阻塞之后有了新的任务，由生产者将阻塞解除，工作线程开始工作。


管理者线程：不处理任务队列中的任务，1个。

它的任务是周期性的对任务队列中的任务数量以及处于忙状态的工作线程个数进行检测。
当任务过多的时候，可以适当的创建一些新的工作线程。
当任务过少的时候，可以适当的销毁一些工作的线程，减少资源的消耗。



线程池的简单模型





线程池属于 “生产者-消费者”模型中的部分内容。
线程池中的线程在操作资源时，需要加锁和解锁，同一时间内只有一个线程操作同一块资源。
线程池作用

当你想要最小化加载和销毁线程的时间以及你想要限制同时运行的并行 job 的数量时，线程池很有帮助的。例如，可以在线程池中处理耗时的事件，让 UI 响应更快。

参考
基于C++11实现线程池的工作原理
C++ 动态伸缩线程池

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>threadPool</tag>
      </tags>
  </entry>
  <entry>
    <title>concurrency</title>
    <url>/Cpp/Cpp/concurrency/</url>
    <content><![CDATA[

1. 基础知识1.1. 阻塞阻塞是指当前执行的线程调用一个方法，在该方法没有返回值之前，当前执行的线程会被挂起，无法继续进行其他操作。
1.2. 非阻塞非阻塞是指当前执行的线程调用一个方法，当前执行的线程不受该方法的影响，可以继续进行其他操作。
1.3. 异步异步是执行或调用方法时，不需要等待上一次执行的结果，继续执行下一条。
异步模型中，允许同一时间发生（处理）多个事件。
在异步编程中，通常会针对比较耗时的功能提供一个函数，函数的参数中包含一个额外的参数，用于回调。而这个函数往往称作回调函数。当比较耗时的功能执行完毕时，通过回调函数将结果返回。
多线程或单线程都实现异步。
1.4. 同步同步是执行或调用一个方法时，每次都需要拿到对应的结果才会继续往后执行
1.5. 并行当系统有一个以上CPU时，则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另一个线程，两个线程互不抢占 CPU 资源，可以同时进行，这种方式我们称之为并行（Parallel）。
1.6. 并发1.7. 高并发场景

电商的高并发
抖音的高并发
12306卖火车票的高并发
基金交易系统的高并发
海量数据处理的高并发

区别
多线程都是关于功能的并发执行。而异步编程是关于函数之间的非阻塞执行，我们可以将异步应用于单线程或多线程当中。
Data race (数据竞争): 两个线程并发操作同一块数据导致不可预期的行为。
Waiting and Polling (等待和轮训)

2. API2.1. async
async() 提供一个接口，让一段功能或一个可调用对象在后台运行，成为一个独立的线程。
async_wait()

2.2. future
Class future&lt;&gt; 允许你等待线程结束并获取其结果。
std::shared_future&lt;&gt;允许你在多个地点等待和处理线程结束。

Condition Variable条件变量接口 API

wait(ul): 使用 unique_lock 锁来等待通知
wait(ul, pred): 使用 unique_lock锁来等待通知，直到 pred 在一次苏醒之后结果为 true。
wait_for(ul, duration): 使用 unique_lock锁来等待通知，等带期限是一个时间段 duration。
wait_for(ul, duration, pred): 使用 unique_lock锁来等待通知，等带期限是一个时间段 duration 或直到 pred 在一次苏醒之后结果为 true。
wait_until(ul, timepoint): 使用 unique_lock锁来等待通知，直到某个时间点 time point。
wait_until(ul, timepoint, pred): 使用 unique_lock锁来等待通知，直到某个时间点 time point 或直到 pred 在一次苏醒之后结果为 true。
notify_one(): 唤醒一个等待者（线程）。
notify_all(): 唤醒所有的等待者（线程）。

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>enable_shared_from_this</title>
    <url>/Cpp/Cpp/enable_shared_from_this/</url>
    <content><![CDATA[

1. 什么是 enable_shared_from_this?C++11 开始时支持 enable_shared_from_this，它一个模板类，定义在头文件 &lt;memory&gt;，其原型为： 
template&lt; class T &gt; class enable_shared_from_this;


std::enable_shared_from_this 能让其一个对象（假设其名为 t ，且已被一个 std::shared_ptr 对象 pt 管理）安全地生成其他额外的 std::shared_ptr 实例（假设名为 pt0, pt2, … ） ，它们与 pt 共享对象 t 的所有权。

若一个类 T 继承 std::enable_shared_from_this ，则会为该类 T 提供成员函数： shared_from_this 。 当 T 类型对象 t 被一个为名为 pt 的 std::shared_ptr 类对象管理时，调用 T::shared_from_this 成员函数，将会返回一个新的 std::shared_ptr 对象，它与 pt 共享 t 的所有权。


2. 为什么要用 enable_shared_from_this？
需要在类对象的内部中获得一个指向当前对象的 shared_ptr 对象。
如果在一个程序中，对象内存的生命周期全部由智能指针来管理。在这种情况下，要在一个类的成员函数中，对外部返回this指针就成了一个很棘手的问题。

3. 什么时候用？
当一个类被 share_ptr 管理，且在类的成员函数里需要把当前类对象作为参数传给其他函数时，这时就需要传递一个指向自身的 share_ptr。
在当前类的内部需要将当前类的对象传递给其它的类用。

4. 如何安全地将 this 指针返回给调用者?
一般来说，我们不能直接将this指针返回。如果函数将 this 指针返回到外部某个变量保存，然后这个对象自身已经析构了，但外部变量并不知道，此时如果外部变量再使用这个指针，就会使得程序崩溃。

5. 标准库中的源码  template&lt;typename _Tp&gt;    class enable_shared_from_this    &#123;    protected:      constexpr enable_shared_from_this() noexcept &#123; &#125;      enable_shared_from_this(const enable_shared_from_this&amp;) noexcept &#123; &#125;      enable_shared_from_this&amp;      operator=(const enable_shared_from_this&amp;) noexcept      &#123; return *this; &#125;      ~enable_shared_from_this() &#123; &#125;    public:      shared_ptr&lt;_Tp&gt;      shared_from_this()      &#123; return shared_ptr&lt;_Tp&gt;(this-&gt;_M_weak_this); &#125;      shared_ptr&lt;const _Tp&gt;      shared_from_this() const      &#123; return shared_ptr&lt;const _Tp&gt;(this-&gt;_M_weak_this); &#125;#if __cplusplus &gt; 201401L || !defined(__STRICT_ANSI__) // c++11 or gnu++11#define __cpp_lib_enable_shared_from_this 201602      weak_ptr&lt;_Tp&gt;      weak_from_this() noexcept      &#123; return this-&gt;_M_weak_this; &#125;      weak_ptr&lt;const _Tp&gt;      weak_from_this() const noexcept      &#123; return this-&gt;_M_weak_this; &#125;#endif    private:      template&lt;typename _Tp0&gt;	void	_M_weak_assign(_Tp0* __p, const __shared_count&lt;&gt;&amp; __n) const noexcept	&#123; _M_weak_this._M_assign(__p, __n); &#125;      // Found by ADL when this is an associated class.      friend const enable_shared_from_this*      __enable_shared_from_this_base(const __shared_count&lt;&gt;&amp;,				     const enable_shared_from_this* __p)      &#123; return __p; &#125;      template&lt;typename, _Lock_policy&gt;	friend class __shared_ptr;      mutable weak_ptr&lt;_Tp&gt;  _M_weak_this;    &#125;;

enable_shared_from_this类中的成员函数
(constructor)：构造一个 enable_shared_from_this 对象，是一个受保护的成员函数，成员属性为 protected。
(destructor)：销毁一个 enable_shared_from_this 对象，是一个受保护的成员函数，成员属性为 protected。
operator&#x3D;：返回到 this 的引用，是一个受保护成员函数，成员属性为 protected。
shared_from_this：返回共享 *this 指针所有权的 shared_ptr，是一个 public 属性的成员函数。
weak_from_this(C++16)：返回共享 *this 所指针有权的 weak_ptr，是一个public 属性的成员函数。



6. 具体的代码示例#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;memory&gt;using namespace std;// 比较推荐的写法struct Good : std::enable_shared_from_this&lt;Good&gt; // note: public inheritance&#123;    std::shared_ptr&lt;Good&gt; getptr() &#123;        return shared_from_this();    &#125;&#125;;// 错误的用法：用不安全的表达式试图获得 this 的 shared_ptr 对象struct Bad&#123;    std::shared_ptr&lt;Bad&gt; getptr() &#123;        return std::shared_ptr&lt;Bad&gt;(this);    &#125;    ~Bad() &#123; std::cout &lt;&lt; &quot;Bad::~Bad() called\n&quot;; &#125;&#125;; int main()&#123;    // 正确的用法: 两个 shared_ptr 共享同一个对象    std::shared_ptr&lt;Good&gt; gp1 = std::make_shared&lt;Good&gt;();    std::shared_ptr&lt;Good&gt; gp2 = gp1-&gt;getptr();    std::cout &lt;&lt; &quot;gp2.use_count() = &quot; &lt;&lt; gp2.use_count() &lt;&lt; &#x27;\n&#x27;;     // 错误的用法: 调用 shared_from_this 但其没有被 std::shared_ptr 占有     try &#123;        Good not_so_good;        std::shared_ptr&lt;Good&gt; gp1 = not_so_good.getptr();    &#125;     catch(std::bad_weak_ptr&amp; e) &#123;        // 在 C++17 之前，编译器不能捕获 enable_shared_from_this 抛出的std::bad_weak_ptr 异常        // 这是在C++17之后才有的特性        std::cout &lt;&lt; e.what() &lt;&lt; &#x27;\n&#x27;;        &#125;     // 错误的用法，每个 shared_ptr 都认为自己是对象的唯一拥有者    // 调用错误的用法，会导致两次析构 Bad的对象，第二次析构时，指针指向的空间已经被析构，    // 会导致程序出错    std::shared_ptr&lt;Bad&gt; bp1 = std::make_shared&lt;Bad&gt;();    std::shared_ptr&lt;Bad&gt; bp2 = bp1-&gt;getptr();    std::cout &lt;&lt; &quot;bp2.use_count() = &quot; &lt;&lt; bp2.use_count() &lt;&lt; &#x27;\n&#x27;;    return 0;&#125;  

7. 使用注意事项
enable_shared_from_this 的常见实现为：其内部保存着一个对 this 的弱引用（例如 std::weak_ptr )。 std::shared_ptr 的构造函数检测无歧义且可访问的 (C++16 起) enable_shared_from_this 基类，并且若内部存储的弱引用没有被以存在的 std::shared_ptr 占有，则 (C++17 起)赋值新建的 std::shared_ptr 为内部存储的弱引用。为另一个 std::shared_ptr 所管理的对象构造一个 std::shared_ptr ，将不会考虑内部存储的弱引用，从而将导致未定义行为(undefined behavior)。

只允许在先前已被std::shared_ptr 管理的对象上调用 shared_from_this 。否则调用行为未定义 (C++17 前)抛出 std::bad_weak_ptr 异常（通过 shared_ptr 从默认构造的 weak_this 的构造函数） (自C++17 起)。

enable_shared_from_this 提供安全的替用方案，以替代 std::shared_ptr(this) 这样的表达式（这种不安全的表达式可能会导致 this 被多个互不知晓的所有者析构）。


8. 参考
cpp reference解释其用法 
enable_shared_from_this用法分析
enable_shared_from_this类的作用和实现
C++11标准库的一个工具类enable_shared_from_this的作用及原理分析

]]></content>
      <categories>
        <category>Cpp</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>enable_shared_from_this</tag>
      </tags>
  </entry>
  <entry>
    <title>DataStructure</title>
    <url>/DataStructure/DataStructure/DataStructure/</url>
    <content><![CDATA[ 

1. 概念
算法：处理问题的策略。
数据结构：描述问题的数据模型。
程序：计算机按照处理问题的策略，处理问题信息的一组指令集。
计算机处理问题的过程（按流程图走向）
具体问题
抽象
问题模型
数据分析
数据结构
算法分析
算法
程序设计
程序
测试通过
问题得以解决


程序解题步骤
建模型：给定的条件是什么，得到的结果是什么
设计
数据结构设计：分析数据对象、时间对象间的联系、确定数据对象的存储方式、确定要对数据对象进行的操作
软件结构设计：用“自顶向下，逐步求精”法，把问题分解成规模适中且便于处理的若干模块
算法设计：为每个模块完成的功能进行具体的描述，把功能描述转化为精确到、结构化的过程描述


编程
验证
测试
纠错




数据结构的三要素：
逻辑结构（Logic Structure）
集合：结点间无关系
线性结构：结点间一对一关系
树形结构：结点间一对多关系
图形结构：结点间多对多关系


物理结构（Physical Structure）
顺序存储
链式存储
索引存储
散列存储


数据的运算


用空间换时间思想：将计算的中间结果缓存下来，从缓存中找出目标结果，以牺牲内存空间来提高时间效率。
用时间换空间思想: 对于一些对内存要求比较严格时，需要牺牲时间的执行效率，来换取空间的利用率。

2. 代码的规范性
正确性
完整性
鲁棒性：程序在执行的时候，可能会出现访问空指针的问题，会导致程序崩溃。

3. 结构体定义（3种）
法一：在定义结构体类型的同时说明结构体变量
struct 结构名&#123;    成员表列;&#125;变量名表列;

法二:直接说明结构体变量
struct&#123;    成员表列;&#125;变量名表列;

法三：先定义结构体，在说明结构体变量
struct 结构名&#123;    成员表列;&#125;;struct 结构名 变量名表列;

结构体调用

 . 成员选择结构  结构体变量名.成员名
 -&gt; 成员选择指针  结构指针-&gt;结构成员



4. 链表
链表是一种动态的数据结构，每添加一个结点分配一次内存，占用的内存是连续的，没有闲置的内存
数组的内存是一次性分配内存


    



4.1. 线性表
同一个线性表中所有的结点都必须是 相同的数据类型

主要操作

创建
求长度
取元素
定位
插入
删除
遍历


链表结点结构

data：存放结点的值，即为数据域
next：存放结点的直接后继地址，即为指针域或链域


单链表中的每个结点的存储地址是存放在 前驱结点next域中，开始结点无 前驱

终端结点无 后继，终端结点的 指针域 为空

头指针 head 指向开始结点





结点信息
相邻结点地址



data
next



链表操作的精髓：先改变指针指向，再移动指针。

4.2. 循环链表
建立循环链表时，必须使最后一个结点的指针指向表头结点
判断是否到表尾时，判断该结点链域的值是否是表头结点，当链域值等于表头指针，说明已到达表尾

5. 栈
栈（stack）是一种特殊的线性表，所有的插入和删除都限制在表的同一端进行。进行插入、删除操作的一端为栈顶（top）,另一端为栈底，栈中没有元素时为空栈。

特点：先入后出

栈的主要操作

创建：建立一个空栈S
判断栈空：判断栈是否为空
进栈：在栈S中插入元素X，使其成为新的栈顶元素
出栈：删除栈S的栈顶元素
取栈顶元素的值，不改变栈顶的指针
求栈的长度


顺序栈：采用一个数组和整型变量实现

数组：顺序存储栈中的元素
整型变量：存储栈元素的下标位置
缺点：栈满后就不能再进栈了。
分类 
静态顺序栈：不能根据需要增大栈的存储空间。
动态顺序栈：根据需要可以增大栈的存储空间。




链式栈：采用链表的方式实现栈操作，插入和删除只能在表头进行。


6. 队列
定义：只允许在一端（队尾）进行插入操作，在另一端（队头）进行删除操作的线性表
特点： 先入先出 方式管理的线性表，一般用于数据的缓存。
分类
顺序队列：队列的顺序存储结构
循环队列：顺序队列的空间是以循环的方式使用


队列规则
排列顺序：结点排成一队，后来的排在队尾
处理过程：在队头处理事件；队列中有元素则一直处理，直到队空或者发生中断事件


结论
顺序队列中已经出队的元素不需要删除
顺序队列的存储空间是循环使用
循环队列中头尾指针的计算规则
尾指针：rear = （rear+1） % 表长(QUEUE_SIZE)
头指针：front = （front+1）%表长(QUEUE_SIZE)


队满状态：rear+1 = front
队空状态：rear = front
队列中少用一个元素的空间，达到使队满和队空的条件不一样




    




链队列
用链表的方式实现的队列，仅允许在表头删除和表尾插入的单链表。



7. 树
定义
树是包含n（n≥0）个结点的有限集。在任意一棵非空树中，有且仅有一个称为根的结点；其余结点分为m（m≥0）个互不相交的子集，每个子集又是一棵树，称为根的子树


特点
每个结点有零个或多个子结点，无子结点的结点称为 叶子结点
没有父结点的结点称为 根结点
每一个非根结点有且只有一个父结点
树是非线性结构


树的术语
结点层：规定树中根结点的层定义为 1，其余结点的层等于其双亲结点的层加1；根的孩子为第二层结点。
结点的度（degree）：一个结点拥有的子树个数。作用对象是 结结点。
树的度：树中结点度的最大值，即拥有子树个数的最大值。
树的深度（depth）：也叫数的高度，树中结点的最大层数值
分支结点：也叫非终端结点，度大于 0 的结点
叶子结点：也叫终端结点，是度为 0 的结点
孩子：结点子树的根称为该结点的孩子
双亲：孩子的直接前驱结点称为该结点的双亲
兄弟：同一个双亲的结点互称为兄弟
子孙：以某结点为根的各个子树上的所有结点称为该结点的子孙
祖先：从树根到该结点所经过的所有分支结点称为该结点的祖先
森林（forest）：m（m≥0）个树的集合



7.1. 树的存储
利用数组的下标将离散的树结点的编号一一对应起来。
存储原则
存数值、存联系
存的进、取得出


存储方式
顺序连续存储
链式离散存储：
二叉链表结点： 一个数据域，两个分别指向左右子结点的指针域。内部数据的指针指向采用长兄为父的思想。


Lchild
data
Rchild




三叉链表结点： 一个数据域，两个分别指向左右子结点的指针域，还有一个父结点。


Lchild
data
parent
Rchild




双亲结点表示法：在子结点中存储双亲结点的位置。




树如何存储在数据库中？
建立两张表，一张存储树结点的表，另一张存储结点与结点之间关系的表。



7.2. 树的创建
利用 #号法 进行树的创建。#号法 的先序遍历能确定一颗树。


7.3. 二叉树（binary tree）
定义：二叉树的定义是递归的，是n(n≥0)个结点的有限集。该集合为空或者由一个根加上两棵互不相交的、分别称为左子树和右子树的二叉树组成。

二叉树的双亲表示法


二叉树的操作

创建：建立一棵二叉树，初始化
查找：查找根结点、双亲结点、孩子结点、叶子结点
插入：在指定位置差结点
删除：在指定位置删除结点
遍历：沿着某条搜索线路，依次对二叉树中每个结点均做依次且仅做一次访问
求深度：计算二叉树的高度


性质

在二叉树的第 i 层上至多有 $2^{i-1}$ 个结点
深度为 k 的二叉树上至多有 $2^{k}-1$ 个结点，$k{\geq}1$
设二叉树中有 $n_2$ 个度为 2 的结点，$n_1$ 个度为 1 的结点，$n_0$ 个度为 0 的结点，则有：$n_0 &#x3D; n_2 + 1$，分支总数 &#x3D; $n_1 + 2n_2$，结点总数 &#x3D; $n_0 + n_1 + n_2$
具有 n 个结点的完全二叉树的深度为 $k&#x3D;[log_2 n] + 1$


完全二叉树（complete binary tree）

定义：
第一种：每一棵树除最下层外，每一层的结点数均达到最大值，在最下层只缺少右边的若干结点。
第二种：先给满树编号，根结点编号为 1，从根结点开始自上而下，自左向右进行编号，若去掉树中的若干结点后，树的编号依然连续，则是完全二叉树。


特点
前 k－1 层是满的，第 k 层可以不满，但第 k 层结点集中在 左侧。
完全二叉树是满二叉树的一部分，而满二叉树是完全二叉树的特例。
n 个结点的完全二叉树的树深度为 $[log_2 n]+1$，其中$[log_2 n]$ 向下取整数。




满二叉树（full binary tree）

定义：除了叶子结点以外每一个结点都有左右子树且叶子结点都处在最底层上。
特点
每一层上的结点数总是达到最大的结点数。
所有分支结点都有左、右子树。
深度为 k 的满二叉树，结点总数为： $2^{k} - 1$ 
第 i 层上的结点数为 $2^{i-1}$
一个层数为 i 的满二叉树的叶子结点个数（也就是最后一层）为 $2^{i-1}$





7.4. 遍历二叉树（traverse binary tree）
先序遍历（inorder tree walk）：（根–&gt;左–&gt;右）

访问根结点 
先序遍历左子树 
先序遍历右子树


中序遍历（preorder tree walk）：（左–&gt;根–&gt;右） 

中序遍历左子树 
访问根结点 
中序遍历右子树


后序遍历（postorder tree walk）：（左–&gt;右–&gt;根）  

后序遍历左子树 
后序遍历右子树 
最后访问根结点


无论是采用先序遍历、中序遍历还是后序遍历，算法遍历的过程是一样的，只是访问树结点的时机不一样。

前序遍历和中序遍历不采用非递归的方法时，采用栈的思想，因为先经过的结点后访问。后序遍历采用堆的思想实现。

非递归中序遍历步骤

步骤一：若结点有左子树，则该结点入栈；若结点没有左子树，则访问该结点。
步骤二：若结点有右子树，则重复步骤 1；若结点没有右子树，则结点访问结束，根据栈顶指示，访问栈顶元素，进行出栈。
步骤三：若栈为空，则遍历结束。


如何确定一棵树？ 

通过先序遍历和中序遍历可以确定一棵树。
步骤一：根据先序遍历 的序列得到根结点的位置，再由根结点在 中序遍历 中的位置得到左右子树的集合；
步骤二：在左子树集合中根据先序遍历得到左子树集合的根结点，重复步骤一；
步骤三：在右子树集合中根据先序遍历得到右子树集合的根结点，重复步骤一；


通过 中序遍历 和 后序遍历 可以确定一棵树。
通过 先序遍历 和 后序遍历 不能确定一棵树。



7.5. DFS与BFS
DFS(Deep First Search) 深度优先搜索
BFS(Breath First Search) 广度优先搜索

7.6. 二叉搜索树(binary search tree)
什么是二叉搜索树？

二叉搜索树是一种特殊的二叉树，实现更快速的查找。一棵树用链表数据结构表示，每个结点就是一个对象。


性质

树中的任意一个结点都大于等于它左子树中的结点，小于等于它右子树中的结点。 
在一棵高度为 h 的二叉搜索树上，动态集合上的操作 Search、Minimum、Maximum、Successor、Predecessor可以在 O(h) 时间内完成。
在一棵高度为 h 的二叉搜索树上，动态集合操作 Insertion、Deletion 的运行时间均为 O(h) 或 lg(n)


查找

如果二叉查找树为空，则返回空；
如果二叉查找树不为空
先查找取根结点，如果结点 X 等于根结点，则返回；
如果结点小于根结点，则递归查找左子树；
如果结点大于根结点，则递归查找右子树。




查找最大、最小结点

若二叉搜索树为空，则返回空。
若二叉搜索树不为空
判断是否只有一个结点（即只有根结点），如果是则返回根结点，否则就到右子树中递归查找，找到最大结点。
同理，查找最小结点类似，只是到左子树中查找而已。




插入

若树为空，则直接插入新结点。
若树不为空时
如果要插入的结点比根结点大，则到右子树中插入新数据。如果右子树为空，则将新数据直接插入到右子结点的位置；如果右子树不为空，则继续遍历右子树，查找插入位置。
如果要插入的结点比根结点小，则到左子树中插入新数据。如果左子树为空，则将新数据直接插入到左子结点的位置；如果左子树不为空，则继续遍历左子树，查找插入位置。




删除

要删除的结点没有子结点时，删除结点并修改它的父结点，用NULL作为孩子来替换要删除的结点。
要删除的结点只有一个结点，即只有左子结点或右子结点时，用左结结点或右子结点来替换要删除的结点，并修改要删除结点的父结点。
要删除的结点有两个子树结点
先查找要删除结点的后继结点，若这个后继结点没有左孩子且位于要删除结点的右子树中，则用这个后继结点来替换树中要删除的结点。
若要删除结点的后继结点位于要删除结点的右子树中，但不是要删除结点的直系右孩子，则需要先用要删除结点的后继结点的右孩子去替换要删除结点的后继结点，再用要删除结点的后继结点去替换需要删除的结点。





7.7. 平衡二叉树（AVL树）
概念
平衡二叉树是一颗空树或者左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一颗平衡二叉树。不管我们是执行插入还是删除操作，只要不满足上面的条件，就要通过旋转来保持平衡，而旋转是非常耗时的，由此我们可以知道 AVL 树适合用于插入与删除次数比较少，但查找多的情况。



7.8. 红黑树（Red black tree）7.8.1. 概念
什么是红黑树？
红黑树是一颗二叉搜索树，它在每个结点上增加了一个存储位来表示结点的颜色，结点的颜色为红色或黑色。通过对任何一条从根结点到叶子结点路径上各个结点的颜色进行约束，确保红黑树上没有一条路径会比其它的路径长出 2 倍，使红黑树近似是平衡的。



7.8.2. 红黑树特点
每个结点是红色或黑色。
根结点是黑色。
所有叶子都是黑色（叶子是指针为空的的结点）。
如果一个结点是红色的，则它的两个子结点是黑色。（每个叶子到根的所有路径上不能有两个连续的红色结点。）
任意一结点到每个叶子结点的路径都包含数量相同的黑结点。（红黑树黑色结点的高度等于它根结点的黑色结点高度。


注意点

红黑树是平衡二叉查找树的一种变体。
红黑树的时间复杂度：$log(n)$
一颗有 n 个结点的红黑树的高度最多为 $2*lg(n+1)$
如果一个结点存在黑色的子结点，那么该结点肯定有两个子结点


应用场景

红黑树主要用来存储有序的数据。
适合排序，查找的场景。
容器的基本组成，如Java中的HashMap&#x2F;TreeMap，STL中的set、map等。
Linux内核的完全公平调度器和Linux的虚拟内存管理
Linux中epoll机制的实现



7.8.3. 旋转
为什么红黑树要旋转？

添加或删除红黑树中的结点之后，红黑树的结构发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。通过旋转，可以使这颗树重新成为红黑树。为了维护这些特性，必须要改变树中某些结点的颜色和指针结构。


左旋：逆时针旋转红黑树的结点，使被旋转结点的右孩子成为被旋转结点的父结点，被旋转的结点成为新树的左孩子，被旋转结点的右孩子的左结点成为被旋转结点的右孩子。

右旋：顺时针旋转红黑树的结点，使被旋转结点的左孩子成为被旋转结点的父结点，被旋转的结点成为新树的右孩子，被旋转结点的左孩子的右结点成为被旋转结点的左孩子。


变色：结点变化后的红黑树必须重新满足红黑树的性质，则需要把红色结点变为黑色，或者把黑色结点变为红色。



红黑树旋转和变色的核心思想：将红色结点移动到根结点，再将根结点设置为黑色。

7.8.4. 插入
为什么红黑树中新插入的结点必须是红色？

一颗正常的红黑树中新插入的结点不是红色时，否则就违反了红黑树的性质 4：每个叶子结点到根结点的所有路径上不能有两个连续的红色结点。


插入前需要找到结点插入的位置，如果插入结点小于当前遍历到的结点，则到当前结点的左子树中继续查找；如果插入结点大于当前结点，则到当前结点的右子树中继续查找。

新插入的结点为红色结点时，分为以下几种情况

若被插入的结点是根结点，直接把此结点涂为黑色。
若被插入的结点的父结点是黑色，结点被插入后，没有违反红黑树的性质，仍然是红黑树。
若被插入的结点的父结点是红色，违反了红黑树的特性，需要做旋转和变色处理。


若当前结点的父结点和叔叔结点为红色时

将父结点和叔叔结点设置为黑色，     
如果此时祖父结点是根结点，则则直接将祖父结点设置为黑色。
如果此时祖父结点不是根结点，则将祖父结点（父结点的父结点）设置为红色，并将祖父结点更新为新的当前结点，然后再对祖父结点进行后续的操作。      


若新的当前结点的父结点为红色，叔叔结点为黑色，且新的当前结点是其父结点的右孩子 

将父结点重新作为新的当前结点
以新的当前结点为支点进行左旋。此时新的当前结点满足左旋的特点，因此要用左旋来改变红黑树的结构。
如果原来的当前结点经过旋转后变为根结点，则直接将其设置为黑色。
如果原来的当前结点经过旋转后不是根结点，则需要将原来当前结点的父结点设置为新的当前结点。


若新的当前结点的父结点为红色，叔叔结点为黑色，且新的当前结点是其父结点的左孩子

将父结点设置为黑色，祖父结点设置为红色
以祖父结点为支点进行右旋  







7.8.5. 删除
将红黑树当作一颗二叉查找树，待删除的结点按照儿子的个数，删除时分为3种情况。

被删除结点没有儿子，即为叶子结点。那么，直接将该结点删除就OK了 
若果被删除结点只有一个儿子，那么直接删除该结点，并用该结点的唯一子结点顶替它的位置。
删除的结点有两个儿子。先找到要删除结点的后继结点，然后把它后继结点内的值复制给当前要删除的结点，再删除它的后继结点。巧妙地利用了删除后继结点达到删除当前结点的目的。
当被删除结点有两个非空子结点的情况时，该结点的后继结点要么没有儿子，要么 只有一个儿子；若只有没有儿子，则按第一种情况处理，若只有一个儿子，则按第二种情况处理。




如果删除的是红色结点，那么原红黑树的性质依旧保持，此时不用做修正操作；如果删除的结点是黑色结点，原红黑树的性质可能会被改变，我们要对其做修正操作。

结点删除时，红黑树的哪些特性会发生变化？
如果删除的结点不是树唯一结点，那么删除结点的那一个支到各叶结点的黑色结点数会发生变化，此时性质5被破坏。
如果被删结点的唯一非空子结点是红色，而被删结点的父结点也是红色，那么性质4被破坏。
如果被删结点是根结点，而它的唯一非空子结点是红色，则删除后新根结点将变成红色，违背性质2。




如何进行删除分析？

删除的结点为树中的非叶子结点。 


case1：当前结点为新的根结点，删除没有影响，直接删除 
case2：当前结点为黑色，兄弟结点为红色，父结点和兄弟结点的儿子结点都为黑色 
把父结点染成红色，兄弟结点染成黑色，然后再进行左旋操作


case3：当前结点为黑色，兄弟结点、兄弟结点的儿子结点、父结点全都为黑色
只需要简单的把兄弟结点颜色变为红色就可以了。


case4：当前结点颜色是黑色，兄弟结点和它的儿子结点都为黑色，父结点为红色
简单的将要删除结点的兄弟结点和父结点颜色进行交换就可以了。 


case5：当前结点颜色是黑色且为父结点的左子结点，兄弟结点是黑色，兄弟的左子结点是红色，右子结点是黑色
把兄弟结点染成红色，兄弟左子结点染黑色，再以兄弟结点为支点，进行右旋转操作。 


case6：当前结点颜色是黑色且为父结点的左子结点，兄弟结点是黑色，兄弟结点的右子结点是红色，兄弟结点的左子结点颜色是任意色
将兄弟结点染成当前结点的父结点颜色，兄弟结点右子结点染成黑色，再以当前结点的父结点为支点进行左旋转操作。 





7.8.6. 参考
维基百科英文解释红黑树 讲解最全面，重点掌握。
维基百科中文解释红黑树
Github详解：教你透彻了解红黑树
A complete and working implementation in C
James Paton. “Red-Black Trees”
红黑树(一)之 原理和算法详细介绍

7.9. 字典数（trie树）
是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题

特点

根结点不包含字符，除根结点外的每一个子结点都包含一个字符。
从根结点到某一结点，路径上经过的字符连接起来，就是该结点对应的字符  串。
每个字符串的公共前缀作为一个字符结点保存。


缺点

构造Trie树需要很大的内存空间。因为父子字符结点之间用 指针关联。如果用数组保存这些指针，这意味着子结点的数组需要穷举出每一种可能。


应用场景

关键词匹配，提示，纠错。
最长公共前缀匹配。
命令自动补全，如zsh.
网址浏览历史记录。
手机号码簿查询



7.10. 堆树
堆是一种特殊的二叉树。

当树根值为最大值，则为最大堆；

一颗完全二叉树中，任意一个结点的值总是小于等于根结点的值。


当树根值为最小值，则为最小堆；

一颗完全二叉树中，任意一个结点的值总是大于等于根结点的值。


当前结点（根结点除外）与父结点和子结点地址、数据值之间的关系

父结点的索引值等于当前结点的索引值的 1/2 
左子结点的索引值等于当前结点的索引值的 2倍
右子结点的索引值等于当前结点的索引值的 2倍加1 


结点的插入、删除操作

添加新元素的时候，先存放到数组的尾部，然后在通过自下向上重新排序，使加添新元素后的二叉树，满足为堆数据结构的特性。
删除元素时，一般默认删除第一个根结点，将数组的最后一个元素放到根结点的位置，之后通过自上而下重排序，使删除元素后的二叉树也满足堆数据结构的特性。


参考

堆树（最大堆、最小堆）详解
彻底弄懂最大堆的四种操作(图解+程序)（JAVA）
堆排序
算法】堆，最大堆（大顶堆）及最小堆（小顶堆）的实现



7.11. B树
什么是B Tree？

在计算机科学中，B树（英语：B-tree）是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树（binary search tree）一个节点可以拥有2个以上的子节点。与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。B树减少定位记录时所经历的中间过程，从而加快存取速度。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。


B tree 应用

主要用于文件系统以及部分数据库索引（MongoDB） 而Mysql是用B+树的。


参考

从B树、B+树、B*树谈到R 树
维基百科解释B树



7.12. B+树
什么是B++ Tree？

基础概念

操作系统在对磁盘进行访问的时候，通常按照块的方式进行读取。
B+树内部使用双向链表的方式实现。
B+树是一颗完全平衡的m阶多叉树


B+树如何进行检索？

先确定要检索的值位于数组中的哪两个元素之间，然后再将第一个元素对应的指针读出，获得下一个 block 的位置，读出 block 中节点的数据后，再对该块进行同样处理。逐层访问内部节点，直到读出叶子节点。对于叶子节点中的数组，直接使用二分查找算法，判断查找的元素是否存在。如果存在，得到该查询值对应的存储数据，如果这个数据是详细信息的位置指针，则还需要再访问磁盘一次，将详细信息读出。


B+树的优点

将索引存放在磁盘，让检索技术摆脱了内存的限制，通过将索引和数据分离的方式，使索引的数组大小保持在较小的范围内。


参考

B树和B+树的插入、删除图文详解
维基百科解释B+树



8. 算法排序算法时间复杂度、空间复杂度、稳定性比较。




8.1. 快速排序
参考
维基百科解释快速排序
快速排序及优化



8.2. 桶排序
桶排序详解

8.3. 堆排序
什么是堆排序？

堆排序是一种结合二叉树，采用一个辅助记录空间进行排序的算法。对于一个完全二叉树来说，如果所有结点（除叶子结点外）的值都大于或小于其左右孩子结点的值，那么这颗完全二叉树就被称为一个堆。由堆的定义可知，若堆顶结点（二叉树的根节点）一定对应整个序列中最大或最小的记录。若每次将堆顶的记录输出，同时调整剩余的记录，使它们重新排成一个堆，重复以上的过程，最终得到一个有序的序列，完成排序的过程，这种排序的方法，称为堆排序。


堆排序过程中两个关键的问题？

如何将一个无序序列中所有的记录排成一个堆？
在输出了堆顶记录后，如何将序列中剩余的记录再次排成一个堆？


堆排序注意点

对于记录较少的序列排序时，并不建议使用堆排序。但是当记录数据是很大的序列进行排序时，堆排序会比较好。因为堆排序主要时间耗费在建立初始堆和调整新堆时反复进行的“筛选”上。（从堆顶到叶子这一不断调整为堆的过程称为“筛选”。）
在最坏的情况下，时间复杂度为 $\Omicron(n*log_2 n)$


参考

堆排序详解 
《数据结构与算法分析新视角》



8.4. 递归
函数自己调用自己。
缺点：
需要消耗时间和空间：每一次函数调用，都需要在栈上分配空间来保存参数、返回地址和临时变量，而且往栈里面压入数据和弹出数据都需要时间的。 
可能会导致栈溢出。
递归分解的子问题中存在大量重复的计算，导致效率较低。



8.5. 动态规划
求一个问题的最优解，通常是最大值或最小值，而且问题可以分解为若干个子问题，并且子问题之间还有重叠的更小的子问题。 
从上往下分析问题，从下往上求解问题。

8.6. KMP(字符串查找)
从头到尾彻底理解KMP（2014年8月22日版）

9. 编写程序需要思考的问题
它容易读懂吗？
它有完善的文档吗？
它容易修改吗？
它在运行时需要多大内存？
它的运行时间有多长？
它的通用性如何？能不能不加修改就可以用它来解决更大范围的问题？
它可以在多种机器上编译和运行吗？或者说需要经过修改才能在不同的机器上运行吗？

10. 参考资源
Data Structure Visualizations San Francisco大学计算机学院提供一个可视化的教学资源 
visualgo 是一款可视化学习算法的工具，从简单的排序算法到复杂的图形数据结构和算法都有 
algorithm-visualizer 支持的语言有：Java，C++，JS 等，还有控制台也会输出整个执行的过程，能帮你更好的理解算法。
实验楼上实现了LeetCode中一些经典的算法
LeetCode英文版
数组、单链表和双链表介绍 以及 双向链表的C&#x2F;C++&#x2F;Java实现 
DFS与BFS对比
维基百科解释AVL树  
排序算法时间复杂度、空间复杂度、稳定性比较

]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>dataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title>DesignPattern</title>
    <url>/DesignPattern/DesignPattern/DesignPattern/</url>
    <content><![CDATA[

1. 思考

Elements of Reusable Object-Oriented Software(可复用面向对象软件)
只有理解了模式，你才能清楚代码中的运行时刻结构。
建立一套思维和一套模型
设计模式：在变化和稳定中寻找一个平衡点。
设计模式之间应该相互配合，共同解决问题。
《The Timeless Way of Building》 Christopher Alexander著作
层次：分析、设计实现。



设计模式是做什么的？
它的基本原理和意图是什么？
它解决的是什么样的特定设计问题？
什么时候、什么地方去使用该设计模式？
该设计模式可用来改良哪些不良的设计？
你怎样识别这些情况？
参与者：设计模式中的类或对象以及它们各自的职责？
模式的参与者怎样协作以及实现它们的职责？
模式怎样支持它们的目标？
使用设计模式的效果和所需做的权衡取舍？系统结构的哪些方面可以独立改变？
实现设计模式时需要知道的提示、技术要点及应避免的缺陷？以及是否存在某些特定于实现语言的问题。
与这个模式紧密相关的模式有哪些？其间重要的不同之处是什么？这个应与其它的哪些模式一起使用？

2. 设计模式概括三大类型设计模式，共23种。按照目的准则可将设计模式分为下面三大类。

创建型模式(Creational patterns)：共5种；

提供对象创建机制，以提高灵活性和现有代码的重用性，在系统的某个地方实例化具体的类。通过抽象对象的创建过程，创建型模式提供不同的方式在实例化时建立接口和实现的透明连接。创建型模式确保你的系统是针对接口的方式书写的，而不是针对实现而书写的。


工厂方法模式（factory method pattern）
抽象工厂模式（abstract factory pattern）
建造者模式（builder pattern）
单例模式（singleton pattern）
原型模式（prototype pattern）


结构型模式(Structural patterns)：如何将对象和类组装为更大的结构，同时保持结构的灵活性和效率，共7种。

代理模式（proxy pattern）  
装饰者模式（decorator pattern）
适配器模式（adapter pattern）
桥接模式（bridge pattern）
组合模式（composite pattern）
外观模式（facade pattern）
享元模式（flyweight pattern）


行为型模式(Behavioural patterns)：对类或对象怎样交互和怎样分配职责，共11种。

模板方法模式（template method pattern） 
命令模式（command pattern）
责任链模式（chain of responsibility pattern）
策略模式（strategy pattern）
中介者模式（mediator pattern）
观察者模式（observer pattern）
备忘录模式（memento pattern）
访问者模式（visitor pattern）
状态模式（state pattern）
解释模式（interpreter pattern）
迭代模式（iterator pattern）



3. 设计模式原则使用设计模式的最终目的：高内聚，低耦合。
8种基本原则

依赖倒置原则（DIP: dependence inversion principle）：依赖于抽象接口，不要依赖于具体的类，即针对接口编程。

开放封闭原则（OCP）：类的改动是通过增加代码来进行的，而不是修改源代码。

迪米特原则（LOD：low of demeter）：一个对象应该对其它的对象尽可能少的了解，从而降低各个对象之间的耦合，提高系统的可维护性。

例如：在一个程序中，各个模块之间相互调用时，通常会提供一个统一的接口来实现，使其它的模块不需要了解另一个模块的内部实现，这样当一个模块发生改变时，其它的模块不会受到影响。


单一责任原则（SRP）：一个类应该仅有一个引起它变化的原因，变化的方向隐含着类的责任。

替换原则（LSP）：子类必须能够替换它们的基类。

接口隔离原则（ISP）：不应该强迫客户程序依赖它们不用的方法。

优先使用对象组合而不是类继承：继承在某种程度上破坏了封装性，子类父类耦合度高；对象组合则只要求被组合的对象具有良好定义的接口，耦合度较低。

封装变化点：使用封装来创建对象之间的分界层，让设计者可以在分界层的一侧进行修改，而不会对另一侧产生不良的影响，从而实现层次间的松耦合。

针对接口编程，而不是针对实现编程。

不将变量类型声明为某个特定的具体类，而是声明为某个接口。
客户程序无需获知对象的具体类型，只需要知道对象所具有的接口。
减少系统中各部分的依赖关系，从而实现“高内聚、松耦合”的类型设计方案。



4. Creational patterns(创建型模式)4.1. Singleton(单例模式)4.1.1. 什么是单例模式？
保证一个类只能生成一个唯一的实例对象，同时提供该实例访问的全局方法。


4.1.2. 实现的步骤
构造函数可见性设置为 private，禁止类创建额外的实例，只能创建一个实例。
提供一个全局的静态（static）方法，作为外部类共享的唯一实例。
在类中定义一个静态（static）指针，指向该类变量的静态变量指针。

代码示例
class Singleton&#123;public:    static Singleton* getInstance();                 // 提供一个全局的静态方法private:    static Singleton* m_Instance;                    // 静态指针     Singleton();                                     // 构造函数私有化，禁止他人创建    ~Singleton();&#125;;// 类外部初始化静态变量Singleton* Singleton::m_Instance = nullptr   

注意代码中 getInstance() 方法的修饰符：public 和 static。public 修饰表示它是一个公共的方法，以便供外界其他对象使用；static 关键字表示它是一个静态方法，在类的外部可以直接通过类名（Singleton::getInstance()）来访问，而无须创建 Singleton 对象，事实上在类的外部也无法创建类的对象，因为构造函数是私有的。
在类的外部我们无法直接创建新的 Singleton 对象，但可以通过类的成员方法 Singleton::getInstance() 来访问实例对象，第一次调用 getInstance() 方法时将创建唯一实例，再次调用时将返回第一次创建的实例，从而确保实例对象的唯一性。
4.1.3. 单例模式实现4.1.3.1. 饿汉式饿汉式就是在类刚加载的时候就创建了类的实例，是一个全局对象，生命周期一直到程序退出，其申请的内存空间才被释放。若对象创建的实例一直没有被使用，即程序中没有地方去调用，则存在申请的内存空间浪费的情况。这种以空间换时间的方式，虽然浪费了一些内存空间，但在多线程中保证了线程访问的安全，不会造成多线程之间资源竞争的问题。
代码实现
#include &lt;iostream&gt;#include &lt;stdlib.h&gt;using namespace std;class Singleton&#123;public:    static Singleton* getInstance();                 // 提供一个全局的静态方法    static Singleton* freeInstance();                // 释放内存private:    static Singleton* m_Instance;                    // 静态指针     Singleton();                                     // 构造函数私有化，禁止他人创建    ~Singleton();&#125;;Singleton* Singleton::m_Instance = new Singleton;    // 静态全局变量创建对象Singleton::Singleton()&#123;    cout &lt;&lt; &quot;执行构造函数&quot; &lt;&lt; endl;&#125;Singleton::~Singleton()&#123;    cout &lt;&lt; &quot;执行析构函数&quot; &lt;&lt; endl;&#125;Singleton* Singleton::getInstance()&#123;    return m_Instance;&#125;Singleton* Singleton::freeInstance()&#123;    if (m_Instance != nullptr) &#123;        delete m_Instance;        m_Instance = nullptr;        cout &lt;&lt; &quot;释放对象内存&quot; &lt;&lt; endl;    &#125;    return m_Instance;&#125;int main(int argc, char *argv[])&#123;    cout &lt;&lt; &quot;执行饿汉式的单例模式&quot; &lt;&lt; endl;    Singleton *s1 = Singleton::getInstance();    Singleton *s2 = Singleton::getInstance();    if (s1 == s2) &#123;        cout &lt;&lt; &quot;是同一个对象&quot; &lt;&lt; endl;    &#125;    else &#123;        cout &lt;&lt; &quot;不是同一个对象&quot; &lt;&lt; endl;    &#125;    Singleton::freeInstance();    return 0;&#125;

执行结果：
执行构造函数执行饿汉式的单例模式是同一个对象执行析构函数释放对象内存

执行 main 函数之前就创建了一个对象，一直到程序的生命周期结束，被创建对象的内存才会得到释放。若多线程访问时，在线程还没开始启动之前，类的实例就被创建完成了，因此就不会存在多线程安全的问题。
使用场景

适用于单例对象较少的情况。这样可以保证绝对线程安全、执行效率比较高。
如果系统中有很多的地方使用了饿汉单例模式，系统初始化时就创建很多的单例对象，会导致大量的内存浪费。即无论对象用与不用都占着空间，浪费了内存空间。

4.1.3.2. 懒汉式懒汉式就是代码中需要调用类的实例时，才会创建类的实例。比如，第一次在调用 getInstace()  的方法时，会去创建类的实例，给实例分配内存空间，而不是在类加载的时候就创建类的实例和分配空间，这种技术又称为 延迟加载(Lazy Load) 技术。
普通懒汉式代码实现
#include &lt;iostream&gt;#include &lt;unistd.h&gt;using namespace std;class Singleton&#123;public:    static Singleton* getInstance() &#123;        if (m_Instance == nullptr) &#123;            m_Instance = new Singleton;             &#125;        return m_Instance;    &#125;    // 手动释放内存    static Singleton* freeInstance() &#123;        if (m_Instance != nullptr) &#123;            delete m_Instance;            m_Instance = nullptr;            cout &lt;&lt; &quot;Free instance memory.&quot; &lt;&lt; endl;        &#125;        return m_Instance;    &#125;private:    Singleton() &#123; cout &lt;&lt; &quot;Execute constructor.&quot; &lt;&lt; endl; &#125;    ~Singleton() &#123; cout &lt;&lt; &quot;Execute destructor.&quot; &lt;&lt; endl; &#125;    static Singleton* m_Instance;           // 静态指针    &#125;;// 静态全局变量初始化Singleton* Singleton::m_Instance = nullptr; 

这种以时间换空间的方式，节约了效率，但最重要的问题是：在多线程访问时单例模式可能存在线程安全的问题。
多线程访问懒汉单例模式，代码实现，支持 C++11 风格。
#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;thread&gt;#include &lt;chrono&gt;using namespace std;class Singleton&#123;public:    static Singleton* getInstace(const std::string&amp; value);    /**     * Singletons should not be cloneable.     */    Singleton(Singleton&amp; other) = delete;    /**     * Singletons should not be assignable.     */    void operator=(const Singleton&amp;) = delete;    std::string getValue() &#123;        return m_value;    &#125;private:    Singleton(const std::string value);     // constructor    ~Singleton();                           // destructor    static Singleton* m_singleton;          // 静态成员指针    std::string m_value;&#125;;// 静态变量外部初始化Singleton* Singleton::m_singleton = nullptr;// 没有加锁，存在多个线程访问时资源竞争的问题Singleton* Singleton::getInstace(const std::string&amp; value)&#123;    if (m_singleton == nullptr) &#123;        m_singleton = new Singleton(value);    &#125;    return m_singleton;&#125;Singleton::Singleton(const std::string value)    : m_value(value)&#123;&#125;Singleton::~Singleton()&#123;&#125;// 第一个线程处理函数void ThreadFirst()&#123;    std::this_thread::sleep_for(chrono::milliseconds(1000));    Singleton* singleton = Singleton::getInstace(&quot;First&quot;);    std::cout &lt;&lt; singleton-&gt;getValue() &lt;&lt; std::endl;&#125;// 第二个线程处理函数void ThreadSecond()&#123;    std::this_thread::sleep_for(chrono::milliseconds(1000));    Singleton* singleton = Singleton::getInstace(&quot;Second&quot;);    std::cout &lt;&lt; singleton-&gt;getValue() &lt;&lt; std::endl;&#125;int main(int argc, char *argv[]) &#123;    std::thread t1(ThreadFirst);    std::thread t2(ThreadSecond);    t1.join();                          // 回收创建的线程，避免资源浪费    t2.join();    return 0;&#125;

实现结果：有时出现下面第一种情况，有时出现下面第二中情况。因此存在多个线程访问时，有资源竞争的问题。
// 第一种情况SecondFirst

// 第二种情况FirstFirst

针对上面的两种情况，我们知道第二种结果肯定是我们期望的，但为什么会产什么第一种结果呢？
因为： 假如在某一瞬间线程 A 和线程 B 都在调用 getInstance() 方法，此时实例对象为 nullptr 值，均能通过 m_Instance == nullptr 的判断。当线程 1   new 一个对象的过程还没有完成时，线程 2 也通过了判断，需要去 new 一个对象，现在程序中存在两个不同的对象，违背了单例模式的原则，因此是多线程不安全的。 至于哪个先被创建，则取决于线程抢占的时机。
现在我们思考下，要怎么去解决多线程访问不安全的问题？下面我们来一一探讨。
4.1.3.3. C++ 中多线程安全问题？
第一种：牺牲内存空间，采用饿汉式单例模式，用法见上面的饿汉式的实现过程。

第二种：加锁。既然多个线程访问时，不能确定同一时间内有多少个线程同时访问，导致资源竞争（race condition）的问题。那么就给线程加把锁，让每个线程每次访问的时候，同一时间内只有一个线程在创建对象，其它的线程需要等锁的资源被释放后，才能工作。这样就保证了多个线程访问时，线程是安全的。
首先我们在实例是否被创建之前就去加锁。
#include &lt;iostream&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;mutex&gt;#include &lt;unistd.h&gt;using namespace std;std::mutex m_mutex;class Singleton&#123;public:    static Singleton* getInstance() &#123;        m_mutex.lock();        if (m_Instance == nullptr) &#123;            m_Instance = new Singleton;             &#125;        m_mutex.unlock();        return m_Instance;    &#125;    // 手动释放内存        static Singleton* freeInstance() &#123;        if (m_Instance != nullptr) &#123;            delete m_Instance;            m_Instance = nullptr;            cout &lt;&lt; &quot;Free instance memory.&quot; &lt;&lt; endl;        &#125;        return m_Instance;    &#125;private:    Singleton() &#123; cout &lt;&lt; &quot;Execute constructor.&quot; &lt;&lt; endl; &#125;    ~Singleton() &#123; cout &lt;&lt; &quot;Execute destructor.&quot; &lt;&lt; endl; &#125;    static Singleton* m_Instance;           // 静态指针    &#125;;// 静态全局变量初始化Singleton* Singleton::m_Instance = nullptr; 

上述代码虽然解决了线程安全问题，但是每次调用 getInstance() 时都需要进行锁的判断。假设当线程 1 在执行 m_instance = new Singleton() 的时候，线程 2 也在调用 getInstance()，线程 2 一定会被阻塞在加锁处，等待线程 1 执行结束后释放这个锁，最后再去执行线程 2。在多线程高并发访问环境中，频繁的进行加锁和解锁，将会导致系统性能大大降低，因为加锁和解锁都是一个耗时的过程。
那如何既解决线程安全问题又不影响系统性能呢？下面我们继续对懒汉式单例进行改进。
static Singleton* getInstance() &#123;    if (m_Instance == nullptr) &#123;        m_mutex.lock();              // 加锁        if (m_Instance == nullptr) &#123;            m_Instance = new Singleton;             &#125;        m_mutex.unlock();    &#125;    return m_Instance;&#125;

加锁和解锁的步骤只有在第一次执行 new Singleton() 才是有必要的，只要 m_instance 实例被创建出来了，就没必要加锁解锁了，直接返回这个对象的指针。以后不管多少线程同时访问，使用 if (m_instance == nullptr) 进行判断就行了（只是读操作，不需要加锁），没有线程安全问题，加了锁之后反而存在性能问题。因此我们在加锁之前再进行一次实例是否存在的判断。两次进行加锁判断的这种方式称为**双重检查锁定(Double Check Locking)**。
是不是觉得这样就完美啦？其实在一段时间内，大家都以为这是正确的、有效的做法。实际上却不是这样的。幸运的是，后来有大牛们发现了DCL中的问题，避免了这样错误的写法在更多的程序代码中出现。原因是内存读写的乱序执行造成的（编译器的问题）。
那么到底错在哪里？
我们看 m_instance = new Singleton() 这句话，是创建对象的过程。其实这个过程可以分成三个步骤来执行：

分配了一个 Singleton 类型对象所需要的内存。
在分配的内存处构造 Singleton 类型的对象。
把分配的内存的地址赋给指针 m_instance。

主观上，我们会觉得计算机在会按照1、2、3 的步骤来执行的，但是问题就出在这。实际上只能确定步骤 1 最先执行，而步骤 2、3 的执行顺序却是不一定的。假如某个线程 A 在调用执行m_instance = new Singleton() 的时候是按照 1, 3, 2 的顺序的，那那么当刚刚执行完步骤 3 的时候发生线程切换，计算机开始执行另外一个线程 B。因为第一次 check 没有上锁保护，那么在线程 B 中调用 getInstance 的时候，不会在第一次 check 上等待，而是执行后面的语句，而此时发现 m_instance 已经被赋值了，就会直接返回 m_instance，但是在线程 A 中步骤 2 还没有执行，对象没有被构造！也就是说在线程 B 中通过 getInstance 返回的对象还没有被构造就被拿去使用了！这样就会发生一些难以debug的灾难问题。

加锁的过程中，需要思考的问题？
类中资源的初始化可能有顺序问题，一些资源依赖于其他资源的初始化，可能会导致一些资源释放的问题。

第三种：静态局部变量。
java 和 c# 发现这个问题后，就加了一个关键字 volatile，在声明 m_instance变量的时候，要加上volatile修饰，编译器看到之后，就知道这个地方不能够 reorder（一定要先分配内存，在执行构造器，都完成之后再赋值）。而对于 c++ 标准却一直没有改正，所以 VC++ 在 2005 版本也加入了这个关键字，但是这并不能够跨平台（只支持微软平台）。不过在新的 C++11 中，这个问题得到了解决。因为新的 C++11 规定了新的内存模型，保证了执行上述 3 个步骤的时候不会发生线程切换，相当这个初始化过程是“原子性”的的操作，DCL 又可以正确使用了。不过在 C++11 下却有更简洁的多线程 Singleton 写法了，比如用局部静态变量（local static variable）。
 C++11 以上，其设置为 static，再将该单例对象这样运行时确保只调用一次静态构造函数，实现的代码量不仅少。
#include &lt;iostream&gt;#include &lt;unistd.h&gt;using namespace std;class Singleton&#123;public:    static Singleton&amp; getInstance() &#123;        static Singleton instance;        return instance;    &#125;  private:    Singleton() &#123; cout &lt;&lt; &quot;Execute constructor.&quot; &lt;&lt; endl; &#125;    ~Singleton() &#123; cout &lt;&lt; &quot;Execute destructor.&quot; &lt;&lt; endl; &#125; &#125;;

原因在于在C++11之前的标准中并没有规定local static变量的内存模型，所以很多编译器在实现local static变量的时候仅仅是进行了一次check，但是在C++11却是线程安全的，这是因为新的C++标准规定了当一个线程正在初始化一个变量的时候，其他线程必须得等到该初始化完成以后才能访问它。
不过有些编译器在C++11之前的版本就支持这种模型，例如g++，从g++4.0开始，meyers singleton就是线程安全的，不需要 C++11。其他的编译器就需要具体的去查相关的官方手册了。


4.1.4. 单例模式内存释放大多数时候，使用上面第一种或第二种方法获取实例，不去手动释放内存，这种实现都不会出现问题，因为程序结束时，操作系统会负责自动回收资源，替代了人为的实现的过程。但有经验的读者可能会问，m_Instance 指向的空间什么时候释放呢？更严重的问题是，该实例的析构函数什么时候执行？如果在类的析构中执行一些必须的操作，比如关闭文件描述符，销毁锁的资源等。那么上面的代码无法实现这个要求，我们需要一种方法，正常的删除该实例。
单例模式中释放用 new 申请的内存，有两种方式可以实现。
第一种：在类中定义一个属性为 public 的内存销毁的方，使用 delete 关键字实现去释放内存。给外部类提供接口，去销毁对象。 
static Singleton* freeInstance() &#123;    if (m_Instance != nullptr) &#123;        delete m_Instance;        m_Instance = nullptr;        cout &lt;&lt; &quot;Free instance memory.&quot; &lt;&lt; endl;    &#125;    return m_Instance;&#125;

第一种方式可以实现内存的释放，但有时候忘记去写销毁内存的方法了，程序可能会出现问题。那么有没有一种方式：单例模式运行的生命周期结束时，自动去释放申请的内存，不用在类的外部额外的手动销毁，有一点类似于垃圾回收机制，这就是第二种方式。
我们知道，程序在结束的时候，系统会自动析构所有的全局变量。事实上，系统也会析构所有的类的静态成员变量，就像这些静态成员也是全局变量一样。利用这个特征，我们可以在单例类中定义一个这样的静态成员变量，而它的唯一工作就是在析构函数中删除单例类的实例。
class Singleton&#123;public:    static Singleton* getInstace(const std::string&amp; value);               // 懒汉式    Singleton(Singleton&amp; other) = delete;                                 // 禁止拷贝操作    const Singleton&amp; operator=(const Singleton&amp;) = delete;                // 禁止赋值操作    std::string getValue() &#123;        return m_value;    &#125;private:    // GC 类：程序结束时，进入析构函数销毁 Singleton 类的实例    class GC    &#123;    public:        GC() &#123;&#125;        ~GC() &#123;            if (m_Instance != nullptr) &#123;                delete m_Instance;                m_Instance = nullptr;                cout &lt;&lt; &quot;Exec GC dector, delete m_Instance.\n&quot;;            &#125;        &#125;    &#125;;    static GC gc;                           // 定义静态成员变量，当程序结束时，会调用 GC 类的析构函数private:    Singleton(const std::string value);     // constructor    ~Singleton();                           // destructor    static Singleton* m_Instance;           // 静态成员指针    std::string m_value;&#125;;// 静态变量外部初始化Singleton::GC Singleton::gc; Singleton* Singleton::m_Instance = nullptr;Singleton::Singleton(const std::string value)    : m_value(value)&#123;    cout &lt;&lt; &quot;Exec Singleton ctor.\n&quot;;&#125;Singleton::~Singleton()&#123;    cout &lt;&lt; &quot;Exec Singleton dector.\n&quot;;&#125;// 懒汉式单例，存在多个线程访问时资源竞争的问题Singleton* Singleton::getInstace(const std::string&amp; value)&#123;    if (m_Instance == nullptr) &#123;        m_Instance = new Singleton(value);    &#125;    return m_Instance;&#125;// 第一个线程处理函数void ThreadFirst()&#123;    std::this_thread::sleep_for(chrono::milliseconds(1000));    Singleton* singleton = Singleton::getInstace(&quot;First&quot;);    std::cout &lt;&lt; singleton-&gt;getValue() &lt;&lt; std::endl;&#125;// 第二个线程处理函数void ThreadSecond()&#123;    std::this_thread::sleep_for(chrono::milliseconds(1000));    Singleton* singleton = Singleton::getInstace(&quot;Second&quot;);    std::cout &lt;&lt; singleton-&gt;getValue() &lt;&lt; std::endl;&#125;int main(int argc, char *argv[]) &#123;    std::thread t1(ThreadFirst);    std::thread t2(ThreadSecond);    t1.join();                          // 回收创建的线程，避免资源浪费    t2.join();    return 0;&#125;

执行结果
Exec Singleton ctor.FirstExec Singleton ctor.SecondExec Singleton dector.Exec GC dector, delete m_Instance.

4.1.5. 单例模式优缺点优点

在内存中只有一个对象，节省内存空间。
避免频繁的创建销毁对象，可以提高性能。
避免对共享资源的多重占用，简化访问。
为整个系统提供一个全局访问点。

缺点

单例模式中没有抽象层，单例类的可扩展性差。
单例类的职责过重，在一定程度上违背了“单一职责原则”。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。

4.1.6. 参考
java单例模式
设计模式之单例模式：segmentfault 上面使用C++实现的单例模式。
C++中多线程与Singleton的那些事儿：写的很详细。
《C++ and the Perils of Double-Checked Locking》

4.2. Factory Method(工厂模式)简单工厂模式
简单工厂模式(Simple Factory Pattern)：专门定义一个类（工厂类）来负责创建其他类的实例。可以根据创建方法的参数来返回不同类的实例，被创建的实例通常都具有共同的父类。

举例：简单工厂模式像一个代工厂，一个工厂可以生产多种产品。举个例子，一个饮料加工厂同时帮百事可乐和可口可乐生产，加工厂根据输入参数Type来生产不同的产品。

优点

使用者只需要给工厂类传入一个正确的约定好的参数，就可以获取你所需要的对象，而不需要知道其创建细节，一定程度上减少系统的耦合。
客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，减少开发者的记忆成本。




缺点

如果业务上添加新产品的话，就需要修改工厂类原有的判断逻辑，这其实是违背了开闭原则的。
在产品类型较多时，有可能造成工厂逻辑过于复杂。所以简单工厂模式比较适合产品种类比较少而且增多的概率很低的情况。



4.2.1. 什么是 Factory Method？工厂方法模式(Factory Method Pattern)又称为工厂模式，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，即通过不同的工厂子类来创建不同的产品对象。Factory Method 将类的实例化推迟到子类中。
举例子：工厂方法和简单工厂有一些区别，简单工厂是由一个代工厂生产不同的产品，而工厂方法是对工厂进行抽象化，不同产品都由专门的具体工厂来生产。可口可乐工厂专门生产可口可乐，百事可乐工厂专门生产百事可乐。
4.2.2. 优点
用户只需要关心其所需产品对应的具体工厂是哪一个即可，不需要关心产品的创建细节，也不需要知道具体产品类的类名。
当系统中加入新产品时，不需要修改抽象工厂和抽象产品提供的接口，也无须修改客户端和其他的具体工厂和具体产品，而只要添加一个具体工厂和与其对应的具体产品就可以了，符合了开闭原则。

4.2.3. 缺点
当系统中加入新产品时，除了需要提供新的产品类之外，还要提供与其对应的具体工厂类。因此系统中类的个数将成对增加，增加了系统的复杂度。

4.3. Abstract Factory(抽象工厂模式)4.3.1. 什么是抽象工厂模式？
提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。它封装了一组相关的工厂。



举例子：抽象工厂和工厂方法不同的地方在于：生产产品的工厂是抽象的。举例，可口可乐公司生产可乐的同时，也需要生产装可乐的瓶子和箱子，瓶子和箱子也是可口可乐专属定制的，同样百事可乐公司也会有这个需求。这个时候我们的工厂不仅仅是生产可乐饮料的工厂，还必须同时生产同一主题的瓶子和箱子，所以它是一个抽象的主题工厂，专门生产同一主题的不同商品。
4.3.2. UML图

4.3.3. 优点
具体产品在应用层代码隔离，不需要关心产品细节。只需要知道自己需要的产品是属于哪个工厂的即可。当一个产品族中的多个对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。这对一些需要根据当前环境来决定其行为的软件系统来说，是一种非常实用的设计模式。

4.3.4. 缺点
规定了所有可能被创建的产品集合，产品族中扩展新的产品困难，需要修改抽象工厂的接口。

4.3.5. 工厂模式与抽象工厂模式的区别
工厂模式只能生产一个产品；而抽象工厂模式可以产生一列的产品。


4.4. Builder(建造者模式)4.4.1. 什么是建造者模式?
将一个复杂对象的构建与它的表示进行分离，使得同样的构建过程可以创建不同的表示。


4.4.2. 适用性
创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方式。
构造过程必须允许被构造的对象有不同的表示

4.4.3. UML图

4.4.4. 优点
客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。
每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者， 用户使用不同的具体建造者即可得到不同的产品对象 。
增加新的具体建造者无须修改原有类库的代码，指挥者类针对抽象建造者类编程，系统扩展方便，符合“开闭原则”。
可以更加精细地控制产品的创建过程 。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。

4.4.5. 缺点
建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。
如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。

4.5. Prototype(原型模式)4.5.1. 什么是原型模式？
指定类的原型实例，拷贝该实例来创建新的对象。


原型模式为每个对象提供一个接口，让一个复杂的对象具有自我复制的功能，统一一套接口。举例子：原型模式就像复印技术，根据原对象复印出一个新对象，并根据需求对新对象进行微调。
4.5.2. 优点
可以利用原型模式简化对象的创建过程，尤其是对一些创建过程繁琐，包含对象层级比较多的对象来说，使用原型模式可以节约系统资源，提高对象生成的效率。
可以很方便得通过改变值来生成新的对象：有些对象之间的差别可能只在于某些值的不同；用原型模式可以快速复制出新的对象并手动修改值即可。

4.5.3. 缺点
对象包含的所有对象都需要配备一个克隆的方法，这就使得在对象层级比较多的情况下，代码量会很大，也更加复杂。

5. Structural patterns(结构型模式)5.1. Composite(组合模式)5.1.1. 什么是组合模式？
组合模式是将对象组合成树型结构以表示“部分-整体”的层次结构。 Composite使得客户对单个对象和复合对象的使用具有一致性。


5.2. Proxy(代理模式)5.2.1. 什么是代理模式？
为某个对象提供一个代理，并由这个代理对象控制对原对象的访问。



举例子：代理模式像一个房屋中介，买家只能通过中介来买房，代理具备被代理类的所有功能，就像房东有卖房功能，中介也具有卖房功能。此外代理实例还可以帮助被代理实例进行一些额外处理，比如中介可以帮助房东筛选优质买家的功能，帮助房东pass掉一些不符合条件的买家。还有消息队列也是该模式。

5.2.2. 优点
降低系统的耦合度：代理模式能够协调调用者和被调用者，在一定程度上降低了系 统的耦合度。
不同类型的代理可以对客户端对目标对象的访问进行不同的控制：
远程代理,使得客户端可以访问在远程机器上的对象，远程机器 可能具有更好的计算性能与处理速度，可以快速响应并处理客户端请求。
虚拟代理通过使用一个小对象来代表一个大对象，可以减少系统资源的消耗，对系统进行优化并提高运行速度。
保护代理可以控制客户端对真实对象的使用权限。



5.2.3. 缺点
由于在客户端和被代理对象之间增加了代理对象，因此可能会让客户端请求的速度变慢。

5.3. Decorator装饰器模式)5.3.1. 什么是装饰器模式？
装饰模式是动态地给一个对象添加一些额外的职责。就扩展功能而言， Decorator 模式比生成子类方式更为灵活。


5.4. Adapter(适配器)5.4.1. 什么是适配器模式？
适配器模式是将一个类的接口转换成另外一个接口。 Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。


5.4.2. 优点将一些旧的接口放到新的接口中使用，但新接口的功能是旧接口所不包含的。在遗留代码、类库迁移中是非常有用的。
5.5. Bridge(桥接模式)5.5.1. 什么是桥接模式？
桥接模式是将抽象部分与它的实现部分进行分离，使它们都可以独立地变化。


5.6. Facade(外观模式)5.6.1. 什么是外观模式？
为子系统中的一组接口提供统一的高层次接口。


5.6.2. Facade模式概述
Facade模式描述了怎样用对象表示完整的子系统。
定义了一个高层接口，为子系统中的一组接口提供一个统一的接口。
外观模式提供了简单明确的接口，将内部众多子系统功能进行整合。像图片缓存，内部包含了涉及到其他子系统的如缓存、下载等处理，外观模式将这些复杂的逻辑都隐藏了。

5.6.3. 优点
实现了客户端与子系统间的解耦：客户端无需知道子系统的接口，简化了客户端调用子系统的调用过程，使得子系统使用起来更加容易。同时便于子系统的扩展和维护。
符合迪米特法则（最少知道原则）：子系统只需要将需要外部调用的接口暴露给外观类即可，而且他的接口则可以隐藏起来。

5.6.4. 缺点
违背了开闭原则：在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的代码。

5.7. Flyweight(享元模式)5.7.1. 什么是享元模式？
描述了如何支持大量的最小粒度的对象。运用共享技术复用大量细粒度的对象，降低程序内存的占用，提高程序的性能。

享元模式保证共享内部状态，而外部状态根据不同需求定制如各种访问权限，使用中不能去改变内部状态，以达到共享的目的。


例子

音乐服务根据收费划分出免费用户和会员用户，免费用户只能听部分免费音乐，会员用户可以听全部的音乐，并且可以下载。虽然权限上二者间有一些区别，但是他们所享受的音乐来是自于同一个音乐库，这样所有的音乐都只需要保存一份就可以了。另外如果出现音乐库里没有的音乐时，则需要新增该音乐，然后其他服务也可以享受新增的音乐，相当于享元池或缓存池的功能。

5.7.2. 优点
使用享元模可以减少内存中对象的数量，使得相同对象或相似对象在内存中只保存一份，降低系统的使用内存，也可以提性能。
享元模式的外部状态相对独立，而且不会影响其内部状态，从而使得享元对象可以在不同的环境中被共享。

5.7.3. 缺点
使用享元模式需要分离出内部状态和外部状态，这使得程序的逻辑复杂化。
对象在缓冲池中的复用需要考虑线程问题。

6. Behavioural patterns(行为型模式)6.1. Template Method(模板方法模式)6.1.1. 模板模式概述模板方法模式是最简单的行为型设计模式，在其结构中只存在父类与子类之间的继承关系。通过使用模板方法模式，可以将一些复杂流程的实现步骤封装在一系列基本方法中，在抽象父类中提供一个称之为模板方法的方法来定义这些基本方法的执行次序，而通过其子类来覆盖某些步骤，从而使得相同的算法框架可以有不同的执行结果。模板方法模式提供了一个模板方法来定义算法框架，而某些具体步骤的实现可以在其子类中完成。
6.1.2. 什么是模板方法模式？
定义一个操作中算法的框架，而将一些步骤延迟到子类中。模板方法模式使得子类可以不改变一个算法的结构即可重定义（override: 重写）该算法的某些特定步骤。延迟：子类实现父类的虚函数。


6.1.3. UML图

6.1.4. 优点(1) 在父类中形式化地定义一个算法，而由它的子类来实现细节的处理，在子类实现详细的处理算法时并不会改变算法中步骤的执行次序。
(2) 模板方法模式是一种代码复用技术，它在类库设计中尤为重要，它提取了类库中的公共行为，将公共行为放在父类中，而通过其子类来实现不同的行为，它鼓励我们恰当使用继承来实现代码复用。
(3) 可实现一种反向控制结构，通过子类覆盖父类的钩子方法来决定某一特定步骤是否需要执行。
(4) 在模板方法模式中可以通过子类来覆盖父类的基本方法，不同的子类可以提供基本方法的不同实现，更换和增加新的子类很方便，符合单一职责原则和开闭原则。
6.1.5. 缺点
需要为每一个基本方法的不同实现提供一个子类，如果父类中可变的基本方法太多，将会导致类的个数增加，系统更加庞大，设计也更加抽象，此时，可结合桥接模式来进行设计。

6.1.6. 应用场景(1) 对一些复杂的算法进行分割，将其算法中固定不变的部分设计为模板方法和父类具体方法，而一些可以改变的细节由其子类来实现。即：一次性实现一个算法的不变部分，并将可变的行为留给子类来实现。
(2) 各子类中公共的行为应被提取出来并集中到一个公共父类中以避免代码重复。
(3) 需要通过子类来决定父类算法中某个步骤是否执行，实现子类对父类的反向控制。
参考

Six common uses of the Template Design Pattern: Design Pattern series

6.2. command(命令模式)6.2.1. 命令行模式概述在软件开发中，我们经常需要向某些对象发送请求（调用其中的某个或某些方法），但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个，此时，我们特别希望能够以一种松耦合的方式来设计软件，使得请求发送者与请求接收者能够消除彼此之间的耦合，让对象之间的调用关系更加灵活，可以灵活地指定请求接收者以及被请求的操作。命令模式为此类问题提供了一个较为完美的解决方案。
6.2.2. 什么是命令模式？
将一个请求或操作封装成一个对象，用不同的请求对客户进行参数化，对请求排队或者记录请求日志，以及支持可撤销的操作。

命令模式是一种对象行为型模式，其别名为动作(Action)模式或事务(Transaction)模式。

命令模式可以将请求发送者和接收者完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。命令模式的本质是对命令进行封装，将发出命令的责任和执行命令的责任分割开。例如遥控器是一个调用者，不同按钮代表不同的命令，而电视是接收者。
6.2.3. UML图

6.2.4. 优点
降低系统的耦合度。由于请求者与接收者之间不存在直接引用，因此请求者与接收者之间实现完全解耦，相同的请求者可以对应不同的接收者，同样，相同的接收者也可以供不同的请求者使用，两者之间具有良好的独立性。
新的命令可以很容易地加入到系统中。由于增加新的具体命令类不会影响到其他类，因此增加新的具体命令类很容易，无须修改原有系统源代码，甚至客户类代码，满足“开闭原则”的要求。
可以比较容易地设计一个命令队列或宏命令（组合命令）。
为请求的撤销(Undo)和恢复(Redo)操作提供了一种设计和实现方案。

6.2.5. 缺点
使用命令模式可能会导致某些系统有过多的具体命令类。因为针对每一个对请求接收者的调用操作都需要设计一个具体命令类，因此在某些系统中可能需要提供大量的具体命令类，这将影响命令模式的使用。

6.2.6. 应用场景(1) 系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。请求调用者无须知道接收者的存在，也无须知道接收者是谁，接收者也无须关心何时被调用。
(2) 系统需要在不同的时间指定请求、将请求排队和执行请求。一个命令对象和请求的初始调用者可以有不同的生命期，换言之，最初的请求发出者可能已经不在了，而命令对象本身仍然是活动的，可以通过该命令对象去调用请求接收者，而无须关心请求调用者的存在性，可以通过请求日志文件等机制来具体实现。
(3) 系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作。
(4) 系统需要将一组操作组合在一起形成宏命令。
6.3. strategy(策略模式)6.3.1. 什么是策略模式？
定义一系列的算法，把它们一个个封装起来, 并且使它们可相互替换。本模式使得算法的变化可独立于使用它的客户。


将抽象部分与它的实现部分进行分离，使它们都可以独立的变化。相同的接口，不同的实现类，同一方法结果不同，实现的策略也不同。比如一个配置文件，是放在 xml 里，还是放在 json 文件里，实现的策略是不同的。
6.4. mediator(中介者模式)6.4.1. 什么是中介者模式？
用一个中介对象来封装一系列的对象交互。

中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。

6.5. observer(观察者模式)6.5.1. 什么是观察者模式？
定义对象之间的一种一对多的依赖关系，以便每当一个对象状态发生改变时，所有依赖于它的对象都得到通知并自动刷新。

观察者模式也叫发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。


在观察者模式中，发生改变的对象称为观察目标（Subject），而被通知的对象称为观察者（Observer），一个 Subject 可以对应无数个 Observer，而且这些 Observer 相互之间可以没有的任何联系，一旦 Subject 的状态发生改变 , 所有的 Observer 都得到通知。作为对这个通知的响应，每个观察者都将查询观察目标，使其状态与目标的状态同步。
 使用一个图来简单说明 



6.5.2. 为什么要用observer？
一般的设计是将一个系统分割成一系列相互协作的类，这样做有一个常见的副作用：需要维护相关对象间的一致性。但是我们不希望为了维持这种一致性而使各个类紧密耦合，这样做降低了它们的可重用性。而使用观察者模式降低了耦合度，观察目标不必要了解正在观察自己的观察者的具体类型，只需要知道基本接口（基类）即可。
可以根据需要增加和删除观察者，使得系统更易于扩展。
对象维护一个它所依赖的对象（观察者）列表，并通过调用观察者的方法通知观察者。

6.5.3. 怎样去使用observer？
当一个抽象模型有两个方面 , 其中一个方面依赖于另一方面。将这二者封装在独立的对象中，使它们可以各自独立地改变和复用。
当对一个对象的改变需要同时改变其它的对象, 但是不知道具体有多少对象要被改变。
当一个对象必须通知其它对象时，而它又不能假定其它对象是谁。换言之 , 你不希望这些对象之间是紧密耦合的。

6.5.4. UML图


Subject（观察目标）
观察目标知道它有哪些观察者，它可以有任意多个观察者观察同一个目标。
保存一个观察者列表，将观察者注册进来，以便获得通知。
支持添加或删除观察者对象，而且还能通知所有已注册的观察者。


Observe（观察者）
为那些在观察目标发生改变时需获得通知的对象定义一个更新接口。


ConcreteSubject（具体的观察目标）
将有关状态存入各个 ConcreteObserver 对象。
当它的状态发生改变时, 向它的各个观察者发出通知。


ConcreteObserver（具体的观察者）
维护一个指向 ConcreteSubject 对象的引用。
存储有关状态，这些状态应与观察目标的状态保持一致。
实现 Observer 更新接口以使自身状态与观察目标的状态保持一致。



6.5.5. 执行步骤
当 ConcreteSubject 发生任何可能导致其观察者与其本身状态不一致的改变时，它将通知它的各个观察者。

在得到一个具体观察目标的改变通知后, ConcreteObserver 对象可向观察目标对象查询信息。ConcreteObserver 使用这些信息让它的状态与观察目标对象的状态一致。



注意发出改变请求的 Observer 对象并不立即更新 ,而是将其推迟到它从目标得到一个通知之后。Notify 不总是由目标对象调用。它也可被一个观察者或其它对象调用。

6.5.6. 优点Observer 模式允许你独立的改变目标和观察者。你可以单独复用目标对象而无需同时复用其观察者, 反之亦然。它也使你可以在不改动目标和其他的观察者的前提下增加观察者。

观察目标和观察者间的抽象耦合。一个观察目标所知道的仅仅是它有一系列观察者, 每个都符合抽象 Observer 类的简单接口，观察目标并不知道任何一个观察者是属于哪一个具体的类，这样观察目标和观察者之间的耦合是抽象的、也是最小的。

因为观察目标和观察者不是紧密耦合的, 它们属于一个系统中的不同抽象层次。一个处于较低层次的观察目标对象可与一个处于较高层次的观察者通信并通知它, 这样就保持了系统层次的完整性。如果观察目标和观察者混在一块 , 那么得到的对象要么横贯两个层次 (违反了层次性), 要么必须放在这两层的某一层中(这可能会损害层次抽象)。


支持广播通信。不像通常的请求, 观察目标发送的通知不需指定它的接收者，通知被自动广播给所有已向该观察目标对象登记的有关对象。观察目标对象并不关心到底有多少对象对自己有用，它唯一的责任就是通知它的各个观察者。这给了你在任何时刻增加和删除观察者的自由，处理还是忽略一个通知取决于观察者。


6.5.7. 缺点
意外的更新。一个观察者并不知道还有其它的观察者存在, 它可能对改变观察目标的最终代价一无所知。在观察目标上一个看似无害的的操作可能会引起一系列对观察者以及依赖于这些观察者的那些对象的更新。如果依赖准则的定义或维护不当，常常会引起错误的更新, 这种错误通常很难捕捉。 
如果一个观察目标对象有很多直接和间接观察者，将所有的观察者都通知到会花费很多时间。
如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。
观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。

6.5.8. 使用时注意事项？
创建观察目标到其观察者之间的映射。一个观察目标对象跟踪它应通知的观察者的最简单的方法是显式地在观察目标中保存对它们的引用。然而, 当观察目标很多而观察者较少时, 这样存储可能代价太高。一个解决办法是用时间换空间, 用一个关联查找机制 (例如一个 hash 表)来维护观察目标到观察者的映射。这样一个没有观察者的观察目标就不产生存储开销。但另一方面, 这一方法增加了访问观察者的开销。

观察多个观察目标。在某些情况下, 一个观察者依赖于多个观察目标可能是有意义的。例如, 一个表格对象可能依赖于多个数据源。在这种情况下, 必须扩展 Update 接口以使观察者知道是哪一个观察目标送来的通知。观察目标对象可以简单地将自己作为 Update 操作的一个参数, 让观察者知道应去检查哪一个观察目标。

谁触发更新。 观察目标和它的观察者依赖于通知机制来保持一致。但到底哪一个对象调用 Notify 来触发更新? 此时有两个选择:

由观察目标对象的状态设定操作在改变观察目标对象的状态后自动调用 Notify。这种方法的优点是客户不需要记住要在观察目标对象上调用 Notify，缺点是多个连续的操作会产生多次连续的更新, 可能效率较低。
让客户负责在适当的时候调用 Notify。这样做的优点是客户可以在一系列的状态改变完成后再一次性地触发更新，避免了不必要的中间更新。缺点是给客户增加了触发更新的责任。由于客户可能会忘记调用 Notify，这种方式较易出错。


对已删除观察目标的悬挂引用。 删除一个观察目标时应注意不要在其观察者中遗留对该观察目标的悬挂引用。一种避免悬挂引用的方法是：当一个目标被删除时，让它通知它的观察者将对该观察目标的引用复位。一般来说, 不能简单地删除观察者, 因为其他的对象可能会引用它们 , 或者也可能它们还在观察其他的观察目标。

在发出通知前确保观察目标的状态自身是一致的。在发出通知前确保状态自身一致这一点很重要, 因为观察者在更新其状态的过程中需要查询观察目标的当前状态。

避免特定于观察者的更新协议：推&#x2F;拉模型。观察者模式的实现经常需要让观察目标广播关于其改变的其他一些信息。观察目标将这些信息作为 Update 操作一个参数传递出去。这些信息的量可能很小，也可能很大。

一个极端情况是，观察目标向观察者发送关于改变的详细信息, 而不管它们需要与否，我们称之为推模型(push model)。另一个极端是拉模型(pull model)： 观察目标除最小通知外什么也不送出 ,而在此之后由观察者显式地向目标询问细节。
拉模型强调的是观察目标不知道它的观察者 , 而推模型假定观察目标知道一些观察者的需要的信息。推模型可能使得观察者相对难以复用，因为观察目标对观察者的假定可能并不总是正确的。另一方面，拉模型可能效率较差, 因为观察者对象需在没有观察目标对象帮助的情况下确定什么改变了。


显式地指定感兴趣的改变。 你可以扩展目标的注册接口 ,让各观察者注册为仅对特定事件感兴趣，以提高更新的效率。当一个事件发生时, 观察目标仅通知那些已注册为对该事件感兴趣的观察者。支持这种做法一种途径是，对使用目标对象的方面（aspects）的概念。可用如下代码将观察者对象注册为对观察目标对象的某特定事件感兴趣：void Subject::Attach(Observer*, Aspect&amp; interest);此处 interests 指定感兴趣的事件。在通知的时刻, 观察目标将这方面的改变作为 Update 操作的一个参数提供给它的观察者，例如 :void Observer::Update(Subject*, Aspect&amp; interest);

封装复杂的更新语义。当观察目标和观察者间的依赖关系特别复杂时, 可能需要一个维护这些关系的对象，我们称这样的对象为更改管理器（ChangeManager）。它的目的是尽量减少观察者反映其观察目标的状态变化所需的工作量。例如, 如果一个操作涉及到对几个相互依赖的目标进行改动, 就必须保证仅在所有的观察目标都已更改完毕后，才一次性地通知它们的观察者 ,而不是每个观察目标都通知观察者。ChangeManager有三个责任:

它将一个观察目标映射到它的观察者并提供一个接口来维护这个映射。这就不需要由观察目标来维护对其观察者的引用, 反之亦然。
它定义一个特定的更新策略。
根据一个观察目标的请求, 它更新所有依赖于这个目标的观察者。



6.5.9. Relations with Other Patterns
Chain of Responsibility(责任链模式)、 Command(命令模式)、 Mediator(中介者模式)和 Observer(观察者模式)用于处理请求发送者和接收者之间的不同连接方式：

责任链按照顺序将请求动态传递给一系列的潜在接收者， 直至其中一名接收者对请求进行处理。
命令在发送者和请求者之间建立单向连接。
中介者清除了发送者和请求者之间的直接连接， 强制它们通过一个中介对象进行间接沟通。
观察者允许接收者动态地订阅或取消接收请求。


中介者和观察者之间的区别往往很难记住。 在大部分情况下， 你可以使用其中一种模式， 而有时可以同时使用。 让我们来看看如何做到这一点。

中介者的主要目标是消除一系列系统组件之间的相互依赖。 这些组件将依赖于同一个中介者对象。 观察者的目标是在对象之间建立动态的单向连接， 使得部分对象可作为其他对象的附属发挥作用。

有一种流行的中介者模式实现方式依赖于观察者。 中介者对象担当发布者的角色， 其他组件则作为订阅者， 可以订阅中介者的事件或取消订阅。 当中介者以这种方式实现时， 它可能看上去与观察者非常相似。

当你感到疑惑时， 记住可以采用其他方式来实现中介者。 例如， 你可永久性地将所有组件链接到同一个中介者对象。 这种实现方式和观察者并不相同， 但这仍是一种中介者模式。

假设有一个程序， 其所有的组件都变成了发布者， 它们之间可以相互建立动态连接。 这样程序中就没有中心化的中介者对象， 而只有一些分布式的观察者。




6.6. iterator(迭代器模式)6.6.1. 什么是迭代器模式？在软件开发中，我们经常需要使用聚合对象来存储一系列数据。聚合对象拥有两个职责：一是存储数据；二是遍历数据。从依赖性来看，前者是聚合对象的基本职责；而后者既是可变化的，又是可分离的。因此，可以将遍历数据的行为从聚合对象中分离出来，封装在一个被称之为“迭代器”的对象中，由迭代器来提供遍历聚合对象内部数据的行为，这将简化聚合对象的设计，更符合“单一职责原则”的要求。

迭代模式是提供一种方法来顺序遍历聚合对象中的各个元素，而不用暴露这个对象的内部结构。


6.6.2. UML图
### 6.6.3. 优点


通过引入迭代器可以将数据的遍历功能从聚合对象中分离出来，聚合对象只负责存储数据，而遍历数据由迭代器来完成。
在迭代器模式中，由于引入了抽象层，增加新的聚合类和迭代器类都很方便，无须修改原有代码，满足“开闭原则”的要求。

6.6.4. 缺点
由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。
抽象迭代器的设计难度较大，需要充分考虑到系统将来的扩展。

6.6.5. 应用场景(1) 访问一个聚合对象的内容而无须暴露它的内部表示。将聚合对象的访问与内部数据的存储分离，使得访问聚合对象时无须了解其内部实现细节。
(2) 需要为一个聚合对象提供多种遍历方式。
(3) 为遍历不同的聚合结构提供一个统一的接口，在该接口的实现类中为不同的聚合结构提供不同的遍历方式，而客户端可以一致性地操作该接口。
6.7. visitor(访问者模式)6.7.1. 访问者模式概述访问者模式是一种较为复杂的行为型设计模式，它包含访问者和被访问元素两个主要组成部分，这些被访问的元素通常具有不同的类型，且不同的访问者可以对它们进行不同的访问操作。例如处方单中的各种药品信息就是被访问的元素，而划价人员和药房工作人员就是访问者。访问者模式使得用户可以在不修改现有系统的情况下扩展系统的功能，为这些不同类型的元素增加新的操作。
在使用访问者模式时，被访问元素通常不是单独存在的，它们存储在一个集合中，这个集合被称为“对象结构”，访问者通过遍历对象结构实现对其中存储的元素的逐个操作。
6.7.2. 什么是访问者模式？
封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改，接受这个操作的数据结构可以保持不变。

访问者模式适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。提供一个作用于某对象结构中的各元素的操作表示，它使我们可以在不改变各元素的类的前提下定义作用于这些元素的新操作。访问者模式是一种对象行为型模式。


注意：Visitor接口必须反映出visitor能访问的对象的所有类。

6.7.3. UML图

6.7.4. 优点(1) 增加新的访问操作很方便。使用访问者模式，增加新的访问操作就意味着增加一个新的具体访问者类，实现简单，无须修改源代码，符合“开闭原则”。
(2) 将有关元素对象的访问行为集中到一个访问者对象中，而不是分散在一个个的元素类中。类的职责更加清晰，有利于对象结构中元素对象的复用，相同的对象结构可以供多个不同的访问者访问。
(3) 让用户能够在不修改现有元素类层次结构的情况下，定义作用于该层次结构的操作。
6.7.5. 缺点(1) 增加新的元素类很困难。在访问者模式中，每增加一个新的元素类都意味着要在抽象访问者角色中增加一个新的抽象操作，并在每一个具体访问者类中增加相应的具体操作，这违背了“开闭原则”的要求。
(2) 破坏封装。访问者模式要求访问者对象访问并调用每一个元素对象的操作，这意味着元素对象有时候必须暴露一些自己的内部操作和内部状态，否则无法供访问者访问。
6.7.6. 应用场景(1) 一个对象结构包含多个类型的对象，希望对这些对象实施一些依赖其具体类型的操作。在访问者中针对每一种具体的类型都提供了一个访问操作，不同类型的对象可以有不同的访问操作。
(2) 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作“污染”这些对象的类，也不希望在增加新操作时修改这些类。访问者模式使得我们可以将相关的访问操作集中起来定义在访问者类中，对象结构可以被多个不同的访问者类所使用，将对象本身与对象的访问操作分离。
(3) 对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。
6.8. chain of responsibility(责任链模式)6.8.1. 什么是责任链模式？
为解除请求的发送者和接收者之间耦合，使多个对象有机会处理来自发送者对象的请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它。


6.9. memento(备忘录模式)6.9.1. 什么是备忘录模式？
捕获对象内部的状态，以便将来可将该对象恢复到保存的状态。

它规定了Memento对象必须定义两个接口：一个是允许客户保持和复制Memento的限制接口；另一个是只有原对象才能使用的用来存储和提取Memento中状态的特权接口。

6.10. state(状态模式)6.10.1. 什么是状态模式？
允许一个对象在其内部状态改变时改变它的行为。对象看起来似乎修改了它所属的类。


6.11. interpreter(解释器模式)6.11.1. 什么是解释器模式？
指定如何对某种语言的语句进行表示和判断。


7. 参考
Wiki解释设计模式：具有权威性和系统性。
refactoring.guru: 这是一本关于设计模式及其背后原则的电子书籍。比较详细的介绍了设计模式的用法，很通俗易懂。
设计模式：可复用面向对象软件的基础：Wiki中关于GOF这本设计模式数据的描述，很有权威性。
GoF Design Patterns reference: Learning Object-Oriented Design &amp; Programming。
史上最全设计模式导学目录（完整版）：刘伟老师力作，讲的非常好，通俗易懂，而且举例的应用场景也非常恰当。
图说设计模式 利用许多的图例去描述每一种设计模式的过程，值得参考学习。
Github: 学习并理解 23 种设计模式 Github上笔者记录自己学习设计模式的笔记。
Trip-to-iOS-Design-Patterns：Github上笔者从设计模式、架构、实践三个方面梳理了 iOS 架构的设计，推荐了许多不错的学习设计模式的书籍和诸多实战的项目。
JAVA设计模式总结之23种设计模式
JAVA设计模式总结之六大设计原则

]]></content>
      <categories>
        <category>DesignPattern</category>
      </categories>
      <tags>
        <tag>designPattern</tag>
      </tags>
  </entry>
  <entry>
    <title>API-Gateway</title>
    <url>/Distributed/Distributed/API-Gateway/</url>
    <content><![CDATA[

API 网关教程什么是API网关原理怎么使用ReferenceGoogle Cloud：https://cloud.google.com/api-gateway/docs/about-api-gateway?hl=zh-cn
]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>aPI-Gateway</tag>
      </tags>
  </entry>
  <entry>
    <title>Keepalived</title>
    <url>/Distributed/Distributed/Keepalived/</url>
    <content><![CDATA[Keepalived安装命令
// 源码配置依赖加载./configure -prefix=/usr/local/keepalived// 安装命令make &amp;&amp; make install// 启动脚本变量引用文件cp /usr/local/keepalived/etc/sysconfig/keepalived  /etc/sysconfig/// 将keepalived主程序加入到环境变量cp /usr/local/keepalived/sbin/keepalived /usr/sbin/// keepalived启动脚本，放到/etc/init.d/目录下就可以使用service命令便捷调用cp /你当初解压的keepalived目录/keepalived/etc/init.d/keepalived  /etc/init.d/// 创建keepalived目录mkdir /etc/keepalived// 拷贝keepalived配置文件cp /usr/local/keepalived/etc/keepalived/keepalived.conf /etc/keepalived/keepalived.conf// 查看keepalived版本keepalived --version// 启动、关闭、重启、查看状态systemctl start|stop|restart|status keepalived// 设置开机启动systemctl enable keepalived

LVS相关术语LB (Load Balancer 负载均衡)HA (High Available 高可用)Failover (失败切换)Cluster (集群)LVS (Linux Virtual Server Linux 虚拟服务器)DS (Director Server)，指的是前端负载均衡器节点RS (Real Server)，后端真实的工作服务器VIP (Virtual IP)，虚拟的 IP 地址，向外部直接面向用户请求，作为用户请求的目标的 IP 地址DIP (Director IP)，主要用于和内部主机通讯的 IP 地址RIP (Real Server IP)，后端服务器的 IP 地址CIP (Client IP)，访问客户端的 IP 地址

命令
// 实时查看负载均衡状态watch ipvsadm -Ln --stats





References
keepalived centos 安装教程
LVS+Keepalived 高可用环境部署记录（主主和主从模式）
LVS+KeepAlived高可用部署架构

]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT6.824</title>
    <url>/Distributed/Distributed/MIT6.824/</url>
    <content><![CDATA[1. MIT 6.824 分布式课程RPC(Remote Procedure Call)
Raft(Reliable, Replicated, Redundant, And Fault-Tolerant: 可靠、可复制、可冗余、可容错) 

Inforstructure
Performance
Fault Tolerance(差错性)
Availability
Recoversbility(可恢复性)


Consistency(一致性)

41 min
1.1. LABS
Lab1: MapReduce
Lab2: Raft
Lab3: K&#x2F;V Raft
Lab4: Shared K&#x2F;V

]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>mIT6.824</tag>
      </tags>
  </entry>
  <entry>
    <title>Microservices</title>
    <url>/Distributed/Distributed/Microservices/</url>
    <content><![CDATA[

微服务
注册中心
拉取或注册服务信息。

配置中心
拉取配置信息。

服务网关


分布式
分布式锁
分布式一致性算法
分布式事务
一致性 HASH 算法
微服务
分布式 唯一 ID 生成

面对的挑战
负载均衡
熔断降级
灰度发布
故障切换
分布式跟踪

]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>microservices</tag>
      </tags>
  </entry>
  <entry>
    <title>jdk-Configure</title>
    <url>/Distributed/Distributed/jdk-Configure/</url>
    <content><![CDATA[JDK 环境配置
Linux
打开文件：vim /etc/profile，末尾添加

export JAVA_HOME=/usr/local/java/jdk1.8.0_171export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH		


环境变量生效
source /etc/profile

添加软链接
ln -s /usr/local/java/jdk1.8.0_171/bin/java /usr/bin/java

注意正确的 jdk 安装路径。


检查
java --version javac

参考：https://www.cnblogs.com/stulzq/p/9286878.html


Windows]]></content>
      <categories>
        <category>Distributed</category>
      </categories>
      <tags>
        <tag>distributed</tag>
        <tag>jdk-Configure</tag>
      </tags>
  </entry>
  <entry>
    <title>glibc</title>
    <url>/GNU/GNU/glibc/</url>
    <content><![CDATA[

1. binutilsGNU Binary Utilities 或 binutils 是一整套的编程语言工具程序，用来处理许多格式的目标文件。它提供了一系列用来创建、管理和维护二进制目标文件的工具程序，如下表。通常，binutils 与 GCC 是紧密相集成 的，没有 binutils 的话，GCC 是不能正常工作的。



命令
说明



as
汇编器


ld
链接器


gprof
性能分析工具程序


addr2line
从目标文件的虚拟地址获取文件的行号或符号


ar
可以对静态库做创建、修改和取出的操作。


c++filt
解码 C++ 的符号


gold
另一种链接器


nlmconv
可以转换成NetWare Loadable Module目标文件格式


nm
显示目标文件内的符号


objcopy
复制目标文件，过程中可以修改


objdump
显示目标文件的相关信息，亦可反汇编


ranlib
产生静态库的索引


readelf
显示ELF文件的内容


size
列出总体和 section 的大小


strings
列出任何二进制档内的可显示字符串


strip
从目标文件中移除符号


Windows 环境下。



命令
说明



windmc
产生Windows消息资源


windres
Windows 资源档编译器


dlltool
创建Windows 动态库


1.1. c++filtc++filt 是 C++ 源码编译后生成二进制文件中符号表中的符号名还原工具。
2. glibcglibc 是 GNU 发布的 libc 库，也即 C 运行库，又称 GNU C 库。glibc 是 linux 系统中最底层的 API（应用程序开发接口），几乎其它任何的运行库 都会倚赖于 glibc。glibc 除了封装 linux 操作系统所提供的系统服务外，它本身也提供了许多其它一些必要功能服务的实现，主要的如下：

string，字符串处理
signal，信号处理
dlfcn，管理共享库的动态加载
direct，文件目录操作
elf，共享库的动态加载器，即 interpreter
iconv，不同字符集的编码转换
inet，socket接口的实现
intl，国际化，也即gettext的实现
io
linuxthreads
locale，本地化
login，虚拟终端设备的管理，及系统的安全访问
malloc，动态内存的分配与管理
nis
stdlib，其它基本功能

使用一张图表示




2.1. glibc 和 libc 的区别libc 是 Linux 下的 ANSI C 的函数库；glibc 是 Linux 下的 GUN C 函数库。

ANSI C 是基本的 C 语言函数库，包含了 C 语言最基本的库函数。这个库可以根据 头文件划分为 15 个部分。其中包括：
字符类型 (&lt;ctype.h&gt;)
错误码 (&lt;errno.h&gt;)
浮点常数 (&lt;float.h&gt;)
数学常数 (&lt;math.h&gt;)
标准定义 (&lt;stddef.h&gt;)
标准 I&#x2F;O (&lt;stdio.h&gt;)
工具函数 (&lt;stdlib.h&gt;)
字符串操作 (&lt;string.h&gt;)
时间和日期 (&lt;time.h&gt;)
可变参数表 (&lt;stdarg.h&gt;)
信号 (&lt;signal.h&gt;)
非局部跳转 (&lt;setjmp.h&gt;)
本地信息 (&lt;local.h&gt;)
程序断言 (&lt;assert.h&gt;)


GNU C 函数库是一种类似于第三方插件的东西，由于 Linux 是用Ｃ语言写的，所以 Linux 的一些操作是用Ｃ语言实现的，所以 GNU 组织开发了一个Ｃ语言的库，让我们更好的利用 C 语言开发基于 Linux 操作系统的程序。

2.2. glibc version$ ldd --versionldd (GNU libc) 2.17Copyright (C) 2012 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.Written by Roland McGrath and Ulrich Drepper.

3. libstdc++libstdc++ 是 GCC 的标准 C++ 库。
64 位操作系统下查看 libstdc++.so 的版本$ strings /usr/lib64/libstdc++.so.6 | grep GLIBCXX  


https://GCC.gnu.org/onlinedocs/libstdc++/ 
https://GCC.gnu.org/onlinedocs/GCC-4.8.5/libstdc++/manual/

4. libc++libc++ 是针对 clang 编译器重写的 C++ 标准库。
net-toolsnet-tools 包括下面的软件包

arp
hostname
ifconfig
netstat
rarp 
route
iptunnel
ipmaddr

注：Debian 包管理系统中查看软件包中有哪些工具
dpkg -L net-tools | grep -E &#x27;/bin/|/sbin/&#x27; | xargs -I &#123;&#125; basename &#123;&#125;


apache2-toolsapache2-tools 包括下面的软件包

ab
checkgid
fcgistarter
htcacheclean
htdbm
htdigest
htpasswd
logresolve
rotatelogs
check_forensic
httxt2dbm
split-logfile

注：Debian 包管理系统中查看软件包中有哪些工具
dpkg -L apache2-utils | grep -E &#x27;/bin/|/sbin/&#x27; | xargs -I &#123;&#125; basename &#123;&#125;


5. References
官网： glibc 文档
glibc 官方 GUN 源码地址
The GNU C Library Release Timeline
glibc源码分析-1:构建过程
关于linux系统里glibc库的一些记述
Binutils - c++filt工具_qazw9600的博客-CSDN博客

]]></content>
      <categories>
        <category>GNU</category>
      </categories>
      <tags>
        <tag>gNU</tag>
        <tag>glibc</tag>
      </tags>
  </entry>
  <entry>
    <title>GIt-SVN</title>
    <url>/Git-SVN/Git-SVN/GIt-SVN/</url>
    <content><![CDATA[服务器使用的是 SVN，但是想本地使用 Git 的 local branch 或者离线编辑代码等，这时 Git-SVN 就是最好的。
下面是 Git-SVN 通用的操作
#Download an SVN project and its entire code history and initialize it as a git code base$ git svn clone -s [repository]#View the current version Library$ git svn info#Retrieve changes from all branches of the remote warehouse$ git svn fetch#Retrieve the changes of the current branch of the remote warehouse and merge it with the local branch$ git svn rebase #Upload the local warehouse of the current branch to the remote warehouse$ git svn dcommit#Pull new branch and submit to remote warehouse$ git svn copy [remote_branch] [new_remote_branch] -m [message]#Create local branch corresponding to remote branch$ git checkout -b [local_branch] [remote_branch]





References官方英文文档
Compared with GIT and SVN, this article is easy to understand
The Best of Git working with Subversion
The Dream of a Bi-directional Git-SVN mirror
]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>gIt-SVN</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-FAQ</title>
    <url>/Git-SVN/Git-SVN/Git-FAQ/</url>
    <content><![CDATA[

1. FAQ1.1. git 远程仓库更换名称，本地如何修改？
适用于本地和远程的代码没得任何问题，就是远程仓库改了个名称，直接在本地修改远程仓库地址即可： git remote set-url origin new_address
另外还可以先删除，然后添加地址：git remote rm origingit remote add origin new_address



1.2. Git 中文乱码
解决 Git 在 windows 下中文乱码的问题

1.3. LF or CRLFGit 多平台换行符问题 (LF or CRLF)。文本文件所使用的换行符，在不同的系统平台上是不一样的。UNIX&#x2F;Linux 使用的是 0x0A（LF），早期的 Mac OS 使用的是 0x0D（CR），后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS&#x2F;Windows 一直使用 0x0D0A（CRLF） 作为换行符。
跨平台协作开发是常有的，不统一的换行符确实对跨平台的文件交换带来了麻烦。最大的问题是，在不同平台上，换行符发生改变时，Git 会认为整个文件被修改，这就造成我们没法 diff，不能正确反映本次的修改。还好 Git 在设计时就考虑了这一点，其提供了一个 autocrlf 的配置项，用于在提交和检出时自动转换换行符，该配置有三个可选项：
# 提交时转换为 LF，检出时转换为 CRLFgit config --global core.autocrlf true# 提交时转换为 LF，检出时不转换git config --global core.autocrlf input# 提交检出均不转换git config --global core.autocrlf false

如果把 autocrlf 设置为 false 时，那另一个配置项 safecrlf 最好设置为 ture。该选项用于检查文件是否包含混合换行符，其有三个可选项：
# 拒绝提交包含混合换行符的文件git config --global core.safecrlf true# 允许提交包含混合换行符的文件git config --global core.safecrlf false# 提交包含混合换行符的文件时给出警告git config --global core.safecrlf warn

Windows 上 Git bash 客户端自带了 dos2unix 转换工具，将换行符统一转换为 Unix 下的 LF。只需执行下面的命令即可：
find . -type f -exec dos2unix &#123;&#125; +

Linux 与 Windows 换行符 转换
Linux 下使用 cat -A file 来查看文件采用的是哪种换行符。Windows 下编辑的文件放到 Linux 下打开，发现每行结尾是 ^M$，表示 CRLF；而 Linux 下的文件每行结尾是 $，表示 LF。使用 dos2unix 和 unix2dos 命令进行 Linux 与 windows 不同平台下的换行符格式转换。dos2unix [-kn] file [newfile]unix2dos [-kn] file [newfile]参数项  -n: 保留原本的旧文件，将转换后的内容输出到新文件  -k: 保留文件中原本的 mtime 时间格式

1.4. Github 开源项目搜索技巧


搜索名字
in:name xxx



搜索描述
in:description xxx


搜索 readme
in:readme xxx


按 stars
stars:&gt;2000


按 fork
fork:&gt;3000


按仓库大小
size:&gt;&#x3D;5000  (5000KB)


按更新时间
pushed:&gt;2021-02-06


按语言
language:xxx


按作者名
user:xxx



1.5. References
Github 仓库搜索高级技巧：https://github.com/search/advanced
Git 多平台换行符问题 (LF or CRLF)

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>git-FAQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-Install</title>
    <url>/Git-SVN/Git-SVN/Git-Install/</url>
    <content><![CDATA[Git 安装Git 是一个开源跨平台的版本管理软件，可以运行在 Windows、Linux&#x2F;Unix、macOS 等不同的操作系统上。下面讲解在不同平台上的安装。
WindowsLinux电脑连接了网络，安装操作步骤很简单。比如在 Ubuntu 平台下，只需要执行 sudo apt install git 就可以；但在 Centos 系统中，使用 yum 源安装的 git 版本是1.7.1，太老了，Github 需要的 Git 版本最低都不能低于1.7.2 。
所以我们一般不用上面的方法。而是下载 git 源码，编译安装，或者因环境的保密性，工作电脑没有连接外网，需要采用源码的形式安装 Git。
源码的安装一般分为三部：配置(configure)、编译(make)、安装(make install)

卸载 CentOS 系统中老的 Git。
yum remove git

首先下载 Git 相应的依赖环境，可以在一台有网的电脑中执行下面的命令，将下载好的依赖通过 ftp 工具上传到要安装的服务器中。
yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel gcc perl-ExtUtils-MakeMaker

去 Git 官网下载所需要的 Git 源码版本，在一台电脑中下载好源码，然后上传至没有网络的 Linux 服务器上。
官网： https://mirrors.edge.kernel.org/pub/software/scm/git/

解压源码，进入到 git 源码目录
[root@KF-CFT-AP2 packets]# tar -zxvf git-2.34.1.tar.gz[root@KF-CFT-AP2 packets]# cd git-2.34.1[root@KF-CFT-AP2 git-2.34.1]#

检查配置，检测当前操作系统是否有安装 Git 的依赖环境，同时配置 Git 安装路径。
[root@KF-CFT-AP2 git-2.34.1]# ./configure --prefix=/usr/local/git

 若不配置安装路径，操作系统把 git 默认安装到 /usr/local/bin/ 路径下，配置了安装路径，执行 ./configure 命令后，设置 git 的安装路径到指定的位置。 

编译
[root@KF-CFT-AP2 git-2.34.1]# make

安装。执行make install 会将 git 安装到第三步指定的 /usr/local/git 路径下
[root@KF-CFT-AP2 git-2.34.1]# make install

查看 Git 版本。进入之前指定的安装目录，查看 git 版本，能成功则表示 git 安装完成
[root@KF-CFT-AP2 git-2.34.1]# cd /usr/local/git/bin[root@KF-CFT-AP2 bin]# lsgit  git-cvsserver  gitk  git-receive-pack  git-shell  git-upload-archive  git-upload-pack[root@KF-CFT-AP2 bin]# ./git --versiongit version 2.34.1

配置环境变量。/etc/profile 文件的最后追加 git 的可执行文件的路径 export PATH=/usr/local/git/bin:$PATH，修改完成之后，执行 source /etc/profile 命令，生效配置文件。若在第五步中没有设置安装路径，则这一步骤可以省略。
vi /etc/profile

在任意的目录下 执行 git --version命令，可查看当前 git 安装的版本。
[root@KF-CFT-AP2 /]# pwd/[root@KF-CFT-AP2 /]# git --versiongit version 2.34.1

ReferencesGit 官网镜像
]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>git-Install</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-Internals</title>
    <url>/Git-SVN/Git-SVN/Git-Internals/</url>
    <content><![CDATA[

1. Git协议Git 支持四种协议传输

本地(Local)协议
Git协议
HTTP协议
SSH(Secure Shell)协议

1.1. SSH(Secure Shell)协议SSH 协议支持口令与密钥两种安全验证模式，但无论那种模式，最终都需要使用密钥来加密数据以确保安全，而 SSH 密钥通常使用的算法为 RSA 和 DSA。
命令　

SSH1：只支持RSAS算法
SSH2：支持RSA和DSA算法  
ssh -T git@github.com 查看SSHkey
sssh-keygen -t rsa 使用RSA算法创建密钥
id_rsa 密钥 和 id_rsa.pub 公钥

为什么要用SSH？

是保证本机(当前电脑)与GitHub服务器连接的有效凭证
因为GitHub需要识别出你推送的提交确实是你推送的，而不是别人冒充的，而Git支持SSH协议，所以，GitHub只要知道了你的公钥，就可以确认只有你自己才能推送。
GitHub允许你添加多个Key，只要把每台电脑的Key都添加到GitHub，就可以在每台电脑上往GitHub推送了。
Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快。

2. Git InternalsGit 不是存储每个文件与初始版本的差异，而是把数据看作是对小型文件系统的一组快照 (snapshots)。每次你提交更新，或在 Git 中保存项目状态时，它主要对当时的全部文件制作一个快照并保存这个快照的索引。 为了高效，如果文件没有修改，Git 不再重新存储该文件，而是只保留一个链接指向之前存储的文件。  
Git保证了数据的完整性。所有数据在存储前都计算校验和(SHA-1 散列)，然后以校验和来引用。Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。
2.1. Git 文件状态
已提交（committed）：表示数据已经安全的保存在本地仓库中。
已修改（modified）：表示修改了文件，但还没保存到本地仓库中。 
已暂存（staged）：表示对一个已修改文件的当前版本做了标记，存储到暂存区中。

2.2. .Git 目录组成随着 Git 版本的不同，该目录下可能还会包含其他内容。 不过对于一个全新的 git init 版本库，这将是你看到的默认结构。 

description 文件仅供 GitWeb 程序使用，我们无需关心。
config 文件包含项目特有的配置选项。 
info 目录包含一个全局性排除（global exclude）文件 ， 用以放置那些不希望被记录在 .gitignore 文件中的忽略模式（ignored patterns）。 
hooks 目录包含客户端或服务端的钩子脚本（hook scripts）。
objects 目录存储所有的数据内容。
refs 目录存储指向数据（分支、远程仓库和标签等）提交对象的指针。
index 文件保存到暂存区中的信息。
HEAD 文件指向目前被检出的分支。

2.3. Git objectsGit 是一个内容寻址文件系统，听起来很酷。但这是什么意思呢？ 这意味着，Git 的核心部分是一个简单的键值对数据库（key-value data store）。 你可以向 Git 仓库中插入任意类型的内容，它会返回一个唯一的键，通过该键可以在任意时刻再次取回该内容。
可以通过底层命令 git hash-object 来演示上述效果: 可将任意数据保存于 .git/objects 目录（即 对象数据库），并返回指向该数据对象的唯一的键。即计算对象 ID 并可选择性的从文件创建一个 blob（Compute object ID and optionally creates a blob from a file）。 

-w：选项表示该命令不要只返回键，还要将该对象写入数据库中。
--stdin：从标准输入读 object，而不是从文件中读。若不指定此选项，则须在命令尾部给出待存储文件的路径。

$ echo &quot;hello&quot; | git hash-object   --stdin -wce013625030ba8dba906f756967f9e9ca394464a$ ls -a .git/objects/./  ../  ce/  info/  pack/$ git cat-file -p ce013625030ba8dba906f756967f9e9ca394464ahello$ git cat-file -t ce013625030ba8dba906f756967f9e9ca394464ablob

此命令输出一个长度为 40 个字符的校验和。 这是一个 SHA-1 哈希值——一个将待存储的数据外加一个头部信息（header）一起做 SHA-1 校验运算而得的校验和。
$ find .git/objects/ -type f.git/objects/ce/013625030ba8dba906f756967f9e9ca394464a.git/objects/info/packs

再次查看 .git/objects 目录，那么可以在其中找到一个与新内容对应的文件。 这就是开始时 Git存储内容的方式——一个文件对应一条内容， 以该内容加上特定头部信息一起的 SHA-1 校验和为文件命名。 校验和的前 2 个字符用于命名子目录，余下的 38 个字符则用作文件名。
查看文件为 sha-1 值中内容: 
$ git cat-file -p 007105d165b1e388febc15f648156fd0ec3bb53ftree 49fea036e5503edada62e2cd82bf2d25c3d6d2beparent 2dda59cea1dc91a74101ef1fd0f30d7fc38919d9author xxx &lt;xxx@gmail.com&gt; 1612772353 +0800committer xxx &lt;xxx@gmail.com&gt; 1612772353 +0800Update C++ STL

git cat-file -t 命令，查看 Git 内部存储对象的类型，只要给定该对象的 SHA-1 值：
$ git cat-file -t 007105d165b1e388febc15f648156fd0ec3bb53fcommit

Git 仓库中有五个对象（object）：三个 blob 对象（保存着文件快照）、一个 树对象（记录着目录结构和 blob 对象 index）以及一个提交对象（包含着指向上次提交对象 （父对象）的指针和所有提交信息）。

数据对象（blob object）：也叫文件对象，保存着文件的快照。

树对象（tree object），它能解决文件名保存的问题，也允许我们将多个文件组织到一起。 Git 以一种类似于 UNIX 文件系统的方式存储内容，但作了些许简化。 所有内容均以树对象和数据对象的形式存储，其中树对象对应了 UNIX 中的目录项，数据对象则大致上对应了 inodes 或文件内容。 一个树对象包含了一条或多条树对象记录（tree entry），每条记录含有一个指向数据对象或者子树对象的 SHA-1 指针，以及相应的模式、类型、文件名信息。

git update-index ：为文件创建一个暂存区。
git write-tree ：将暂存区内容写入一个树对象。
git read-tree ：把树对象读入暂存区。
--prefix 选项，将一个已有的树对象作为子树读入暂存区&#96;。




提交对象（commit object）：包含着指向树对象（tree object）的指针和所有提交信息。每一个提交在 Git 中都通过 git 提交对象（git commit object）存储，该对象具有一个全局唯一的名称，叫做 revision hash。它的名字是由 SHA-1 算法生成，形如”998622294a6c520db718867354bf98348ae3c7e2”，我们通常会取其缩写方便使用，如”9986222”。

对象构成：commit 对象中包含了 author 和 commit message 等内容。
对象存储：commit object 保存一次变更提交内的所有变更内容，而不是增量（delta）变化的数据（很多人都理解错了这一点），所以 Git 对于每次改动存储的都是全部状态的数据。
大对象存储：因对于大文件的修改和存储，同样也是存储全部状态的数据，所以可能会影响 Git 使用时的性能(glfs 可以改进这一点）。


提交树：多个 commit 对象会组成一个提交树，它让我们可以轻松的追溯 commit 的历史，可以用来对比提交树上提交信息（commit）之间变化的差异。



 用 git add 和 git commit 命令时，Git 所做的工作实质就是将被改写的文件保存为数据对象，更新暂存区，记录树对象，最后创建一个指明了顶层树对象和父提交的提交对象。 

2.3.1. 文件模式Git 有三种文件模式。

100644，表明这是一个普通文件。
100755，表示一个可执行文件。
120000，表示一个符号链接。

2.4. Git HEADGit 中用 reference 或简写refs 这个指针来替代原始提交文件的 SHA-1 值。
HEAD reference：是一个符号引用（symbolic reference），并不完全是指向目前所在的分支, 而是指向正在操作的 commit 提交。

符号引用：表示它是一个指向其他引用的指针。 


cat .git/HEAD 或者git symbolic-ref HEAD  查看HEAD文件中的内容
git show HEAD 查看HEAD信息

当前活跃的分支在哪儿，HEAD 就指向哪儿，是git内部用来追踪当前位置的方式。 HEAD 并非只能指向分支的最顶端（时间节点距今最近的那个），它也可以指向任何一个节点。
当 HEAD 指针直接指向提交时，就会导致 detached HEAD 状态，即游离状态。在此状态下创建了新的提交，新提交的信息不属于任何分支。相对应的，现存的所有分支也不会受 detached HEAD 状态提交的影响。两种情况会导致detached HEAD，即游离状态。

git checkout --detach  HEAD 直接脱离分支头指针，指向分支头指针指向的 commit
git checkout &lt;commit id&gt;  直接切换到commit id号

其它几种HEAD文件

ORIG_HEAD 当使用一些在 Git 看来比较危险的操作去移动 HEAD 指针的时候，ORIG_HEAD 就会被创建出来，记录危险操作之前的 HEAD，方便恢复HEAD。可以看作一个修改 HEAD 之前的简单备份。
FETCH_HEAD 记录从远程仓库拉取的记录。
MERGE_HEAD 当运行 git merge 时，MERGE_HEAD 记录你正在合并到你的分支中的提交。MERGE_HEAD在合并的时候会出现，合并结束时就删除了这个文件。
CHERRY_PICK_HEAD 记录您在运行 git cherry-pick 时要合并的提交。这个文件只在 cherry-pick 期间存在。

3. References
Git for Computer Scientists: 简短的解释Git的数据模型，有很多的图来阐述。
How to explain git in simple words?: 解释了Git底层实现的一些过程。
Git from the Bottom Up: 不仅解释了Git的数据模型，还解释了其实现的细节。
Git PAT 使用: Github 支持 personal access token 的用法。
A successful Git branching model： Vincent Driessen 介绍 git 工作流。

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>git-Internals</tag>
      </tags>
  </entry>
  <entry>
    <title>Git-commit-convention</title>
    <url>/Git-SVN/Git-SVN/Git-commit-convention/</url>
    <content><![CDATA[
1. Git Commit 规范约定1.1. 背景Git 每次提交代码都需要写 commit message，否则就不允许提交。一般来说，commit message 应该清晰明了，说明本次提交的目的，具体做了什么操作，但是在日常开发中，大家的 commit message 千奇百怪，中英文混合使用、fix bug 等各种笼统的 message 司空见怪，这就导致后续代码维护成本特别大，有时自己都不知道自己的 fix bug 修改的是什么问题。基于以上这些问题，我们希望通过某种方式来监控用户的 git commit message，让规范更好的服务于质量，提高大家的研发效率。
1.2. Commit message 结构提交信息应该遵循下面的结构：
&lt;type&gt;[optional scope]: &lt;description&gt;[optional body][optional footer(s)]

type: 是必选项，表示类型。用于说明 git commit 的类别，只允许使用下面的标识。

feat：新功能（a new feature）。
fix&#x2F;to：修复 bug，可以是 QA 发现的 BUG，也可以是研发自己发现的 BUG。
fix：产生 diff 并自动修复此问题。适合于一次提交直接修复问题。
to：只产生 diff 不自动修复此问题。适合于多次提交，最终修复问题提交时使用 fix。


style：代码格式类的变更，不影响代码运行的变动。比如用格式化代码或删除空行等。
refactor：既不是新增功能，也不是修改 bug 的代码变动。其它类代码的变动，例如简化代码、重命名变量、删除冗余代码等。
chore：构建流程、依赖管理或辅助工具的变动。
perf：代码的改变是为了提高新能、体验等。
test：新增测试用例或更新现有测试用例。
ci: 持续集成或部署相关的变动，例如修改 Jenkins、GitLab CI 等 CI 配置文件或更新系统单元文件。
docs：只有文档（documentation）的改变。包括修改用户文档、开发文档。
revert：回滚到上一个版本。
merge：代码合并。
sync：同步主线或分支的 Bug。

description: 必选项，提交信息的简短描述，不超过 50 个字符。写描述应遵循下面的规则：

建议使用中文，感觉中国人用中文描述问题能更清楚一些。
结尾不加句号或其他标点符号。

optional: 是可选项，提交时可以设置也可以不设置，由组内人员或开发者自行约定。

scope: 用于说明 commit 发生变动的范围。比如数据层、控制层、视图层等等，视项目不同而不同。
提交信息中带有 scope 的可选项时，后面的花括号应采用英文。


body:
footer: 脚本。

根据以上 git commit message 规范，编写的格式如下：
fix(DAO): 用户查询缺少username属性 feat(Controller): 用户查询接口开发

1.3. Commit 约定遵循准则
每个提交都必须使用类型字段前缀，它由一个名词构成，诸如 feat 或 fix ， 其后接可选的范围字段，可选的 !范围，以及必要的冒号（英文半角）和空格。
当一个提交为应用或类库实现了新功能时，必须使用 feat 类型。
当一个提交为应用修复了 bug 时，必须使用 fix 类型。
范围字段可以跟随在类型字段后面。范围必须是一个描述某部分代码的名词，并用圆括号包围，例如： fix(parser): xxxx
描述字段必须直接跟在 &lt;类型&gt;(范围) 前缀的冒号和空格之后。 描述指的是对代码变更的简短总结，例如： fix: array parsing issue when multiple spaces were contained in string
在简短描述之后，可以编写较长的提交正文，为代码变更提供额外的上下文信息。正文必须起始于描述字段结束的一个空行后。
提交的正文内容自由编写，并可以使用空行分隔不同段落。
在正文结束的一个空行之后，可以编写一行或多行脚注。每行脚注都必须包含 一个令牌（token），后面紧跟 :&lt;space&gt; 或 &lt;space&gt;# 作为分隔符，后面再紧跟令牌的值（受 git trailer convention 启发）。
脚注的令牌必须使用 - 作为连字符，比如 Acked-by (这样有助于区分脚注和多行正文)。有一种例外情况就是 BREAKING CHANGE，它可以被认为是一个令牌。
脚注的值可以包含空格和换行，值的解析过程必须直到下一个脚注的令牌&#x2F;分隔符出现为止。
破坏性变更必须在提交信息中标记出来，要么在 &lt;类型&gt;(范围) 前缀中标记，要么作为脚注的一项。
包含在脚注中时，破坏性变更必须包含大写的文本 BREAKING CHANGE，后面紧跟着冒号、空格，然后是描述，例如：BREAKING CHANGE: environment variables now take precedence over config files 
包含在 &lt;类型&gt;(范围) 前缀时，破坏性变更必须通过把 ! 直接放在 : 前面标记出来。 如果使用了 !，那么脚注中可以不写 BREAKING CHANGE:， 同时提交信息的描述中应该用来描述破坏性变更。
在提交说明中，可以使用 feat 和 fix 之外的类型，比如：docs: updated ref docs
工具的实现必须不区分大小写地解析构成约定式提交的信息单元，只有 BREAKING CHANGE 必须是大写的。
BREAKING-CHANGE 作为脚注的令牌时必须是 BREAKING CHANGE 的同义词。

2. References
Github Angular 项目 commit 约定规范
Conventional Commits
阿里巴巴：约束 git commit 提交规范
How to Write a Git Commit Message
Git 修改已提交的commit注释
Commit message 和 Change log 编写指南
git rebase vs git merge详解

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>git-commit-convention</tag>
      </tags>
  </entry>
  <entry>
    <title>Git</title>
    <url>/Git-SVN/Git-SVN/Git/</url>
    <content><![CDATA[

1. Git Command1.1. Git init
git init 初始化一个 Git 仓库

1.2. Git add
git add &lt;file&gt; 添加文件到暂存区
git add -p(patch) 依次存储每一个文件的改动，包括文件中做的哪些些改动

1.3. Git log
git log 查看历史记录。按提交时间列出所有的更新，最近的更新排在最上面。显示的有 HASH 散列码、提交日期、提交的注释等。
HEAD 表示当前版本，下标从零开始。
HEAD^ 上一个版本就是，HEAD^^ 上上一个版本就是, 当然往上 100 个版本写 100 个 ^ 比较容易数不过来，所以写成 HEAD~100


git log -g: 按照标准日志的格式输出引用日志 reflog
git log -p 打印提交更新的所有内容，包括文件的内容
git log -p -2 显示最近两次提交的内容
git log --stat 显示每次提交的简略统计信息，包括多少个文件改变、HASH 码、日期、提交的注释等信息。
git log --pretty=keyword 指定使用不同于默认格式的方式展示提交历史。keyword 有以下内建的子选项
online：将每个提交放在一行显示，查看的提交数很大时非常有用。
format：定制自己要显示的记录格式。


git log --graph：显示 ASCII 图形表示的分支合并历史，常与 --pretty=format 结合使用。例如：git log --pretty=format:&quot;%h %s&quot; --graph
git log --all --graph --decorate 用 ASCII 图像化显示所有提交的历史记录、各个分支的指向以及项目的分支分岔情况。
git log --since=2.weeks 列出所有最近两周内的提交。since 与 until 按照时间对提交的内容做筛选，后面可以直接跟特定的时间。--since=2020-01-07
git log -S 筛选内容   列出那些添加或移除了某些字符串的提交。
git fsck --full: 显示出所有没有被其他对象指向的对象。git fsck 检查所有数据库的完整性。
gir log --name-status 显示每次修改的文件列表及修改状态：新增、修改、删除。
git log --name-only 只显示每次修改的文件列表



git whatchanged  显示每次修改的文件列表
git whatchanged --stat 显示每次修改的文件列表及统计信息



git reflog expire --expire=now --all 清除所有 reflog 的引用
git show 显示最后一次文件改变的具体内容

1.4. Git tagGit tag 有两种类型。

轻量标签（lightweight）：很像一个不会改变的分支——它只是一个特定提交的引用。
本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。
git tag 标签名  创建标签


附注标签（annotated）：存储在 Git 数据库中的一个完整对象
git tag -a v1.0 -m &quot;first commit&quot; 创建标签;-m 选项指定了一条将会存储在标签中的信息。
git show 标签名  看到标签信息与对应的提交信息





git tag -a 标签号 HASH 码  后期给指定文件打标签

git push origin(仓库别名) 标签名  将标签共享到远程仓库上

git push origin --tags 将所有不在远程仓库服务器上的标签全部推送到上面。

git tag -d &lt;tagname&gt; 删除掉本地仓库上的标签

git push &lt;remote&gt; :refs/tags/&lt;tagname&gt;  更新并删除远程仓库标签

git tag 查看历史 tag 记录

git checkout v1.0 切换到某个 tag，查看某个标签所指向的文件版本。

注意： 会导致仓库处于分离头指针 (detacthed HEAD) 状态. 在 “分离头指针” 状态下，如果你做了某些更改然后提交它们，标签不会发生变化，但你的新提交将不属于任何分支，并且将无法访问，除非确切的提交哈希。



1.5. Git alias
git config --global alias.unstage &#39;reset HEAD --&#39;  给取消暂存取一个别名

1.6. Git checkout切换或者创建新分支

git checkout  &lt;new_branch_name&gt;   切换到 new_branch_name 分支下
git branch Develop  新建 Develop 分支
git checkout -b &lt;new_branch_name&gt;   创建 new_branch_new 分支，并切换到当前分支
Git 2.23 版本之后，使用 git switch 替代原先的 git chechout。切换到已存在的分支: git switch testing-branch; 创建一个新分支并切换到当前分支: git switch -c new-branch; 返回到你 checkout 之前的分支: git switch -


git checkout -b &lt;new_branch_name&gt; origin/feature 从远程已存在的 feature 分支上拉取代码到本地新建的分支 new_branch_name，同时切换到新创建的分支上。

用暂存区或者指定 commit 提交内容覆盖工作区内容

用暂存区内容覆盖工作区内容
git checkout readme.txt 将暂存区中的 readme.txt 文件还原到工作区，如果要还原多个文件，使用 空格 分隔
还原所有文件 git checkout .
特别说明：如果 checkout 后面是文件名称，以下写法更为稳妥：git checkout -- readme.txt
文件名称前面有两个 横杠，并且中间采用 空格 分隔（否则报错）。此种方式可以防止 Git 出现误判，加入暂存区有一个文件名为 ant（没有后缀名），恰好当前项目也有有个名为 ant 的分支，这个时候 Git 会优先将 ant 当做分支处理，于是就有可能导致错误




指定 commit 提交的内容覆盖工作区
git checkout Develop -- readme.txt  将对应分支中的文件 (readme.txt) 还原到当前分支 (Develop) 的工作区



1.7. Git commit参数项  pick 使用这个参数，commit 信息什么都不用做。  reword 修改 commit 信息。  --edit  修改 commit 提交的内容。但是使用这个命令的时候，rebase 操作会停在 commit 提交处，等待修改完毕，使用 git add . 和  git commit --amend 修改提交，git rebase --continue 继续 rebase 进程。  --squash 将当前需要改变的 commit 信息与之前 commit 提交的信息进行合并，把融合的信息保存到融合后的提交中。  --fixup 放弃融合后提交的提交信息。  exec 在新的一行使用 shell 来运行 commit 信息。  drop 删除 commit 提交信息。

修改最近一次的注释

git commit --amend 修改最后一次提交的注释
git rebase --continue 执行修改的 commit
push 到远程 GitHub，若有冲突，需要将远程 repository 的代码 pull 到本地，然后再 push 到远程 repository。

修改历史提交的注释

git log -n 4 查看最近 4 次操作的日志
git rabase -i HEAD~n 修改倒数第 n 次的 commit
将 pick 修改为 edit
git commit --amend 修改 commit 的内容
git rebase --continue 执行修改的 commit
push 到远程 GitHub，若有冲突，需要将远程 repository 的代码 pull 到本地，然后再 push 到远程 repository。

Git commit 提交规范：请参考 Git-commit-convertion.md 文档。
1.8. Git diff执行 Git diff 命令后，显示的结果分析：

执行命令之后，绿色部分代表增加的内容，红色部分代表删除的内容，
—代表源文件，即修改前的文件；+++代表目标文件，即修改后的文件;
小技巧：比较两个分支中的文件有哪些差异时，先将原来的文件放在前面，改动后的文件放在后面。这样放的好处是：对显示的结果好分析，更符合常人的逻辑思考结果。比如，改动后的文件相对未改动之前的文件，有添加的行，显示结果就为 ++++，若有删除除的行，显示的结果就显示 ———，非常的直观。


git diff 比较工作区和暂存区之间的差异
git diff HEAD 比较工作区与最新本地仓库之间的差异
git diff --cached 比较暂存区与最新本地仓库的差异
git diff --stat &lt;local branch&gt; &lt;remote branch&gt; 比较本地分支与远程指定分支之间的差异。
统计有哪些文件被改动，有多少文件被改动，使用 --stat 参数。例如，比较本地分支 feat_grpc 与远程分支 dev 之间的差异git diff --stat feat_grpc  remotes/origin/dev
查看指定路径下文件的详细差别。// 注意：路径名要在仓库的根路径之下git diff feat_grpc  remotes/origin/dev /src/comm.cpp
查看本地仓库中分支为 master 的文件与 Github 远程仓库中别名为 origin 下 master 分支文件的差异。git diff master origin/master



1.9. Git stash
Git 提供了一个 stash 功能，把当前工作现场” 储藏” 起来，等以后恢复现场后继续工作：git stash，去解决 Bug 问题。
git stash list ：查看所有已存储的工作现场 。
Git 把 stash 内容存在某个地方了，需要恢复存储的内容，有两个办法
用 git stash apply 恢复，但是恢复后，stash 内容并不删除，你需要用 git stash drop 来删除
用 git stash pop，恢复的同时把 stash 内容也删了。



1.10. Git blame在 Git 中，blame 是一个命令，用于查看文件的每一行是由哪个提交引入的。它可以帮助你确定代码中每个行的作者和最后修改的时间。
git blame 的基本用法如下：
git blame &lt;file&gt;

这会显示文件的每一行，以及每一行最后一次修改的提交信息，包括提交的哈希值、作者的姓名、修改的日期和时间。
你也可以通过指定一个特定的提交范围来限制 blame 的输出。以下是几个示例：

指定一个文件的某个版本：git blame &lt;commit&gt; -- &lt;file&gt;
这会显示指定提交中文件的每一行。
指定某个提交之前的所有提交：git blame &lt;commit&gt;^ -- &lt;file&gt;
这会显示指定提交之前的所有提交中文件的每一行。
指定一个提交范围：git blame &lt;start-commit&gt;..&lt;end-commit&gt; -- &lt;file&gt;
这会显示指定提交范围内文件的每一行。

git blame 还支持其他一些选项，例如 -L 选项用于指定只显示文件中的特定行号范围，以及 -w 选项用于忽略空白字符的变化。这些只是 git blame 的基本用法和一些常见选项，还有其他更高级的用法，你可以查看 Git 的官方文档或运行 git blame --help 来获取更多详细信息。
1.11. Git bisect找到某个 bug 是哪次 commit 的。
1.12. Git rebaseRebase 官方翻译为 “变基”，我觉得翻译为 重新改变基准 更为合适。git rebase 和 git merge 都可以用于分支的合并，但使用 git rebase 合并的分支，提交（commit）信息是线性的，因为它会清除当前分支提交（commit）的版本历史信息，只选择保留最后一次的提交信息；而 merge 是把不同分支的最终结果合并在一起。
总结下，git rebase 有两个功能

压缩提交的记录。
分支合并时，让合并的分支更简洁，只选择保留最后一次的提交信息，线性显示提交的记录，观察起来更优美。

1.13. Git revert1.14. Git Resetgit reset 命令是 Git 提供的后悔药之一，它可以帮我们把内容恢复到指定的 commit 提交版本。
reset 翻译成中文有 重置 的意思，恰如起名，git reset 命令可以重置当前分支所指向提交的位置。使用 git reset 命令后 commit  提交信息依然存在，只是当前分支所指向的 commit 提交进行了重置，分支所指向的新 commit 提交之后的提交就像消失了一样（git log 无法查询到）。
git reset 后面紧跟一个指定的标识项。标识可以是 sha-1 值或者 HEAD、HEAD^ 或者分支名称等形式。

标识为 commit 提交信息的 hash 值。比如： git reset 5609309 --hard，也可以
标识为分支名称。比如：git reset master^ --hard。
标识为 HEAD。例如：git reset HEAD^ --hard
标识为 ^。^ 表示当前分支所指向提交的前一个提交，^^ 表示当前分支所指向提交的前一个分支的前一个分支，以此类推；^^ 过多自然不太方便，可以使用 HEAD~2 表示

mixed、soft 和 hard 参数项的区别

--mixed：默认值，当重置分支所指向 commit 提交位置时，暂存区中的内容会被新指向的 commit 提交内容所替换，工作区内容不变，即它回退到某个版本，只保留源码，回退 commit 和 index 信息。
--soft：暂存区和工作区的内容都保持原样，不会被替换，只回退了 commit 的信息。
--hard：暂存区和工作区的内容都会被新指向的 commit 提交内容所替换，彻底回退到某个版本，本地的源码也会变为上一个版本的内容；git reset --hard 只影响被跟踪的文件，如果工作区有新增的文件，并不会被影响。

 注意 

假如 commit 已经被 push 到远程仓库上，那么其他开发人员可能会基于对应的 commit 提交进行开发产生新的 commit，如果此时进行 reset 操作，会造成其他开发人员的提交历史丢失，这可能会产生严重后果。

1.15. Remove or Restore文件的删除与重新存储文件。
1.15.1. remove
rm 删除命令，指令前面不加 git
删除本地目录文件，不会删除提交到暂存区的文件。例如：rm filename

git rm 是 git 中封装的 rm 命令。

git rm filename：，删除已经提交到本地版本库中的内容，同时删除暂存区中的内容。
git rm --cache filename：只删除暂存区中的 filename 文件。
特别说明：处于未跟踪状态 (untracked) 只是没有存在于暂存区。





删除暂存区步骤
git rm filenamegit commit -m &quot;comment content&quot;git push origin master

删除暂存区并更新远程仓库
git rm --cached filenamegit commit -m &quot;comment content&quot;git push origin master --force


1.15.2. restore恢复工作区中被删除的文件

rm 指令只是将工作区中的文件删除，已提交到暂存区中的文件依然存在。此时想要恢复被 rm 指令删除的文件，只要将暂存区内容恢复到工作区即可。
git checkout filename ：恢复误删除的单个文件
恢复误删除的多个个文件
git ls-files -d：查看误删除的有哪些文件
git ls-files -d | xargs -i git checkout &#123;&#125; 恢复多个文件



恢复暂存区中误删除的文件

git rm 命令会删除已经提交到本地版本库中的内容，同时暂存区中的内容也会被删除。若要想恢复删除的内容，那么只能从 commit 提交记录中恢复。使用 git checkout HEAD readme.txt 命令， 将最后一次 commit 提交的 readme.txt 文件从本地仓库中恢复。

 任何情况都可以恢复吗? 

当然不是，如果你把 .gti 目录删除了，那肯定是无法再恢复。实质上，之所以能将删除的文件恢复，因为在 .git 目录中有备份，Git 会将 暂存区 或者 历史提交 中内容来恢复。

1.16. other command
git gc: 清理不必要的文件并优化本地存储库（Cleanup unnecessary files and optimize the local repository）。
git count-objects -v: 计算未打包的对象数量及其磁盘消耗（Count unpacked number of objects and their disk consumption）。
git update: windows 下更新 git，使用命令 git update-git-for-windows

2. Git Branch2.1. Local repo branch本地仓库分支常用命令

git branch 只查看本地仓库分支。
git branch -r 只查看远程仓库的所有分支。
git branch -a 查看远程和本地的已有的所有分支。
git branch -v 查看每个分支最后一次提交的内容。
git reflog show --date=iso master  查看指定分支的历次更改记录。
git branch --merge 查看哪些分支已经合并到当前分支。
git branch --no-merged 查看所有包含未合并工作的分支。
git branch branch_name 创建一个分支，且不会自动切换到新分支中去。
git merge 合并分支：在分支 a 下写代码，与分支 master 上的代码合并
第一步，切换到分支 master 下 git chechout master
第二步，与分支 a 合并 git merge a


git branch -d a 删除指定分支 a 。删除分支时，不要在当前分支删除当前分支，一定要切换的到另一个分支去删除。
git branch -D a 强制把未合并的分支删除
git branch | grep &quot;feature-&quot; | xargs git branch -d  批量删除多个本地的分支
git log --oneline --decorate --graph --all 查看提交历史、各个分支的指向以及项目的分支分叉情况
git stash save 切换分支之前保存要修改的文件，不想提交之前的工作
git stash list 查看存储在栈上的文件
git stash apply 将最近存储的文件重新使用
git stash apply stash_name 使用之前某次存储的文件

2.2. Remote repo branch远程仓库分支常用命令

git branch --remote 查看远程仓库分支

git push &lt;remote&gt; --delete &lt;branch&gt; 命令行终端删除远程仓库分支，remote 可为远程仓库地址或者是仓库的别名，branch 为待删除分支的名字。
git push origin --delete feature_0426

常用分支命名：
developtopicproposedhotfix(紧急分支)iss534experiment

重命名远程分支

本地分支改名： git branch -m 旧分支名 新分支名 
删除远程分支：git push --delete origin 旧分支名 
将新分支名推上去： git push origin 新分支名 
将新本地分支和远程相连： git branch --set-upsteam-to origin / 新分支名 

2.3. Branches PrincipleGit 中的分支只是指向提交对象之一的轻量级可移动指针。
Git 是怎么创建新分支的呢？ 很简单，它只是为你创建了一个可以移动的新的指针。 比如，创建一个 testing 分支， 你需要使用 git branch 命令：
git branch testing




Git 分支的本质是一个文件：包含所指对象的校验和（长度为 40 的 SHA-1 character），所以它的创建和销毁都非常高效。 创建一个新分支就相当于往一个文件中写入 41 个 bytes (40 characters 和 1 newline)。

Git 又是怎么知道当前在哪一个分支上呢？ 也很简单，它有一个名为 HEAD 的特殊指针。 请注意它和许多其它版本控制系统（如 Subversion 或 CVS）里的 HEAD 概念完全不同。 在 Git 中，它是一个指针，指向当前所在的本地分支（译注：将 HEAD 想象为当前分支的别名）。 在本例中，你仍然在 master 分支上。 因为 git branch 命令仅仅 创建 一个新分支，并不会自动切换到新分支中去。
HEAD 指针指向的当前所在分支，HEAD 分支随着提交操作自动向前移动。
每次提交，Git 都把它们串成一条时间线，这条时间线就是一个分支。HEAD 不是指向提交，而是 指向 master，master 才是 指向 提交的，所以 HEAD 指向当前所在分支。
一开始的时候，master 分支是一条线，Git 用 master 指向最新的提交，再用 HEAD指向master，就能确定当前分支，以及当前分支的提交点：
每次提交，master 分支都会向前移动一步，这样，随着你不断提交，master 分支的线也越来越长。当创建一个新的分支时，Git 就新建了一个指针叫 testing，指向与 master 相同的提交，当你 checkout 到 testing 分支下时，再把 HEAD 指针指向 testing，就表示当前分支在 testing 上:
Git 创建一个分支很快，因为除了增加一个 testing 指针，改变 HEAD 的指向，工作区的文件都没有任何变化！不过，从现在开始，对工作区的修改和提交就是针对 testing 分支了，比如新提交一次后，testing 指针往前移动一步，而 master 指针不变：
此时 Git 工作区中的 分支历史：
假如我们在 testing 上的工作完成了，就可以把 testing 合并到 master 上。Git 怎么合并呢？最简单的方法，就是直接把 master 指向 testing 的当前提交，就完成了合并：
合并完分支后，甚至可以删除 testing 分支。删除 testing 分支就是把 testing 指针给删掉，删掉后，我们就剩下了一条 master 分支：
2.4. Branches conflict为什么会产冲突？

两个分支中修改了相同的文件。注意： 两个分支中分别修改了不同文件中的部分，不会产生冲突，可以直接将这两部分合并。
两个分支中修改了同一个文件的名称

采用 Git rebase 与 git merge 进行解决
2.4.1. Git rebase
合并多次提交纪录例如：合并前 4 次提交的记录 git rebase -i HEAD~4，合并的 commit 不能是已经 push 到远程仓库的记录。

本质是先取消自己的提交，临时保存，然后把当前分支更新到最新的 origin 分支，最后应用自己的提交。



 注意: 已经推送到 github 远程仓库的文件（多人开发的重要分支）不要使用 git rebase，否则远程仓库的分支记录会被修改，别人就不能正常的提交了。
2.4.2. Git merge默认情况下，Git 执行 “快进式合并”（fast-farward merge），会直接将 Master 分支指向 Develop 分支。使用 --no-ff  参数，用普通模式合并，在 master 主分支上生成一个新的节点。可以在分支历史上看哪些曾经做过哪些的合并；而 fast forward 合并，则没有合并操作的记录，会丢掉分支信息。
git merge --no-ff -m &quot;merge with no-ff&quot; dev

两个分支合并时，将一个分支的变更集成到另一个分支上。其中分支合并的语法如下
git merge 要合并进来的分支名 --strategy = 合并策略git merge 要合并进来的分支名 --s = 合并策略

合并策略可以省略。Git  merge 有很多的合并策略。其中常见的是 Fast-forward、Recursive 、Ours、Theirs、Octopus。 Git 默认会帮你自动挑选合适的合并策略，如果你需要强制指定，使用 git merge -s &lt;策略名字&gt; 即可。
fast-forwardrecursive：默认的合并策略，如果你不指定策略参数，那么将使用这个合并策略。这将直接使用递归三路合并算法进行合并。oursoctopussubtreeresolve

分支合并步骤

从远程仓库拉取数据 git fetch origin master 。有时需要将远程仓库分支的数据拉取到本地临时分支，可执行 git fetch origin master:temp
查看远程仓库的版本 git remote -v
比较本地仓库与远程仓库的区别 git diff master origin/master
手动解决冲突，提交（commit）信息。
合并冲突，将远程仓库与本地仓库合并 git merge origin master


Git 合并分支 很快！就改改指针，工作区内容不变。

3. Git Area

Git 与 GitHub 使用，有四个区，需要理解。

Workspace：名为工作区，也可以称为 Working Directory (工作目录)，是你电脑存放代码的地方。
Index：名为暂存区，是 .git 目录下的一个 index 文件，它是 指向 文件的一个索引。
local repository：名为本地版本库，是 Git 用来保存本地项目的元数据和对象数据库的地方。
Remote repository：名为远程仓库，是远程服务器存放代码的地方。

3.1. WorkspaceWorkspace (工作区) 也可以称为 Working Directory (工作目录)，是你电脑存放代码的地方。



工作区目录下的每一个文件只有两种状态：已跟踪（tracked：添加到暂存区）或未跟踪（untracked：没有添加都暂存区）。
3.2. Index在工作区路径下打开终端执行 git init 指令后，工作区内生成一个 .git 的文件，默认情况下，该文件的属性是隐藏的，不可见。暂存区 就是 .git 目录下有一个 index 文件，这个 index 中文翻译为 暂存区，它是 指向 文件的一个索引。而真正的文件是存储在 .git/objects 目录中。
当删除 暂存区 内容时，其实就是删除 index 文件中的内容，但 .git/objects 目录中的内容不会被删除。




Git 清空暂存区


暂存区实质是 .git 目录下的 index 文件，只要将此文件删除，那么暂存区就被清空。可用这条命令来将暂存区中的内容清空 rm .git /index 。
暂存区存在的必要性

有些朋友感觉暂存区多余，其实并非如此，通过这个过渡性区域可以使提交更加条理，避免无用琐碎提交。
暂存区就如同一个临时性仓库，可以将来自工作区的新文件或者修改文件暂时存放起来，然后统一提交到分支中的版本库中。




git ls-files 查看暂存区里所有的内容，后面可加下面任意的选项参数。git ls-files 命令的默认参数是 --cached(-c)，默认情况下默认参数没有显示。- --cached(-c) 显示暂存区中的文件- --deleted(-d) 显示删除的文件- --modified(-m) 显示修改过的文件- --other(-o) 显示没有被 git 跟踪的文件- --stage(-s) 显示 mode 以及文件对应的 Blob 对象，可以获取暂存区中对应文件里面的内容。

3.3. Local repositoryGit 本地版本库是 Git 用来保存项目的元数据和对象数据库的地方。从其它计算机克隆仓库时，拷贝的就是这里的数据。
工作目录下有一个默认隐藏的目录 .git，它并不属于工作目录，而是 Git 的本地版本库（Repository）。而版本库中内容很多，并且都很重要，有两个是我们实际操作中经常要遇到的，那就是暂存区（index）和分支（branch）。
将文件最终提交到版本库基本流程如下：

git add    将工作区未跟踪和修改文件提交到暂存区。
git commit 将暂存区内容提交到版本库中，并执行更新 HEAD 指向的指针，这样就完成了引用与提交、提交与改动快照的——对应了。



Git 清空版本库

rm -rf .git 删除当前目录下的版本库（.git 目录）
git init    重新初始化一个全新的版本库

3.4. Remote repository3.4.1. Git remote
git remote -v 显示远程仓库的别名和对应的 URL。

git remote show remote_name 查看某个远程仓库。

git remote rename old_name new_name 重命名原仓库名字。

git remote rm remote_name 移除一个远程仓库。

git remote add &lt;alias_name&gt; &lt;url&gt; 本地仓库与仓库地址为 URL，别名为 alias_name 的远程仓库进行关联。

有些分支在远程其实早就被删除了，但是在你本地依然可以看见这些被删除的分支，可用下面的命令删除远程服务器上不再存在的远程分支引用。
#  删除本地仓库中已经不存在的远程分支引用git remote prune origin# 更新远程分支信息并清理不存在的分支引用，保持本地仓库和远程仓库的同步。git remote update --prune

3.4.2. Git pull &amp;&amp; Git fetch
git pull: 将远程仓库上当前分支的数据抓取到本地仓库，并自动合并远程分支与本地仓库的分支，git pull 相当于 git fetch 和 git merge 两步操作的叠加。
git fetch: 将远程仓库上当前分支的数据抓取到本地仓库，不修改本地仓库中的内容，需要自己手动进行合并。
git fetch &lt;远程仓库名&gt; &lt; 分支名 &gt; : &lt; 目标分支 &gt;
远程仓库名可以是仓库的别名，也可以直接是仓库的 URL 地址。
git fetch origin master : temp 拉取远程 origin 仓库中 master 分支的数据到本地新建的 temp 分支。


git push &lt;远程主机名&gt; &lt; 本地分支名 &gt; : &lt; 远程分支名 &gt;
git push origin main : main 将本地 main 分支中的数据推送到远程 origin 仓库的 main 分支上。若后面不指定 : &lt;远程分支名&gt;，git 会默认将当前本地的分支提交到远程仓库的默认分支中。



3.4.3. Remote and local repository远程仓库与本地的关联。

git remote add origin   git@github.com:michaelliao/learngit.git 将本地仓库添加到远程 Git 仓库，默认别名为 origin
git push origin master 当前本地仓库内容推送到别名为 origin，分支为 master 的远程仓库。
git clone &lt;URL&gt; &lt;folder_name&gt;
本地位置克隆一个远程仓库地址为 URL 的仓库，并将其写到 folder_name 文件中。这个 &lt;folder_name&gt; 是选择项，若不指定文件名，则克隆后的仓库名默认与远程仓库的名字一样。
git clone https://github.com/xxxxx/Guide.git 远程 Guide 仓库克隆到一个同名的本地仓库
git clone https://github.com/xxxxx/Guide.git temp 远程 Guide 仓库中内容克隆到名称为 temp 的本地仓库。


git push -u origin master 将当前分支的内容推送给远程仓库 origin 的 master 分支
参数 -u，推送的同时将 origin 仓库的 master 分支设置为本地仓库当前分支的 upstream（上游）。
git 不但会把本地的 master 分支内容推送的远程新的 master 分支，还会把本地的 master 分支和远程的 master 分支关联起来，在以后的推送或者拉取时就可以简化命令。



4. Git Config
配置项目或某个仓库的用户名和密码，该配置位于 .git 路径下的 config 文件中。
git config --local user.name xxxxxgit config --local user.email xxxx@gmail.com

配置系统用户级别的用户名和密码，该配置位于用户家目录下的 .gitconfig 文件中。
git config --global user.name xxxxxgit config --global user.email xxxx@gmail.com

配置当前操作系统下，所有用户使用 git 的用户名和密码，一般不建议这么做，不太安全。
git config --system user.name xxxxxgit config --system user.email xxxx@gmail.com

设置了一个本地的凭证助手（credential helper）来处理凭证信息，以便在使用 Git 进行远程操作时，不需要每次都输入用户名和密码。
git config --local credential.helper store

当你运行这个命令时，Git 会将凭证信息存储在本地存储中，通常是在你的用户目录下的一个隐藏文件中（.git-credentials）。存储的凭证信息包括远程仓库的 URL、用户名和密码。
设置了 credential.helper 为 store 后，Git 会将凭证信息明文存储在本地文件中。这样，在后续的操作中，Git 将会自动从本地文件中读取凭证信息，而无需再次输入用户名和密码。这在简化日常的 Git 操作过程中非常有用，特别是当你需要频繁地与远程仓库进行交互时。
需要注意的是，存储凭证信息明文可能存在安全风险，因为其他人可以访问到这些凭证信息。因此，建议在安全的环境下使用 store 凭证助手，或者考虑使用其他更安全的凭证助手，如 cache 或 osxkeychain，它们可以更加安全地存储凭证信息。
如果你希望移除 store 凭证助手的配置，可以使用以下命令：
git config --local --unset credential.helper

这会从 Git 配置中移除 credential.helper 的设置，并停止使用凭证助手来存储和管理凭证信息。
参考文献：

官网 Git 工具 - 凭证存储



5. Git Proxy只对 github 进行代理，不影响国内的仓库
git config --global http.https//github.com.proxy http://127.0.0.1:8001git config --global https.https//github.com.proxy https://127.0.0.1:8001

设置全局代理，国内的仓库速度也会收到一定的影响。
git config --global http.proxy http://127.0.0.1:1080git config --global https.proxy https://127.0.0.1:1080// 取消全局代理git config --global --unset http.proxygit config --global --unset https.proxy

Windows 下修改 Host 文件
192.30.253.112 github.com192.30.253.113 github.com151.101.185.194 github.global.ssl.fastly.net


6. 提交代码总结6.1. 第一次提交
git init  初始化
git add README.md   提交到暂存库
git commit -m &quot;first commit&quot;   为提交的文件添加注释说明
git remote add origin git@github.com:michaelliao/learngit.git  本地 Git 库与远程的仓库关联
git push -u origin master      本地库的所有内容推送到远程库上

6.2. 不是第一次提交
git add README.md  提交到暂存库
git commit -m &quot;first commit&quot;   为提交的文件添加注释说明
git push origin master 本地库的所有内容推送到远程库上

7. Git 常用命令
git init 初始化一个 Git 仓库 。
git add &lt;file&gt; 添加文件到暂存区。
git add -p(patch) 依次存储每一个文件的改动，包括文件中做的哪些改动。
git commit -m &lt;message&gt; 给添加到暂存区的文件增加注释，-m 代表是提交信息。
git status 查看当前工作区的状态。
git diff 比较工作区中当前文件和暂存区快照之间的差异。
git diff --stage 查看已暂存的将要添加到下次提交里的内容。
git difftool 使用图像化工具查看工作区与暂存区之间的差异。
git reflog 查看引用日志。每次提交或改变分支都会改变引用日志 reflog。
git reset --hard HEAD^ 回退到 HEAD^ 版本。
git config --list 列出 Git 所有当的配置信息。
git help &lt;verb&gt; 查看帮助，verb 为 Git 的关键字。

8. References官方手册

git-scm.com: Git 官方参考手册。
GitHub Training Kit: 来自 Github 官方专业服务团队的开源课程软件，非常好！！！


博客、文章

git-recipes：github 上开源的 git 中文食谱，收集了许多国外优秀的文章，质量很高。
图解 Git: 采用画图的方式来理解 Git。
Learn Git Branching：通过玩游戏的方式来学习 Git。
Version Control (Git): MIT 2020 年开设的一门 missing-semester 课程，这是 Version Control (Git) 章节。
Git 头指针分离状态: https://blog.csdn.net/qq_32907195/article/details/109217034
GitHub 实用小技巧总结: https://github.com/Snailclimb/JavaGuide/blob/main/docs/tools/git/github-tips.md
Git 多平台换行符问题(LF or CRLF): https://kuanghy.github.io/2017/03/19/git-lf-or-crlf
Git 代理配置方案


Git branch

彻底搞懂 Git-Rebase: http://jartto.wang/2018/12/11/git-rebase/
Git 冲突与解决方法
Git 分支合并冲突解决

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>SVN</title>
    <url>/Git-SVN/Git-SVN/SVN/</url>
    <content><![CDATA[

1. 概念什么是Subversion?

Subversion的版本库是一种特别的文件版本库，它会记录每一次改变：每个文件的改变，甚至是目录树本身的改变。

文件共享

一般的文件共享采用的是 lock-modify-unlock 的方式
Subversion、VS和一些版本控制系统使用  copy-modify-merge模型。
在这种模型里，每一个客户联系项目版本库建立一个个人工作拷贝—版本库中文件和目录的本地映射。用户并行工作，修改各自的工作拷贝，最终，各个私有的拷贝合并在一起，成为最终的版本，这种系统通常可以辅助合并操作，但是最终要靠人工去确定正误。



工作副本

 .svn 为名的文件夹，也被叫做工作副本的管理目录，这个目录里的文件能够帮助 Subversion 识别哪些文件做过修改，哪些文件相对于别人的工作已经过期。

修订版本

每当版本库接受了一个提交，文件系统进入了一个新的状态，叫做一次修订(revision)，每一个修订版本被赋予一个独一无二的自然数，一个比一个大，初始修订号是0，只创建了一个空目录，没有任何内容。版本库每一次的提交，保存的是工作副本中改变的快照，并不是整个工作副本的快照。

工作副本怎样跟踪版本库？

工作副本基于的修订版本
时间戳：记录了工作副本从版本库中最后一次的拷贝。   
工作副本中的四中状态
未修改且是当前的。文件在工作目录里没有修改，在工作修订版本之后没有修改提交到版本库。
本地已修改且是当前的。文件在工作目录里已经修改，在工作修订版本之后没有修改提交到版本库。
Unchanged, and out of date。这个文件在工作目录没有修改，但在版本库中已经修了。这个文件最终将更新到最新版本，成为当时的公共修订版本。
Locally changed, and out of date。这个文件在工作目录和版本库都得到修改。一个svn commit将会失败，这个文件必须首先更新，svn update命令会合并公共和本地修改，如果Subversion不可以自动完成，将会让用户解决冲突。



2. 目录约定
&#x2F;trunk：开发主线
&#x2F;branches：支线副本
&#x2F;tags：标签副本，一旦创建，不允许修改。

3. 图标
normal：状态正常
modified：对本地的副本做了修改，需要提交到服务器
conflicted：有冲突
readonly：文件是只读的，要修改必须先获取锁
locked：获得锁
deleted：计划从版本库中删除
added：已被计划纳入版本控制
non-versioned：未纳入版本控制

图形化版本中各个图标表示含义

绿色：当前文件没有被修改过
红色：已修改，没有提交
蓝色：不属于版本库的未知文件，未知文件不能提交
蓝色加号：新增加的版本库文件
蓝色：提交一个修改。
紫色：提交一个新增项。
深红：提交一个删除或是替换。
黑色：所有其他项。

4. svn冲突解决冲突有三种选择：

A、放弃自己的更新，使用svn revert（回滚），然后提交。在这种方式下不需要使用svn resolved（解决）
B、放弃自己的更新，使用别人的更新。使用最新获取的版本覆盖目标文件，执行resolved filename并提交(选择文件—右键—解决)。
C、手动解决：冲突发生时，通过和其他用户沟通之后，手动更新目标文件。然后执行resolved filename来解除冲突，最后提交。

如何降低冲突解决的复杂度？

1、当文档编辑完成后，尽快提交，频繁的提交&#x2F;更新可以降低在冲突发生的概率，以及发生时解决冲突的复杂度。
2、在提交时，写上明确的message，方便以后查找用户更新的原因，毕竟随着时间的推移，对当初更新的原因有可能会遗忘
3、养成良好的使用习惯，使用SVN时每次都是先提交，后更新。每天早上打开后，首先要从版本库获取最新版本。每天下班前必须将已经编辑过的文档都提交到版本库。

5. Git与SVN的区别
Git是分布式，svn是集中式
svn只有一个中央版本库，而git有无限个
svn有全局的版本号，git没有
git不必联网就可以看到所有的log，svn必须联网
git保存的是元数据，svn是复制整个文档
git强调分支，svn只是不同的文件目录，就是copy

6. subversion 常用流程
拷贝版本库中的项目到本地工作环境中
svn checkout xxxx


更新你的工作拷贝
svn update


做出修改
svn add
svn delete
svn copy
svn move


检查修改


svn status
svn diff


撤销一些修改
svn revert


解决冲突(合并别人的修改)
svn update
svn resolved


提交你的修改
svn commit



7. 常用命令最重要的是帮助命令，遇见不会的命令，需要自己查看帮助文档：svn help subcommand，其中 subcommand 为 subversion 的内建命令。
7.1. add
往版本库中添加新的文件 
svn add *.php 添加当前目录下所有后缀名为 .php 的文件。

7.2. checkout
将从SVN版本库中拷贝项目到本地工作目录中，得到一个本地拷贝，这个拷贝包括了命令行指定版本库中的HEAD(最新的)版本。
例如：svn checkout svn://192.168.1.131/45dian/brand

7.3. commit
将本地版本库中改变的文件提交到SVN版本库中
svn commit -m “LogMessage“ [-N] [--no-unlock] PATH (如果选择了保持锁，就使用–no-unlock开关)
例如：svn commit -m “add test file for my test“ test.php

7.4. lock&#x2F;unlocklock&#x2F;unlock 表示 加锁  与解锁。

svn lock -m “LockMessage“ [--force] PATH
例如：svn lock -m “lock test file“ test.php

7.5. update更新你的工作拷贝 

svn update： 会把版本库的修改带到工作拷贝,如果没有给定修订版本,它会把你的工作拷贝更新到 HEAD 修订版本,否则,它会把工作拷贝更新到你用 --revision 指定的修订版本。为了保持同步, svn update 也会删除所有在工作拷贝发现的无效锁定
每个更新的项目开头都有一个表示所做动作的字符
A: add
B: Broken lock (third column only)
D: delete
U: update
C: conflict
G: merge
E: existed
R: replace
M: modified
?: 未添加到工程中的文件。
!: 工程中没有该文件，但并没有从版本库中删除。




 .svn 目录记录着文件的修改日期和原始内容。


用法

svn update 后面没有加目录，表示默认更新当前目录及子目录的所有文件到最新版本。
svn update -r 200 test.php 将版本库中的 test.php 文件还原到 200 版本。


update命令还可以进行文件恢复。

不小心写错了很多东西，想撤销所写的东西（已经把修改提交到服务器）svn update -r 版本号
不小心删错了文件，想把文件恢复回来（已经把删除提交到服务器）svn update -r 版本号



7.6. status
svn status: 打印所有本地修改的文件，默认情况下，不会联系版本库.
svn status -v: 显示所有版本控制下的文件。

7.7. delete
svn delete aa.txt 删除工作区远程库中的 aa.txt 文件；若只是在工程中删除 aa.txt 文件，不使用 svn delete 指令，则远程版本库中还存在 aa.txt 文件，使用 svn update 命令后，原先已存在 aa.txt 文件会再次更新到工作区中。

7.8. cat
svn cat: 检查一个过去的版本而不希望察看它们的区别$ svn cat -r 2 rules.txtBe kind to othersFreedom = Chocolate Ice CreamEverything in moderationChew with your mouth open

7.9. list
svn list  可以在不下载文件到本地目录的情况下来察看服务器远程库目录中的文件$ svn list http://svn.collab.net/repos/svnREADMEbranches/clients/tags/trunk/

7.10. diff
svn diff file 将修改的 file 文件与基础版本比较。

例如：svn diff test.php


svn diff -r m:n path: 对版本m和版本n比较差异

例如：svn diff -r 200:201 test.php
简写：svn di



7.11. copy
从主干上创建分支: svn cp -m &quot;create branch&quot;  http://svn_server/xxx_repository/trunk  http://svn_server/xxx_repository/branches/br_feature001 

获得分支: svn checkout http://svn_server/xxx_repository/branches/br_feature001


7.12. merge
svn merge -r m:n path
例如：svn merge -r 200:205 test.cpp（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下）

7.13. log
svn log -l 10: 查看最近提交的10条记录
svn log test.cpp: 显示这个文件的所有修改记录，及其版本号的变化。
svn log -r &#123;2018-07-03&#125;:&#123;2018-07-09&#125;: 查看一段时间的日志
svn log -r r196674 -v: 查看某一版本所修改的文件列表及说明

7.14. info
svn info test.cpp：查看test.cpp文件的详细信息。Path: xxx.cppName: xxx.cppWorking Copy Root Path: /home/john/development/GMP2000URL: https://112.17.80.221/svn/xxx.cppRelative URL: ^/branches/xxx.cppRepository Root: https://112.17.80.221/svn/xxxRepository UUID: d9902de0-23ea-1e4c-b6e9-eed385be7707Revision: 3485Node Kind: fileSchedule: normalLast Changed Author: xxxxLast Changed Rev: 3482Last Changed Date: 2021-02-25 10:52:10 +0800 (Thu, 25 Feb 2021)Text Last Updated: 2021-02-23 11:46:24 +0800 (Tue, 23 Feb 2021)Checksum: fa59dd9a5472e6ad5cdd17968c9b8952dcf107c5

7.15. resolved
svn resolved: 移除工作副本的目录或文件的“冲突”状态。
用法: svn resolved PAT
注意: 本命令不会依语法来解决冲突或是移除冲突标记，它只是移除冲突的相关文件，然后让 PATH 可以再次提交。

7.16. switch
svn switch (sw): 更新工作副本至不同的URL。
1、更新你的工作副本，映射到一个新的URL，其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。这是将工作副本对应到同一仓库中某个分支或者标记的方法。
2、改写工作副本的URL元数据，以反映单纯的URL上的改变。当仓库的根URL变动(比主机名称变动)，但是工作副本仍旧对映到同一仓库的同一目录时使用这个命令更新工作副本与仓库的对应关系



7.17. revert
本地文件发生改变后，想要恢复到未改变之前的状态，可以用 svn revert 命令。
svn revert files 将 files 恢复到未改变之前的状态。
svn revert --recursive build/xxx/file 将 build&#x2F;xxx&#x2F; 路径下的多个 file 恢复到未改变之前的状态。
注意: 此命令只改变本地工作区的内容，对远程库不行，文件已被 svn delete 指令删除，则不会被恢复。

8. 参考
linux下svn命令使用大全
Linux下常用svn命令
SVN的安装和使用手册    
SVN简介
windows下使用SVN命令行
版本控制器：SVN教程
SVN教程

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>sVN</tag>
      </tags>
  </entry>
  <entry>
    <title>develop</title>
    <url>/Git-SVN/Git-SVN/develop/</url>
    <content><![CDATA[开发流程
克隆仓库，拉取最新代码
cd workspacegit clone &lt;remote_repository_url&gt;

创建分支并切换到要拉取代码的新分支
git checkout -b &lt;new_branch_name&gt;

功能开发，提交commit
git add git commit

功能开发完成，先拉取远程仓库最新的代码到本地开发分支，若有冲突，则解决冲突，解决完成后，合并到本地 dev 分支，最后推送到远程的 dev 分支。
采用 merge 方式：
// feature分支下git pull origin dev// 第一次推送远程featuregit push --set-upstream origin feature// 非第一次推送远程featuregit push origin feature   // 或直接 git pushgit switch devgit merge featuregit push origin dev

采用 rebase 方式：
// feature分支下未做任何的提交git pull origin dev// feature分支下有commit历史// 拉取远程最新的提交到本地feature分支下，并将本地之前feature的提交记录放到当前记录的最后git pull origin dev --rebase // 继续开发git add git commit// 开发完成后，切换到dev分支下，采用merge方式，为了保存合并记录git switch devgit merge feature// 本地dev分支下提交到远程dev分支git push origin dev

]]></content>
      <categories>
        <category>Git-SVN</category>
      </categories>
      <tags>
        <tag>git-SVN</tag>
        <tag>develop</tag>
      </tags>
  </entry>
  <entry>
    <title>Compiler</title>
    <url>/Go/Go/Compiler/</url>
    <content><![CDATA[
Compile Analysis概述Golang 编译器底层源码分析。
编译器原理Go编译器的基本工作流程和主要组件：

词法分析（Lexical Analysis）：
编译器首先会对源代码进行词法分析，将源代码分割成一系列标记（tokens）。这些标记包括关键字、标识符、常量和操作符等。
词法分析器会识别源代码中的各个语法元素，并生成相应的标记。


语法分析（Syntax Analysis）：
语法分析器（也称为解析器）将词法分析生成的标记组织成语法树（抽象语法树或AST），表示源代码的结构和语法关系。
语法分析器检查源代码是否符合Go语言的语法规则，同时将其转换成更容易处理的形式。


语义分析（Semantic Analysis）：
语义分析阶段对AST进行检查，确保代码的语义正确性，包括变量的声明和使用、类型匹配、函数调用等。
在这个阶段，还会进行类型推导，确定变量和表达式的类型。
这个阶段还会检查是否有未使用的变量或者不可达的代码。


中间表示（Intermediate Representation）：
Go编译器通常会生成一种中间表示，称为SSA（Static Single Assignment），它是一种静态单赋值形式，更容易进行优化。
中间表示是一个抽象的、与机器无关的表示，它包含了源代码的结构和语义信息。


优化（Optimization）：
编译器会对生成的中间表示进行各种优化，以提高程序的性能。优化包括常量折叠、循环优化、内联函数等。
Go编译器使用了一些高级优化技术，如逃逸分析和并发优化，以提高多核处理器上的性能。


代码生成（Code Generation）：
最后一个阶段是将优化后的中间表示翻译成目标机器的机器代码。
Go编译器可以生成多种目标平台的机器代码，因此在不同的操作系统和体系结构上都可以运行Go程序。


链接（Linking）：
对于多个源文件的程序，链接器将各个模块的机器代码组合在一起，解决外部符号引用，生成可执行文件或共享库。



需要注意的是，Go编译器与C&#x2F;C++等编译器不同，它在编译时进行了垃圾回收和自动内存管理的处理，因此Go程序不需要显式地释放内存。此外，Go编译器还包括一些与Go语言特性相关的特殊处理，如goroutine的支持和反射（reflection）等。
自动内存管理Go语言的自动内存管理是通过垃圾回收器（Garbage Collector，GC）来实现的。Go编译器和运行时系统共同协作，以管理程序中的内存分配和回收。下面是Go语言中的自动内存管理是如何工作的：

内存分配：
当你在Go程序中创建变量、切片、地图或其他数据结构时，Go运行时会负责在堆（heap）上为这些数据结构分配内存空间。
Go运行时会维护一个堆内存池，用于高效地分配和管理内存。


垃圾回收：
Go语言的垃圾回收器会周期性地扫描程序的堆内存，查找不再被引用的对象。
垃圾回收器识别不再被引用的对象，并将其标记为可回收（即垃圾）。
被标记为垃圾的对象的内存将被回收，以便用于将来的内存分配。


并发回收：
Go的垃圾回收器是并发的，它可以在程序继续运行的同时执行垃圾回收操作。这有助于减少暂停时间（stop-the-world时间）。
在Go 1.5及以后的版本中，Go引入了并发标记（concurrent marking）和并发清除（concurrent sweeping）来减小垃圾回收对程序性能的影响。


逃逸分析：
Go编译器还进行逃逸分析，用于确定变量的生命周期是否超出了当前函数的作用域。
如果一个变量的引用逃逸到了堆上，编译器会将其分配到堆上，否则，它将被分配到栈上，从而减少堆上分配的开销。


Finalizer（终结器）：
Go语言允许你为对象关联终结器函数，这些函数会在对象被垃圾回收前被调用。这可以用于执行一些清理操作。



总之，Go语言的自动内存管理通过垃圾回收器实现，这个回收器负责追踪和回收不再被引用的内存对象，从而确保程序不会出现内存泄漏问题。这种自动化的内存管理使得Go程序员可以更专注于编写业务逻辑而不用过多关注内存管理的细节。同时，Go的并发垃圾回收器允许程序在进行垃圾回收时仍然保持高度的并发性能。
逃逸分析 Go编译器中的逃逸分析是一项关键的静态分析技术，用于确定一个变量的生命周期是否超出了当前函数的作用域。逃逸分析的主要目的是优化内存分配，减少对堆内存的不必要分配，从而提高程序的性能和减少垃圾回收的压力。
逃逸分析是在编译阶段完成的。
逃逸的检测是通过 -gcflags=-m，一般还需要关闭内联比如 -gcflags=&quot;-m -l&quot;。
逃逸分析的主要作用包括：

栈分配 vs. 堆分配决策：
逃逸分析帮助编译器决定是否将一个对象分配在栈上还是堆上。
如果一个对象的引用不会逃逸到函数外部（即不会被其他函数引用或返回），那么编译器可以安全地将其分配在栈上，从而避免了堆内存分配和垃圾回收的成本。


减少垃圾回收压力：
堆内存的分配和垃圾回收是一项昂贵的操作。通过减少对堆内存的不必要分配，可以降低垃圾回收的频率和成本，提高程序的性能。



逃逸分析的实现原理主要包括以下几个步骤：

建立静态单赋值（SSA）表达式：
编译器首先将源代码转换成中间表示（通常是SSA形式），以便更容易进行分析。


分析变量的引用：
编译器分析变量在函数中的引用情况。它会跟踪变量的作用域，查看哪些地方引用了该变量，以及这些引用是否会逃逸到函数外部。


逃逸分析算法：
编译器使用逃逸分析算法来决定一个变量是否会逃逸。
如果编译器发现一个变量的引用会逃逸到函数外部，那么它将决定将该变量分配在堆上，否则分配在栈上。


优化生成的代码：
根据逃逸分析的结果，编译器可能会对生成的代码进行优化，例如，将某些对象分配在栈上，以减少堆内存的使用。



需要注意的是，逃逸分析不仅限于决定对象的分配位置，还可以影响编译器对函数调用和内联的决策。这些优化可以显著提高Go程序的性能，减少内存分配和垃圾回收的开销。
目录结构Go编译器中逃逸分析源码的结构和关键文件的简要概述：

目录结构：
逃逸分析的源代码位于src/cmd/compile/internal/escape目录下。


文件列表：
escape.go：这是逃逸分析的主要实现文件，包含了逃逸分析器的核心逻辑。
main.go：包含逃逸分析的入口点，用于设置分析器的选项和运行分析。
debug.go：包含用于调试逃逸分析的代码。
inline.go：包含与内联函数（inlining）有关的逃逸分析逻辑。
stmt.go：包含用于处理不同类型语句的逃逸分析代码。
type.go：包含用于处理类型信息的逃逸分析代码。
alloc.go：包含用于分配对象的逃逸分析代码。


数据结构：
逃逸分析的核心数据结构包括EscAnalyzer结构，它用于表示逃逸分析的状态和选项。
在escape.go中，你会找到许多与逃逸分析相关的数据结构和函数，如allocFrame、valueEscapes等。


逃逸分析算法：
逃逸分析算法的核心任务是确定一个变量的生命周期是否逃逸到了当前函数的外部。这涉及到静态分析源代码，跟踪变量的引用和作用域。
逃逸分析会标记哪些变量逃逸到了堆上，以及哪些可以分配在栈上。


优化和代码生成：
逃逸分析的结果可以影响编译器的优化和代码生成决策。如果一个变量被确定为不逃逸，编译器可以将其分配在栈上，从而减少堆内存分配和垃圾回收的开销。



这些文件和逻辑组成了Go编译器中逃逸分析的主要部分。逃逸分析是Go语言的一项重要优化，它有助于减少内存分配和垃圾回收的成本，提高程序性能。你可以通过查看这些源代码文件来更深入地了解逃逸分析的实现细节。
References
Github escape analysis: https://github.com/golang/go/tree/master/src/cmd/compile/internal/escape

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>compiler</tag>
      </tags>
  </entry>
  <entry>
    <title>DebugVScode</title>
    <url>/Go/Go/DebugVScode/</url>
    <content><![CDATA[Debugvscode 下调试 go 文件。
安装 delveDelve 是Golang的调试工具。
linux 下安装
go get -u github.com/go-delve/delve/cmd/dlv



设置 launch.json 配置文件ctrl+shift+p 输入 Debug: Open launch.json 打开 launch.json 文件，如果第一次打开,会新建一个配置文件，默认配置内容如下
&#123;    &quot;version&quot;: &quot;0.2.0&quot;,    &quot;configurations&quot;: [        &#123;            &quot;name&quot;: &quot;Launch&quot;,            &quot;type&quot;: &quot;go&quot;,            &quot;request&quot;: &quot;launch&quot;,            &quot;mode&quot;: &quot;auto&quot;,            &quot;program&quot;: &quot;$&#123;fileDirname&#125;&quot;,        &#125;    ]&#125;

常见属性如下



属性
介绍



name
调试界面下拉选择项的名称


type
设置为go无需改动，是 vs code 用于计算调试代码需要用哪个扩展


mode
可以设置为 auto, debug, remote, test, exec 中的一个


program
调试程序的路径（绝对路径）


env
调试时使用的环境变量。例如:&#123; &quot;ENVNAME&quot;: &quot;ENVVALUE&quot; &#125;


envFile
包含环境变量文件的绝对路径，在 env 中设置的属性会覆盖 envFile 中的配置


args
传给正在调试程序命令行参数数组


showLog
布尔值，是否将调试信息输出


logOutput
配置调试输出的组件（debugger, gdbwire, lldbout, debuglineerr, rpc）,使用,分隔， showLog 设置为 true 时，此项配置生效


buildFlags
构建 go 程序时传给 go 编译器的标志


remotePath
远程调试程序的绝对路径，当 mode 设置为 remote 时有效


在 debug 配置中使用 VS Code 变量
$&#123;workspaceFolder&#125; 调试 VS Code 打开工作空间的根目录下的所有文件
$&#123;file&#125; 调试当前文件
$&#123;fileDirname&#125; 调试当前文件所在目录下的所有文件

ReferenceGithub golang vscode debug: https://github.com/golang/vscode-go/blob/master/docs/debugging.md
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>debugVScode</tag>
      </tags>
  </entry>
  <entry>
    <title>GPM</title>
    <url>/Go/Go/GPM/</url>
    <content><![CDATA[GPM Model在Golang（也称为Go）中，GPM代表着Go中的并发模型，它包括三个关键的组件：Goroutines（协程）、Scheduler（调度器）和系统线程（M：Machine）。GPM模型是Go语言实现并发的核心。下面是关于GPM模型的简要解释：

G(Goroutine)

Goroutine是Go语言中的轻量级线程，它由Go运行时（runtime）管理。与传统的线程相比，Goroutines的创建和销毁更加高效。
Goroutines通过go关键字启动，可以在程序中创建数千甚至数百万个Goroutines而不会消耗太多内存。
每个Goroutine都运行一个函数，它们可以异步执行，互不干扰。
存储了 goroutine 执行的栈信息、goroutine 状态及goroutine的任务函数。


P(Processor)：协程执行需要的上下文。

P 的数量决定了系统内最大可并行的G数量。P 中拥有的是各种G对象队列、链表、一些缓存和状态。

Go运行时包含了一个调度器，它负责管理和调度Goroutines的执行。

调度器会在多个系统线程（M）之间分配Goroutines的执行。

调度器使用一种叫做”work-stealing”的技术，来确保各个系统线程都有足够的工作负载。



M(Machine)：操作系统的主线程，也叫工作线程。

系统线程是Go运行时的底层执行单元，它们由操作系统管理。
一个Go程序可以使用多个系统线程，每个线程都可以同时运行一个Goroutine。
系统线程会被调度器用来执行Goroutines。



GPM模型的工作流程如下：

当一个Go程序启动时，它通常会创建一个或多个系统线程（M），这些线程称为”工作线程”。
当你使用go关键字启动一个新的Goroutine时，调度器会将这个Goroutine分配给一个工作线程来执行。
如果一个工作线程的Goroutine执行完毕或者发生了阻塞（例如等待I&#x2F;O操作完成），那么调度器会将另一个Goroutine分配给该线程，以充分利用线程的资源。
如果某个Goroutine发生了死锁或者其他无法继续执行的情况，Go运行时会触发恢复机制（panic recovery）来防止整个程序崩溃。
调度器会周期性地检查Goroutines的状态，以确保它们都能够正常执行。

总之，GPM模型是Go语言并发性能的核心之一，它使得Go程序能够高效地运行大量的并发任务而无需过多的线程管理开销。这种模型的好处包括更高的并发性能、更低的内存开销以及更简单的并发编程模型。
References
https://golang.design/under-the-hood/zh-cn/part2runtime/ch06sched/mpg/

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>gPM</tag>
      </tags>
  </entry>
  <entry>
    <title>Go</title>
    <url>/Go/Go/Go/</url>
    <content><![CDATA[

1. How to learn go(学习方法)
先知道怎么做，再知道为什么？
对知识有一个整体的框架，然后再学习具体的内容。
学习一门新的语言，需要掌握语言的变量、常量、表达式、控制流和函数等基本语法，这些都是每门语言通用的特性。

GO 程序员的五个进化阶段:

第一个阶段 (菜逼): 刚刚学习了这门语言。 已经通过一些教程或者培训班了解基本的语法，可以写短的代码片段。
第二个阶段 (探索者): 可以写一个完整的程序，但不懂一些更高级的语言特征，比如 “channels”。还没有使用 GO 写一个大项目。
第三个阶段 (大手): 你能熟练的使用 Go, 能够用 GO 去解决，生产环境中一个具体和完整的问题。已经形成了一套自己的惯用法和常用代码库。在你的编码方案中 Go 是一个非常好用的工具。
第四阶段 (大神): 绝逼清楚 Go 语言的设计选择和背后的动机。能理解的简洁和可组合性哲学。
布道师: 积极地与他人分享关于 Go 语言知识和你对 Go 语言的理解。在各种合适的场所发出自己的声音, 参与邮件列表、建立 QQ 群、做专题报告。成为一个布道者不见得是一个完全独立的阶段，这个角色可以在上述的任何一个阶段中。

如何快速高效率地学习 Go 语言：https://studygolang.com/articles/27295
2. Concept(基本概念)2.1. 吉祥物GO 语言的吉祥物：樱花鼠。
2.2. 命令查看 Go 工具链支持哪些命令，命令行终端输入 go help 即可。
$ go helpGo is a tool for managing Go source code.Usage:        go &lt;command&gt; [arguments]The commands are:        bug         start a bug report        build       compile packages and dependencies        clean       remove object files and cached files        doc         show documentation for package or symbol        env         print Go environment information        fix         update packages to use new APIs        fmt         gofmt (reformat) package sources        generate    generate Go files by processing source        get         add dependencies to current module and install them        install     compile and install packages and dependencies        list        list packages or modules        mod         module maintenance        work        workspace maintenance        run         compile and run Go program        test        test packages        tool        run specified go tool        version     print Go version        vet         report likely mistakes in packagesUse &quot;go help &lt;command&gt;&quot; for more information about a command.Additional help topics:        buildconstraint build constraints        buildmode       build modes        c               calling between Go and C        cache           build and test caching        environment     environment variables        filetype        file types        go.mod          the go.mod file        gopath          GOPATH environment variable        gopath-get      legacy GOPATH go get        goproxy         module proxy protocol        importpath      import path syntax        modules         modules, module versions, and more        module-get      module-aware go get        module-auth     module authentication using go.sum        packages        package lists and patterns        private         configuration for downloading non-public code        testflag        testing flags        testfunc        testing functions        vcs             controlling version control with GOVCSUse &quot;go help &lt;topic&gt;&quot; for more information about that topic.

go get 和 go install 是 Go 语言中的两个不同命令，它们的主要区别在于功能和用途。

go get 
功能：用于获取和安装远程包（外部依赖）。
用途：主要用于在你的代码中引入其他人或团队编写的包，以便在你的项目中使用它们。
示例：go get github.com/example/package。此命令会下载指定的远程包并将其安装到你的 Go 语言环境中的工作目录（通常是 $GOPATH/src 目录）或模块缓存（Go Modules）。


go install 
功能：用于编译并安装可执行文件或库。
用途：主要用于构建和安装你自己的 Go 项目或库，以便在本地使用或分享给其他人。
示例：go install github.com/your-username/your-package。此命令会编译指定的包，并将生成的可执行文件或库安装到你的 Go 语言环境中的 bin 目录（通常是 $GOPATH/bin 目录）。



总结：

go get 用于获取和安装外部依赖（远程包）。
go install 用于构建和安装你自己的项目或库。

需要注意的是，自Go 1.16版本开始，引入了 Go Modules 作为官方的依赖管理工具，它不再依赖 $GOPATH 和传统的工作目录结构。使用 Go Modules 时，go get 和 go install 的行为会有所不同。它们会直接操作项目的 go.mod 文件和模块缓存，而不需要使用 $GOPATH 或 $GOBIN。
Go mod（又称为 Go Modules）是 Go 语言 1.11 及以上版本引入的一种依赖管理工具。它旨在改善 Go 语言项目的依赖管理和版本控制。
在早期，Go 语言使用 GOPATH 作为项目的工作空间，并使用第三方工具（如 dep、glide 等）来管理依赖关系。然而，这种方式在多项目开发和版本管理方面存在一些问题。
Go mod 的出现解决了这些问题。它允许在项目的源码目录内直接管理依赖关系，而无需依赖于 GOPATH。通过使用 Go mod，开发人员可以轻松地添加、更新和删除项目所需的依赖项。
Go mod 使用一个名为 go.mod 的文件来记录项目的依赖关系和版本信息。该文件会明确列出项目所依赖的模块及其版本约束。当构建项目时，Go mod 会自动下载所需的依赖项，并确保其符合指定的版本约束。
Go mod 还支持语义版本控制，使开发人员能够定义依赖项的最小和最大版本要求。这有助于确保项目在不引入不兼容的更改的情况下，持续使用稳定的依赖项版本。
总之，Go mod 是 Go 语言中的一种依赖管理工具，它简化了项目的依赖管理和版本控制，提供了更灵活和可靠的方式来管理和使用第三方库。
go mod tidy: 用来通过扫描当前项目中的所有代码来添加未被记录的依赖至go.mod文 件或从go.mod文件中删除不再被使用的依赖。
go get: 用拉添加、升级、降级或者删除单个依赖。
2.2.1. go mod tidygo mod tidy 是 Go 语言的一个命令，用于自动处理你的 Go 项目的依赖关系。具体来说，它会做以下两件事：

删除无用的模块：go mod tidy 会移除 go.mod 文件中所有未被项目中的任何代码直接或间接引用的模块。
添加缺失的模块：go mod tidy 会查找所有项目中直接或间接引用的模块，如果这些模块在 go.mod 文件中没有被列出，那么 go mod tidy 会将它们添加进去。

这个命令通常在以下几种情况下使用：

当你添加了一个新的依赖，但是忘记更新 go.mod 文件时。
当你删除了一些代码，这些代码是项目中唯一引用某个依赖的地方，你想要移除这个不再使用的依赖时。
当你的 go.mod 文件因为某些原因（比如合并冲突）变得不一致，你想要修复它时。

使用这个命令的基本格式是在你的项目目录中运行 go mod tidy。
2.2.2. go rungo run：这是 Go 语言的一个命令，用于编译并运行 Go 代码。它会先编译代码，然后立即运行编译后的程序。
2.2.3. goproxy下载 golang tools 比较慢，一般是下载不下来的，因为 golang 的服务器在国外，被中国大陆给屏蔽了。通常想快速的下载golang tools，一般是设置一个国内的代理。
打开 Linux terminal，然后执行下面的命令
go env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.cn,direct



3. Golang 特点3.1. 拥有特性
自动立即回收。
更丰富的内置类型。
函数多返回值。
错误处理。
匿名函数和闭包。
包（package）。必须恰当导入需要的包，缺少了必要的包或者导入了不需要的包，程序都无法编译通过。这项严格要求避免了程序开发过程中引入未使用的包
类型和接口。方法不仅可以定义在结构体上，而且，可以定义在任何用户自定义的类型上；具体类型和抽象类型（接口）之间的关系是隐式的，所以很多类型的设计者可能并不知道该类型到底实现了哪些接口。
并发编程。
反射。
语言交互性。
只读的 UTF8 字符串
静态编译，编译好后，扔服务器直接运行。

3.2. 不支持的特性
没有隐式的数值转换。
没有构造函数和析构函数。
没有运算符重载。
没有默认参数。
没有继承、类、多态。仅仅通过组合简单的对象来构建复杂的对象。
没有泛型。
没有异常。
没有宏。
没有函数修饰。
没有线程局部存储。

Go 语言有足够的类型系统以避免动态语言中那些粗心的类型错误。
3.3. 应用方向
服务器编程：处理日志、数据打包、虚拟机处理、文件系统、分布式系统、数据库代理等；
网络编程： Web 应用、API 应用、下载应用等；
内存数据库和云平台领域，目前国外很多云平台都是采用 Go 开发。

4. Go 基础4.1. Agent(代理)众所周知，国内网络访问国外资源经常会出现不稳定的情况。 Go 生态系统中有着许多中国 Gopher 们无法获取的模块，比如最著名的 golang.org/x/...。并且在中国大陆从 GitHub 获取模块的速度也有点慢。Linux 环境下，终端直接执行下面的命令进行国内镜像加速。
# 启用 Go Modules 功能go env -w GO111MODULE=on# 设置七牛云镜像加速go env -w GOPROXY=https://goproxy.cn,direct# 设置国内的能访问到的 GOSUMDB go env -w GOSUMDB=sum.golang.org

执行完后确认一下，看环境是否设置对
go env | grep GOPROXYGOPROXY=&quot;https://goproxy.cn&quot;



4.2. 项目目录结构在进行 Go 语言开发的时候，我们的代码总是会保存在 $GOPATH/src 目录下。在工程经过 go build、go install 或 go get 等指令后，会将下载的第三方包源代码文件放在 $GOPATH/src 目录下， 产生的二进制可执行文件放在 $GOPATH/bin  目录下，生成的中间缓存文件会被保存在 $GOPATH/pkg 下。
建立 Go 的工作空间（workspace，也就是 GOPATH 环境变量指向的目录）
Go 代码必须在工作空间内。工作空间是一个目录，其中包含三个子目录：

src：源代码目录。里面每一个子目录，就是一个包。
pkg： 存放编译后生成的库文件，如 go module。
bin：存放编译后生成的二进制文件（目标文件）。

自动生成 pkg、bin 目录文件，需用 go install 命令即可，还需在 go 的环境变量中配置 GOBIN 路径。
4.3. Compile(编译)Go 是一门编译型语言，Go 语言的工具链将源代码及其依赖转换成计算机的机器指令。Go 语言提供的工具都通过一个单独的命令 go 调用，go 命令有一系列子命令。最简单的一个子命令就是 run。这个命令编译一个或多个以 .go 结尾的源文件，链接库文件，并运行最终生成的可执行文件。
go run xxx.go

Go 编译使用 go build, go install 命令。
Go build 编译参数
-w 去掉调试信息-s 去掉符号信息-a 强制编译所有依赖包-race 协程竞争关系// 示例go build -ldflags &quot;-s -w&quot; -o main-ldflags main.go





4.4. key-words(关键字)25 个关键字
break    default      func    interface    selectcase     defer        go      map          structchan     else         goto    package      switchconst    fallthrough  if      range        typecontinue for          import  return       var


4.5. built-in type(内置类型)4.5.1. Value types(值类型)boolint(32 or 64), int8, int16, int32, int64uint(32 or 64), uint8(byte), uint16, uint32, uint64float32, float64stringcomplex64, complex128array    -- 固定长度的数组


4.5.2. Reference types(引用类型)slice          -- 切片map            -- 映射chan           -- 管道interface      -- 接口function types --函数类型


4.6. built-in function(内置函数)Go 语言拥有一些不需要进行导入操作就可以使用的内置函数。
append          -- 用来追加元素到数组、slice 中, 返回修改后的数组、sliceclose           -- 主要用来关闭 channeldelete          -- 从 map 中删除 key 对应的 valuepanic           -- 停止常规的 goroutine  （panic 和 recover：用来做错误处理）recover         -- 允许程序定义 goroutine 的 panic 动作real            -- 返回 complex 的实部   （complex、real imag：用于创建和操作复数）imag            -- 返回 complex 的虚部make            -- 用来分配内存，返回 Type 本身（只能应用于 slice, map, channel）new             -- 用来分配内存，主要用来分配值类型，比如 int、struct。返回指向 Type 的指针cap             -- capacity 是容量的意思，用于返回某个类型的最大容量（只能用于切片和 map）copy            -- 用于复制和连接 slice，返回复制的数目len             -- 来求长度，比如 string、array、slice、map、channel ，返回长度print、println  -- 底层打印函数，在部署环境中建议使用 fmt 包

官方英文文档：https://pkg.go.dev/builtin@go1.19.4
4.6.1. append函数原型
func append(slice []Type, elems ...Type) []Type

功能：在原 slice 的末尾添加元素，返回修改后的 slice，返回值是一个新的slice
s1 := []int&#123;2, 3, 5, 7&#125;s1 = append(s1, 10)


4.6.2. copy函数原型：
func copy(dst, src []Type) int

功能：将一个 slice 复制另一个相同类型的 slice。
参数：

copy 函数的第一个参数是要复制的目标 slice，
第二个参数是源 slice， 目标和源的位置顺序和 dst = src 赋值语句是一致的。

两个 slice 可以共享同一个底层数组， 甚至有重叠也没有问题。
返回值：返回成功复制的元素的个数， 等于两个 slice 中较小的长度， 所以我们不用担心覆盖会超出目标 slice 的范围。
4.6.3. makemake 也是用于内存分配的，区别于 new，它只用于 slice、map 以及 chan 的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型就是 **引用类型 **，所以就没有必要返回他们的指针了。
用法
var b map[string]intb = make(map[string]int, 10)// 等价于b := make(map[string]int, 10)

用内置的 make 函数创建一个指定元素类型、 长度和容量的 slice。  容量部分可以省略， 在这种情况下， 容量将等于长度。
make([]T, len)make([]T, len, cap)

在底层，make 创建了一个匿名的数组变量， 然后返回一个 slice； 只有通过返回的 slice 才能引用底层匿名的数组变量。 在第一种语句中， slice 是整个数组的 view。 在第二个语句中， slice 只引用了底层数组的前 len 个元素， 但是容量将包含整个的数组。 额外的元素是留给未来的增长用的。
4.6.4. newnew 是 Go 语言内置的一个函数，用于内存的分配。new 函数用于分配内存，并返回一个指向新分配的零值对象的指针。
用法
// 函数签名func new(Type) *Type// 示例a := new(int)1. Type 表示类型，new 函数只接受一个参数，这个参数是一个类型2. *Type 表示类型指针，new 函数返回一个指向该类型内存地址的指针。

new 与 make 的区别

二者都是用来做内存分配的。
make 只用于 slice、map 以及 channel 的初始化，返回的还是这三个引用类型本身。
new 用于类型的内存分配，并且内存对应的值为类型零值，返回的是指向类型的指针。

4.7. 内置接口4.7.1. Error()// 只要实现了 Error() 函数，返回值为 String 的都实现了 err 接口type error interface &#123;	Error()    String&#125;


4.8. declare(声明)Go 语言有四种主要声明方式：
var（声明变量）const（声明常量）type（声明类型）func（声明函数）

Go 的程序是保存在多个 .go  文件中，文件的第一行就是 package XXX 声明，用来说明该文件属于哪个包（package）。package 声明下来就是 import 声明，再下来是类型，变量，常量，函数的声明。
4.8.1. varGo 变量声明以关键字 var 开头，变量类型放在变量的后面，行尾无需分号。
其标准声明格式如下：
var 变量名 变量类型var name stringvar age intvar isOk bool

其中，变量类型名可以省略，就变成了隐式类型定义，因为编译器可以根据变量的值来推断其类型。
var namevar agevar isOk

批量声明。每声明一个变量就需要写 var 关键字会比较繁琐，Go 语言中还支持批量变量声明：
var (    a string    b int    c bool    d float32)

Go 语言在声明变量的时候，会自动对变量对应的内存区域进行初始化操作。每个变量会被初始化成其类型的默认值，例如： 整型和浮点型变量的默认值为 0；字符串变量的默认值为空字符串；布尔型变量默认为 false； 切片、函数、指针变量的默认为 nil。
简短变量声明。用于声明和初始化局部变量。 它以 名字:= 表达式 形式声明变量， 变量的类型根据表达式来自动推导。
a := 10 // a 为 intb := &quot;boy&quot; // b 为 string

变量分为局部变量和全局变量。

局部变量：只在 &#123;&#125; 范围内定义的变量有效，离开了此作用域就失效了。
全部变量：定义在函数的外部的变量。

4.8.2. type类型声明通用格式
type 类型名字 底层类型

一个类型声明语句创建了一个新的类型名称， 和现有类型具有相同的底层结构。 新命名的类型提供了一个方法， 用来分隔不同概念的类型， 这样即使它们底层类型相同也是不兼容的。type 声明的类型是原类型的一个别名。
type Celsius float64 // 摄氏温度type Fahrenheit float64 // 华氏温度

在 Go 语言中，使用 type 关键字创建新的类型是一种常见的做法，这样做有几个好处：

增强代码的可读性和可理解性：新的类型名称可以更好地描述它的用途。在你的例子中，ThingInnerServiceName 比 string 更能表达它的含义。

类型安全：新的类型不会与它的基础类型混淆。例如，你不能将一个 ThingInnerServiceName 类型的值赋给一个 string 类型的变量，除非你进行显式的类型转换。这可以防止一些类型错误。

可以添加方法：你可以为新的类型添加方法。这是 Go 语言中的一种重要特性，可以让你创建更丰富的接口。


例如：
type ThingInnerServiceName stringfunc (t ThingInnerServiceName) Print() &#123;    fmt.Println(&quot;ThingInnerServiceName is: &quot; + string(t))&#125;func main() &#123;    var name ThingInnerServiceName = &quot;MyService&quot;    name.Print()  // 输出：ThingInnerServiceName is: MyService&#125;

在这个例子中，ThingInnerServiceName 类型有一个 Print 方法，可以打印出它的值。
注意：

Go 编译器不会对不同类型的值做隐式转换，需要做类型转换时，要显式指定。

4.9. Unicode在很久以前， 世界还是比较简单的， 起码计算机世界就只有一个 ASCII 字符集： 美国信息交换标准代码。 ASCII， 更准确地说是美国的 ASCII， 使用 7bit 来表示 128 个字符： 包含英文字母的大小写、 数字、 各种标点符号和设备控制符。 对于早期的计算机程序来说， 这些就足够了，但是这也导致了世界上很多其他地区的用户无法直接使用自己的符号系统。
Go 语言中的 Unicode 编码为 rune，即 int32 类型。
unicode 包提供了 IsDigit、 IsLetter、 IsUpper  和 IsLower 等类似功能， 它们用于给字符分类。 每个函数有一个单一的 rune 类型的参数， 然后返回一个布尔值  。
4.10. Basic Data Types(基础数据类型)数据类型的作用：告诉编译器变量以多大的内存去存储。
4.10.1. Constant(常量)常量表达式的值在编译期计算， 而不是在运行期。 每种常量的潜在类型都是基础类型：boolean、 string 或数字。一个常量的声明语句定义了常量的名字和变量的声明语法类似， 常量的值不可修改， 这样可以防止在运行期被意外或恶意的修改。
// 定义常量const pi = 3.14

注意点

定义后，不能再修改
在定义的时候必须初始化
常量名也通过首字母的大小写来控制常量的访问范围。

批量声明常量。除了第一个外其它的常量右边的初始化表达式都可以省略， 如果省略初始化表达式则表示使用前面常量的初始化表达式写法， 对应的常量类型也一样的。
// 多个常量声明const (	// 同时声明多个常量时，如果省略了值则表示和上面一行的值相同	// n1 n2 n3 的值都为 100	n1 = 100	n2	n3)


4.10.2. iota常量声明可以使用 iota 常量生成器初始化， 它用于生成一组以相似规则初始化的常量， 但是不用每行都写一遍初始化表达式。 在一个 const 声明语句中， 在第一个声明的常量所在的行，iota 将会被置为 0， 然后在每一个有常量声明的行加一。
// 常量中的 iota，go 中的常量计数器// 位于内部第一行被置为 0，每新增一行 iota 引用次数加 1// 常用于枚举中const (	t1 = iota // 0	t2        // 1	_         // 跳过 2	t4        // 3	t5 = iota // 中间插入 iota，4	t6        // 5)func PrintConstIota() &#123;	fmt.Println(t1, t2, t4, t5, t6)&#125;// 定义数量级const (	_  = iota	KB = 1 &lt;&lt;(10 * iota)	MB = 1 &lt;&lt;(10 * iota)	GB = 1 &lt;&lt;(10 * iota)	TB = 1 &lt;&lt;(10 * iota)	PB = 1 &lt;&lt;(10 * iota))func PrintConstIotaShift() &#123;	fmt.Println(KB, MB, GB, TB, PB)&#125;// 多个 iot 定义在一行const (	a, b = iota + 1, iota + 2 // a=0+1, b=0+2	c, d                      // c=1+1, c=1+2	e, f                      // e=2+1, f=2+2)func PrintConstIotaMulti() &#123;	fmt.Println(a, b, c, d, e, f)&#125;


4.10.3. String标准库中有四个包对字符串处理尤为重要： bytes、 strings、strconv 和 unicode 包。

strings 包提供了许多如字符串的查询、 替换、 比较、 截断、 拆分和合并等功能。
bytes 包也提供了很多类似功能的函数， 但是针对和字符串有着相同结构的 []byte 类型。 因为字符串是只读的， 因此逐步构建字符串会导致很多分配和复制。 在这种情况下， 使用 bytes.Buffer 类型将会更有效。
strconv 包提供了布尔型、 整型数、 浮点数和对应字符串的相互转换， 还提供了双引号转义相关的转换。
path 和 path/filepath 包提供了关于文件路径名更一般的函数操作。

Strings 包中常用 API：
func Contains(s, substr string) boolfunc Count(s, sep string) intfunc Fields(s string) []stringfunc HasPrefix(s, prefix string) boolfunc Index(s, sep string) intfunc Join(a []string, sep string) string//  所有函数func Clone(s string) stringfunc Compare(a, b string) intfunc Contains(s, substr string) boolfunc ContainsAny(s, chars string) boolfunc ContainsRune(s string, r rune) boolfunc Count(s, substr string) intfunc Cut(s, sep string) (before, after string, found bool)func EqualFold(s, t string) boolfunc Fields(s string) []stringfunc FieldsFunc(s string, f func(rune) bool) []stringfunc HasPrefix(s, prefix string) boolfunc HasSuffix(s, suffix string) boolfunc Index(s, substr string) intfunc IndexAny(s, chars string) intfunc IndexByte(s string, c byte) intfunc IndexFunc(s string, f func(rune) bool) intfunc IndexRune(s string, r rune) intfunc Join(elems []string, sep string) stringfunc LastIndex(s, substr string) intfunc LastIndexAny(s, chars string) intfunc LastIndexByte(s string, c byte) intfunc LastIndexFunc(s string, f func(rune) bool) intfunc Map(mapping func(rune) rune, s string) stringfunc Repeat(s string, count int) stringfunc Replace(s, old, new string, n int) stringfunc ReplaceAll(s, old, new string) stringfunc Split(s, sep string) []stringfunc SplitAfter(s, sep string) []stringfunc SplitAfterN(s, sep string, n int) []stringfunc SplitN(s, sep string, n int) []stringfunc Title(s string) stringDEPRECATEDfunc ToLower(s string) stringfunc ToLowerSpecial(c unicode.SpecialCase, s string) stringfunc ToTitle(s string) stringfunc ToTitleSpecial(c unicode.SpecialCase, s string) stringfunc ToUpper(s string) stringfunc ToUpperSpecial(c unicode.SpecialCase, s string) stringfunc ToValidUTF8(s, replacement string) stringfunc Trim(s, cutset string) stringfunc TrimFunc(s string, f func(rune) bool) stringfunc TrimLeft(s, cutset string) stringfunc TrimLeftFunc(s string, f func(rune) bool) stringfunc TrimPrefix(s, prefix string) stringfunc TrimRight(s, cutset string) stringfunc TrimRightFunc(s string, f func(rune) bool) stringfunc TrimSpace(s string) stringfunc TrimSuffix(s, suffix string) string

字符串常用函数

统计字符串的长度，按照 字节。
len(str)

遍历字符串，同时处理含有中文。
str := &quot;中国&quot;r := []rune(str)

字符串转整型
func Atoi(s string) (int, error)&#123;&#125;

整型转字符串
func Itoa(i int) string &#123;&#125;

字符串转 []byte
var bytes = []byte(&quot;hello&quot;)

[]byte 转 字符串
str := string([]byte&#123;97, 98, 99&#125;)

判断字符串 s 是否包含子串 substr。
func Contains(s, substr string) bool

统计一个字符串中有几个指定的字串。
func Count(s, sep string) int

判断两个 utf-8 编码字符串（将 unicode 大写、小写、标题三种格式字符视为相同）是否相同。
func EqualFold(s, t string) bool

注意：用 == 比较两个字符串是否相等，是区分大小写的。

将指定的字串替换为另一个字符串，返回一个替换后的新字符串，old string 没有发生被改变。传递的是值拷贝。
func Replace(s, old, new string, n int) string

n 为指定替换的个数。若 n &lt; 0，替换所有的老串。

将一个字符串，按照指定的分隔符分拆分为多个字串。
func Split(s, sep string) []string

将字符串左右两边的空格去掉
func TrimSpace(s string) string// fmt.Println(strings.TrimSpace(&quot;\t\n Hello, Gophers \n\t\r\n&quot;))

将字符串左右两边指定的字符串去掉
func Trim(s, cutset string) string// fmt.Print(strings.Trim(&quot;¡¡¡Hello, Gophers!!!&quot;, &quot;!¡&quot;))// 输出：Hello, Gophers

将字符串左边指定的字符串去掉
func TrimLeft(s string, cutset string) string

将字符串右边指定的字符串去掉
func TrimRight(s string, cutset string) string

bytes 包中常用 API：
func Contains(b, subslice []byte) boolfunc Count(s, sep []byte) intfunc Fields(s []byte) [][]bytefunc HasPrefix(s, prefix []byte) boolfunc Index(s, sep []byte) intfunc Join(s [][]byte, sep []byte) []byte

4.10.4. anyany 是 Go built-in package 中的一种类型，表示的是空接口（interface&#123;&#125;）的别名。**空接口 ** 表示可以接受任何类型的值。
原型
type any = interface&#123;&#125;


4.11. Composite Types(复合类型)4.11.1. Array数组是一个由固定长度的特定类型元素组成的序列， 一个数组可以由零个或多个元素组成。因为数组的长度是固定的， 因此在 Go 语言中很少直接使用数组。 和数组对应的类型是 Slice（ 切片） ， 它是可以增长和收缩动态序列， slice 功能也更灵活， 但是要理解 slice 工作原	理的话需要先理解数组。

Declaring an array set to its zero value// Declare an integer array of five elements.var array [5]int
Declaring an array using an array literal // Declare an integer array of five elements.// Initialize each element with a specific value.array := [5]int&#123;10, 20, 30, 40, 50&#125;
Declaring an array with Go calculating size// Declare an integer array.// Initialize each element with a specific value.// Capacity is determined based on the number of values initialized.array := [...]int&#123;10, 20, 30, 40, 50&#125;

4.11.2. SliceSlice（切片）切片是围绕动态数组的概念构建的，动态数组可以根据需要增长（grow）和收缩（shrink）。一个 slice 类型一般写作 []T， 其中 T 代表 slice 中元素的类型。slice 的语法和数组很像， 只是没有固定长度而已。  切片是数组的一个引用，因此切片是引用类型。但自身是结构体，值拷贝传递。
切片的定义
var 变量名 [] 类型// 比如:var str []stringvar arr []int// Create a slice of strings. Use build-in function make()// Contains a length and capacity of 5 elements.slice := make([]string, 5)// Create a slice of integers.// Contains a length of 3 and has a capacity of 5 elements.slice := make([]int, 3, 5)// Create a slice of integers.// Make the length larger than the capacity.slice := make([]int, 5, 3)Compiler Error:len larger than cap in make([]int)// Create a slice of strings.// Contains a length and capacity of 5 elements.slice := []string&#123;&quot;Red&quot;, &quot;Blue&quot;, &quot;Green&quot;, &quot;Yellow&quot;, &quot;Pink&quot;&#125;// Create a slice of integers.// Contains a length and capacity of 3 elements.slice := []int&#123;10, 20, 30&#125;// Create a nil slice of integers.var slice []int

一个 slice 是一个轻量级的数据结构，提供了访问数组子序列（或者全部）元素的功能，而且 slice 的底层确实引用一个数组对象。一个 slice 由三个部分构成：指针（addr pointer）、长度（length）和容量（capacity）。

指针指向第一个 slice 元素对应的底层数组元素的地址，要注意的是 slice 的第一个元素并不一定就是数组的第一个元素。长度对应 slice 中元素的数目。
长度不能超过容量。切片遍历方式和数组一样，可以用 len() 求长度。表示可用元素数量，读写操作不能超过该限制。
容量一般是从 slice 的开始位置到底层数据的结尾位置。内置的 len() 和 cap() 函数分别返回 slice 的长度和容量。
cap() 可以求出 slice 最大扩张容量，不能超出数组限制。0 &lt;= len(slice) &lt;= len(array)，其中 array 是 slice 引用的数组。
如果 slice == nil，那么 len、cap 结果都等于 0。



 注意：

slice 之间不能比较， 因此我们不能使用 == 操作符来判断两个 slice 是否含有全部相等元素。 不过标准库提供了高度优化的 bytes.Equal 函数来判断两个字节型 slice 是否相等 ，但是对于其他类型的 slice， 我们必须自己展开每个元素进行比较
判断一个 slice 值是否为空，使用 len(0) == 0 来判断，不应该使用 s = nil 去判断。

4.11.3. Map在 Go 语言中， 一个 map 就是一个哈希表的引用， map 类型可以写为 map[K]V， 其中 K 和 V 分别对应 key 和 value。 map 中所有的 key 都有相同的类型， 所有的 value 也有着相同的类型， 但是 key 和 value 之间可以是不同的数据类型。 其中 K 对应的 key 必须是支持 == 比较运算符的数据类型， 所以 map 可以通过测试 key 是否相等来判断是否已经存在。对于 V 对应的 value 数据类型则没有任何的限制。
用内置的 make 函数创建一个 map
m := make(map[string]int)

用 map literal 方式去创建 map 是很常用的方式。下面的代码中，创建一个 map 并同时给 map 赋初值。注：赋的初值可以为空值，形如：m := map[string]int &#123;&#125;。
m := map[string]int &#123;	&quot;John&quot;: 10,	&quot;Anna&quot;: 20&#125;

 Declaring a map that stores slices of strings
// Create a map using a slice of strings as the value.dict := map[int][]string&#123;&#125;

注意：

map 中的 key：** 切片、函数不能作为 key。**
// Create a map using a slice of strings as the key.dict := map[[]string]int&#123;&#125;// 编译器报错Compiler Exception:invalid map key type []string

map 中没有 cap() 函数，只有 len() 函数。

map 是无序的，无法决定返回值的顺序，每次打印的返回值的结果可能不一样。



读&gt;&gt;写时，建议用 sync.Map。写&gt;&gt;读时，建议用 runtime.map。读&#x3D;写时，建议用 courrentMap。

4.11.4. Struct结构体声明
type 结构体名称 struct &#123;	field1 type	field2 type&#125;// 示例type Stu struct &#123;    Name string    Id int&#125;

结构体中的属性名首字母大写，外部的包可以访问结构体中的变量，若属性的首字母是小写，只能在当前的包中可以访问。
创建一个结构体后，若没有给结构体赋初值，编译器会默认给结构中的字段一个零值。布尔类型是 false，整型是 0，字符串是 &quot;&quot;，指 针、slice、map 的零值都是 nil，即还没有分配空间；数组的默认值和它的元素类型有关。
如果结构体没有任何成员的话就是空结构体， 写作 struct&#123;&#125;， 它的大小为 0， 不包含任何信息。
4.11.4.1. unname定义：没有名字的结构体，通常只用于在代码中仅使用一次的结构类型。
func showMyCar() &#123;    newCar := struct &#123;        make    string        model   string        mileage int    &#125;&#123;        make:    &quot;Ford&quot;,        model:   &quot;Taurus&quot;,        mileage: 200000,    &#125;    fmt.Printlb(newCar.mode)&#125;

使用的好处：如果一个结构体初始化后只被使用一次，那么使用匿名结构体就会很方便，不用在程序的 package 中定义太多的结构体类型，比如在解析接口的响应到结构体后，就可以使用匿名结构体
注意

结构体数据拷贝默认是 值拷贝 的。
结构体中所有字段在内存中都是连续分配的。
结构体是用户单独定义的类型，结构体之间相互转换时，需要结构体完全一样，即结构体的名字、字段个数、类型。// 结构体 A 可以转化为结构体 Btype A struct &#123;	Num int&#125;type B type &#123;	Num int&#125;
结构体进行 type 重定义（相当于取别名），Golang 认为是新的数据类型，二者之间可以强转。type Teacher struct &#123;	ID   int	Name string&#125;type YuanDing Teacher // Golang 认为 YuanDing 是一种新的数据类型var t1 Teachervar y1 YuanDing// t1 = y1 // error：y1 与 t1 之间不能互转t1 = Teacher(y1) // 强转fmt.Println(&quot;t1:&quot;, t1, &quot;y1:&quot;, y1)
struct 的每个字段上，可以写一个 tag，该 tag 可以通过 反射机制 获取。常见的场景就是序列化和反序列化。

for range 循环用于迭代 array、slice、map 和 channel，但不适用于结构体类型。
5. 语言特性5.1. Function(函数)5.1.1. 函数声明函数声明包括函数名、 形式参数列表、 返回值列表（ 可省略） 以及函数体
func name(parameter-list) (result-list) &#123;	body&#125;

当调用一个函数的时候， 函数的每个调用参数将会被赋值给函数内部的参数变量， 所以 函数参数变量接收的是一个复制的副本， 并不是原始调用的变量。 因为函数参数传递的机制导致传递大的数组类型将是低效的， 并且对数组参数的任何的修改都是发生在复制的数组上， 并不能直接修改调用时原始的数组变量。
5.1.2. 多返回值5.1.3. 错误5.1.4. 匿名函数5.1.5. 可变参数5.1.6. Panic(异常)Golang 的类型系统会在编译时捕获很多错误， 但有些错误只能在运行时检查， 如数组访问越界、空指针引用等。 这些运行时错误会引起 painc 异常。
一般而言， 当 panic 异常发生时， 程序会中断运行，并立即执行在该 goroutine 中被延迟的函数（defer 机制）。 随后， 程序崩溃并输出日志信息。 日志信息包括 panic value 和函数调用的堆栈跟踪信息。 panic value 通常是某种错误信息。
对于每个 goroutine（协程），日志信息中都会有与之相对的， 发生 panic 时的函数调用堆栈跟踪信息。 通常， 我们不需要再次运行程序去定位问题， 日志信息已经提供了足够的诊断依据。 因此， 在我们填写问题报告时， 一般会将 panic 异常和日志信息一并记录。
错误处理策略

传播错误
重新尝试失败的操作。如果错误的发生是偶然性的， 或由不可预知的问题导致的。 一个明智的选择是重新尝试失败的操作。 在重试时， 我们需要限制重试的时间间隔或重试的次数， 防止无限制的重试。
输出错误信息并结束程序。 需要注意的是， 这种策略只应在 main 中执行。 对库函数而言， 应仅向上传播错误， 除非该错误意味着程序内部包含不一致性， 即遇到了 bug， 才能在库函数中结束程序  。
只需要输出错误信息，不需要中断程序的运行。
直接忽略掉错误信息。

自定义错误
Go 语言中也支持自定义错误，使用内置的 errors.New() 和 内置的 panic() 函数即可。

errors.New(&quot;错误说明&quot;)：返回一个 error 类型的值，表示一个错误。内置的 error 是接口类型。可能是 nil 或者 non-nil。 nil 表示函数运行成功， non-nil 表示失败。
panic() 函数：接收一个 error 类型的的变量，输出错误信息，并退出程序。因为 panic(v interface&#123;&#125;) 函数的参数类型为空接口（interface&#123;&#125;），任何一个变量都可以赋值给空接口。

5.1.7. defer(延迟调用)defer 是 Go 中的一个关键字，用于延迟调用。
为什么要使用 defer?

在函数中程序员经常要创建资源（比如：数据库连接、文件句柄、锁），在函数结束时，及时的释放申请的资源，这时就要用到 defer。

在调用普通函数或方法前加上关键字 defer， 就完成了 defer 所需要的语法。 当 defer 语句被执行时， 跟在 defer 后面的函数会被延迟执行。 直到包含该 defer 语句的函数执行完毕时，defer 后的函数才会被执行， 不论包含 defer 语句的函数是通过 return 正常结束， 还是由于 panic 导致的异常结束。 你可以在一个函数中执行多条 defer 语句， 它们的执行顺序与声明顺序相反  。

多个 defer 语句执行顺序：按 先进后出 的方式。

defer 语句中的变量，在 defer 声明时就决定了。
func Test() &#123;var n1, n2 = 10, 20   defer fmt.Println(n1) // 10   defer fmt.Println(n2) // 20   n1++   n2++   sum := n1 + n2     // sum= 11 + 21   defer fmt.Println(sum)&#125;

只能放在函数或方法的内部。


5.1.8. Recoverrecover 是 Go 语言内置的一个函数。如果在 defer 函数中调用了内置函数 recover， 并且定义该 defer 语句的函数发生了 panic 异常， recover 会使程序从 panic 中恢复， 并返回 panic value。 导致 panic 异常的函数不会继续运行， 但能正常返回。 在未发生 panic 时调用 recover， recover 会返回 nil。
注意：recover 只有在 defer 调用的函数中有效。
Golang 对错误处理的方式，引入了 Panic、defer、recover 机制，而不再使用传统的  try...catch...finally 机制去处理异常，Go 语言追求简洁优雅。
使用的方式：Go 抛出一个 Panic 异常，在 defer 中用内置函数 recover() 去捕获异常，然后再正常处理。
5.2. Object Oriented Programming(面向对象)Golang 中没有类（class），只有结构体 struct。Golang 是基于 struct 来实现面向对象的。
Golang 面向对象编程非常简洁，去掉了传统面向对象的继承、方法重载、构造函数、析构函数、隐藏的 this 指针。
Golang 中仍然有面向对象编程的继承、封装、多态的特性，只是实现的方式和其它的语言不一样。比如，Golang 中的 继承 是通过 匿名字段 来实现的。
面向对象编程的步骤：

声明结构体，确定结构体的名字。
编写结构体的字段。
编写结构体的方法。

5.2.1. Method(方法)函数声明时，在函数名字之前放了一个变量，就是一个方法。这个变量叫接收者，可以是普通类型或者是结构体。
// 函数func functionName(参数列表)(返回值列表)&#123;&#125;// 方法func (recevier type) methodName(参数列表)(返回值列表)&#123;	方法体    return 返回值&#125;

Go 语言的面向对象机制与一般语言不同。它没有类层次结构，甚至可以说没有类；仅仅通过组合（而不是继承）简单的对象来构建复杂的对象。
注意

方法作用在指定的类型上。这个类型可以是 结构体，也可以 任何用户自定义的类型；并且，具体类型和抽象类型（接口）之间的关系是隐式的，所以很多类型的设计者可能并不知道该类型到底实现了哪些接口。

一般方法中的类型与结构体绑定，采用 传指针 的方式，这样做的效率高。

方法的访问范围的控制规则和函数一样：若方法名首字母大写，可在本包和其它包访问；若方法名小写，只能在本包中访问。

自定义实现了 String() 方法，用 fmt.Printf() 函数调用时，优先执行自己定义实现的  String() 方法，而不是去执行 Go 中自带的  String() 方法。
// 重写 String() 方法type Student struct &#123;	Name  string	Score int&#125;func (stu *Student) String() string &#123;	str := fmt.Sprintf(&quot;Name=%s, Score=%d&quot;, stu.Name, stu.Score)	return str&#125;

5.2.2. Encapsulation(封装)封装就是把抽象的 字段和对字段的操作封装在一起，数据被保护在内部，程序的其它包只有通过授权的操作，才能对字段进行访问。
如何体现封装的特性.

对结构体中的属性进行封装
通过方法、包实现封装。

说明：Golang 中没有特别强调封装，对面向对象的特性做了简化。
5.2.3. Inheritance(继承)为什么需要继承？

类似功能的代码冗余，不利于维护，不利于功能的扩展。

继承的实现

通过嵌入一个匿名结构体来实现继承。也就是说，在 Golang 中，如果一个 struct 嵌套了另一个匿名结构体，那么这个结构体可以直接访问匿名结构体的字段和方法，从而实现了继承特性。

基本语法
type Goods struct &#123;	Name  string	Price float64&#125;type Books struct &#123;	Goods // 嵌套的匿名结构体	Color string&#125;

注意点

新的结构体可以使用嵌套匿名结构体中所有的字段和方法，无论是这个匿名结构体中字段、方法的首字母是否是大小写。

匿名结构体字段访问可以简化结构体的名字。
type A struct &#123;    Name string    Age int&#125;type B struct &#123;    A    Score int&#125;// 调用var b1 Bb1.Name = &quot;Xue&quot;  // 等价于 b1.A.Name = &quot;Xue&quot;b1.Age = 66b1.Score  // 调用 B 结构体中自己的字段

当结构体和匿名结构体有相同的字段或者方法时，编译器采用 就近访问 原则；若希望访问匿名结构体中的字段和方法，则要通过匿名结构体名字来区分，这时不能省略匿名结构体的名字。
type A struct &#123;    Name string    Age int&#125;type B struct &#123;    A    Name string&#125;// 调用var b1 Bb1.Name = &quot;Xue&quot;  // 调用的是 B 自己的字段 Nameb1.Age = 66      // 调用匿名结构体 A 中的字段b1.A.Name = &quot;Good&quot;  // 调用匿名结构体 A 中的字段 Name，此时结构体名 A 不能省略

结构体嵌入两个或者多个匿名结构体，例如，两个匿名结构体有相同的字段和方法（新的结构体本身没有同名的字段和方法），在访问时，必须明确指定匿名结构体的名字，否则编译器报错。
type A struct &#123;    Name string    Age int&#125;type B struct &#123;    Name string    Score int&#125;type C struct &#123;    A    B    // 没有 Name    // name string&#125;// 调用var c1 Cc1.A.Name = &quot;wangyi&quot;c2.B.Name = &quot;lier&quot;

如果一个 struct 嵌套了一个有名的结构体，这种模式就是组合，那么在访问有名的结构体的字段或方法时，必须带上结构体的名字。
type A struct &#123;    Name string    Age int&#125;type B struct &#123;    a A&#125;// 调用var b2 Bb2.a.Name = &quot;Mike&quot;be.a.Age = 20

如果一个 struct 中嵌套了多个匿名结构体，那么该结构体直接可以访问匿名结构体中的字段和方法，从而实现了 多重继承。在 Golang 开发中，为了代码的简洁性，尽量不使用多重继承。


5.2.4. polymorphism(多态)接口体现多态的两种方式

多态参数
多态数组

5.2.5. Interfaces(接口)Go 语言的接口（interface）是一种抽象的 类型，interface 是一组方法（method ）的集合。接口做的事情就像是定义一个协议（规则），不关心属性，只关心方法。
为什么要有接口？

降低代码的耦合性。

接口声明的通用形式：
type 接口类型名 interface&#123;    // 声明的方法不需要实现，在外部去实现所有的方法	方法名 1(参数列表 1) 返回值列表 1	方法名 2(参数列表 2) 返回值列表 2	…&#125;

每个接口由数个方法组成。
// 示例type usb interface &#123;	// 两个方法	Start()	Stop()&#125;

注意

接口里的方法都没有方法体，即接口中的方法是没有实现的。接口体现了程序设计的多态和高内聚低耦合的思想。

Go 语言推荐尽量定义小的接口，并通过接口组合的方式构建程序。尽量让一个接口中的方法数量控制在 1-3 个内。
将方法写的小优势

接口越小，抽象度越高，被接纳程度越高。
易于实现和测试。
指责单一，易于复合使用。


对于接口类型，优先以单个单词命令。对于拥有一个或多个方法的接口组合而成的接口，Go 语言的惯例是用 方法名+er这样的方式来命名。
type Writer interface &#123;	Write(p []byte) (n int, err error)&#125;type Reader interface &#123;	Read(p []byte) (n, int, err error)&#125;type Closer interface &#123;	Close() error&#125;type ReadWriteCloser interface &#123;	Reader	Writer	Closer&#125;

Golang 中的接口不需要显示的实现，即不需要指定结构体或者变量具体实现了哪些接口。只需要将接口中的所有方法都实现就可以了。

Golang 的接口里面不能有任何的变量。
type Say interface &#123;	MyPrint() // ok	Name string // error&#125;

一个接口（A）可以继承多个接口（B、C），如果要实现接口 A，也必须把接口 B、C 也实现。注意：接口 B、C 中不能有相同的方法。
type A interface &#123;    Test01()&#125;type B interface &#123;    Test02()&#125;// C 接口中继承了两个接口type C interface &#123;    Test03()    A    B&#125;

interface 类型默认是一个指针（引用类型），若没有初始化 interface 就是用，那么默认值为 nil。

空接口中没有任何的方法，所有的类型都实现了空接口 。即任何一个变量都可以赋值给空接口。（很常用）
type Stu struct &#123;	Name string&#125;// 空接口type T interface &#123;&#125;// 调用var stu = Stuvar t1 T = stu   // 赋结构体类型f := 3.14var t2 interface&#123;&#125; = f // 赋基础类型

尽量减少将空接口（interface&#123;&#125;）作为函数的参数类型，因为空接口类型编译时会逃过编译器的类型安全检查。需要编程者自己去检查传入参数的错误信息，并且直到运行时才能发现错误。


空接口应用

空接口作为函数的参数  // 空接口作为函数参数// 实现可以接收任意类型的函数参数func show(a interface&#123;&#125;) &#123;    fmt.Printf(&quot;type:%T value:%v\n&quot;, a, a)&#125;
空接口作为map的值  // 空接口作为map值，可以保存任意值的字典var studentInfo = make(map[string]interface&#123;&#125;)studentInfo[&quot;name&quot;] = &quot;李白&quot;studentInfo[&quot;age&quot;] = 18studentInfo[&quot;married&quot;] = falsefmt.Println(studentInfo)

Go 中的 interface 底层包含 2 中：eface、iface。
interface 赋值的过程，即为 iface、eface 生成的过程。如果编译阶段编译器无法确定 interface 类型（比如 :iface 入参）会通过 conv 完成打包，有可能会导致逃逸。

很多对 interface 类型的赋值(并非所有)，都会导致空间的分配和拷贝，这也是 Interface 函数为什么可能会导致逃逸的原因 go 这么做的主要原因：逃逸的分析位于编译阶段，对于不确定的类型在堆上分配最为合适。

5.2.6. Type Assertions(类型断言)类型断言（Type Assertion）是在编程语言中用于判断和转换值类型的操作。在 Go 语言中，类型断言被用于从接口类型中提取出具体的值，并判断其是否为特定的类型。 语法上它看起来像 x.(T) 被称为断言类型， 这里 x 表示类型为interface&#123;&#125;的变量，T 表示断言 x 可能是的类型。
在 Go 中，类型断言有两种形式：

单个值的类型断言：
value, ok := x.(T)
这种形式的类型断言用于从接口值 x 中提取出具体的值，并将其转换为类型 T。如果 x 的类型可以转换为 T，则断言成功，value 将接收转换后的值，ok 的值为 true。如果断言失败，即 x 的类型不能转换为 T，则 value 将得到 T 类型的零值，ok 的值为 false。

类型检查的类型断言：
_, ok := x.(T)
 这种形式的类型断言只关注接口值 x 的类型是否可以转换为类型 T。如果可以转换，ok 的值为 true，否则为 false。这种形式的类型断言通常用于 判断某个接口值是否满足特定的接口类型。


需要注意的是，类型断言只能应用于接口类型的值。它将接口值分为两个部分：底层的具体值和该值的类型信息。类型断言可以提取底层的具体值，并检查该值是否与目标类型兼容。
以下是一个示例，展示了在 Go 中的类型断言的用法：
// interface&#123;&#125; 为空接口var x interface&#123;&#125; = &quot;Hello&quot;value, ok := x.(string)if ok &#123;    fmt.Println(&quot;Value:&quot;, value)&#125; else &#123;    fmt.Println(&quot;Type assertion failed&quot;)&#125;

在上述示例中，我们将字符串 &quot;Hello&quot; 赋值给接口变量 x。然后，使用类型断言判断 x 的底层类型是否为 string 类型。由于 x 的底层类型是 string，类型断言成功，value 变量接收到转换后的字符串值，并打印输出。
类型断言在 Go 中常用于处理接口类型的值，可以根据具体的类型执行特定的操作或获取特定的属性。然而，应谨慎使用类型断言，确保断言的正确性，以避免运行时的类型错误。
另一个示例来辅助说明。
package mainimport &quot;fmt&quot;type Point struct &#123;	x int	y int&#125;func main() &#123;	var a interface&#123;&#125;	var p1 Point = Point&#123;10, 20&#125;	a = p1 // ok	var p2 Point	// p2 = a // error	p2 = a.(Point) // 使用类型断言	fmt.Println(p2)&#125;

注意：

类型断言是一个作用在接口值上的操作。
接口是一般的类型，不知道具体类型，要将接口转化为具体的类型，就需要使用断言。
使用空接口和类型断言可能会导致运行时的类型错误，因为类型断言是在 ** 运行时 ** 进行的。因此，在使用空接口和类型断言时，需要确保值的实际类型与预期类型匹配，或者通过适当的错误处理来处理类型不匹配的情况。

5.2.7. constructor(构造函数)在许多编程语言中，构造函数（constructor）是一种用于创建和初始化对象的特殊方法。它的主要目的是在对象创建时执行必要的初始化操作，并确保对象的有效状态。
然而，在 Go 语言中，并没有像其他语言中的构造函数那样的特殊语法或关键字。相反，Go 推崇简洁性和灵活性，通过 普通的函数和结构体组合来实现对象的创建和初始化。
尽管如此，为什么还要模拟构造函数呢？以下是一些可能的原因：

初始化对象：通过模拟构造函数，可以将对象的创建和初始化过程封装在一个函数中，使代码更加清晰和可读。它可以在一个地方集中处理对象的初始化逻辑，减少重复代码。
隐藏内部实现：模拟构造函数可以帮助隐藏对象的内部实现细节，将对象的创建过程与外部调用代码分离。这样，外部代码只需要关注如何使用对象，而无需了解其创建和初始化的具体细节。
提供参数化初始化：构造函数的模拟可以接收参数，并根据不同的参数值创建不同的对象实例。这样可以在创建对象时根据需要进行个性化的初始化。
简化对象的创建：通过构造函数的模拟，可以简化对象的创建过程，尤其是在需要进行多个初始化步骤或依赖注入时。它可以封装复杂的初始化逻辑，使代码更易于维护和扩展。

需要注意的是，尽管模拟构造函数在某些情况下可以提供便利和代码组织上的好处，但在 Go 语言中，并没有像其他语言那样的语言级别的构造函数概念。因此，它仍然只是一种模拟，并没有与语言本身的特性和语法相对应。
5.3. 泛型函数的泛型参数是一种在函数定义中使用的通用类型参数，可以用于表示多种不同的类型。在 Go 语言中，从 Go 1.18 版本开始引入了 泛型特性，允许开发者定义具有泛型参数的函数、方法和数据结构。
泛型参数使用方括号（**[]**）包围，并在函数名后面紧跟泛型参数列表。泛型参数可以是任何合法的标识符，用于表示类型的占位符。通过将泛型参数放在函数签名中，可以在函数体内使用它们作为类型的抽象。
泛型参数的主要作用是增加代码的复用性和灵活性，使函数能够适用于多种类型，而不仅仅局限于特定的类型。通过使用泛型参数，可以编写更通用、更灵活的函数，减少代码的重复编写。
以下是一个示例函数，展示了如何在 Go 语言中定义带有泛型参数的函数：
codefunc PrintSlice[T any](slice []T) &#123;    for _, element := range slice &#123;        fmt.Println(element)    &#125;&#125;

在上面的示例中，PrintSlice 函数定义了一个泛型参数 T，它接受一个切片 slice 作为参数。在函数体内，可以使用 T 来表示切片中的元素类型，实现对切片元素的打印。
通过在函数调用时指定具体的类型，可以使用 PrintSlice 函数打印不同类型的切片。例如：
codeintSlice := []int&#123;1, 2, 3&#125;PrintSlice(intSlice)stringSlice := []string&#123;&quot;Hello&quot;, &quot;World&quot;&#125;PrintSlice(stringSlice)

在上述示例中，PrintSlice 函数被分别调用了两次，一次传入 int 类型的切片，一次传入 string 类型的切片。由于函数使用了泛型参数 T，它能够适用于不同类型的切片。
注意：

泛型参数只在函数内部有效，它们的作用范围仅限于函数体内。在函数外部是无法直接使用泛型参数的，因为泛型参数在编译时会被具体的类型替换。
一个泛型类型必须被实例化才能被用作值类型。

6. Concurrency(并发)Go 并发采用 goroutines 和 channel 去处理并发编程。
6.1. Goroutine6.1.1. 概念在 Go 语言中， 每一个并发的执行单元叫作一个 goroutine，即协程。 设想这里的一个程序有两个函数，一个函数做计算， 另一个输出结果， 假设两个函数没有相互之间的调用关系。 一个线性的程序会先调用其中的一个函数， 然后再调用另一个。 如果程序中包含多个 goroutine， 对两个函数的调用则可能发生在同一时刻。
如果你使用过操作系统或者其它语言提供的线程， 那么你可以简单地把 goroutine 类比作一个线程， 这样你就可以写出一些正确的程序了。
当一个程序启动时， 其主函数即在一个单独的 goroutine 中运行， 我们叫它 main goroutine。 新的 goroutine 会用 go 语句来创建。 在语法上， go 语句是一个普通的函数或方法调用前加上关键字go。 Go 语句会使其语句中的函数在一个新创建的 goroutine 中运行， 而 go 语句本身会迅速地完成。
func gt() &#123;	// 函数体	...&#125;// 调用go gt() // 创建一个协程去调用函数 gt()

简而言之：协程就是一个轻量级的线程（编译器做了优化），一个 Go 主线程，可以起多个协程，很轻松的开启上万个协程。
**并发(comcurrency)**：多线程在单核上运行。从微观上看，同一时间上只有一个任务在执行，这个时间点很短，短的肉眼无法分辨。
**并行(parallelism)**：多线程在多核上运行。从微观上看，同一时间点，有多个任务在同时执行。即不同的代码片段同时在不同的物理处 理器上执行。
在很多情况下，并发的效果比并行好，因为操作系统和硬件的 总资源一般很少，但能支持系统同时做很多事情。
如果希望让 goroutine 并行，必须使用多于一个逻辑处理器。当有多个逻辑处理器时，调度器 会将 goroutine 平等分配到每个逻辑处理器上。这会让 goroutine 在不同的线程上运行。不过要想真 的实现并行的效果，用户需要让自己的程序运行在有多个物理处理器的机器上。否则，哪怕 Go 语 言运行时使用多个线程，goroutine 依然会在同一个物理处理器上并发运行，达不到并行的效果。
6.1.2. 特点
有独立的栈空间。Go 运行时默认为每个 goroutine 分配的栈空间为 2KB。
共享程序堆空间
调度由用户控制。goroutine 调度的切换也并不用陷入（trap）操作系统内核完成，代价很低。

6.1.3. goroutine schedulergoroutine 调度器：将 goroutine  按照一定的算法放到 CPU 上执行的程序就叫协程调度器。
6.2. Channel一个 channel 是一个通信机制，让一个 goroutine 通过  channel 给另一个 goroutine 发送信息。 每个 channel 都有一个特殊的类型， 也就是 channels 可发送数据的类型。
6.2.1. 声明 channel// 通用用法var 变量名 chan type// 示例，声明一个 int 类型的 channelvar flow chan int

注意点

channel 是引用类型
channel 必须初始化后才能写入数据，即必须使用 make 创建之后才能用。

6.2.2. 创建 channel// 发送 int 类型数据；其中 cap 表示容量，可以省略ch := make(chan int, cap)

注意点：

channel 的本质就是一个数据结构 队列。
channel 本身是线程安全的，多个协程同时访问时，不需要加锁。
channel 是有类型的，指定了管道的类型，管道中就只能存放该类型。
channel 的容量是在 make 时就指定了，不能自动增长，超过容量时，会报错。
在没有使用协程的情形下，若管道中的数据已全部取出，再取就报 deadlock 错误。
同步操作：通道上的发送和接收操作是原子性的，保证了数据的一致性和可靠性。
阻塞机制：当通道为空时，接收操作会阻塞等待数据；当通道满时，发送操作会阻塞等待空间。

6.2.3. 关闭 channel使用内置的函数 close() 可以关闭 channel，当管道关闭后，就不能向管道中 写（write）数据 了，但是仍然可以从管道中 读（read）数据。
6.2.4. 遍历 channelchannel 支持 for ... range 的方式进行遍历。不能用普通的 for 循环，因为在遍历时，管道的长度是动态变化的。
遍历时请注意下面的细节：

遍历时，若 channel 没有关闭，返回时则出现 deadlock 错误。
遍历时，若 channel 已经关闭，则会正常遍历数据，遍历完后，退出循环。

6.2.5. 注意事项
默认情况下，管道是双向的。
// 声明双向管道var c1 chan int

声明为只读的管道，不能往管道中写入数据。
// 声明只读管道var c2 &lt;-chan int

声明为只写的管道，不能从管道中读数据。
// 声明只写的管道var c3 chan&lt;- int

使用 select  解决从管道中取（read）数据阻塞的问题。在实际的开发中，可能遇见比较复杂的需求，无法确定什么时候关闭 channel？若不关闭就会导致 deadlock 问题，这时 select 就派上用场了。
语法格式：
select &#123;    case v1 := &lt;- 管道 1:    ...    case v2 := &lt;- 管道 2:    ....    case v3 := &lt;- 管道 3:    ...    default:    ...&#125;// 示例intChan := make(chan int, 10) // 定义一个 int 类型的管道，其容量为 10，并创建stringChan := make(chan string, 10)select &#123;    case v1 := &lt;-intchan:   		fmt.Println(v1)    case v2 := &lt;-stringchan:    	fmt.Println(v2)    default:    	fmt.Println(&quot;nothing...&quot;)&#125;

使用 select 实现多路 channel 的并发控制。

协程（goroutine）中使用 recover ，解决协程中出现异常（Panic）导致程序崩溃的问题。
一个协程出现了问题导致其它的协程不能工作，致使整个程序崩溃掉。这时我们就可以在出现问题的协程中使用 recover 来捕获异常（Panic），进行处理，即使这个协程发生问题，不会影响其它的协程，程序照样正常运行。


6.2.6. 应用场景
消息收发
超时机制
定时器

6.3. 竞争(data race)6.3.1. 原子函数(atmoic)func incCountAtomic() &#123;	defer wg111.Done()	for i := 0; i &lt; 2; i++ &#123;		atomic.AddInt32(&amp;count, 1)		runtime.Gosched()	&#125;&#125;

常见的原子函数
LoadInt64StoreInt64LoadInt32StoreInt32LoadPointerStorePointer

注意：原子函数操作的数据类型都比较简单，不容易处理复杂的组合数据类型或者带有逻辑的大代码。
6.3.2. MutexGo提供了另外一个sync包，用对代码段加锁解锁的办法来解决；这段代码叫做“临界区”。临界区在同一时刻只能有一个 goroutine 访问；这段代码就是同步执行的
func incCountSync() &#123;	defer wg111.Done()	for i := 0; i &lt; 2; i++ &#123;		mutex.Lock()		value := count		runtime.Gosched()		value++		count = value		mutex.Unlock()	&#125;&#125;

注意：锁住的代码段开销尽量小，否则肯定影响性能。
6.3.3. RWMutex读写锁：允许只读操作可以并发执行，写操作需要获得完全独享的访问权限。Golang 中读写锁的类型是 sync.RWMutex
var mu sync.RWMutexvar balance intfunc Balance() int &#123;	mu.RLock()	defer mu.RUnlock()	return balance&#125;

注意：

仅在绝大部分goroutine都在获取读锁并且锁竞争比较激烈的时（即：goroutine一般都需要等待后才能获取锁），RWMutex才有优势。因为RWMutex需要更复杂的内部记录工作，所以在竞争不激烈的时候他比普通互斥锁还要慢。

7. Package(包)利用 Go 自带的工具，使用单个命令完成编译、测试、基准测试、代码格式化、文档以及其他诸多任务。
Go 以包的形式来管理文件和项目目录结构的。所有的 go 代码都被组织在包中。一个包其实就是包含很多 .go 文件的一个路径，这样就实现了代码的组织和互相隔离，阅读代码从一个包开始。要想写好 go 代码，要不断理解包和基于包多实践。
7.1. init function每个包可以包含任意多个 init 函数，这些函数都会在程序执行开始的时候被串行调用且仅调用执行一次。所有被编译器发现的 init 函数都会安排在 main 函数之前执行。
 init 函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作。
在同一个源文件中声明的init函数将按从上到下的顺序被调用执行。 对于声明在同一个包中的 两个不同源文件中的两个init函数，Go语言白皮书推荐（但不强求）按照它们所处于的源文件的 名称的词典序列（对英文来说，即字母顺序）来调用。 所以最好不要让声明在同一个包中的两个 不同源文件中的两个init函数存在依赖关系。 
在加载一个代码包的时候，此代码包中声明的所有包级变量都将在此包中的任何一个init函数执 行之前初始化完毕。
7.2. 包的作用
区分相同名字的函数、变量等标识符。
当项目的文件很多时，可以很好的管理项目。
控制函数、变量等访问的范围。

7.3. 注意事项
一个 package 对应一个文件夹。 文件的 package 名通常与文件所在的文件名字一致，一般为小写字母。
在 import 包时，路径从 $GOPATH 的 src 下开始，不用带 src，编译器自动从 src 下开始引入。
为了让其它的包文件，可以访问到本包的函数，该函数名的是字母必须大写，类似其它语言中的 public，这样才能挎包访问。若函数名的首字母是小写，函数只能在当前的包中使用，类似于其它语言的 private。
访问其它的包函数或变量时，其语法格式是：包名. 函数名包名. 变量名
在同一个包下不能有相同的两个函数名，否则会报重复定义。

7.4. 包之间调用1、不同包之间是同一级目录

同一个目录时，包 1 去调用 包 2，包 2 中的包名必须和包 1 中一样。
包 1 去调用 包 2 中的函数，包 1 中直接调用 包 2 中函数即可，不需要引用包 2 名中的包名。

2、不同包之间是不同的目录

一个包去调用另外一个包，先导入另一个包，函数调用格式：包名. 函数名
另一个包中的函数名称的首字母必须大写，若是小写字母，调用的包不能识别当前包中的函数。

7.5. 打包打包基本语法
package 包名


7.6. 导入包import 语句告诉编译器到磁盘的哪里去找想要导入的包。导入包需要使用关键字 import，它会告诉编译器你想引用该位置的包内的代码。如果需要导入多个包，习惯上是将 import 语句包装在一个导入块中
每个包是由一个全局唯一的字符串所标识的导入路径定位。
导入包的基本语法
import &quot;包路径&quot;

多种方式导入包
// 导入单个包import &quot;fmt&quot;// 导入多个包import (	&quot;fmt&quot;    &quot;os&quot;)// 给导入的包起一个别名import io &quot;fmt&quot;io.Println(&quot;调用包别名&quot;)// 忽略导入的包。目的：为了调用包里面的 init 函数import _ &quot;fmt&quot;

编译器会使用 Go 环境变量设置的路径，通过引入的相对路径来查找磁盘上的包。标准库中的包会在安装 Go 的位置找到。 Go 开发者创建的包会在 GOPATH 环境变量指定的目录里查找。GOPATH 指定的这些目录就是开发者的个人工作空间。
8. Reflection(反射)反射是一个强大的编程工具，是一种程序在运行期间审视自己的能力。
8.1. 概念Go 语言提供了一种机制， 能够在运行时更新变量和检查它们的值、 调用它们的方法和它们支持的内在操作， 而不需要在编译时就知道这些变量的具体类型， 这种机制被称为反射。
8.2. 重要 API
reflect.TypeOf(变量名)：获取变量的类型，返回 reflect.Type 类型。
reflect.ValueOf(变量名)：获取变量的值，返回 reflect.Value 类型，reflect.Value 是一个结构体类型。type Value struct &#123;    // 内含隐藏或非导出字段&#125;
reflect.Value.Elem()：Elem 返回 v 持有的接口保管的值的 Value 封装，或者 v 持有的指针指向的值的 Value 封装。num := 100rval := reflect.Value(&amp;num) // 传入的时 num 地址rval.Elem().SetInt(200) // 改变传入的 int 类型的值fmt.Println(&quot;value&quot;: num)  // num=200

例子：利用反射去获取结构体的字段、方法、标签。
8.3. 注意事项
基于反射的代码是比较脆弱的。 对于每一个会导致编译器报告类型错误的问题， 在反射中都有与之相对应的误用问题， 不同的是编译器会在构建时马上报告错误， 而反射则是在真正运行到的时候才会抛出 panic 异常， 可能是写完代码很久之后了， 而且程序也可能运行了很长的时间。
即使对应类型提供了相同文档， 但是反射的操作不能做静态类型检查， 而且大量反射的代码通常难以理解。
基于反射的代码通常比正常的代码运行速度慢一到两个数量级。

9. Problems大规模软件开发存在的问题。

程序构建慢；
依赖复杂；
开发人员使用编程语言的不同子集。
代码理解性差；（可读性差、文档差）
功能重复实现；
升级更新消耗大；
实现自动化工具难度高；
版本问题；
跨语言问题；

10. Garbage Collector(垃圾回收)在 Go 语言中，内存的分配和释放是由垃圾回收器（Garbage Collector）自动处理的，而不需要显式地进行手动内存管理。
垃圾回收器会自动跟踪对象的引用和使用情况，在对象不再被引用时自动回收其所占用的内存。
开发者可以专注于业务逻辑而无需手动管理内存。通过使用 new 函数创建对象后，当对象不再被引用时，垃圾回收器会自动将其标记为不可达，并在适当的时候回收其占用的内存。
11. References
Go 官方英文文档：https://go.dev/
Go 官方英文标准库：https://pkg.go.dev/std
Go 官方 Github 源码：https://github.com/golang/go
Go 官方 Wiki：https://github.com/golang/go/wiki
Go 官方命令文档: https://pkg.go.dev/cmd/go
Github 英文 Go 开发者成长路线图：https://github.com/Alikhll/golang-developer-roadmap
Go Slice Tricks Cheat Sheet: https://ueokande.github.io/go-slice-tricks/
golang goproxy.cn: https://goproxy.cn


Project structure

Gihub golang-standards: https://github.com/golang-standards/project-layout 
golang 编程规范 - 项目目录结构：https://makeoptim.com/golang/standards/project-layout/
Go 工程化 (二) 项目目录结构 Go 工程化 (二) 项目目录结构：https://lailin.xyz/post/go-training-week4-project-layout.html


Packages

Package names: https://go.dev/blog/package-names
Style guideline for Go packages: https://rakyll.org/style-packages/
Github paper-code: https://github.com/danceyoung/paper-code/tree/master 对一些好的技术文章结合自己的实践经验进行翻译、举例说明等或自己的经验分享。主要包括架构设计、模式设计、模型设计、重构及源码解析等。


Testing

极客兔兔 Go Test 单元测试简明教程：https://geektutu.com/post/quick-go-test.html
Go单测从零到溜系列0—单元测试基础：https://www.liwenzhou.com/posts/Go/unit-test-0/


Garbage

Go 官网 A Guide to the Go Garbage Collector: https://tip.golang.org/doc/gc-guide


Reflection

https://halfrost.com/go_reflection


Tutorials

Go 教程：https://www.topgoer.com/ 非常详细，值得学习。
Go 语言圣经中文教程：https://books.studygolang.com/gopl-zh/
Golang 标准库中文文档：https://studygolang.com/pkgdoc
Go 中文文档教程：https://tour.go-zh.org/list


log

Go语言结构化日志：打破日志的边界，解放你的应用程序
slog：Go官方版结构化日志包：https://tonybai.com/2022/10/30/first-exploration-of-slog/


Community skills sharing 

LeetCode-Go: GO 语言题解 LeetCode，比较全面，使用 GO 语言时值得参考。
Halfrost-Field 冰霜之地：Github 上的一位作者记录了学习 GO 语言的一些方法和经验。
Go 语言问题集 (Go Questions)：作者学习 Go 语言的笔记
Go 语言设计与实现：https://draveness.me/golang/这位作者是个大牛，开源作品很多，该项目系统的讲解了 Go 语言的知识，非常值得学习。
雨痕笔记，Go 语言大佬：https://www.yuque.com/qyuhen/go
嗨客网：https://haicoder.net/golang/golang-lib.html
learnku 社区网站：https://learnku.com/go
腾讯大佬个人博客：https://www.hitzhangjie.pro/blog/
印度小哥 mohitkhare 博客：https://www.mohitkhare.com/blog/go-dependency-injection/
Go 语言高性能编程：https://geektutu.com/post/high-performance-go.htm介绍了 Go 中一些常踩的坑和性能优化技巧。
Go的50度灰：Golang新开发者要注意的陷阱和常见错误：https://colobu.com/2015/09/07/gotchas-and-common-mistakes-in-go-golang/
Go总结（九）| goroutine+channel并发编程：https://chende.ren/2020/12/28140907-009-concurrency.html


Github excellent open source project

golang-open-source-projects: https://github.com/hackstoic/golang-open-source-projects
awesome-go-cn: https://github.com/jobbole/awesome-go-cn
go-awesome: https://github.com/shockerli/go-awesome
国外 awesome-go: https://github.com/avelino/awesome-go
Go 夜读：
https://github.com/talkgo/read  
https://github.com/talkgo/night




Tools

https://colobu.com/gotips/041.html 
技术文章摘抄：https://learn.lianglianglee.com/

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>GoInternals</title>
    <url>/Go/Go/GoInternals/</url>
    <content><![CDATA[

程序是怎样跑起来的曹大的 《Go 程序的启动流程》和@全成的 《Go 程序是怎样跑起来的》
HTTP
https://kingjcy.github.io/post/golang/go-net-http/#http%E6%9C%8D%E5%8A%A1%E7%AB%AF

References
Github golang-internals-resources: https://github.com/emluque/golang-internals-resources
Github learning go: https://github.com/yangwenmai/learning-golang
Go 源码阅读工具： https://mp.weixin.qq.com/s/E2TL_kcbVcRJ0CnxwbXWLw
Github golang-notes, 源码剖析：https://github.com/cch123/golang-notes/tree/master
Go Context 并发编程简明教程：https://geektutu.com/post/quick-go-context.html

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>goInternals</tag>
      </tags>
  </entry>
  <entry>
    <title>GoStandardLibrary</title>
    <url>/Go/Go/GoStandardLibrary/</url>
    <content><![CDATA[

1. GO Standard libraryGo 语言的标准库（通常被称为语言自带的电池），提供了清晰的构建模块和公共接口，包含 I&#x2F;O 操作、文本处理、图像、密码学、网络和分布式应用程序等，并支持许多标准化的文件格式和编解码协议。
学习标准库达到三个层面：

会使用标准库提供的 API 接口。用这些接口熟练的去写业务代码。
熟悉标准库的源码，理解库作者设计的思路和优秀的编码习惯。
在第二步的基础上，自己去扩充标准库，自己尝试去写、封装一些库，然后开源，让更多的人了解到，去使用自己写的库，在别人用的过程中加深理解。

优质的内容

源码结构清晰，架构、布局合理。
完整的文档。
社区广泛。

2. IO2.1. MultiWriterfunc MultiWriter(writers ...Writer) Writer

MultiWriter 函数是一个变参函数，可以接受任意个实现了 io.Writer 接口的值。这个函数会返回一个 io.Writer 值，这个值会把所有传入的 io.Writer 的值绑在一起。当对这个返回值进行写入时，会向所有绑在一起的 io.Writer 值做写入。
2.2. io.Writerio.Writer 是 Go 语言标准库中的接口，用于写入数据。它定义了一个用于写入字节的通用接口，可以在不同的数据源和目标上使用。以下是 io.Writer 的基本用法和示例：

导入标准库：

goCopy codeimport &quot;io&quot;


使用 io.Writer 接口的类型进行写入。最常见的类型是 os.File 和 bytes.Buffer，但你也可以自定义实现 io.Writer 接口的类型。
使用 Write 方法来写入数据。Write 方法的签名如下：

func (w WriterType) Write(p []byte) (n int, err error)

其中 WriterType 是实现了 io.Writer 接口的类型，p 是要写入的字节切片，n 是写入的字节数，err 是可能发生的错误。
以下是一些基本示例：
示例 1: 写入到文件
package mainimport (    &quot;io&quot;    &quot;os&quot;)func main() &#123;    // 打开文件进行写入    file, err := os.Create(&quot;example.txt&quot;)    if err != nil &#123;        panic(err)    &#125;    defer file.Close()    // 创建一个 io.Writer    writer := io.Writer(file)    // 写入数据    data := []byte(&quot;Hello, World!\n&quot;)    n, err := writer.Write(data)    if err != nil &#123;        panic(err)    &#125;    // 打印写入的字节数    println(n) // 输出：13&#125;

示例 2: 使用 bytes.Buffer
package mainimport (    &quot;bytes&quot;    &quot;io&quot;    &quot;os&quot;)func main() &#123;    // 创建一个 bytes.Buffer 作为 io.Writer    var buf bytes.Buffer    // 写入数据    data := []byte(&quot;Hello, World!\n&quot;)    n, err := buf.Write(data)    if err != nil &#123;        panic(err)    &#125;    // 打印写入的字节数    println(n) // 输出：13    // 将数据写入文件    file, err := os.Create(&quot;example.txt&quot;)    if err != nil &#123;        panic(err)    &#125;    defer file.Close()    _, err = io.Copy(file, &amp;buf)    if err != nil &#123;        panic(err)    &#125;&#125;

这些示例演示了如何使用 io.Writer 接口来写入数据到不同的目标中，包括文件和内存缓冲区。无论目标是什么，你都可以使用相同的 Write 方法来写入数据。在实际编程中，你可以根据需要选择合适的 io.Writer 实现。
2.3. io.ReadFullio.ReadFull 是 Go 语言标准库中的一个函数，它的作用是从输入流中读取指定数量的字节，直到读取到足够数量的字节或者发生错误为止。通常，它用于确保从输入流中读取到指定数量的字节，即使输入流中的数据不够也会一直尝试读取，直到达到指定数量或者发生错误。
io.ReadFull 的函数签名如下：
func ReadFull(r Reader, buf []byte) (n int, err error)

其中：

r 是一个实现了 io.Reader 接口的对象，表示输入流。
buf 是一个字节数组，用来存储读取到的数据。
返回值 n 表示实际读取到的字节数。
返回值 err 表示读取过程中是否发生了错误，如果成功读取到了指定数量的字节，err 将为 nil，否则将包含一个描述错误的值。

下面是一个示例，演示如何使用 io.ReadFull 从输入流中读取指定数量的字节：
package mainimport (	&quot;fmt&quot;	&quot;io&quot;	&quot;os&quot;)func main() &#123;	// 打开一个文件作为输入流	file, err := os.Open(&quot;example.txt&quot;)	if err != nil &#123;		fmt.Println(&quot;Error:&quot;, err)		return	&#125;	defer file.Close()	// 读取 10 个字节的数据	data := make([]byte, 10)	n, err := io.ReadFull(file, data)	if err != nil &#123;		fmt.Println(&quot;Error:&quot;, err)		return	&#125;	fmt.Printf(&quot;Read %d bytes: %s\n&quot;, n, data)&#125;

在上述示例中，io.ReadFull 从文件中读取 10 个字节的数据，如果文件中的数据不足 10 个字节，它将返回一个错误。
3. loglog 包实现了简单的日志服务。本包定义了 Logger 类型，该类型提供了一些格式化输出的方法。本包也提供了一个预定义的 “标准”Logger，可以通过辅助函数 Print[f|ln]、Fatal[f|ln] 和 Panic[f|ln]访问，比手工创建一个 Logger 对象更容易使用。Logger 会打印每条日志信息的日期、时间，默认输出到标准错误。Fatal 系列函数会在写入日志信息后调用 os.Exit(1)。Panic 系列函数会在写入日志信息后 panic。

Fatal 系列函数用来写日志消息，然后使用 os.Exit(1) 终止程序。
Panic 系列函数用来写日志消息，然后触发一个 panic。除非程序执行 recover 函数，否则会导致程序打印调用栈后终止。
Print 系列函数是写日志消息的标准方法。

log 包的日志记录器是多 goroutine 安全的。这意味着在多个 goroutine 可以同时调用来自同一个日志记录器的这些函数，而不 会有彼此间的写冲突。标准日志记录器具有这一性质，用户定制的日志记录器也应该满足这一性质。
logger 类实现的所有方法
func (l *Logger) Fatal(v ...interface&#123;&#125;)func (l *Logger) Fatalf(format string, v ...interface&#123;&#125;)func (l *Logger) Fatalln(v ...interface&#123;&#125;)func (l *Logger) Flags() intfunc (l *Logger) Output(calldepth int, s string) errorfunc (l *Logger) Panic(v ...interface&#123;&#125;)func (l *Logger) Panicf(format string, v ...interface&#123;&#125;)func (l *Logger) Panicln(v ...interface&#123;&#125;)func (l *Logger) Prefix() stringfunc (l *Logger) Print(v ...interface&#123;&#125;)func (l *Logger) Printf(format string, v ...interface&#123;&#125;)func (l *Logger) Println(v ...interface&#123;&#125;)func (l *Logger) SetFlags(flag int)func (l *Logger) SetPrefix(prefix string)

Logger 类型的函数
func New(out io.Writer, prefix string, flag int) *Logger &#123;	return &amp;Logger&#123;out: out, prefix: prefix, flag: flag&#125;&#125;// 功能创建并正确初始化一个 Logger 类型的值，返回新创建值的地址// 参数说明out: 指定了日志要写到的目的地；这个参数传入的值必须实现了 io.Writer 接口prefix: 每行日志开头的前缀flag: 定义日志包含了哪些属性（时间、文件等）

4. strconvimport &quot;strconv&quot;

strconv 包实现了基本数据类型和其字符串表示的相互转换。
5. encoding5.1. jsonGo 标准库中的 encoding/json 包提供了对 JSON（JavaScript Object Notation）数据的编码和解码功能。它允许将 Go 语言中的数据结构转换为 JSON 格式的字符串，并且可以将 JSON 格式的字符串解析为 Go 语言的数据结构。
encoding/json 包的主要作用如下：

JSON 序列化：encoding/json 包可以将 Go 语言的数据结构（如结构体 struct、切片 slice、映射 map 等）转换为 JSON 格式的字符串。这个过程被称为 JSON 序列化或编码。序列化过程将数据转换为可传输或存储的字符串形式，以便在网络传输或数据持久化时使用。
JSON 反序列化：encoding/json 包可以将 JSON 格式的字符串解析为 Go 语言的数据结构。这个过程被称为 JSON 反序列化或解码。反序列化过程将字符串解析为对应的数据结构，以便在程序中进行进一步的处理和使用。
自定义 JSON 标签：encoding/json 包通过使用结构体字段上的标签（tag）来控制 JSON 编码和解码的行为。可以使用 json:&quot;fieldname&quot; 标签来指定字段在 JSON 中的名称，也可以使用其他标签选项来自定义编码和解码的行为。
错误处理：encoding/json 包提供了处理 JSON 解析过程中可能发生的错误的机制。例如，如果 JSON 格式与 Go 数据结构不匹配，或者 JSON 中的值无法正确解析为 Go 类型，encoding/json 包会返回相应的错误信息。
编码器和解码器：encoding/json 包提供了 Encoder 和 Decoder 类型，它们封装了 JSON 编码和解码的功能。这些类型提供了更高级别的 API，可以方便地进行 JSON 数据的流式编码和解码。

5.2. MarshalGo 语言中，Marshal（编组）是指将数据结构或对象转换为字节流或字符串的过程。Marshal 操作通常用于将 Go 语言中的数据结构序列化为可传输或持久化的格式，例如 JSON、XML、Protobuf 等。
在 Go 语言中，Marshal 操作可以通过标准库中的 encoding/json、encoding/xml  等包实现。这些包提供了 Marshal 函数，可以将 Go 语言中的数据结构转换为对应格式的字符串或字节流。net
5.3. http
一文说透 Go 语言 HTTP 标准库：https://www.luozhiyun.com/archives/561

6. Context
Go标准库Context: https://www.liwenzhou.com/posts/Go/context/

7. sql
在 Go 中如何使用 database&#x2F;sql 来操作数据库
Go packages database

8. References
Go Standard library: https://pkg.go.dev/std
Go 语言中文网：https://studygolang.com/pkgdoc
Mastering GO 中文翻译：https://wskdsgcf.gitbook.io/mastering-go-zh-cn/
Go语言标准库 Example: https://books.studygolang.com/The-Golang-Standard-Library-by-Example/

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>goStandardLibrary</tag>
      </tags>
  </entry>
  <entry>
    <title>GoTest</title>
    <url>/Go/Go/GoTest/</url>
    <content><![CDATA[

1. Testing(测试)Go 语言的工具和标准库中集成了轻量级的测试功能，避免了强大但复杂的测试框架。测试库提供了一些基本构件，必要时可以用来构建复杂的测试构件。
go test 命令是一个按照一定的约定和组织来测试代码的程序。 在包目录内， 所有以 _test.go 为后缀名的源文件在执行 go build 时不会被构建成包的一部分， 它们是 go test 测试的一部分。
go test 命令执行原理

go test 命令会遍历所有的 *_test.go 文件中符合上述命名规则的函数， 生成一个临时的 main 包用于调用相应的测试函数， 接着构建并运行、 报告测试结果， 最后清理测试中生成的临时文件。

1.1. 测试函数
测试用例文件名必须以 _test.go 结尾，例如：socket_test.go

在 *_test.go 文件中， 分为三种类型的函数： 测试函数、 基准测试 (benchmark) 函数、 示例函数。 一个测试函数是以 Test 为函数名前缀的函数， 用于测试程序的一些逻辑行为是否正确，go test 命令会调用这些测试函数并报告测试结果是 PASS 或 FAIL。 基准测试函数是以 Benchmark 为函数名前缀的函数， 它们用于衡量一些函数的性能； go test 命令会多次运行基准函数以计算一个平均的执行时间。

每个测试用例中必须导入 testing 包。
import &quot;testing&quot;

测试用例中的函数名必须以 Test 开头，可选的后缀名必须以大写字母开头 。常见的命名原则：Test + 被测试的函数名 。测试用例函数 TestSocket(t *testing.T) 的形参必须是 *testing.T
func TestSocket(t *testing.T) &#123; /* ..*/&#125;func TestSin(t *testing.T) &#123; /* ... */ &#125;func TestCos(t *testing.T) &#123; /* ... */ &#125;func TestLog(t *testing.T) &#123; /* ... */ &#125;

其中 t 参数用于报告测试失败和附加的日志信息。

一个测试用例文件中可以有多个测试用例函数，比如：TestAdd()、TestSub() 等。

测试用例运行指令：
// 若运行正确，则无日志；若运行错误，则有日志// go test 后面没有参数指定包，那么将默认采用当前目录对应的包go test// 无论运行是正确还是错误，都有日志输出// 参数 -v: 显示每个测试用例的结果和运行时间go test -v// 测试单个文件go test -v socket_test.go socket.go// 测试单个方法go test -v -test.run TestAdd// CPU 剖析数据标识了最耗 CPU 时间的函数。 在每个 CPU 上运行的线程在每隔几毫秒都会遇到// 操作系统的中断事件， 每次中断时都会记录一个剖析数据然后恢复正常的运行。go test -cpuprofile=cpu.out// 堆剖析则标识了最耗内存的语句。剖析库会记录调用内部内存分配的操作，// 平均每 512KB 的内存申请会触发一个剖析数据。go test -memprofile=mem.out// 阻塞剖析则记录阻塞 goroutine 最久的操作， 例如系统调用、 管道发送和接收，// 还有获取锁等。 每当 goroutine 被这些操作阻塞时， 剖析库都会记录相应的事件。go test -blockprofile=block.out

若同时开启 CPU 剖析、堆剖析、阻塞剖析时，要当心， 因为某一项分析操作可能会影响其他项的分析结果 。

当出现错误时，用 t.Fatalf 来格式化输出错误信息，并退出程序。

t.Logf 可在测试用例中输出日志。

测试用例函数，并没有放在 main 函数中，但用例程序也执行。因为在导入测试用例的包时，Golang 的测试框架中有 main 开始执行，然后再加载 测试用例程序 xxx_test.go 和 业务程序 xxx.go。

测试用例程序执行完全后，显示的结果是 PASS 或者 FAIL。其中：PASS 表示测试用例运行成功；FAIL 表示测试用例执行失败。测试用例文件中的函数都执行成功，才显示 PASS；若发现有一个执行不成功，也会显示 FAIL。


1.2. 基准测试基准测试是测量一个程序在固定工作负载下的性能。 在 Go 语言中， 基准测试函数和普通测试函数写法类似， 但是以 Benchmark 为前缀名， 并且带有一个 *testing.B 类型的参数； *testing.B 参数除了提供和 *testing.T 类似的方法， 还有额外一些和性能测量相关的方法。 它还提供了一个整数 N， 用于指定操作执行的循环次数。
import &quot;testing&quot;// 循环中执行 N 次func BenchmarkSum(b *testing.B) &#123;	for i := 0; i &lt; b.N; i++ &#123;		Sum(&quot;A man, a plan, a canal: Panama&quot;)	&#125;&#125;

运行基准测试：
基准测试与普通的测试不同，默认情况下不运行任何基准测试。要运行基准测试，使用 -bench 命令参数，该参数是一个正则表达式， 用于匹配要执行的基准测试函数的名字， 默认值是空的。 其中 . 模式将可以匹配所有基准测试函数 。
// 匹配当前路径下所有的基准测试函数go test -bench=.goos: linuxgoarch: amd64pkg: test/productcpu: Intel(R) Core(TM) i5-10400H CPU @ 2.60GHzBenchmarkBuy-8...1000000000               0.0001251 ns/opPASSok      test/product    0.007s// 只运行某个基准函数got test -v -bench=&quot;基准函数名&quot;

基准测试结果中 BenchmarkBuy-8，基准测试函数的后缀部分 8，表示运行时对应的 GOMAXPROCS 值， 这对于一些与并发相关的基准测试是重要的信息。
-benchmem 命令行参数：提供每次操作分配内存的次数，以及总共分配内存的字节数。
go test -bench=. -benchmemgoos: linuxgoarch: amd64pkg: test/wordcpu: Intel(R) Core(TM) i5-10400H CPU @ 2.60GHzBenchmarkIsPalindrome02-8        4092888               281.4 ns/op           248 B/op          5 allocs/opBenchmarkIsPalindrome03-8        4306605               277.4 ns/op           248 B/op          5 allocs/opBenchmarkIsPalindrome04-8        7649563               147.7 ns/op           128 B/op          1 allocs/opPASSok      test/word       4.225s

优化后的 BenchmarkIsPalindrome04 函数从从之前的 5 次内存分配变成了一次内存分配 1 allocs/op。
注：

单位为 allocs/op 的值表示每次操作从堆上分配内存的次数。
单位为 B/op 的值表示每次操作分配的字节数。

比较型的基准测试就是普通程序代码。 它们通常是单参数的函数， 由几个不同数量级的基准测试函数调用， 就像这样：
func benchmark(b *testing.B, size int) &#123; /* ... */ &#125;func Benchmark10(b *testing.B) &#123; benchmark(b, 10) &#125;func Benchmark100(b *testing.B) &#123; benchmark(b, 100) &#125;func Benchmark1000(b *testing.B) &#123; benchmark(b, 1000) &#125;

通过函数参数来指定输入的大小， 但是参数变量对于每个具体的基准测试都是固定的。 要避免直接修改 b.N 来控制输入的大小。 除非你将它作为一个固定大小的迭代计算输入， 否则基准测试的结果将毫无意义。
1.3. Coverage(测试覆盖率)执行 go 的测试程序时，用 coverage 来统计测试用例的覆盖率。
go test -v -run=Coverage example/word

 执行 example/word 路径下所有 go 测试用例，并统计测试用例的覆盖率。
查看 测试用例覆盖攻击的使用方法，可用 go tool cover 命令。
Usage of &#x27;go tool cover&#x27;:Given a coverage profile produced by &#x27;go test&#x27;:        go test -coverprofile=c.outOpen a web browser displaying annotated source code:        go tool cover -html=c.outWrite out an HTML file instead of launching a web browser:        go tool cover -html=c.out -o coverage.htmlDisplay coverage percentages to stdout for each function:        go tool cover -func=c.outFinally, to generate modified source code with coverage annotations(what go test -cover does):        go tool cover -mode=set -var=CoverageVariableName program.goFlags:  -V    print version and exit  -func string        output coverage profile information for each function  -html string        generate HTML representation of coverage profile  -mode string        coverage mode: set, count, atomic  -o string        file for output; default: stdout  -var string        name of coverage variable to generate (default &quot;GoCover&quot;)  Only one of -html, -func, or -mode may be set.

go tool 命令运行 Go 工具链的底层可执行程序。 这些底层可执行程序放在  $GOROOT/pkg/tool/$&#123;GOOS&#125;_$&#123;GOARCH&#125; 目录。 因为有 go build 命令的原因， 我们很少直接调用这些底层工具。
现在我们可以用 -coverprofile 标志参数重新运行测试：
go test -run=Coverage -coverprofile=c.out  example/word

 -coverprofile 在测试代码中插入生成钩子来统计覆盖率数据。 也就是说， 在运行每个测试前，它将待测代码拷贝一份并做修改， 在每个词法块都会设置一个布尔标志变量. 当被修改后的被测试代码运行退出时，将统计日志数据写入 c.out 文件， 并打印一部分执行的语句的一个总结。（ 如果你需要的是摘要， 使用 go test -cover 。）
为了收集数据， 我们运行了测试覆盖率工具， 打印了测试日志， 使用下面的命令，生成一个 HTML 报告， 然后在浏览器中打开  。
go tool cover -html=c.out



2. 为测试做设计
测试编码规范
测试编码流程
测试编码工具
测试平台的思考和构建

坚持的原则：尽早测试，经常测试，自动测试。一旦代码写出来，就要尽早开始测试。
2.0.1. 对代码阅读的思考
在代码里把事情讲明白，让人能快速理解他人的代码，就能快速做出修改的决策。“猜测他人代码的逻辑用意”是很难受且困难的，他人的代码也会在这种场景下，产生被误读。
一般阅读他人的代码时，可能有些没有必要的地方，别人要花很多的脑子猜“为什么是这样的？”
代码写的原则是：简单、易理解、逻辑清晰。
写代码前先理清基本的需求、设计以及实现的流程。
不要面向需求编程，要面向业务模型编程。把变更的需求看成是业务模型的一个可变的参数，类似于函数的参数一样。
注释要把问题讲清楚, 讲不清楚的日志等于没有

3. References
腾讯工作13年之所思所想，那些优秀程序员的共性特征
腾讯 13 年，我所总结的Code Review终极大法

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>goTest</tag>
      </tags>
  </entry>
  <entry>
    <title>Performance</title>
    <url>/Go/Go/Performance/</url>
    <content><![CDATA[GO 性能分析性能分析的主要工具为：profile、trace。
ProfileTraceGo trace 工具查看协程的调度耗时。
References
微信公众号深入浅出 Go trace：https://mp.weixin.qq.com/s/I9xSMxy32cALSNQAN8wlnQ
我是如何实现Go性能5倍提升的？https://mp.weixin.qq.com/s/SlPdSoMs1po1l19uaNMrIQ

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>performance</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/Go/Go/README/</url>
    <content><![CDATA[个人 Golang 语言命名风格原则：遵循官方 Golang 命令规范。

文件名：字母加下划线组合。例如：tool_cmd.go
不能导出（私有）的函数、方法、接口、变量均按照小驼峰式命名，单词的首字母小写。若是能导出（公开）的函数、方法、接口、变量均按照大驼峰式命名，每个单词的首字母均大写。
测试用例文件均已 _test.go 后缀结尾。

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>ReleaseFeature</title>
    <url>/Go/Go/ReleaseFeature/</url>
    <content><![CDATA[Release FeatureGo 1.20Go 1.19Go 1.182022年3月15日，Go1.18 版本发布。

增加了一个主要的新语言特性: 对泛型的支持。

Go 1.17Go 1.162021年2月18日，Go1.16版本发布。

支持苹果的 M1 芯片。
go build/run 命令不再自动更新 go.mod 和 go.sum 文件。
新增 io/fs 包，建立 Go 原生系统的抽象。
新增 embed 包，作为在二进制文件中嵌入静态资源文件的官方方案。
GODEBUD环境变量支持跟踪包 init 函数的消耗。

Go 1.152020年8月12日，Go1.15版本发布。

module 的本地缓存可通过 GOMODCACHE 环境变量配置。
增加 tzdata 包，用于操作附加到二进制文件中的时区信息。

Go 1.142020年2月16日，Go 1.14版本发布。

重新实现了运行时的 timer。
testing 包的 T 和 B 类型都增加了自己的 Cleanup 方法。
基于信号系统机制实现了异步抢占式的 goroutine 调度。

Go 1.132019年9月4日，Go 1.13版本发布。

标准库中新增 errors.Is 和 errors.As 函数来解决错误值的比较判定，增加 errors.Unwrap 函数来解决 error 的展开问题。

Go 1.122019年2月15日，Go1.12版本发布。

增加对 TLS 1.3 的支持。
对Go module 机制做了进一步优化。
Build cache 默认开始成为必需的功能。

Go 1.112018年8月25日，Go1.11版本发布。这也是一个具有里程碑意义的版本。

引入了 Go module 包管理机制。
引入了对 web Assemble 的支持。
为调试器新增了一个试验的功能—允许在调试过程中动态调用 Go 函数。

Go 1.102018年2月17日，Go 1.10 版本发布。

支持默认的 GOROOT，开发者无需显示的设置 GOROOT 的环境变量。
通过 cache 大幅度提升构建和 go test 的执行性能，并基于源文件中内容的变化与否，判断是否使用cache中的结果。
增加 GOTMPDIR 环境变量。

Go 1.92017年8月25日，Go 1.9 颁布发布。

新增 type alias 语法。
增加支持并发的 Map 类型—sync.map。
增加 math/bits 包。

Go 1.82017年2月16日，Go 1.8 版本发布。

标准库中增加 sort.Slice 函数。
支持 HTTP&#x2F;2 push 机制
支持HTTP Server 优雅退出。
增加了对 Mutex 和 RWMutex 的profiling 的支持。

Go 1.72016年8月15日，Go1.7版本发布。

go test 支持 subtests 和 sub-benchmarks。
标准库新增 context 包。

Go 1.62016年2月17日，Go 1.6版本发布。

支持 HTPTP&#x2F;2
定义了在C代码中共享 Go 指针的规则。

Go 1.52015年8月19日，Go 1.5 版本发布。是Go 语言历史上具有里程碑意义的重要版本。

Go 实现了自举。Go 语言的编译器和运行时全部使用Go重写，原先C代码实现被彻底移除。
增加 go tool trace 子命令。
go build 增加 -buildmode 命令选项，支持将go 代码编译为共享库（shared library）的形式。
支持 map 类型字面量（literal）。

References
Go 官方Release History：https://go.dev/doc/devel/release

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>releaseFeature</tag>
      </tags>
  </entry>
  <entry>
    <title>Slice</title>
    <url>/Go/Go/Slice/</url>
    <content><![CDATA[Slice(切片)今天给大家介绍的是 Golang 语言中的 Slice，也就是切片。自己学习 Golang 很久了，但有时候，对一些问题点很模糊，不是特别的清楚和熟悉，没有形成系统化，因此根据我自己学习的经验，把这部分的知识分享出来。
一般学习一门知识大脑中要有框架思维，有从整体到局部的脉络。我一般在脑海里会想一下几个问题：

是什么？
这个知识点讲解的是什么。

有什么用？
花费了时间学习这个知识点有什么用？能解决哪些问题？

怎样去用？
明白了前两个问题后，一个新的知识点最简单、最直观的是知道该怎么去使用它，快速上手。

注意点？
学习这个知识点有哪些地方需要注意的，哪些地方会犯错、容易踩坑的，这些在学习完后，仔细想想，多留心。

底层原理？
这个知识点的底层原理是什么？这个是比较高的层次了，想要把知识点掌握牢固，不想只做一个调参侠，了解和学习一定的底层原理知识是有必要的。


方法已经介绍完了，下面开始进入正题：Go 中 Slice 的用法。

Slice 是什么？为了一个主观的印象，下文中的 Slice就不翻译为切片了，个人认为直接说 Slice 直观，英文就是 Slice，按照外国人的思维来。
Slice 是一种数据结构，这种数据结构便于使用和管理数据集合。Slice 是围绕动态数组的概念构建的，可以根据需要自动增长（grow）和收缩（shrink）。Slice 的动态增长是通过内置函数 append 来实现的。这个函数可以快速且高效地增长 Slice。还可以通过对 slice 再次 slice 来缩小一个切片的大小。因为 slice 的底层内存也是在连续块中分配的，所以 slice 还能获得索引、迭代以及为垃圾回收优化的好处。
一个 slice 类型一般写作 []T， 其中 T 代表 slice 中元素的类型。slice 的语法和数组很像， 只是没有固定长度而已。  切片是数组的一个引用，因此切片是引用类型。但自身是结构体，按照值拷贝传递。
Slice 的声明
// 格式var 变量名 [] 类型// 比如:var str []string  // 声明一个string类型的切片var arr []int     // 声明一个int类型的切片



怎么去用 Slice？Go 语言中有多种方法可以创建和初始化 slice，是否提前知道 slice 的容量通常决定了如何去创建 slice。
创建一个Slice
使用内置的 make 函数去创建 slice。当使用 make 函数时，需要指定 slice 的长度。
// Create a slice of strings. Use build-in function make()// Contains a length and capacity of 5 elements.slice := make([]string, 5)

若只指定 length，那么 slice 的 length 和 capacity 是相等的。也可以分别指定 capacity 和 length。
// Create a slice of integers.// Contains a length of 3 and has a capacity of 5 elements.slice := make([]int, 3, 5)

上面的实例，在创建 slice 时分别指定了长度和容量，而 slice 底层数组的长度是指定的 capacity
// Create a slice of integers.// Make the length larger than the capacity.slice := make([]int, 5, 3)Compiler Error:len larger than cap in make([]int)// Create a slice of strings.// Contains a length and capacity of 5 elements.slice := []string&#123;&quot;Red&quot;, &quot;Blue&quot;, &quot;Green&quot;, &quot;Yellow&quot;, &quot;Pink&quot;&#125;// Create a slice of integers.// Contains a length and capacity of 3 elements.slice := []int&#123;10, 20, 30&#125;// Create a nil slice of integers.var slice []int



Slice 有什么用？注意点
slice 之间不能比较， 因此我们不能使用等号== 操作符来判断两个 slice 是否含有全部相等元素。 不过标准库提供了高度优化的 bytes.Equal 函数来判断两个字节型 slice 是否相等 ，但是对于其他类型的 slice， 我们必须自己展开每个元素进行比较
判断一个 slice 值是否为空，使用 len(0) == 0 来判断，不应该使用 s = nil 去判断。

底层原理一个 slice 是一个轻量级的数据结构，提供了访问数组子序列（或者全部）元素的功能，而且 slice 的底层确实引用一个数组对象。一个 slice 由三个部分构成：指针（addr pointer）、长度（length）和容量（capacity）。

pointer：指针指向第一个 slice 元素对应的底层数组元素的地址，要注意的是 slice 的第一个元素并不一定就是数组的第一个元素。长度对应 slice 中元素的数目。
length：长度不能超过容量。切片遍历方式和数组一样，可以用 len() 求长度。表示可用元素数量，读写操作不能超过该限制。
capacity：一般是从 slice 的开始位置到底层数据的结尾位置。内置的 len() 和 cap() 函数分别返回 slice 的长度和容量。
cap() 可以求出 slice 最大扩张容量，不能超出数组限制。0 &lt;= len(slice) &lt;= len(array)，其中 array 是 slice 引用的数组。
如果 slice == nil，那么 len、cap 结果都等于 0。



]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>slice</tag>
      </tags>
  </entry>
  <entry>
    <title>SlicesByte</title>
    <url>/Go/Go/SlicesByte/</url>
    <content><![CDATA[[] byte 字节切片日常工作中，[]byte 会经常遇到，但对这个知识点总是模模糊糊的，有些地方不是特别的清楚，因此把自己对 []byte 的理解梳理出来，供大家分享。
在 Go 语言中，[]byte 是一个 字节切片 类型，用于表示二进制数据或字节序列。它常用于处理文件、网络传输和加密等场景。用作变量、函数的参数、函数的返回值以及结构体、接口中都很常用。
在这里要理解两个概念：一个是字节（byte），另一个是切片（Slice）。

byte：就是 []byte 右边的部分，表示元素类型是 byte，一个字节的数据，是一个无符号的 8 位整数类型。在 Go 语言中，byte 类型实际上是 uint8 的别名，所以 byte 的取值范围是 0 到 255。Go 标准库中的 byte 实现：
// uint8 is the set of all unsigned 8-bit integers.// Range: 0 through 255.type uint8 uint8// byte is an alias for uint8 and is equivalent to uint8 in all ways. It is// used, by convention, to distinguish byte values from 8-bit unsigned// integer values.type byte = uint8

[]: 也就是切片，[]byte 左边的部分，是 Go 语言中的一种数据类型，可以理解一种动态的数组，只不过数组的长度不是固定的。


因此，[]byte 切片表示一系列字节数据的集合，其中每个元素都是一个字节（byte）。
以下是一些常见的 []byte 的用法和操作：
创建 []byte
使用字符串字面量初始化



  data := []byte(&quot;hello&quot;)
 使用 `make` 函数创建指定长度的空切片

 data := make([]byte, 10)`


获取 []byte 长度

使用 len 函数获取切片的长度：length := len(data)。


访问和修改 []byte 元素

通过索引访问和修改切片中的单个字节：data[0]。访问下标为 0 的字节切片中的数据。

也可以使用切片语法获取子切片
// 语法subSlice := data[start:end]   // 其中 start 和 end 分别是起始和结束索引


连接 []byte
使用 go 中内建的 append() 连接两个 []byte 切片，返回的结果是一个新的切片类型
result := append(data1, data2...)

字符串与 []byte 之间的转换

将字符串转换为 []byte
str := &quot;hello&quot;data := []byte(str)

将 []byte 转换为字符串
data := []byte(&quot;hello&quot;)str := string(data)


比较 []byte

使用 bytes.Equal 函数比较两个 []byte 切片是否相等
equal := bytes.Equal(data1, data2)


其他操作

用 os 包中的函数读取文件内容到 []byte 切片中
// os package 下的 ReadFilefunc ReadFile(name string) ([]byte, error) &#123; 	...&#125;// 调用 ReadFile 函数filename := &quot;./a.txt&quot;data, err := os.ReadFile(filename)

用 encoding/base64 包进行 []byte 的 Base64 编码和解码。
package mainimport (	&quot;encoding/base64&quot;	&quot;fmt&quot;)func main() &#123;	// 要编码的原始数据	originalData := []byte(&quot;Hello, World!&quot;)	// 进行Base64编码	encodedData := base64.StdEncoding.EncodeToString(originalData)	fmt.Println(&quot;Base64 编码结果:&quot;, encodedData)	// 进行Base64解码	decodedData, err := base64.StdEncoding.DecodeString(encodedData)	if err != nil &#123;		fmt.Println(&quot;解码时发生错误:&quot;, err)		return	&#125;	fmt.Println(&quot;Base64 解码结果:&quot;, string(decodedData))&#125;



上面清楚了 []byte 的基本用法后，下面我们更深层次的理解 []byte。
一、[]byte 表示的数值范围是多少在 Go 语言中，[]byte 切片表示的数值范围是 0 到 255。byte 类型实际上是 uint8 类型的别名，它是一个无符号的 8 位整数类型。
由于 byte 类型的取值范围是 0 到 255（或者用十六进制表示是 0x00 到 0xFF），因此 []byte 切片中的每个元素都是一个在这个范围内的整数。
需要注意的是，虽然 byte 类型的底层表示是无符号的，但在进行运算时，它会被视为一个 8 位的无符号整数。这意味着在进行加法、减法或其他算术运算时，会按照无符号整数的规则进行计算。
二、编译器将 data :&#x3D; []byte(“hello”) 解释成什么程序中写了一行下面的代码，将字符串转化为字节切片
data := []byte(&quot;hello&quot;)

对这一行代码编译器会做哪些操作：

创建一个长度为 5 的 []byte 切片。
将字符串 &quot;hello&quot; 按照 UTF-8 编码转换为字节序列。
将字节序列的每个字节分别赋值给 []byte 切片的对应位置。

这个过程可以分解为以下步骤：

编译器根据 &quot;hello&quot; 字符串字面量创建一个不可变的字符串值。
编译器检测到将这个字符串字面量转换为 []byte 类型，并生成代码以执行转换。
在运行时，转换代码将字符串按照 UTF-8 编码转换为字节序列。
创建一个长度为 5 的 []byte 切片。
将字节序列的每个字节依次复制到切片的对应位置。
最后，变量 data 将引用这个切片。

这样，data 就成为一个包含字符串 &quot;hello&quot; 的字节序列的切片，每个元素都是一个字节。
三、字符串 “hello” 按照 UTF-8 编码转换为字节序列后，转换后的字节序列是什么？当字符串 &quot;hello&quot; 按照 UTF-8 编码转换为字节序列后，转换后的字节序列如下所示：
[104 101 108 108 111]

这个字节序列表示字符串 &quot;hello&quot; 中每个字符的 UTF-8 编码。每个数字代表一个字节，对应于字符串中相应位置的字符的 UTF-8 编码。这些数字就是 ASCII 值。
为什么是一个数字是一个字节？

 根据 UTF-8 编码规则，英文字母和常见符号通常使用一个字节表示。

解读转换后的字节序列：

第一个字节 104 对应字符’h’ 的 UTF-8 编码。
第二个字节 101 对应字符’e’ 的 UTF-8 编码。
第三个字节 108 对应字符’l’ 的 UTF-8 编码。
第四个字节 108 对应字符’l’ 的 UTF-8 编码。
第五个字节 111 对应字符’o’ 的 UTF-8 编码。

四、data :&#x3D; []byte(“hello”) 在编译器和内存中存储的格式是什么在编译器和内存中，data := []byte(&quot;hello&quot;) 所表示的数据格式如下：

编译器处理：
在编译阶段，编译器会将字符串字面量 &quot;hello&quot; 解析为一个不可变的字符串值。
编译器会为 data 变量分配内存空间，并确定其类型为 []byte 切片。
编译器会生成代码以执行将字符串按照 UTF-8 编码转换为字节序列的操作。


内存中的存储格式：
在运行时，data 变量引用一个 []byte 切片的实例。
切片的实例包含两个字段：
指向底层数组的指针：指向实际存储字节数据的数组。
长度：切片中字节数据的数量。





实际的字节数据存储在一个连续的、可变长度的数组中。对于 data := []byte(&quot;hello&quot;)，data 切片的底层数组中存储的字节数据为：[104 101 108 108 111]，对应字符串 &quot;hello&quot; 的 UTF-8 编码序列。而 data 变量通过指针和长度字段引用该底层数组。
References
ASCII 值常用对照表：https://tool.oschina.net/commons?type=4

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>slicesByte</tag>
      </tags>
  </entry>
  <entry>
    <title>ThirdPackages</title>
    <url>/Go/Go/ThirdPackages/</url>
    <content><![CDATA[

1. Kratos1.1. 简介Kratos 一套轻量级 Go 微服务框架，包含大量微服务相关框架及工具。
1.2. 用法1.3. References
官网: https://go-kratos.dev/
Github: https://github.com/go-kratos/kratos

2. Go zero2.1. 简介zerolog 是一个高性能、零内存分配的 Go 日志库，结构化日志记录，即日志输出打印的格式为 JSON。
2.2. 用法在大型工程中使用zerolog库进行日志记录可以按照以下步骤进行：

引入zerolog库：在代码中导入zerolog库，使用类似于import &quot;github.com/rs/zerolog/log&quot;的语句将zerolog库引入到你的工程中。
配置zerolog：根据你的需求对zerolog进行配置，例如设置日志级别、输出目标（如文件、标准输出等）、格式化选项等。你可以使用zerolog库提供的方法来进行配置，比如zerolog.Level、zerolog.Output等。
创建Logger实例：使用zerolog提供的方法创建一个Logger实例，通常可以使用zerolog.New()来创建一个默认配置的Logger。你也可以根据需要进行自定义配置，比如设置输出格式、添加字段等。
记录日志：使用Logger实例记录日志。zerolog库提供了多个级别的日志记录方法，如Info()、Error()、Debug()等。你可以根据需要选择适当的级别，并使用提供的方法记录日志消息。
格式化日志消息：使用zerolog库提供的方法来格式化日志消息。你可以使用Msg()方法来记录简单的文本消息，或者使用Interface()、Str()等方法来记录结构化的日志消息。
添加字段和上下文：zerolog库支持在日志消息中添加字段和上下文信息，以提供更多的上下文和可查询性。你可以使用WithXXX()系列方法添加字段，如WithInt()、WithString()等，或者使用Context()方法添加上下文信息。
输出日志：使用Logger实例的输出方法将日志信息输出到目标位置。你可以使用Log()方法将日志输出到默认目标（通常是标准输出），或者使用Output()方法将日志输出到自定义的目标，如文件。

package mainimport (	&quot;os&quot;	&quot;github.com/rs/zerolog&quot;	&quot;github.com/rs/zerolog/log&quot;)func main() &#123;	// 配置zerolog	zerolog.TimeFieldFormat = zerolog.TimeFormatUnix	logLevel := zerolog.InfoLevel	logFormat := &quot;2006-01-02 15:04:05.000&quot;	// 创建Logger实例	logger := log.Output(zerolog.ConsoleWriter&#123;Out: os.Stdout&#125;).Level(logLevel).With().Timestamp().Logger().Format(logFormat)	// 记录日志	logger.Info().Str(&quot;event&quot;, &quot;start&quot;).Msg(&quot;Application started&quot;)	logger.Warn().Str(&quot;event&quot;, &quot;warning&quot;).Msg(&quot;Something unexpected happened&quot;)	logger.Error().Str(&quot;event&quot;, &quot;error&quot;).Msg(&quot;An error occurred&quot;)	// 添加字段和上下文	logger = logger.With().Str(&quot;userID&quot;, &quot;123&quot;).Logger()	logger.Info().Msg(&quot;User logged in&quot;)	// 输出日志	logger.Info().Msg(&quot;Logging complete&quot;)&#125;


2.3. FAQ在 ZeroLog 日志库中，Err() 和 Error() 方法用于记录错误信息，但它们在使用方式和输出内容上有所区别。

Err() 方法：
Err() 方法是 zerolog.Event 结构体的方法之一，用于将错误作为日志事件的一部分记录下来。它接收一个 error 类型的参数，并将其添加到日志事件中。
示例：
log.Err(err).Msg(&quot;An error occurred&quot;)

在日志输出中，Err() 方法将错误对象记录为事件的一个字段，并将其键设置为 &quot;error&quot;。
输出示例：
&#123;&quot;level&quot;:&quot;error&quot;,&quot;error&quot;:&quot;error message&quot;,&quot;message&quot;:&quot;An error occurred&quot;&#125;

Err() 方法可以将错误与其他日志信息一起记录，但它不会触发错误的传播或导致程序停止。

Error() 方法：
Error() 方法是 ZeroLog 日志库的顶级函数之一，用于将错误信息作为独立的日志消息记录下来。它接收一个 error 类型的参数，并将其作为单独的日志消息输出。
示例：
log.Error(err).Msg(&quot;An error occurred&quot;)

在日志输出中，Error() 方法会创建一个独立的日志消息，其中包含错误信息。
输出示例：
An error occurred: error message

Error() 方法会将错误信息作为单独的日志消息输出，并可选择性地添加其他的日志内容。


总结：

Err() 方法将错误作为事件字段记录，并可以与其他日志信息一起输出。
Error() 方法将错误信息作为独立的日志消息输出，不会与其他日志内容混合在一起。

2.4. References
Go packages: https://pkg.go.dev/github.com/rs/zerolog
Github: https://github.com/rs/zerolog
Better Stack 教程：https://betterstack.com/community/guides/logging/zerolog/

文档页面排版很好看，图标配色好看，很值得自己学习！！！
https://learning-cloud-native-go.github.io/
3. wire3.1. 简介wire 是 google 开源用 Go 语言写的用于编译时依赖注入的（dependency injection）代码生成工具。它能够根据你的代码，生成相应的依赖注入 go 代码。
注：依赖注入的工具还有用反射实现的。
3.2. 用法Wire通过读取Go代码中的注释和类型信息，生成依赖注入相关的代码。这些生成的代码包括初始化函数、依赖注入容器和相应的依赖关系。生成的代码可以帮助开发人员更容易地管理和解决复杂的依赖关系。

wire.NewSet(): 将多个 provides 放到一个 set 集合中。
Injector:  注入器（Injector）是通过编写一个函数声明来声明的，声明的函数体内是对 wire.build 的调用。

3.3. Reference
Go packages: https://pkg.go.dev/github.com/google/wire 
Github: https://github.com/google/wire
Compile-time Dependency Injection With Go Cloud’s Wire: https://go.dev/blog/wire
Go工程化 - 依赖注入: https://go-kratos.dev/blog/go-project-wire/
Compile-time Dependency Injection With Go Cloud’s Wire: https://go.dev/blog/wire

4. Cobra4.1. 简介Go Cobra 是一个开源的用 Go 语言实现的命令行工具（库），被广泛用于构建命令行工具和 CLI 应用程序。它提供了一组简单且一致的API，可以帮助开发者轻松构建具有命令、子命令、标志、参数和帮助文档的命令行工具。
Cobra提供了以下主要功能和特点：

命令和子命令：Cobra允许定义多个命令和子命令，通过层级结构组织命令，并支持嵌套和嵌入式子命令。
标志和参数：Cobra支持在命令中定义标志（flags）和参数（arguments），可以用于接收和解析命令行输入。
自动生成帮助文档：Cobra能够自动生成丰富的帮助文档，包括命令、子命令、标志、参数以及自定义用法说明。
灵活的命令行解析：Cobra提供了灵活的命令行解析功能，可以轻松处理各种命令行输入情况。
插件系统：Cobra支持插件系统，可以通过插件扩展和定制 CLI 应用程序的功能。

官方解释

Cobra is built on a structure of commands, arguments &amp; flags.
Commands represent actions, Args are things and Flags are modifiers for those actions.

4.2. 用法官方推荐命令格式
./APPNAME COMMAND ARG --FLAG// 示例hugo server --port=1313// 解释appName: hugocommand: server--Flag: --port=1313


4.3. References
Go 官网包：https://pkg.go.dev/github.com/spf13/cobra
官网：https://cobra.dev/

5. viperViper 是适用于 Go 应用程序的完整配置解决方案。它被设计用于在应用程序中工作，并且可以处理所有类型的配置需求和格式。
它支持以下特性：

设置默认值
从JSON、TOML、YAML、HCL、envfile和Java properties格式的配置文件读取配置信息
实时监控和重新读取配置文件（可选）
从环境变量中读取
从远程配置系统（etcd或Consul）读取并监控配置变化
从命令行参数读取配置
从buffer读取配置
显式配置值

5.1. 为什么选择Viper?在构建现代应用程序时，你无需担心配置文件格式；你想要专注于构建出色的软件。Viper的出现就是为了在这方面帮助你的。
Viper能够为你执行下列操作：

查找、加载和反序列化JSON、TOML、YAML、HCL、INI、envfile和Java properties格式的配置文件。
提供一种机制为你的不同配置选项设置默认值。
提供一种机制来通过命令行参数覆盖指定选项的值。
提供别名系统，以便在不破坏现有代码的情况下轻松重命名参数。
当用户提供了与默认值相同的命令行或配置文件时，可以很容易地分辨出它们之间的区别。

Viper会按照下面的优先级。每个项目的优先级都高于它下面的项目:

显示调用Set设置值
命令行参数（flag）
环境变量
配置文件
key&#x2F;value存储
默认值

重要： 目前 Viper 配置的键（Key）是大小写不敏感的。目前正在讨论是否将这一选项设为可选。
5.2. References
Github：https://github.com/spf13/viper
Go语言配置管理神器——Viper中文教程：https://www.liwenzhou.com/posts/Go/viper/

6. Go-toml6.1. 简介Go-toml 是一个操作 TOML 格式的 Go library。
6.2. ReferencesGithub: https://github.com/pelletier/go-toml
Go packages: https://pkg.go.dev/github.com/pelletier/go-toml
7. GORM7.1. 简介GORM是 Golang 目前比较热门的数据库 ORM 操作库，对开发者也比较友好，使用非常方便简单，使用上主要就是把struct类型和数据库表记录进行映射，操作数据库的时候不需要直接手写Sql代码，这里主要介绍 MySQL数据库。
7.2. References
官网: https://gorm.io/
Github: https://github.com/go-gorm/gorm
Go packages: https://pkg.go.dev/gorm.io/gorm

8. sarama8.1. References
Github: https://github.com/Shopify/sarama

9. Kafka-go和sarama一样，segmentio&#x2F;kafka-go也是一个纯go实现的kafka client，并且在很多公司的生产环境经历过考验，segmentio&#x2F;kafka-go提供低级conn api和高级api(reader和writer)，以writer为例，相对低级api，它是并发safe的，还提供连接保持和重试，无需开发者自己实现，另外writer还支持sync和async写、带context.Context的超时写等。
不过Writer的sync模式写十分慢，1秒钟才几十条，但async模式就飞快了！
不过和confluent-kafka-go一样，segmentio&#x2F;kafka-go 也没有像 sarama 那样提供 mock 测试包，我们需要自己建立环境测试。kafka-go 官方的建议时：在本地启动一个kafka服务，然后运行测试。在轻量级容器十分流行的时代，是否需要 mock 还真是一件值得思考的事情。
9.1. 对比Sarama和segmentio&#x2F;kafka-go是Go语言中两个常用的Kafka客户端库，它们各有优点和缺点。以下是它们的详细比较：
Sarama: 优点：

社区支持：Sarama是Go语言中最受欢迎的Kafka客户端库之一，因此具有一个活跃的社区，提供了广泛的文档、教程和示例代码。
功能丰富：Sarama提供了全面的Kafka功能支持，包括生产者和消费者API、事务支持、元数据管理等。它具有灵活的配置选项，使你能够自定义与Kafka集群的交互。
成熟稳定：Sarama已经存在一段时间，并且在许多生产环境中得到广泛使用，因此它被认为是一个成熟且稳定的选择。

缺点：

性能：尽管Sarama提供了高性能的Kafka客户端，但一些基准测试显示，与segmentio&#x2F;kafka-go相比，它的性能可能稍逊一筹。
依赖性：Sarama的依赖库比较多，这可能增加了项目的复杂性和构建过程的复杂性。
自定义功能限制：尽管Sarama提供了广泛的功能，但在某些特定需求下，可能需要自定义实现，这可能会受到Sarama的架构限制。

segmentio&#x2F;kafka-go: 优点：

简单易用：segmentio&#x2F;kafka-go是一个轻量级的Kafka客户端库，它具有简单、易于使用的API。它专注于提供基本的生产者和消费者功能，适用于一些简单的Kafka应用程序。
性能：segmentio&#x2F;kafka-go在性能方面表现出色，一些基准测试显示它比Sarama具有更高的吞吐量和更低的延迟。
低依赖性：segmentio&#x2F;kafka-go的依赖库相对较少，这有助于减少项目的复杂性和构建过程的复杂性。

缺点：

功能限制：相对于Sarama，segmentio&#x2F;kafka-go的功能较为有限。它提供了基本的生产者和消费者功能，但在某些高级特性（如事务支持、元数据管理等）方面可能不如Sarama全面。
社区支持：尽管segmentio&#x2F;kafka-go在一些项目中得到广泛使用，但相比Sarama，它的社区规模较小，可能在文档、教程和示例方面略显不足。

综上所述，如果你需要一个成熟、功能丰富的Kafka客户端库，并且对社区支持和文档重视，那么Sarama可能是一个更好的选择。但如果你希望一个简单、高性能的Kafka客户端库，并且对于基本的生产者和消费者功能满足需求，那么segmentio&#x2F;kafka-go可能更适合你的项目。最终的选择应该根据你的具体需求和偏好来决定。
9.2. Reference
Github: https://github.com/segmentio/kafka-go
Go packages: https://pkg.go.dev/github.com/segmentio/kafka-go
Go社区主流Kafka客户端简要对比: https://tonybai.com/2022/03/28/the-comparison-of-the-go-community-leading-kakfa-clients/

10. errgroup用于处理 goroutine 中的错误。
11. 用法Group 的核心能力就在于能够并发执行多个子任务，从调用者的角度，我们只需要传入要执行的函数，签名为：func() error即可，非常通用。如果任务执行成功，就返回 nil，否则就返回 error，并且会 cancel 那个新的 Context。
11.1. References
Go packages: https://pkg.go.dev/golang.org/x/sync/errgroup

12. fiber12.1. 简介Fiber，一个受Express启发的Golang Web框架，建立在Fasthttp 的基础之上。旨在简化、零内存分配和高性能，以及快速开发。Go 速度快，占用的内存少，而且性能高，这意味着它也使得 Fiber 框架更快。
12.2. 用法12.2.1. 🧬 内置中间件以下为fiber框架的内置中间件：



中间件
描述



basicauth
basicauth中间件提供HTTP基本身份验证


compress
Fiber的压缩中间件，它支持deflate，gzip 和 brotli（默认）


cache
拦截和响应缓存


cors
跨域处理


csrf
CSRF攻击防护


filesystem
Fiber的文件系统中间件


favicon
favicon图标


limiter
请求频率限制中间件，用于控制API请求频率


logger
HTTP请求与响应日志记录器


pprof
pprof 中间件


proxy
请求代理


requestid
为每个请求添加一个requestid。


recover
Recover中间件将程序从panic状态中恢复过来


timeout
添加请求的最大时间，如果超时，则转发给ErrorHandler。


12.2.2. 🧬 外部中间件有fiber团队维护的外部中间件



中间件
描述



adaptor
net/http 与 Fiber请求的相互转换适配器


helmet
可设置各种HTTP Header来保护您的应用


jwt
JSON Web Token (JWT) 中间件


keyauth
提供基于密钥的身份验证


rewrite
URL路径重写


session
Session中间件


template
模板引擎


websocket
Fasthttp WebSocket 中间件


https://www.bookstack.cn/read/recommend/0002-gofiber.md
12.3. References
官网: https://docs.gofiber.io/
Go packages: https://pkg.go.dev/github.com/gofiber/fiber/v2
Github: https://github.com/gofiber/fiber

13. Gin13.1. 简介流行的web框架。
基于官方 net&#x2F;http 内建标准库封装的。 
13.2. 用法
路由(Route)：URL 到函数的映射。
URL
静态匹配，路径固定。r.GET(&quot;index&quot;, func(ctx *gin.Context) &#123;  ctx.JSON(200, gin.H&#123;    &quot;key&quot;: &quot;helloword&quot;, // 返回结果为json  &#125;)&#125;)
动态匹配，路径参数。比如：/user/find/:idr.POST(&quot;/user/find/:id&quot;, func(ctx *gin.Context) &#123;  param := ctx.Param(&quot;id&quot;)  ctx.JSON(200, param)&#125;)
模糊匹配，使用通配符 *。r.PUT(&quot;/about/*path&quot;, func(ctx *gin.Context) &#123;	param := ctx.Param(&quot;path&quot;)	ctx.JSON(200, param)&#125;)


API 
路由分组：Group()
参数查询
Query() 查询普通的参数

GetQuery() 判断指定的参数是否存在

DefaultQuery() 指定的参数不存在，给定个默认值

BindQuery() 

ShouldBindQuery()  相比 BindQuery()  报错后不影响。

map 类型请求参数不支持。







13.3. Reference
Github: https://github.com/gin-gonic/gin
官网: https://gin-gonic.com/
Go packages: https://pkg.go.dev/github.com/gin-gonic/gin
官方 example: https://github.com/gin-gonic/examples
gin框架源码解析：https://www.liwenzhou.com/posts/Go/gin-sourcecode/

14. go-migrate用 Go 语言编写的数据库迁移命令行工具。
14.1. 为什么要使用数据库迁移工具让代码与数据的改变都进行版本控制。
14.2. Reference
Github: https://github.com/golang-migrate/migrate

15. Watermill15.1. 简介watermill是 Go 语言的一个异步消息解决方案，它支持消息重传、保存消息，后启动的订阅者也能收到前面发布的消息。watermill内置了多种订阅-发布实现，包括Kafka/RabbitMQ，甚至还支持HTTP/MySQL binlog。当然也可以编写自己的订阅-发布实现。此外，它还提供了监控、限流等中间件。
15.2. 难题发布&#x2F;订阅模式一些常见的问题

将消息发送到订阅者管道之后就不管了，这样如果订阅者处理压力较大，会在管道中堆积太多消息，一旦订阅者异常退出，这些消息将会全部丢失！
若没有消息保存，如果订阅者后启动，之前发布的消息，这个订阅者是无法收到的。

15.3. References
官网：https://watermill.io/
Github: https://github.com/ThreeDotsLabs/watermill/
Go packages: https://pkg.go.dev/github.com/ThreeDotsLabs/watermill@v1.2.0/pubsub/gochannel
Go 每日一库之 watermill: https://cloud.tencent.com/developer/article/1693800

16. Gotest16.1. 简介gotests 是一款开源的表格驱动测试函数的工具，不需要从0开始写表格驱动测试函数，工具自动生成表格驱动测试函数的框架，在每个对应的测试函数中填入相应的测试案例即可。
16.2. 用法Minimum Go version: Go 1.6
Use go get to install and update:
// 终端执行go get -u github.com/cweill/gotests/...

From the commandline, gotests can generate Go tests for specific source files or an entire directory. By default, it prints its output to stdout.
$ gotests [options] PATH ...

Available options:
-all                  generate tests for all functions and methods-excl                 regexp. generate tests for functions and methods that don&#x27;t                       match. Takes precedence over -only, -exported, and -all-exported             generate tests for exported functions and methods. Takes                       precedence over -only and -all-i                    print test inputs in error messages-only                 regexp. generate tests for functions and methods that match only.                       Takes precedence over -all-nosubtests           disable subtest generation when &gt;= Go 1.7-parallel             enable parallel subtest generation when &gt;= Go 1.7.-w                    write output to (test) files instead of stdout-template_dir         Path to a directory containing custom test code templates. Takes                       precedence over -template. This can also be set via environment                       variable GOTESTS_TEMPLATE_DIR-template             Specify custom test code templates, e.g. testify. This can also                       be set via environment variable GOTESTS_TEMPLATE-template_params_file read external parameters to template by json with file-template_params      read external parameters to template by json with stdin


终端用 gotests 命令执行代码文件 xxx.go，生成对应的测试文件 xxx_test.go，录下如果事先存在这个文件就不再生成。
gotests -all -w xxx.go


16.3. References
Github: https://github.com/cweill/gotests

17. Gomock用法：
18. gojagoja 是一个用于在Go语言中运行JavaScript代码的库。它提供了与JavaScript交互的功能，包括创建对象、调用函数、访问属性等。
18.1. API
goja.New()
创建了一个新的JavaScript运行环境。
Goja 虚拟机实例本身并不是线程安全的。如果你需要在多个goroutine中使用Goja，你需要为每个goroutine创建一个新的Goja虚拟机实例。如果你尝试在多个goroutine中共享一个Goja虚拟机实例，你可能会遇到并发问题。
例如：
// vm 是一个goja的虚拟机对象vm := goja.New()

vm.Get()
获取一个Javascript变量值：
value, err := vm.Get(&quot;a&quot;)&#123;  value, _ := value.ToInteger()&#125;

vm.Set()
设置一个Javascript变量的值：
vm.Set(&quot;a&quot;, 88)vm.Set(&quot;b&quot;, &quot;hello&quot;)

陷阱函数
“get” 陷阱函数会在尝试获取代理对象的属性时被调用。例如，如果你在 JavaScript 代码中写 Things.property 或 Things[&#39;property&#39;]，那么 “get” 陷阱函数就会被调用。
“set” 陷阱函数会在尝试设置代理对象的属性时被调用。例如，如果你在 JavaScript 代码中写 Things.property = value，那么 “set” 陷阱函数就会被调用

SetFieldNameMapper()
SetFieldNameMapper方法接受一个字段名映射器作为参数。在这里，goja.TagFieldNameMapper(&quot;json&quot;, true)是一个字段名映射器函数，它使用结构体字段的json标签作为字段名。第二个参数true表示忽略未标记为json的字段。
通过调用SetFieldNameMapper方法并传递这个字段名映射器函数作为参数，我们可以告诉goja虚拟机在处理结构体时使用这个映射器来将字段名与JSON字段进行映射。
这个功能在处理结构体与JSON之间的转换时非常有用。例如，当我们从JSON数据中解析出一个结构体对象时，可以使用这个字段名映射器来确保字段名的一致性。这行代码是在Go语言中使用goja库时的一部分。它的作用是设置一个字段名映射器，用于将结构体字段与JSON字段进行映射。

NewObject()
用于创建一个新的JavaScript对象。

NewProxy()
用于创建一个JavaScript代理对象。代理对象允许在JavaScript代码中拦截对对象属性的访问，并在Go代码中处理这些访问。
NewProxy函数接受两个参数：

要代理的对象
一个ProxyTrapConfig对象，其中包含了对属性访问进行拦截的回调函数。


ToValue()
Go语言的值转换为JavaScript的值。这个方法接受一个Go语言的值作为参数，并返回一个表示该值的JavaScript值。

RunString()
vm.RunString() 方法接受一个字符串参数，这个字符串是有效的 JavaScript 代码。这个方法会在当前的 goja 虚拟机环境（vm）中执行这段 JavaScript 代码，并返回执行结果。
返回的结果有两个：第一个是 JavaScript 代码执行后的结果，它的类型是 goja.Value；第二个是一个错误信息，如果在执行 JavaScript 代码过程中发生了错误，这个错误信息就会被返回。
例如：
vm := goja.New()v, err := vm.RunString(&quot;2 + 2&quot;)if err != nil &#123;    log.Fatal(err)&#125; else &#123;    fmt.Println(v.Export())  // 输出：4&#125;

在这个例子中，vm.RunString(&quot;2 + 2&quot;) 会在 goja 虚拟机中执行 JavaScript 代码 &quot;2 + 2&quot;，并返回执行结果 4。

export()
v.Export() 是 Go 语言库 goja 中的一个方法。
v.Export() 方法用于将 JavaScript 的值转换为 Go 语言的值。这个方法没有参数，返回一个 interface&#123;&#125; 类型的值，这个值是 JavaScript 值在 Go 语言中的表示。
例如，如果 JavaScript 的值是一个数字，那么 v.Export() 方法会返回一个 float64 类型的值。如果 JavaScript 的值是一个字符串，那么 v.Export() 方法会返回一个 string 类型的值。
在你的代码中，v.Export() 方法用于获取 JavaScript 代码执行后的结果，并将其转换为 Go 语言的值。例如，如果 JavaScript 代码返回一个对象，那么 v.Export() 方法会返回一个 map[string]interface&#123;&#125; 类型的值，这个值表示 JavaScript 对象的属性和值。

goja.Proxy
goja.Proxy是一个自定义的类型，用于创建一个代理对象，代理对象通常用于封装对其他对象的访问。


18.2. References
Gomock 实战指南：提升 Go 代码测试质量：https://www.lixueduan.com/posts/go/gomock/
Github gomock: https://github.com/golang/mock
CSDN gomock: https://blog.csdn.net/shanxiaoshuai/article/details/115492171

sqlc简介为什么选择sqlc在 Go 语言中编写数据库操作代码真的非常痛苦！database/sql标准库提供的都是比较底层的接口。我们需要编写大量重复的代码。大量的模板代码不仅写起来烦，而且还容易出错。有时候字段类型修改了一下，可能就需要改动很多地方；添加了一个新字段，之前使用 select * 查询语句的地方都要修改。如果有些地方有遗漏，可能就会造成运行时panic。即使使用 ORM 库，这些问题也不能完全解决！这时候，sqlc来了！sqlc可以根据我们编写的 SQL 语句生成类型安全的、地道的 Go 接口代码，我们要做的只是调用这些方法。
用法sqlc.yaml 文件
version: &quot;1&quot;packages:  - name: &quot;db&quot;    path: &quot;./db&quot;    queries: &quot;./query.sql&quot;    schema: &quot;./schema.sql&quot;    emit_json_tags: false  #默认为false，设置该字段为true可以为生成的模型对象结构添加JSON标签 		emit_prepared_queries: false #默认为false，设置该字段为true，会为 SQL 生成对应的prepared statement		emit_interface: false #默认为false，设置该字段为true，会为查询结构生成一个接口。最终生成的代码会多出一个文件querier.goversion：版本；packages：  name：生成的包名；  path：生成文件的路径；  queries：查询 SQL 文件；  schema：建表 SQL 文件。



References
Go library: https://pkg.go.dev/database/sql
sqlc office: https://sqlc.dev/
Github sqlc: https://github.com/sqlc-dev/sqlc
Go 每日一库之 sqlc：https://cloud.tencent.com/developer/article/1693829

Go-sql-driverMySQL golang 数据库驱动。
References
Go library: https://github.com/go-sql-driver/mysql
Go mysql驱动源码分析

]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>thirdPackages</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript</title>
    <url>/JavaScript/JavaScript/JavaScript/</url>
    <content><![CDATA[


How to learn JavaScript?
JavaScript 基础语法
浏览器内置 API(DOM, BOM)
第三方库：jQuery, art-template

IntroductionIn JavaScript, instructions are called statements and are separated by semicolons (;).
Data structures and typesData Types
boolean
null
undefined
number
bigint
string
symbol

References
JSON Schema 
The V8 JavaScript Engine
learn-js
MDN-JavaScript
W3School JavaScript Tutorial

]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>javaScript</tag>
      </tags>
  </entry>
  <entry>
    <title>cgroups</title>
    <url>/Linux/Linux/cgroups/</url>
    <content><![CDATA[

1. Introducecgroup 是 control group 的缩写，cgroups 是 control groups 的缩写，是 Linux 内核提供的一种可以限制、记录、隔离进程组（process groups）所使用物理资源（如： cpu,memory,IO 等等）的机制。最初由 google 的  工程师提出，后来被整合进 Linux 内核。内核版本 2.6.24 开始引入，在 3.15 和 3.16 的内核版本中得到了加强。
2. 概念
hierarchy：cgroups 从用户态看，提供了一种叫cgroup类型的文件系统(Filesystem)，这是一种虚拟的文件系统，并不真正保存文件，类似/proc。通过对这个文件系统的操作（读，写，创建子目录），告诉内核，你希望内核如何控制进程对资源的使用。文件系统本身是层级的，所以构成了hierarchy。
task：进程(process)在cgroups中称为task，taskid就是pid。
subsystem：cgroups支持的所有可配置的资源称为subsystem。例如cpu是一种subsystem，memory也是一种subsystem。linux内核在演进过程中subsystem是不断增加的。
libcgroup：一个开源软件，提供了一组支持 cgroups 的应用程序和库，方便用户配置和使用cgroups。目前许多发行版都附带这个软件。

3. user space interfaces
libcgroup

cgroup-bin

cgroup-tools

cgroupfs-mount


4. The Mounted Hierarchy资源管控器（也称为 cgroup 子系统）代表一种单一资源：如 CPU 时间或者内存。Linux kernel 提供一系列资源管控器，由 systemd 自动挂载。如需参考目前已挂载的资源管控器列表，请参见 /proc/cgroups，或使用 lssubsys 监控工具。
[root@CentOS7 cgroup]# pwd/sys/fs/cgroup[root@CentOS7 cgroup]# ls -altotal 0drwxr-xr-x. 13 root root 340 May 26 21:00 .drwxr-xr-x.  8 root root   0 May 26 21:00 ..drwxr-xr-x.  2 root root   0 May 26 21:00 blkiolrwxrwxrwx.  1 root root  11 May 26 21:00 cpu -&gt; cpu,cpuacctlrwxrwxrwx.  1 root root  11 May 26 21:00 cpuacct -&gt; cpu,cpuacctdrwxr-xr-x.  2 root root   0 May 26 21:00 cpu,cpuacctdrwxr-xr-x.  2 root root   0 May 26 21:00 cpusetdrwxr-xr-x.  5 root root   0 May 26 21:00 devicesdrwxr-xr-x.  2 root root   0 May 26 21:00 freezerdrwxr-xr-x.  2 root root   0 May 26 21:00 hugetlbdrwxr-xr-x.  2 root root   0 May 26 21:00 memorylrwxrwxrwx.  1 root root  16 May 26 21:00 net_cls -&gt; net_cls,net_priodrwxr-xr-x.  2 root root   0 May 26 21:00 net_cls,net_priolrwxrwxrwx.  1 root root  16 May 26 21:00 net_prio -&gt; net_cls,net_priodrwxr-xr-x.  2 root root   0 May 26 21:00 perf_eventdrwxr-xr-x.  5 root root   0 May 26 21:00 pidsdrwxr-xr-x.  5 root root   0 May 26 21:00 systemd


blkio：对输入 ∕ 输出访问存取块设备设定权限。例如:磁盘，光盘以及usb等等。
cpu：使用 cpu 调度程序为 cgroup 任务提供 cpu 的访问。
cpuacct：自动生成 cgroup 中任务占用 CPU 资源的报告。
cpuset：如果是多核心的 cpu，这个子系统会为 cgroup 中的任务分配单独的 cpu 和内存节点。
devices：允许或禁止 cgroup 任务对设备的访问。
freezer：暂停和恢复 cgroup 中任务。
hugetlb：允许使用大篇幅的虚拟内存页，并且给这些内存页强制设定可用资源量。
memory：对 cgroup 中的任务可用内存做出限制，并且自动生成任务占用内存资源报告。
net_cls： 使用等级识别符（classid）标记网络数据包，这让 Linux 流量控制器（tc 指令）可以识别来自特定 cgroup 任务的数据包。
perf_event： 允许使用 perf 工具来监控 cgroup。增加了对每 group 的监测跟踪的能力，即可以监测属于某个特定 group 的所有线程以及运行在特定 CPU 上的线程。

4.1. 注意点
全局的 cgroup_mutex

在线业务或离线业务，都会做内核隔离（sched-idle）
开机时间
资源占用
沙箱 &#x3D; 容器 + 虚机
5. Reference
Control groups, part 6: A look under the hood [LWN.net]：Linux 周刊（LWN.net）分享的文章，非常不错。
Linux资源管理之cgroups简介：美团技术团队分享的 cgroups 用法。

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cgroups</tag>
      </tags>
  </entry>
  <entry>
    <title>clock</title>
    <url>/Linux/Linux/clock/</url>
    <content><![CDATA[1. Linux 时钟1.1. datedate 命令可以用来查看和手动设置日期、时间。命令格式如下：
# 查看日期[root@zz-scf-iot-api02 log]# dateThu Sep 26 10:32:11 CST 2024# 修改时间[root@node1 ~]# date -s &quot;20240225 20:16:00&quot;  #yyyymmdd hh:mm:ssTue Feb 25 20:16:00 CST 2024

MM：月份（两位数，01-12）
DD：日期（两位数，01-31）
hh：小时（两位数，00-23，24小时制）
mm：分钟（两位数，00-59）
YYYY：年份（四位数）
1.2. hwclockLinux 系统的硬件时间。
# 查看硬件时间root@DESKTOP-0S33AUT:/home/hacker# hwclock2024-09-26 10:36:37.978831+08:00# 以系统时间为基准，修改硬件时间。将新的系统时间写入硬件时钟（BIOS时钟）。这是为了确保系统在下次启动时使用正确的时间。hwclock -w, --systohc   #  System Clock to Hardware Clock# 以硬件时间为基准，修改系统时间hwclock -s, --hctosys   # he Hardware Clock to System Clock





1.3. ntpd1.4. 公共时间服务器阿里云
阿里云时间服务器，授时信号来自GPS、北斗两套卫星信号，并配备原子钟守时，以下7个域名提供服务，大家可以直接使用。
http://time1.aliyun.comhttp://time2.aliyun.comhttp://time3.aliyun.comhttp://time4.aliyun.comhttp://time5.aliyun.comhttp://time6.aliyun.comhttp://time7.aliyun.com或者直接访问这个地址  time.pool.aliyun.com// 实例ntpdate -u time.pool.aliyun.com




2. References
ntp时间服务器 时间同步
Linux系统时间同步方法小结

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>clock</tag>
      </tags>
  </entry>
  <entry>
    <title>compile-link</title>
    <url>/Linux/Linux/compile-link/</url>
    <content><![CDATA[

1. 缩写
EXE(Executable)：可执行文件
PE(Portable Executable)：可移植可执行。
ELF(Executable Linkable Format)：可执行可链接格式。
DLL(Dynamic ALinking Library): windows下的以 .dll 方式命名，Linux下的以 .so 方式命名。
SLL(Static ALinking Library): windows下的以 .lib 方式命名，Linux的以 .a 方式命名。
BSS(Block Started by Symbol): 未初始化的全局变量和局部静态变量的区域。

2. 程序处理过程程序处理的流程：源代码→预处理→编译→汇编→目标文件→链接→可执行文件
预处理(Preprocessing)

处理C、C++源代码 #include 文件生成预处理文件 .i 或者 .ii 文件

编译(Compile)

将预处理文件编译成汇编代码 .s 文件

汇编(Assemble)

汇编代码生成目标文件(.o 或者 .obj)

目标文件(Object file)

编译器编译源码后生成的文件叫做目标文件。

链接(Linking)

将库文件(.lib 或 .a)和二进制文件(.o 或 obi)通过链接器(ld: linker directive)生成可执行文件(.out  output file)。通俗的讲：将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可以被加载到内存并执行。链接可以执行于编译时、加载时、运行时。
Windows中启动程序由 CRT、DLL 提供，Linux中由 glibc(libs-start.c) 提供。
静态连接(static linking): 将外部函数库拷贝到可执行文件
动态链接(dynamic linking)：外部函数库不进入安装包，只在运行时动态引用
链接器必须完成的两个任务
符号解析(symbol resolution)：将每个符号引用正好和一个符号定义关联起来。
重定位：链接器通过把每个符号定义于一个内存位置关联起来，从而重定位这些细节，然后修改所有对这些符号的引用，使它们指向这个内存位置。



例如执行流程：hello.cpp-&gt;&gt;hello.ii(预处理)-&gt;&gt;hello.s(汇编)-&gt;&gt;hello.o(目标文件)-&gt;&gt;hello.exe(可执行)

    


可执行文件

加载器
运行程序时，加载器首先加载程序到内存中， 被加载程序称为进程 ，并由操作系统加载。
主要作用：
验证
从硬盘复制可执行文件到主存中
配置栈
配置寄存器
跳转到程序入口点(_start)


加载器加载可执行文件时，操作系统使用的步骤
加载器请求操作系统创建一个新进程
操作系统为新进程建立页表
用无效入口标记页表
开始执行程序，生成即时页面错误异常






    


3. 内存四区首先了解基本的几个概念。

全局变量（外部变量）：出现在代码块 &#123;&#125; 之外的变量就是全局变量。
局部变量（自动变量）：一般情况下，代码块 &#123;&#125; 内部定义的变量就是自动变量，也可使用 auto 显示定义。
static 变量：是指内存位置在程序执行期间一直不改变的变量，用关键字 static 修饰。代码块内部的静态变量只能被这个代码块内部访问，代码块外部的静态变量只能被定义这个变量的文件访问。

源代码编译后在内存中被分成五个主要部分：代码区、数据区、BSS、栈、堆。

代码区(code segment&#x2F;text segment)

用来存放程序执行代码的一块内存区域，里面装的是 CPU 执行的机器指令。
程序加载到内存的时候由操作系统分配，程序结束时由操作系统释放。这部分区域的大小在程序运行前就已经确定，这块内存在程序运行期间是不变的，通常属于只能读，不能写，因为防止程序被指令意外的修改。
代码区是共享的，共享的目的是为了频繁执行的程序，在内存中仅有一份代码的拷贝。
函数也是代码的一部分，故函数都被放在代码区，包括main函数。


数据段(data segment)

用来存放程序中已初始化的 global 变量和static 变量的一块内存区域。
分配优先于main函数，生存期与程序共存亡。
程序一开始就分配了，直到结束才释放。
可读可写。


栈(stack)

栈(stack)是一种先进后出的内存结构，存储局部变量、函数形参和返回地址。
栈是从高地址向低地址方向增长。
在C语言中，函数参数的入栈顺序是从右到左。
C语言中形参和实参之间是值传递。
每个线程都有自己专属的栈。
栈的最大尺寸固定，超出则引起栈溢出。
变量离开作用域后，栈上的内存会由系统自动释放，释放速度很快。
栈分配与释放消耗CPU资源，只能存储少量的数据。


堆(heap)

堆区由操作系统分配给每个进程，动态内存从堆中获取，调用 malloc()、calloc()、realloc()函数分配动态内存。
堆区分配的内存仅能通过指针访问。 
调用 free()函数将内存还给堆。
堆内存用完不释放，可能会导致内存泄漏。
malloc 和 free 函数底层函数是采用全局指针实现的。


BSS段

BSS(Block Started by Symbol): 以符号开始的块，用来存放程序中未初始化的全局变量和局部静态变量的一块区域。
包括所有未初始化的全局变量、用static关键字声明且未初始化的静态全局变量
运行所需空间记录在目标文件中，不在目标文件中占用实际空间
程序启动过程中需要初始化的任意变量都可以存放在BSS段中。



什么时候用堆和栈？

如果明确知道数据占用多少内存，那么数据量较小时用栈，较大时用堆 
如果不知道数据量大小(可能需要占用较大内存)，最好用堆(因为这样保险些)
如果需要动态创建数组，则用堆

Linux 下内存分配管理如下图所示

  



常见的内存错误

内存分配未成功，却使用了它。编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。
内存分配虽然成功，但是尚未初始化就引用它。犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。 内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。
内存分配成功并且已经初始化，但操作越过了内存的边界。
忘记了释放内存，造成内存泄露。
释放了内存却继续使用它。
程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。
函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。
使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。



4. 函数库函数库是可以被调用来执行的一段功能函数。函数库分为静态库和动态库。
Linux 内核提供的库函数大多数放在 /usr/include、/usr/lib、/usr/lib64 里面。
5. 静态库所有编译器都提供一种机制，将所有相关的目标模块打包成一个单独的文件，成为静态库(static library)，它可作为链接器的输入。Linux 系统下以 .a 后缀，而 Windows 下以 .lib 后缀。
命名规则

Linux中以 .a 结尾。形如：lib + 库的名字 + .a 
libtest.a 静态库为 test

制作步骤

由.c 文件生成 .o 文件。   例如：gcc *.c -Wall -I ./include/

将 .o 文件打包。使用 ar 命令，参数为 rcs。基本格式为  ar rcs 静态库的名字(libtest.a) 所有的.o文件 

ar rcs libstatic_1.a *.o


另外一种写法：例子：gcc main.c -I ./include -L lib -l mylib -o main.out


优缺点

优点：加载速度快。发布程序的时候不需要对应的库(include)文件.
缺点：打包的程序占用很大的空间。程序发生改变时，需要重新编译静态库。

6. 动态库动态库也叫共享库(share library)，它是一个目标模块，在运行或加载时，能加载到任意的内存地址，并链接一个内存中的程序，这个过程就叫动态链接(dynamic linking)，它是由一个叫动态链接器(dynamic linker)的程序来执行的。Linux 系统下以 .so 后缀，而 Windows 下以 .dll 后缀。

只有在程序执行的过程中才会加载动态链接库。

思考？

既然动态库是在运行时加载，那为什么在编译时还需要指明？
因为在编译的时候，编译器需要知道每一个动态库中提供了哪些符号。


6.1. Linux平台
命名规则

Linux中以 .so 结尾。形如：lib + 库的名字 + .so
例如：libtest.so


制作步骤

生成与位置无关的 .o 文件。使用的命令 gcc -fPIC -c *.c -I ./include  将当前目录下所有的 .c 文件都生成 .o 文件，其中包括的头文件在 ./include 路径下。
将 .o 文件打包。 gcc -shared -o libmytest.so *o -I ./include  将当前目录下所有的 .o 文件打包为共享库 libmytest.so


共享库的调用

gcc main.c ./lib/libmytest.so -o main.out -I ./include  源文件  main.c 与./lib/libmytest.so 目录下的动态库文件链接生成可执行的 main.out 文件
gcc main.c -L ./lib -l mytest -o main.out -I ./include    这种方式实现，需要在系统中配置动态链接库的环境变量。


ldd 查看可执行文件 (.out) 在动态执行过程中所依赖的所有动态库。
在 ldd 执行的结果中，=&gt; 左边的表示该程序需要连接共享库的名称，右边表示由 Linux 的共享库系统找到对应的共享库，在文件系统中的具体位置。
[root@redis_181 lib64]# ldd libselinux.so.1        linux-vdso.so.1 =&gt;  (0x00007ffe5ec63000)        libpcre.so.1 =&gt; /lib64/libpcre.so.1 (0x00007faf6fbb0000)        libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007faf6f9ac000)        libc.so.6 =&gt; /lib64/libc.so.6 (0x00007faf6f5de000)        /lib64/ld-linux-x86-64.so.2 (0x00007faf70039000)        libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007faf6f3c2000)

程序加载动态库是从系统的环境变量中去查找的。
① 开发过程中临时使用的一种方法，不是永久生效。每次关闭终端，都会将配置的环境变量清除。

系统提供的动态链接库环境变量 LD_LIBRARY_PATH
将自己制作的动态链接库路径导入到 LD_LIBRARY_PATH 路径中。export  LD_LIBRARY_PATH = 制作的动态链接库路径

② 直接在 .bashrc文件中去配置 export  LD_LIBRARY_PATH = 制作的动态链接库路径。每次打开终端都会去读取配置的文件。
③ 比较常用的方法 

查找动态连接器的配置文件。查找 /etc 目录下的 ld.so.conf文件
将自己制作的动态链接库路径写到配置文件中。要使用绝对路径，完整的动态库位置。
更新配置文件。sudo ldconfig -v

优点

执行程序的体积较小。
在程序的接口没有发生改变之前，不需要重新编译程序。

缺点 

发布程序的时候，需要将动态库发布给用户。
加载的速度相对静态库比较慢。

6.2. Windows平台C++ 在调用 Dll 中的函数的时候，如果是企业内部的话，肯定是希望三件套的方式(.h .lib .dll)。这样做的话，编写方可以在头文件中写入很多信息，方便调用方的调用。但是，一旦是给其他公司的人使用，而不想让别人看到的话，那编写方肯定是不想让别人看到过多的信息的，你只管调用。还有一点是 dll 是在调试的时候使用的，lib 是编译的时候使用的，两者是不同时期使用的工具。
7. ELF relocatable

查看符号表内容
readlf -s main.o

8. GCCGCC 原名为 GNU C 语言编译器（GNU C Compiler），只能处理 C 语言。但其很快扩展，变得可处理 C++，后来又扩展为能够支持更多编程语言，如 Fortran、Pascal、Objective -C、Java、Ada、Go 以及各类处理器架构上的汇编语言等，所以改名GNU编译器套件（GNU Compiler Collection）
常用参数项-g(gdb)                生成调试信息-Wall                  编译时生成调试信息-E(prEprocessed)       源文件文件 .c 生成 预处理文件 .i-S(aSsembler)          预处理文件 .i 生成汇编文件 .s-c(compile小写)         汇编文件 .s 生成可执行文件 .o -o(output 小写)         生成可执行的二进制文件(类似于Windows中的.exe文件)-L(link)                链接库路径-O(Optimizations 大写)  优化代码-I(dIr)                 指定include头文件  gcc test.c -I ./include -o test.out  使用 -I 链接指定目录下(./include)的头文件进行编译生成可执行文件。-D(Defn macro)           指定相关的宏文件(控制日志log输出)  链接指定目录下(./include)的头文件进行编译生成可执行文件，并使用 -D 链接定义的 DEBUG 宏，生成调试信息。  gcc test.c -I ./include -o test.out -D DEBUG  -fPIC(position independent code)  生成与位置无关的代码 --Woverride-virtual   编译时检查虚函数


GCC 包下载：fedoraproject.org
gun.org
清华大学 GNU 源镜像

8.1. 源码编译三部曲第一步：执行脚本 configure 文件，设置指定的参数，建立 Makefile 文件。
./configure --prefix=指定软件路径例如：../configure --prefix=/usr/local/gcc-4.9.4 -enable-checking=release -enable-languages=c,c++ -disable-multilibCentOS7 4.8.4 默认安装时的配置../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-x86_64-redhat-linux/cloog-install --enable-gnu-indirect-function --with-tune=generic --with-arch_32=x86-64 --build=x86_64-redhat-linux参数项  --prefix：指定安装路径。  --enable-threads=posix：启用POSIX标准的线程支持。要让程序能在符合POSIX规范的linux发布版上正确运行，就应该启用该选项。这里取决于目标操作系统的类型，其它可用值有：aix、dec、solaris、win32等。  --disable-checking：不对编译时生成的代码进行一致性检查（检查的话一般设置为：--enable-checking=release）。建议机器硬件配置较低以及不愿等待太久编译时间的童鞋，可以设置为disable，但是这会增加产生未预期的错误的风险。  --disable-multilib：如果你的操作系统是32位，默认就已经设置为disable，这意味着gcc仅能生成32位的可执行程序。如果你的操作系统是64位，默认设置为enable，这意味着用gcc编译其它源文件时可以通过-m32选项来决定是否生成32位机器代码。由于我们这里是64位系统上，所以要禁止生成32位代码。  --enable-languages=c,c++：支持的高级语言类型和运行时库，可以设置的所有语言还包括ada、Fortran、java、objc、obj-c++、GO等语言。这里只开启了c和c++，因为支持的语言越多，就需要安装越多的相应静态与动态库，等待的时间也越久。

第二部：执行 make 命令
执行 make 命令进行 编译。

第三步：执行 make install
安装软件到第一步 ./configure 后面指定的路径下。

8.2. CentOS7 安装高版本 gcc8&#x2F;g++81、安装软件仓库包 scl: yum install centos-release-scl2、安装 gcc/g++，数字 8 对应的是 gcc/g++8: yum install devtoolset-8-gcc devtoolset-8-gcc-c++3、shell 终端临时设置默认版本，重启后失效: scl enable devtoolset-8 -- bash；长期有效设置：vim /etc/profile 文件中的最后一行加入: source /opt/rh/devtoolset-8/enable

高版本 GCC 编译器编译 C++11 之下的代码，可能出现的问题？
许多 c++11 功能都需要 C++ 标准库的新 libc++ 实现。但是 libc++ 与旧的 libstdc++ 不兼容，但目前大多数软件通常都与旧的 libstdc++ 链接。
libc++ 使用内联 namespace 来帮助确保 ABI不兼容类型不会被误认为是彼此之间的错误。如果接口(interface) 直接使用 libc++ std::string，则期望 libstdc++ std::string 的库将不会链接到该接口(interface)，因为实际的符号是不同的 :std::string 与 std::__1::string。

8.3. 拓展知识点GCC4.8.1 支持 C++11  GCC 4.8.1 will be C++11 feature-complete [2013-04-01]Support for C++11 ref-qualifiers was added to the GCC 4.8 branch, making G++ the first C++ compiler to implement all the major language features of the C++11 standard. This functionality will be available in GCC 4.8.1.

GCC5.3 支持 C++14  GCC 5 C++14 language feature-complete [2014-12-23]  Support for all C++14 language features has been added to the development sources for GCC, and will be available when GCC 5 is released next year. Contributed by Jason Merrill, Braden Obrzut, Adam Butcher, Edward Smith-Rowland, and Jakub Jelinek.


GNU GCC 历史版本发布说明
离线 GCC 安装教程
Linux编译安装GNU gcc 4.9.4
【推荐】CentOS安装gcc-4.9.4+更新环境+更新动态库)
CentOS下离线安装gcc环境，图文详细，方法全面

9. 工具9.1. readelf读取 ELF(Executable and Linking Format) 文件中信息
参数项-l  readelf -l libxxx.so# -S   查看符号表内容  readelf -S xxx.out/xxx.so/xxx.a-r  查看重定位信息    

9.2. size 查看object文件或者链接库文件中的object文件的各个段(section)的大小及其总的大小。
9.3. nm查看静态库或可执行文件里面的内容（list symbols from object files：列出一个函数库文件中的符号表）。
例如：nm main.out， nm mylib.a 
9.4. pmap打印一个进程的内存映射（report memory map of a process）。
示例：
pmap 进程PID

9.5. patchelfpatchelf 是一个简单的实用程序，用于修改已存在的 ELF 可执行表（executables）和库（libraries）。它会改变 可执行表的动态加载器（loader），同时也会改变可执行表和库的路径（PATH）。
--print-needed  查看一个可执行程序或动态库，依赖于其它哪些模块。  anna$:/usr/lib$ patchelf --print-needed libmpathcmd.so.0  libc.so.6

9.6. objdump是 Linux 下的反汇编目标文件或者可执行文件的命令，它以一种可阅读的格式让你更多地了解二进制文件可能带有的附加信息。
常用符号表字段.text：   已编译程序的机器代码。.rodata： 只读数据，比如printf语句中的格式串和开关(switch)语句的跳转表。.data：   已初始化的全局C变量。局部C变量在运行时被保存在栈中，既不出现在.data中，也不出现在.bss节中。.bss：    未初始化的全局C变量。在目标文件中这个节不占据实际的空间，它仅仅是一个占位符。目标文件格式区分初始化和未初始化变量是为了空间效率在：在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。.symtab： 一个符号表(symbol table)，它存放在程序中被定义和引用的函数和全局变量的信息。一些程序员错误地认为必须通过-g选项来编译一个程序，得到符号表信息。实际上，每个可重定位目标文件在 `.symtab` 中都有一张符号表。然而，和编译器中的符号表不同，.symtab符号表不包含局部变量的表目。.rel.text：当链接噐把这个目标文件和其他文件结合时，`.text` 中的许多位置都需要修改。一般而言，任何调用外部函数或者引用全局变量的指令都需要修改。另一方面调用本地函数的指令则不需要修改。注意，可执行目标文件中并不需要重定位信息，因此通常省略，除非使用者显式地指示链接器包含这些信息。.rel.data：被模块定义或引用的任何全局变量的信息。一般而言，任何已初始化全局变量的初始值是全局变量或者外部定义函数的地址都需要被修改。.debug：  一个调试符号表，其有些表目是程序中定义的局部变量和类型定义，有些表目是程序中定义和引用的全局变量，有些是原始的C源文件。只有以-g选项调用编译驱动程序时，才会得到这张表。.line：  原始C源程序中的行号和 `.text` 中机器指令之间的映射。只有以 `-g` 选项调用编译驱动程序时，才会得到这张表。.strtab：一个字符串表，其内容包括 `.symtab` 和 `.debug` 中的符号表，以及节头部中的节名字。字符串表就是以 `null` 结尾的字符串序列。

参数选项-a  --archive-headers       显示档案库的成员信息,类似ls -l将lib*.a的信息列出。 -b bfdname --target=bfdname 指定目标码格式。这不是必须的，objdump能自动识别许多格式，比如： objdump -b oasys -m vax -h fu.o 显示fu.o的头部摘要信息，明确指出该文件是Vax系统下用Oasys编译器生成的目标文件。objdump -i将给出这里可以指定的目标码格式列表。 -C  --demangle              将底层的符号名解码成用户级名字，除了去掉所开头的下划线之外，还使得C++函数名以可理解的方式显示出来。 -g --debugging              显示调试信息。企图解析保存在文件中的调试信息并以C语言的语法显示出来。仅仅支持某些类型的调试信息。有些其他的格式被readelf -w支持。 -e  --debugging-tags        类似 -g 选项，但是生成的信息是和ctags工具相兼容的格式。 -d --disassemble            从 objfile 中反汇编那些特定指令机器码的 section。 -D  --disassemble-all       与 -d 类似，但反汇编所有section. --prefix-addresses          反汇编的时候，显示每一行的完整地址。这是一种比较老的反汇编格式。 -EB -EL --endian=&#123;big|little&#125;       指定目标文件的小端。这个项将影响反汇编出来的指令。在反汇编的文件没描述小端信息的时候用。例如S-records. -f --file-headers           显示 objfile 中每个文件的整体头部摘要信息。 -h --section-headers --headers 显示目标文件各个section的头部摘要信息。 -H --help 简短的帮助信息。 -j name  --section=name      仅仅显示指定名称为name的section的信息 -l --line-numbers            用文件名和行号标注相应的目标代码，仅仅和 -d、 -D 或者 -r 一起使用使用 -ld 和使用 -d 的区别不是很大，在源码级调试的时候有用，要求编译时使用了 -g 之类的调试编译选项。 -m machine --architecture=machine 指定反汇编目标文件时使用的架构，当待反汇编文件本身没描述架构信息的时候(比如 S-records)，这个选项很有用。可以用 -i 选项列出这里能够指定的架构. -r --reloc                  显示文件的重定位入口。如果和-d或者-D一起使用，重定位部分以反汇编后的格式显示出来。 -R  --dynamic-reloc         显示文件的动态重定位入口，仅仅对于动态目标文件意义，比如某些共享库。 -s  --full-contents         显示指定 section 的完整内容。默认所有的非空section都会被显示。 -S --source                 尽可能反汇编出源代码，尤其当编译的时候指定了 -g 这种调试参数时，效果比较明显。隐含了 -d 参数。--show-raw-insn             反汇编的时候，显示每条汇编指令对应的机器码，如不指定 --prefix-addresses，这将是缺省选项。 --no-show-raw-insn          反汇编时，不显示汇编指令的机器码，如不指定 --prefix-addresses，这将是缺省选项。 --start-address=address     从指定地址开始显示数据，该选项影响 -d、 -r 和 -s 选项的输出。 --stop-address=address      显示数据直到指定地址为止，该项影响-d、-r和-s选项的输出。 -t --syms                   显示文件的符号表入口。类似于 nm -s 提供的信息 -T --dynamic-syms           显示文件的动态符号表入口，仅仅对动态目标文件意义，比如某些共享库。它显示的信息类似于 nm -D|--dynamic 显示的信息。 -V --version                版本信息 --all-headers -x            显示所可用的头信息，包括符号表、重定位入口。 -x 等价于 -a -f -h -r -t 同时指定。 -z --disassemble-zeroes     一般反汇编输出将省略大块的零，该选项使得这些零块也被反汇编。 @file                       可以将选项集中到一个文件中，然后使用这个 @file 选项载入。


10. Build两种编译构建方式。

原生(native)编译构建，即编译构建命令所运行(host)的系统环境和编译构建输出目标(target)的系统环境一致；
交叉(cross)编译构建，上述target和host不一致，即在A系统环境构建出在B系统上运行的目标，这在嵌入式开发中尤为多见。
系统环境：GNU的构建工具链中使用CPU指令集架构、厂商、系统内核的三元组合来指示系统环境



11. References
C++ Dll 编写入门
编译器的工作过程
内存管理(详细版)：详细的解释了内存四区的相关内容。
编译连接出现undefined reference to “”的解决方法 

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>compile-link</tag>
      </tags>
  </entry>
  <entry>
    <title>coredump</title>
    <url>/Linux/Linux/coredump/</url>
    <content><![CDATA[

1. 什么是 Core dump?Core dump 中文翻译为“核心转储”，它是进程运行时在突然崩溃的那一刻的一个内存快照。
程序 core 是指应用程序无法保持正常 running 状态而发生的崩溃行为。程序 core 时会生成相关的 core-dump 文件，是程序崩溃时程序状态的数据备份。
操作系统在程序发生异常而异常在进程内部又没有被捕获的情况下，会把内存、处理器、寄存器、程序计数器、栈指针等状态信息保存在一个文件里。该文件是二进制文件，使用 gdb、elfdump、objdump 或者 windows 下的 windebug、solaris下 的 mdb 等工具打开和分析文件的内容。
2. core 产生原因2.1. Core dump 产生前提条件进程在 core dump 的时候会产生 core 文件，但是有时候却发现进程虽然发生了 core dump，但是在体统中却找不到 core文件。那到底是哪儿出了问题？
ulimit  -c 可以设置 core 文件的大小，如果这个值为 0，则不会产生 core 文件，这个值太小，则 core 文件也不会产生，因为core文件一般都比较大。
使用 ulimit  -c unlimited 来设置无限大，则任意情况下都会产生 core 文件。
2.2. Core dump 生成目录设置 Core dump 的核心转储文件目录和命名规则
/proc/sys/kernel/core_uses_pid 可以控制产生的 core 文件的文件名中是否添加 pid 作为扩展 ，如果添加则文件内容为 1 ，否则为 0
/proc/sys/kernel/core_pattern 可以设置格式化的 core 文件保存位置或文件名 ，比如原来文件内容是 core-%e
可以这样修改 :
echo &quot;/corefile/core-%e-%p-%t&quot; &gt; core_pattern

将产生的 core 文件存放到 /corefile 目录下，产生的文件名为 core- 命令名 -pid- 时间戳
以下是参数列表 
%p - insert pid into filename 添加 pid%u - insert current uid into filename 添加当前 uid%g - insert current gid into filename 添加当前 gid%s - insert signal that caused the coredump into the filename 添加导致产生 core 的信号%t - insert UNIX time that the coredump occurred into filename 添加 core 文件生成时的 unix 时间%h - insert hostname where the coredump happened into filename 添加主机名%e - insert coredumping executable name into filename 添加命令名


2.3. 修改core文件保存路径
默认生成的 core 文件保存在可执行文件所在的目录下，文件名为 core。
通过修改/proc/sys/kernel/core_uses_pid文件使生成的core文件加上pid号，echo 1&gt;/proc/sys/kernel/core_uses_pid。
还可以通过修改/proc/sys/kernel/core_pattern控制生成的 core 文件保存的位置以及文件名。

3. GDB定位 Core 文件定位core的基本流程可总结为以下几步：

明确core的大致触发原因。机器问题？自身程序问题？
定位代码行。哪一行代码出现了问题。
定位执行指令。哪一行指令干了什么事。
定位异常变量。指令不会有问题，是指令操作的变量不符合预期。

善于利用汇编指令以及 打印指令（x、print、display可以更有效的定位Core。
利用 GDB 调试生成的 core 文件。
# gdb execulte_file core_filegdb hello-word.out core.12259


4. References
https://zhuanlan.zhihu.com/p/98700797
https://blog.csdn.net/sunxiaopengsun/article/details/72974548
https://blog.csdn.net/p942005405/article/details/102059719
Linux Core Dump
如何快速定位程序Core？

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>coredump</tag>
      </tags>
  </entry>
  <entry>
    <title>curl</title>
    <url>/Linux/Linux/curl/</url>
    <content><![CDATA[

1. Curllinux curl 是一个利用 URL 规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称 url为下载工具。
1.1. API/usr/include/curl/curl.h 中。
CURLcode curl_global_init(long flags);描述：这个函数只能用一次。(其实在调用curl_global_cleanup 函数后仍然可再用)如果这个函数在curl_easy_init函数调用时还没调用，它讲由libcurl库自动完成。
参数：flags
CURL_GLOBAL_ALL  &#x2F;&#x2F;初始化所有的可能的调用。CURL_GLOBAL_SSL  &#x2F;&#x2F;初始化支持 安全套接字层。CURL_GLOBAL_WIN32 &#x2F;&#x2F;初始化win32套接字库。CURL_GLOBAL_NOTHING   &#x2F;&#x2F;没有额外的初始化。
1.1.2. void curl_global_cleanup(void);描述：在结束libcurl使用的时候，用来对curl_global_init做的工作清理。类似于close的函数。
1.1.3. char *curl_version( );描述: 打印当前libcurl库的版本。
2. The Easy interface同步接口。
curl_easy_init()curl_easy_cleanup()curl_easy_setopt()curl_easy_perform()curl_easy_getinfo()



Easy 接口使用的步骤：

Create easy handle for transfer
Set options for transfer
Perform transfer
Cleanup after transfer

2.0.1. CURL *curl_easy_init( );描述:curl_easy_init用来初始化一个CURL的指针(有些像返回FILE类型的指针一样). 相应的在调用结束时要用curl_easy_cleanup函数清理.一般curl_easy_init意味着一个会话的开始. 它的返回值一般都用在easy系列的函数中.
2.0.2. void curl_easy_cleanup(CURL *handle);描述:这个调用用来结束一个会话.与curl_easy_init配合着用. 
参数:CURL类型的指针.
2.0.3. CURLcode curl_easy_setopt(CURL *handle, CURLoption option, parameter);描述: 这个函数最重要了.几乎所有的curl 程序都要频繁的使用它.它告诉curl库，程序将有如何的行为。比如要查看一个网页的html代码等.(这个函数有些像ioctl函数)
参数:1 CURL类型的指针2 各种CURLoption类型的选项.(都在curl.h库里有定义,man 也可以查看到)3 parameter 这个参数 既可以是个函数的指针,也可以是某个对象的指针,也可以是个long型的变量.它用什么这取决于第二个参数.
CURLoption 这个参数的取值很多.具体的可以查看man手册.
2.0.4. CURLcode curl_easy_perform(CURL *handle);描述:这个函数在初始化CURL类型的指针 以及curl_easy_setopt完成后调用. 就像字面的意思所说perform就像是个舞台.让我们设置的option 运作起来.
2.2. Multi interface异步接口。
接口使用的步骤

Create easy handles for transfers

Set options for transfers

Create multi handle

Set multi handle options

Drive all transfers if not all are completed

Wait for something to happen, goto(5)

Cleanup after transfer


2.3. multi-socket interface3. The primary structs3.1. 命令参数-a/–append    上传文件时，附加到目标文件-A/–user-agent    设置用户代理发送给服务器-anyauth    可以使用“任何”身份验证方法-b/–cookie &lt;name=string/file&gt;    cookie字符串或文件读取位置     –basic    使用HTTP基本验证-B/–use-ascii    使用ASCII /文本传输-c/–cookie-jar    操作结束后把cookie写入到这个文件中-C/–continue-at    断点续传-d/–data    HTTP POST方式传送数据     –data-ascii    以ascii的方式post数据     –data-binary    以二进制的方式post数据     –negotiate    使用HTTP身份验证     –digest    使用数字身份验证     –disable-eprt    禁止使用EPRT或LPRT     –disable-epsv    禁止使用EPSV-D/–dump-header    把header信息写入到该文件中     –egd-file    为随机数据(SSL)设置EGD socket路径     –tcp-nodelay    使用TCP_NODELAY选项-e/–referer    来源网址-E/–cert &lt;cert:[passwd]&gt;    客户端证书文件和密码 (SSL)     –cert-type    证书文件类型 (DER/PEM/ENG) (SSL)     –key    私钥文件名 (SSL)     –key-type    私钥文件类型 (DER/PEM/ENG) (SSL)     –pass    私钥密码 (SSL)     –engine    加密引擎使用 (SSL). “–engine list” for list     –cacert    CA证书 (SSL)     –capath    CA目录 (made using c_rehash) to verify peer against (SSL)     –ciphers    SSL密码     –compressed    要求返回是压缩的形势 (using deflate or gzip)     –connect-timeout    设置最大请求时间     –create-dirs    建立本地目录的目录层次结构     –crlf    上传是把LF转变成CRLF-f/–fail    连接失败时不显示http错误     –ftp-create-dirs    如果远程目录不存在，创建远程目录     –ftp-method [multicwd/nocwd/singlecwd]    控制CWD的使用     –ftp-pasv    使用 PASV/EPSV 代替端口     –ftp-skip-pasv-ip    使用PASV的时候,忽略该IP地址     –ftp-ssl    尝试用 SSL/TLS 来进行ftp数据传输     –ftp-ssl-reqd    要求用 SSL/TLS 来进行ftp数据传输-F/–form &lt;name=content&gt;    模拟http表单提交数据     –form-string &lt;name=string&gt;    模拟http表单提交数据-g/–globoff    禁用网址序列和范围使用&#123;&#125;和[]-G/–get    以get的方式来发送数据-H/–header    自定义头信息传递给服务器     –ignore-content-length    忽略的HTTP头信息的长度-i/–include    输出时包括protocol头信息-I/–head    只显示请求头信息-j/–junk-session-cookies    读取文件进忽略session cookie     –interface    使用指定网络接口/地址     –krb4    使用指定安全级别的krb4-k/–insecure    允许不使用证书到SSL站点-K/–config    指定的配置文件读取-l/–list-only    列出ftp目录下的文件名称     –limit-rate    设置传输速度     –local-port    强制使用本地端口号-m/–max-time    设置最大传输时间     –max-redirs    设置最大读取的目录数     –max-filesize    设置最大下载的文件总量-M/–manual    显示全手动-n/–netrc    从netrc文件中读取用户名和密码     –netrc-optional    使用 .netrc 或者 URL来覆盖-n     –ntlm    使用 HTTP NTLM 身份验证-N/–no-buffer    禁用缓冲输出-o/–output    把输出写到该文件中-O/–remote-name    把输出写到该文件中，保留远程文件的文件名-p/–proxytunnel    使用HTTP代理     –proxy-anyauth    选择任一代理身份验证方法     –proxy-basic    在代理上使用基本身份验证     –proxy-digest    在代理上使用数字身份验证     –proxy-ntlm    在代理上使用ntlm身份验证-P/–ftp-port使用端口地址，而不是使用PASV-q    作为第一个参数，关闭 .curlrc-Q/–quote    文件传输前，发送命令到服务器-r/–range    检索来自HTTP/1.1或FTP服务器字节范围–range-file    读取（SSL）的随机文件-R/–remote-time    在本地生成文件时，保留远程文件时间     –retry    传输出现问题时，重试的次数     –retry-delay    传输出现问题时，设置重试间隔时间     –retry-max-time    传输出现问题时，设置最大重试时间-s/–silent    静默模式。不输出任何东西-S/–show-error    显示错误     –socks4 &lt;host[:port]&gt;    用socks4代理给定主机和端口     –socks5 &lt;host[:port]&gt;    用socks5代理给定主机和端口     –stderr     -t/–telnet-option &lt;OPT=val&gt;    Telnet选项设置     –trace    对指定文件进行debug     –trace-ascii    Like –跟踪但没有hex输出     –trace-time    跟踪/详细输出时，添加时间戳-T/–upload-file    上传文件     –url    Spet URL to work with-u/–user &lt;user[:password]&gt;    设置服务器的用户和密码-U/–proxy-user &lt;user[:password]&gt;    设置代理用户名和密码-w/–write-out [format]    什么输出完成后-x/–proxy &lt;host[:port]&gt;    在给定的端口上使用HTTP代理-X/–request    指定什么命令-y/–speed-time    放弃限速所要的时间，默认为30-Y/–speed-limit    停止传输速度的限制，速度时间



4. References
offical curl docs: https://curl.se/docs/
Everything curl: https://everything.curl.dev/
[libcurl programming tutorial](libcurl - programming tutorial)
libcurl - programming tutorial
curl_easy_setopt的基本选项解析 
curl学习篇3：curl API简介
https://cloud.tencent.com/developer/article/1580392

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title>curses</title>
    <url>/Linux/Linux/curses/</url>
    <content><![CDATA[

1. 介绍ncurses(new curses)是一套编程库，它提供了一系列的函数以便使用者调用它们去生成基于文本的用户界面。ncurses名字中的n意味着“new”，因为它是curses的自由软件版本。由于AT&amp;T“臭名昭著”的版权政策，人们不得不在后来用ncurses去代替它。ncurses是GNU计划的一部分，但它却是少数几个不使用GNU GPL或LGPL授权的GNU软件之一。
其实我们对ncurses本身并不陌生，以下几款大名鼎鼎的软件都用到过ncurses：

vim
emacs
lynx
screen

2. 安装2.1. Ubuntu 中安装 cursessudo apt-get install libncurses5-dev

2.2. centos 中安装 cursesyum install ncurses-devel

2.3. 源码安装 ncurse 库下载地址：http://ftp.gnu.org/pub/gnu/ncurses/
3. 案例示例：生成一个基于文本的图像化界面。
#include &lt;string.h&gt;#include &lt;ncurses.h&gt;int main(int argc,char* argv[])&#123;    initscr();    raw();    noecho();    curs_set(0);    char* ptr = &quot;Hello, StephenWen!&quot;;    mvprintw(LINES/2,(COLS-strlen(ptr))/2,ptr);    refresh();    getch();    endwin();    return 0;&#125;



4. References
https://www.cnblogs.com/memoryXudy/p/10830548.html

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curses</tag>
      </tags>
  </entry>
  <entry>
    <title>cygwin</title>
    <url>/Linux/Linux/cygwin/</url>
    <content><![CDATA[ 

1. Cygwin1.1. Command(命令)
查看当前cygwin版本：cygcheck -c cygwin
显示Windows下的进程 ps -aW 
iconv 将文本文件从一种字符编码转换为另一种字符编码   iconv -f  输入编码  -t  输出编码  输入文件 &gt; 输出文件
cygcheck 包管理，查找或者显示包的信息

1.2. References
silaoA的博客: Cygwin学习路线：介绍了相关Cygwin的使用，重点值得阅读。
Cygwin的使用方法
Cygwin工具使用入门教程

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cygwin</tag>
      </tags>
  </entry>
  <entry>
    <title>gdb</title>
    <url>/Linux/Linux/gdb/</url>
    <content><![CDATA[ 

1. 简介GDB 是什么？
GDB 全称“GNU symbolic debugger”，从名称上不难看出，它诞生于 GNU 计划（同时诞生的还有 GCC、Emacs 等），是 Linux 下常用的程序调试器。发展至今，GDB 已经迭代了诸多个版本，当下的 GDB 支持调试多种编程语言编写的程序，包括 C、C++、Go、Objective-C、OpenCL、Ada 等。实际场景中，GDB 更常用来调试 C 和 C++ 程序。一般来说，GDB主要帮助我们完成以下四个方面的功能：

启动你的程序，可以按照你的自定义的要求随心所欲的运行程序。
在某个指定的地方或条件下暂停程序。
当程序被停住时，可以检查此时你的程序中所发生的事。
在程序执行过程中修改程序中的变量或条件，将一个bug产生的影响修正从而测试其他bug。

简单的讲，GDB 就是一个程序，只不过这个程序通过一些手段可以去调试其它的程序。 
2. 安装 GDB2.1. 在线安装yum install gdb



2.2. 源码安装1. 源码解压  [root@KF-CFT-AP2 ~]# tar -zcvf gdb-10.2.tar.gz2. 进入解压目录  [root@KF-CFT-AP2 ~]# cd gdb-10.23. 设置配置，configure 后面可设置参数和安装路径，  [root@KF-CFT-AP2 gdb-10.2]# ./configure    配置参数项  configure [--help]            [--prefix=dir]  自定义配置路径            [--exec-prefix=dir]            [--srcdir=dirname]            [--target=target]            --enable-tui=yes  配置 TUI模式            --with-ncurses    带 ncurses 库            --with-python=yes 带 python 脚本            4. 编译，执行make  [root@KF-CFT-AP2 gdb-10.2]# make5. 安装   [root@KF-CFT-AP2 gdb-10.2]# make install6. 将编译生成的 gdb 可执行文件考到 /usr/bin/   [root@KF-CFT-AP2 gdb-10.2]# cp gdb/gdb /usr/bin/gdb6. 检查是否安装成功，终端下执行  [root@KF-CFT-AP2 ~]$ gdb -v  GNU gdb (GDB) 10.2  Copyright (C) 2021 Free Software Foundation, Inc.  License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;  This is free software: you are free to change and redistribute it.  There is NO WARRANTY, to the extent permitted by law.

3. Invoking GDBGDB 是一个非常重要的调试工具，要用 GDB，首先要知道如何去启动 GDB。
通过运行 gdb 程序来调用 GDB，一旦开始了，GDB 读来自 terminal 的命令，直到你告诉它要退出，它才退出。
下面是几种启动 GDB 的方式：
启动前提：
使用 gdb 调试程序之前，必须使用 -g 或 –ggdb 编译选项编译源文件：gcc xxx.c -g -o xxx.out 

第一种：直接启动可执行文件，gdb 后面跟一个参数：可执行文件。其中 a.out 是带有调试信息的可执行文件
[root@KF-CFT-AP2 SrcCompile]$ gdb a.outGNU gdb (GDB) 10.2Copyright (C) 2021 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type &quot;show copying&quot; and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;https://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from a.out...

gdb 后面不跟选项字段时，启动后默认会打印 gdb 的描述信息，比如：著作权、法律、证书等。每次启动都打印这些有点啰嗦，让启动时不打印这些信息，后面跟 --silent 或 --quiet/-q 等选项。
[root@KF-CFT-AP2 SrcCompile]$ gdb a.out  --silentReading symbols from a.out...(gdb)[root@KF-CFT-AP2 SrcCompile]$ gdb a.out  --quietReading symbols from a.out...(gdb)[root@KF-CFT-AP2 SrcCompile]$ gdb a.out -qReading symbols from a.out...(gdb)

第二种：启动调试程序名后带参数的程序
gdb --args a.out  ini/hello.ini

第三种：先启动可执行文件，后面不带参数，然后再 GDB 里面设置参数项
(gdb) gdb a.out(gdb) set args  ini/hello.ini

第四种：启动可执行文件和指定一个 core 文件
(gdb) gdb a.out core.3256

4. Shell Commands在 GDB 调试的过程中，需要执行外部的 shell 命令，但同时又不想退出当前 GDB 或悬挂当前GDB 的情况下，要怎么去执行 Shell 命令。
有 2 种方式去实现。一种在命令前添加 shell 关键字即可；另一种在命令前加 !，表示去执行外部的 shell 命令。 
(gdb) shell pwd/home/John/SrcCompile(gdb) !pwd/home/John/SrcCompile

make
GDB 程序中可以直接执行 make 命令，不需要用 shell make 这样的格式。
格式：  make make-args   执行 make 程序，后面指定个参数，参数为可选项。   (gdb) make gdb) make clean

5. Logging Output将 GDB的命令保存到文件中，可用 GDB 的 logging 命令。
// Enable or disable logging.set logging enabled [on|off]// Change the name of the current logfile. The default logfile is gdb.txt.set logging file file// By default, gdb will append to the logfile. Set overwrite if you want set logging enabled on to overwrite the logfile instead.set logging overwrite [on|off]// By default, gdb output will go to both the terminal and the logfile. Setredirect if you want output to go only to the log file.set logging redirect [on|off]// By default, gdb debug output will go to both the terminal and the logfile. Setdebugredirect if you want debug output to go only to the log file.set logging debugredirect [on|off]// Show the current values of the logging settingsshow logging

6. 常用命令6.1. runrun 命令表示启动程序，简写 r。若程序没有打断点，执行命令后程序运行完了就直接退出调试过程。
运行 run 的前提确：确保你的操作系统环境支持进程的执行环境，通常情况下，操作系统都支持，但也有特例。
GDB 程序中执行 run 命令，GDB 会创建一个子进程，让创建的子进程运行你的程序。
开始执行 run 命令之前，需要在 GDB 中加载你要调试的程序信息，这些信息也可在程序运行后进修改，但是修改后的信息只在下次程序开始后生效。因为你要调试程序的执行受到它从父进程（GDB程序）那里接收到的某些信息的影响。而这些信息被划分为下面的 4 大类：
6.1.1. arguments调试程序的参数。有些程序运行带有参数项，在执行 run 命令开始前，需要指定参数项才能让程序运行起来。
set args 命令用来设置被调试程序的参数。有三种方式来指定。
// 指定运行时的参数(gdb) set args 参数

第一种：
在启动GDB时，程序后面直接参数。 gdb --args a.out  ini/hello.ini

第二种
先启动可执行文件，后面不带参数，然后再 GDB 里面设置参数项gdb b.out(gdb) set args  ini/hello.ini

第三种
在运行程序时，直接指定(gdb) run  ini/hello.ini

显示被调试程序设置的参数。
(gdb) show argsArgument list to give program being debugged when it is started is &quot;ini/hello.ini&quot;.(gdb)

6.1.2. environment调试程序的环境变量。你要调试程序的环境通常继承自 GDB 程序。你也可以用 set environmen 和 unset environmen 命令来改变你要调试程序的环境。

path directory  
将目录名 directory 添加到 PATH 环境变量（可执行文件的搜索路径）的前面，环境变量将值传递给你要调试的程序，而 gdb 程序使用的 PATH 值不会更改。你也可以同时指定多个目录名（directory  ），用空格或操作系统依赖的分隔符（‘:’ on Unix, ‘;’on MS-DOS and MS-Windows  ）分割开。 

show paths  
显示可执行文件的搜索路径列表。
(gdb) show pathsExecutable and object file path: /usr/local/git/bin:/usr/local/gcc-4.9.4/bin:/usr/jdk1.8.0_102/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/puppetlabs/bin:/home/John/bin(gdb)

show environment [varname]  
打印你给调试程序设置的环境变量值varname 。若没有给设定的值 varname，将会打印你的调试程序中所有的环境变量和名字。environment 可简写为 env。
(gdb) show env

set environment varname [&#x3D;value]  
设置环境变量的名字等于某个值 value。这个值会改变你要调试程序的环境变量，但不会改变 GDB 程序自身的环境变量。若 value 值被忽略，则变量名将被设置为 null。
// 告诉被调试的程序，当运行 run 命令时，环境变量 kk 的值为 foo(gdb) set env kk=foo

unset environment varname  
从被调试程序的环境变量表中移除环境变量 varname。


6.1.3. working directory调试程序的工作目录。用 set cwd 命令设置你要调试程序的工作路径。没有设置工作路径，若用正向调试（native debugging），你调试的程序继承自 GDB 程序的工作路径；若用远程调试，你调试的程序继承自远程服务器的工作路径。

set cwd [directory]  
设置子程序的工作路径为 directory。若没有指定参数directory，该命令将重置以前设置的路径，并将路径设置一个空的状态。设置的路径不会影响 GDB 程序的工作路径，只会影响下次你启动的子进程（inferior）。

~ 表示 home 目录。


show cwd   
current working directory，简写为 cwd。show cwd 命令表示显示子进程（inferior）的工作路径。若没有指定子进程的工作路径，子进程默认继承自 GDB 程序的工作路径。
(gdb) set cwd ~(gdb) show cwdCurrent working directory that will be used when starting the inferior is &quot;~&quot;.

cd [directory]  
设置 GDB 程序的工作路径为某个目录 directory。若没有指定参数 directory 值，则 directory 参数默认使用 ~ 路径。
// gdb 中切换到 xxx 目录(gdb) pwdWorking directory /home/John/SrcCompile.(gdb) cdWorking directory /home/John.(gdb) pwdWorking directory /home/John.(gdb) cd IOV/Server/Working directory /home/John/IOV/Server.(gdb)

pwd  
打印 GDB 程序的工作目录。
// 显示当前所在目录(gdb) pwdWorking directory /home/John/SrcCompile.

注意：调试的程序在 debug 的过程中，很难找到程序当前的工作路径，因为调试程序的工作路径在改变。若操作系统的 GDB 支持 info proc 命令，则用该命令去找到被调试者（debuggee）的当前工作路径。
(gdb) info procprocess 22593cmdline = &#x27;/home/zhoush/SrcCompile/a.out&#x27;cwd = &#x27;/home/zhoush/SrcCompile&#x27;exe = &#x27;/home/zhoush/SrcCompile/a.out&#x27;(gdb)



6.1.4. standard input and output调试程序的 input&#x2F;output。你要调试的程序通常用相同的标准输入和标准输出。你也可以在 run 命令行中重定向输入和输出，也可以使用 tty 命令为程序设置其他的设备。
执行 GDB 程序中执行 run 命令。
(gdb) run



6.2. startstart 命令表示启动程序时，在程序的 main 函数处设置一个临时断点，然后再调用 run 命令。
(gdb) startTemporary breakpoint 1 at 0x400877: file test.cpp, line 10.Starting program: /home/John/SrcCompile/a.outTemporary breakpoint 1, main (argc=1, argv=0x7fffffffe4c8) at test.cpp:1010          int a = 10;xxxxxxxxxx (gdb)  start (gdb) startTemporary breakpoint 1 at 0x400877: file test.cpp, line 10.Starting program: /home/John/SrcCompile/a.outTemporary breakpoint 1, main (argc=1, argv=0x7fffffffe4c8) at test.cpp:1010          int a = 10;

6.3. startistarti 表示在程序开始执行的第一条指令处设置一个临时断点，然后调用 run命令。
(gdb) startiStarting program: /home/John/SrcCompile/a.outProgram stopped.0x000000304c001420 in _start () from /lib64/ld-linux-x86-64.so.2(gdb)

6.4. continue 继续执行程序，简写 c。
(gdb) continue

6.5. quitquit 表示从 GDB 调试程序中退出，简写 q。执行快捷键 Ctrl-d 也能退出 GDB 程序。
(gdb) quit



6.6. listlist 查看源码中指定的行和函数，默认查看10 行 程序代码，缩写为 l。命令后面可跟参数，指定查看的范围。
list 从当前位置开始处，打印 10 行源码list linenum   以 linenum 行为中心行，开始打印源码  list function  以 function 函数处为中心行，开始打印源码list -  在上一次打印行的最后一行处，往前面开始打印源码，- 后面可跟行号或函数名list +  在上次打印行之后开始打印源码，- 后面可跟行号或函数名list num1,num2  指定位置，打印 num1 到 num2 之间的源码   

用 set listsize 命令改变默认打印源码的行数。
set listsize count      设置默认打印 count 行		set listsize 20     改为默认打印 20 行		set listsize unlimited  默认打印的行数没有限制

show listsize   显示 list 命令默认打印的行数(gdb) show listsizeNumber of source lines gdb will list by default is 10.

指定行的具体位置去打印源码，源文件名与源码位置之间使用冒号（:）分隔
list -offset   参数 offset 为偏移量，表明是向前还是向后打印，从上一次打印的最后一行处开始算list +offset  list filename:function	list xxx.c:func 查看 xxx.c 文件中的 func 函数	filename:linenum	  list xxx.c:100 从第 100 行开始查看 xxx.c 文件中内容





6.7. breakbreak 命令用来设置断点，缩写为 b 。
在进行GDB调试之前需要先打断点。GDB中的断点分为：普通断点、观察断点、捕捉断点，一般使用 break 打的断点称为普通断点，使用 watch 打的断点称为硬件断点，使用 catch 打的断点称为捕捉断点。
// 示例break mian 在 main 函数处设置断点。  break 20   在 20行 处设置断点。// 设置条件断点b 22 if i==10   在22行处，当 i==10 时设置一个断点。可以直接在某个文件的某个函数打断点，然后运行查看，多文件可以设置断点。

注意: 有循环体的时候，断点应设置在循环体的内部。在循环体(for、while等语句)的时候程序不会停。
6.8. delete删除指点的断点，参数必须是断点编号，若不指定编号，删除所有的断点。简写为 del。
// 删除当前编号为 N 的断点，N为数字(gdb) del N

其它相关的命令
(gdb)disable 断点号n：暂停第n个断点(gdb)enable 断点号n：开启第n个断点



6.9. next单步执行命令，简写为 n。单步执行到有函数的位置时，不进入到函数内部，直接跳过去执行下条指令。
用法  1. 单步执行一次：n   2. 单步执行多次，N表示重复的次数：n [N]  (gdb)(gdb) l1       #include &lt;iostream&gt;2       #include &lt;stdlib.h&gt;34       #include &lt;unistd.h&gt;56       using namespace std;78       int main(int argc, char *argv[])9       &#123;10          int a = 10;(gdb)11          int b = 20;12          int x = a + b;13          cout &lt;&lt; x &lt;&lt; endl;1415          return 0;16      &#125;(gdb)Line number 17 out of range; test.cpp has 16 lines.(gdb) b 10Breakpoint 1 at 0x400877: file test.cpp, line 10.(gdb) rStarting program: /home/John/SrcCompile/a.outBreakpoint 1, main (argc=1, argv=0x7fffffffe4c8) at test.cpp:1010          int a = 10;(gdb) p a$1 = 0(gdb) n11          int b = 20;(gdb) p a$2 = 10(gdb) n 213          cout &lt;&lt; x &lt;&lt; endl;(gdb) p x$3 = 30

6.10. next intonexti 全名为 next into ，表示单步汇编调试指令，简写为 ni。单步执行到有函数的位置时，跳过函数内部，然后再继续一步一步的执行指令。
用法  1. 单步执行一次汇编指令：ni  2. 单步执行多次汇编指令：ni [N]





6.11. step单步调试命令，简写为 s。单步执行到有函数的位置时，进入函数内部继续一步一步的执行指令。
用法：  1. 单步执行一次：s  2. 单步执行多次 N 条指令：s [N]

6.12. step intostepi 全名为 step into ，表示单步汇编调试指令，简写为 si。单步执行到有函数的位置时，进入函数内部继续一步一步的执行指令。
用法  1. 单步执行一次汇编指令：si  2. 单步执行多次汇编指令：si [N]

6.13. finishfinish 表示从函数体内部跳出去，简写 fin 。如果该函数体内部打的有断点，首先需要把断点删除，然后再跳出函数体。
6.14. untiluntil 跳出单次循环，然后跳到循环后面的语句，简写 u。
6.15. print查看指定变量值
print(p) 变量名 

查看和设置GDB中的显示项，查看用 show 命令，设置用 set 命令。
(gdb) set print object on   GDB会自动按照虚方法调用的规则显示输出(gdb) set print vtbl on     GDB将用比较规整的格式来显示虚函数表时，默认是关闭的(gdb) set print pretty on   每一行显示结构体查看虚函数显示格式(gdb) show print vtblPrinting of C++ virtual function tables is on.查看静态数据成员选项(gdb) show print static-membersPrinting of C++ static members is on.查看联合体数据的显示方式(gdb) show print unionPrinting of unions interior to structures is on.打开数组显示，打开后当数组显示时，每个元素占一行，如果不打开的话，每个元素则以逗号分隔。这个选项默认是关闭的。(gdb) set print array on显示数组显示方式(gdb) show print arrayPretty formatting of arrays is off.打开地址输出，GDB会显出函数的参数地址，系统默认为打开的(gdb) set print address on显示地址输出方式(gdb) show print addressPrinting of addresses is on.



6.16. ptype查看变量的类型
ptype 变量名 

6.17. displaydisplay 变量名 在循环的时候实时追踪变量的值。 display i 追踪变量 i 的值
6.18. undisplayundisplay 变量名的编号  不追踪某个变量的值。首先查看不需要追踪变量的编号 i(info) display ，然后使用 undisplay 变量名的编号 去掉不用追踪的变量。
whatis显示变量或函数类型
6.19. set设置变量的值
set var=value 



6.20. call调用和执行一个函数。
6.21. clear清除断点。
(gdb)clear 行号n：清除第n行的断点



6.22. dir使用directory（或dir)命令设置源文件的查找目录。如果希望在gdb启动时，加载code的位置，避免每次在gdb中再次输入命令，可以使用gdb的-d 参数
// -q 为 quiet 的缩写，-d 为 directory 的缩写gdb -q a.out -d /search/code/some

6.23. info显示正在调试程序的通用命令。info 是通用命令，简写为 i 后面还要跟具体要显示的子命令（subcommands），这些子命令可以是 args，registers 等等，描述当前程序的命令。
// 语法info subcommands// 示例(gdb) info filesSymbols from &quot;/home/John/IOV/Server/HttpClient&quot;.Local exec file:        `/home/John/IOV/Server/HttpClient&#x27;, file type elf64-x86-64.        Entry point: 0x400840        0x0000000000400200 - 0x000000000040021c is .interp        0x000000000040021c - 0x000000000040023c is .note.ABI-tag        0x0000000000400240 - 0x0000000000400298 is .hash        0x0000000000400298 - 0x0000000000400430 is .dynsym        0x0000000000400430 - 0x0000000000400697 is .dynstr        0x0000000000400698 - 0x00000000004006ba is .gnu.version//  查看设置的断点信息内容info break// 查看程序的是否在运行，进程号，被暂停的原因。(gdb)info program // 打印出当前函数中所有局部变量及其值info locals

6.24. show显示 GDB 本身内部的信息，像 version，environment，user 等等。语法同 info 命令一样。
// 语法show subcommands(gdb) show versionGNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.  Type &quot;show copying&quot;and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-redhat-linux-gnu&quot;.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.// 查看程序运行路径(gdb) show paths  

官方参考：https://sourceware.org/gdb/onlinedocs/gdb/Help.html
command6.25. helphelp 命令查看 GDB 的帮助信息。 帮助手册是学习 GDB 最权威、最好的资料，需要仔细研磨，但是常常被大多数人给遗忘了，去网上搜索各种各样的资料。

help命令后面不加任何参数，得到 GDB 所有命令，而这些命令按照不同的功能分为几大类。
(gdb) helpList of classes of commands:aliases -- Aliases of other commandsbreakpoints -- Making program stop at certain pointsdata -- Examining datafiles -- Specifying and examining filesinternals -- Maintenance commandsobscure -- Obscure featuresrunning -- Running the programstack -- Examining the stackstatus -- Status inquiriessupport -- Support facilitiestracepoints -- Tracing of program execution without stopping the programuser-defined -- User-defined commandsType &quot;help&quot; followed by a class name for a list of commands in that class.Type &quot;help all&quot; for the list of all commands.Type &quot;help&quot; followed by command name for full documentation.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;.Command name abbreviations are allowed if unambiguous.

查看某个命令的具体用法，help 后面跟需要查询的命令。
// 查看 break 命令帮助信息(gdb) help breakSet breakpoint at specified line or function.break [LOCATION] [thread THREADNUM] [if CONDITION]LOCATION may be a line number, function name, or &quot;*&quot; and an address.If a line number is specified, break at start of code for that line.If a function is specified, break at start of code for that function.If an address is specified, break at that exact address.With no LOCATION, uses current execution address of the selectedstack frame.  This is useful for breaking on return to a stack frame.THREADNUM is the number from &quot;info threads&quot;.CONDITION is a boolean expression.Multiple breakpoints at one place are permitted, and useful if theirconditions are different.Do &quot;help breakpoints&quot; for info on other commands dealing with breakpoints.

官网地址：https://sourceware.org/gdb/onlinedocs/gdb/Help.html


6.26. OthersGDB 中特殊的命令。

enter 键执行上一次输入过的命令

7. TUITUI（Text User Interface）进行交互式的源码调试。进入图形界面的进行调试有下面两种方式。
第一种：终端下直接执行 gdb program -tui命令。
gdb program -tui

终端下执行上面这条命令后，利用图形的方式调试可执行程序 program 。


第二种：先进入 GDB 程序，然后再 GDB中执行　layout xxx 命令。
layout 命令用于分割窗口，可以一边查看代码，一边测试。TUI模式下，总共有 4 种窗口。

command：gdb 命令窗口是带有 gdb 提示符和 gdb 输出的 。使用 readline 去管理 GDB 的输入。

source：执行 layout src 命令显示源代码窗口，窗口中显示程序的源文件。可以使用 PageUp，PageDown 和4个方向键来查看源码。

assembly：执行 layout asm 命令显示汇编窗口，窗口中显示程序的汇编代码。

register：执行 layout regs 命令显示寄存器窗口，窗口中显示处理器的寄存器值。寄存器中的值发生改变，寄存器就会高亮。


其它 layout 相关指令

layout split：分离窗口，用来显示多个窗口。
layout next：显示下一个layout
layout prev：显示上一个layout

7.1. TUI 中的断点通过高亮当前行和在当前行开头设置 &gt; 标记来显示当前程序在源文件和汇编文件中的位置。在交互式的窗口上面，设置断点后，断点通过两种标记来显示。第一个标记表明断点的类型，其类型如下：

B 表示断点处代码已经运行至少一次。
b 表示断点处代码还没有运行到
H 表示观察断点（Hardware breakpoint）处代码已经运行至少一次。
h 表示观察断点（Hardware breakpoint）处代码还没有运行到。

第二标记表示断点是否使能。

+ 表示断点处于enable状态。
- 表示断点处于disable状态。

7.2. 快捷键TUI 窗口绑定的快捷键。

Ctrl + L：刷新窗口
Ctrl + x，再按1：单窗口模式，显示一个窗口
Ctrl + x，再按2：双窗口模式，显示两个窗口
Ctrl + x，再按a：回到传统模式，即退出 layout，回到执行 layout 之前的调试窗口。
Ctrl + p 查看上一个（prev）命令
Ctrl + N 查看下一个（next）命令

8. Examining Source Files源文件检查包括查看源码、编辑源文件、搜索源文件、指定源码路径、源码和汇编代码、禁止读源码等内容。
8.1. 查看源码源码的查看使用 list 命令，list 的用法请参考 “常用命令”中的 “list”用发。
8.2. 编辑源码GDB 下对源码进行编辑，使用 edit 命令。有多种方式用 edit 打开源码文件，下面仅列出 2 种常用的方式。
edit number   编辑当前文件，并跳转到 number 行edit file:number 编辑指定的 file 文件，并跳转到 number 行edit function 编辑当前文件，并跳转到 function 函数处的下一行edit file:function 编辑指定的 file 文件，并跳转到 function 函数处

GDB 默认使用的编辑器是 /bin/ex，然而你也可以让 GDB 编辑时打开使用你自定义的编辑器，改变环境变量中的 EDITOR 即可。
比如，配置 GDB 使用 vi 编辑器，在 shell 终端执行下面的命令即可。
EDITOR=/usr/bin/viexport EDITORgdb ...



8.3. 改变源码路径为什么要改变源文件的路径？
某些场景中代码编译与程序执行没有在相同的路径下运行，或者源文件被移动到了另外一个目录，甚至还有可能代码编译实在编译环境中操作，而程序运行则在开发环境下（另一台机器），此时你想要调试怎么办？这时就需要手动指定源路径表（source path）中的源码位置。
手动去指定 source path 的核心：保证 Debug 信息中要有源码的路径，这样你在调试时，才能一边看源码，一边看程序执行的信息。
 源路径（source path）：一个搜索源文件的目录列表（list）。
GDB 的 source path 默认包含两个特别的项 $cwd，$cdir， GDB 启动时会默认去搜索源路径 $cdir:$cwd

cwd(current working directory)：GDB 当前工作路径，和 . 是不一样的。cwd 在 GDB 运行过程中是会改变的，可以通过 cd 命令来修改，要注意这个 cd 修改的是 GDB session 中的当前目录，不会影响启动 GDB 程序时的目录位置。
cdir(compilation directory)：编译目录，是代码在编译时记录到 debug 信息中的目录。

若 Debug 信息中记录了编译路径，但 source path 中搜索不到源文件，这时，GDB 将会结合编译路径和文件名再一次去 source path 中找源文件。
有两种方式查看源代码文件名和编译目录。
第一种：GDB 程序中查看源代码文件名和编译目录
(gdb) i source	Current source file is ../../Src/FrameWorkServer.cpp  Compilation directory is /home/John/SrcCompile/Src/FrameWorkServer/Makefile/Debug  Located in /home/John/SrcCompile/Src/FrameWorkServer/Src/FrameWorkServer.cpp  Contains 65 lines.  Source language is c++.  Compiled with DWARF 2 debugging format.  Does not include preprocessor macro info.// 查看调试的程序中所有的源文件目录和编译目录(gdb) i sources

第二种：外部终端下查看源码路径
$ readelf a.out -p .debug_str

在开始操作之前，需要弄清楚 GDB 中几个重要的概念。

编译路径（compilation directory）：编译源代码的路径。
源码路径（source path）：源码存放的位置。
可执行文件路径：编译完成的程序在哪个目录下运行。
可执行文件记录的源文件路径（the executable records the source file）：编译后的可执行程序中记录的编译时路径。
GDB 当前工作路径（ current working directory）：在哪个目录下启动 GDB 程序。

例子：编译路径为 /project/build，源码路径为 /mnt/cross:$cdir:$cwd，可执行文件记录的源文件路径为 /usr/src/foo-1.0/lib/foo.c，GDB 当前工作路径为 /home/user，GDB　将会从下面的位置中搜索源文件的路径：
/usr/src/foo-1.0/lib/foo.c             /mnt/cross/usr/src/foo-1.0/lib/foo.c   /project/build/usr/src/foo-1.0/lib/foo.c/home/user/usr/src/foo-1.0/lib/foo.c/mnt/cross/project/build/usr/src/foo-1.0/lib/foo.c/project/build/project/build/usr/src/foo-1.0/lib/foo.c/home/user/project/build/usr/src/foo-1.0/lib/foo.c/mnt/cross/foo.c/project/build/foo.c/home/user/foo.c

注意：可执行文件记录的源文件路径不能用来定位源文件（source files）。
若退出 GDB 后，重新启动，GDB 会清除它缓存的有关源文件的位置以及每行在源文件中的位置信息。重新开始 GDB 时，source path 只包含 $cdir 和 $cwd，若想要在源路径列表中添加新的源文件路径，用 directory  或 set substitute-path 命令。
set substitute-path 命令可同时操作多个源文件，操作整个目录树，而 directory 命令每次只能改变一个源文件路径。比如之前源文件在 /usr/src 目录下，现在源文件被移到了 /mnt/cross 目录下。之前源文件中的 foo-1.0 目录中有多个文件，若用 directory 命令，需要对每个文件进行设置，太费时间了，而用 set substitute-path 命令，则需要替换目录名即可，不用对每个文件一一设置。
substitute-path 命令语法
// 替换源码目录，将原来路径下的 src 替换为 xxx/xxxx/dest(gdb) set substitute-path src xxx/xxxx/dest// 例如：将 /usr/src 替换为 /mnt/cross(gdb) set substitute-path /usr/src /mnt/cross// 当有多条 set substitute-path 设置的规则时，按顺序依次添加规则，则源路径列表中按添加的顺序去设置// 将 /usr/src/include/defs.h 路径替换为 /mnt/include/defs.h// 将 /usr/src/lib/foo.c 路径替换为 /mnt/src/lib/foo.c(gdb) set substitute-path /usr/src/include /mnt/include(gdb) set substitute-path /usr/src /mnt/src

// 从路径列表中删除指令的路径 path// 若不指定 path 路径参数，则从 source path 中删除整个替换的规则unset substitute-path [path]

// 打印源路径列表中的替换规则，如果有的话，它将重写该路径// 若不指定 path 路径参数，从源路径列表中打印已存在的替换规则show substitute-path [path]

directory 命令语法，其中 directory 缩写为 dir。
// 查看源路径列表中包含的目录(gdb) show dir    Source directories searched: $cdir:$cwd// dir 后面不跟路径，Linux 系统下则默认设置为 $cdir:$cwd (gdb) dir// 设置源码的路径为 xxxx(gdb) dir   xxxx  // 指定多个路径，linux 下每个路径名之间用冒号（:）分隔开，window下用分号（;）分隔开(gdb) dir dirname1:dirname2:dirname3

若我每次启动 GDB 后都要去设置源码的路径，编写程序文件很少时没问题，但在大工程中用 Makefile 去编译的工程，编译在太机器上，程序运行在另外一台机器上，导致了编译路径、源码路径、可执行程序的路径都发生了变化，并且文件是非常多的。调试程序时，无论是用 directory 命令还是用 substitute-path 命令，都需要设置很多次，感觉很麻烦和费时，那有没有一种操作：将我要执行的命令放到一个文件中，然后 GDB 程序启动时去加载这个文件，然后再执行文件中的命令。
很幸运的告诉你，有这么一种操作，那就是在 GDB 程序启动时后面跟 -x 参数和要执行的文件 file。
man 手册中查看 GDB -x 参数说明。
man gdb       -x file               Execute GDB commands from file file.

示例：新建一个 source-path-file 文件，里面放入要执行的命令。
set substitute-path /usr/src/include /mnt/includeset substitute-path /usr/src /mnt/src

外部 shell  终端 GDB 程序启动要调试的文件，后面跟 source-path-file 文件。执行后的结果与在 GDB 程序里面执行 set substitute-path 命令是等价的。
$ gdb a.out -x source-path-file


9. 调试多进程术语

superior  上级的（父进程）
inferior 下级的（子进程。GDB 将每一个被调试程序的执行状态记录在一个名为 inferior 的结构中。一般情况下一个 inferior 对应一个进程，每个不同的 inferior 有不同的地址空间。inferior 有时候会在进程没有启动的时候就存在。

gdb 追踪多个分支（父子进程）

set follow-fork-mode child  追踪子进程
set follow-fork-mode parent 追踪父进程

10. 调试多线程GDB 多线程调试的术语

all-stop mode      全停模式

single-stepping    单步执行

scheduler-locking  调度锁

schedule-multiple  多进程调度

record mode        记录模式

replay mode        回放模式


使用 GDB 调试多线程程序时，默认的调试模式为：一个线程暂停运行，其它线程也随即暂停；一个线程启动运行，其它线程也随即启动。要知道，这种调试机制确实能帮我们更好地监控各个线程的“一举一动”，但并非适用于所有场景。
一些场景中，我们可能只想让某一特定线程运行，其它线程仍维持暂停状态。要想达到这样的效果，就需要借助 set scheduler-locking 命令。 帮我们将其它线程都“锁起来”，使后续执行的命令只对当前线程或者指定线程有效，而对其它线程无效。
set scheduler-locking 命令的语法格式如下：
(gdb) set scheduler-locking mode

其中，参数 mode 的值有 3 个，分别为 off、on 和 step，它们的含义分别是：

off：不锁定线程，任何线程都可以随时执行，这是默认值；
on：锁定线程，只有当前线程或指定线程可以运行；
step：当单步执行某一线程时，其它线程不会执行，同时保证在调试过程中当前线程不会发生改变。但如果该模式下执行 continue、until、finish 命令，则其它线程也会执行，并且如果某一线程执行过程遇到断点，则 GDB 调试器会将该线程作为当前线程。

常用调试的命令

show scheduler-locking     显示线程的scheduler-locking状态
set scheduler-locking on    调试加锁当前线程，停止所有其他线程
gdb attach pid 让进程号为 PID 的进程停止。
info thread 查看当前进程的所有线程信息。
thread &lt;ID&gt; (或 t ID) 切换到指定的线程 ID 号进行调试。

参考

GDB scheduler-locking 命令详解

11. 查看内存11.1. backtrace查看函数调用堆栈信息，简写为 bt。
(gdb) bt

11.2. examineexamine 查看内存地址中的值，简写 x。作用：在堆栈中从指定的哪个地址开始，以什么样的格式显示多长的数据。
// 格式x/nfu addrx addr 

参数 n，f，u，都是可选项。

n 是一个十进制的整数，默认值为 1， 表示显示多大的内存，有后面的单位 u 来定。也就是说从当前地址向后显示多少地址的内容。 
f(format) 显示的格式，默认是以 16 进制显示。  这些格式可以是：‘x’, ‘d’, ‘u’, ‘o’, ‘t’,‘a’, ‘c’, ‘f’, ‘s’  。
u 表示单位大小 unit。从当前地址往后请求的字节数，如果不指定的话，GDB 默认是4个bytes。b 表示bytes，h表示Halfwords (two bytes)，w表示Words (four bytes)，g表示Giant words (eight bytes)。
addr 表示显示的开始地址。

// 从 0x54320 地址开始显示 3 个 十进制无符号半字（Halfwords）大小的内容(gdb) x/3uh 0x54320(gdb) x/5i $pc-60x804837f &lt;main+11&gt;: mov %esp,%ebp0x8048381 &lt;main+13&gt;: push %ecx0x8048382 &lt;main+14&gt;: sub $0x4,%esp=&gt; 0x8048385 &lt;main+17&gt;: movl $0x8048460,(%esp)0x804838c &lt;main+24&gt;: call 0x80482d4 &lt;puts@plt&gt;




12. Watchpoints普通断点：需要程序运行到哪行，你就在哪行设置断点，然后等程序运行到断点处可以单步执行，查看内存变量，遇到多个位置修改同一个变量时，并且要查看是谁改变了变量的时候，就要设置多个断点来进行查看。
硬件断点（Hardware watchpoint）也叫观察断点（Watchpoints）。观察断点就是为了要监控某个变量或者表达式的值，通过值的变化情况来判断程序的执行过程是否存在异常或者Bug。只有某个变量或者表达式的值发生了改变，程序才会停止执行。相比普通断点，观察断点不需要我们预测变量（表达式）值发生改变的具体位置。
用法 
(gdb) watch var_name


在使用 watch var_name 命名之前，需要使用 file a.out，加载 a.out 中的 symbol table，只有符号表加载成功后，才能打硬件断点。


#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;int g_var = 0;void* thread_func(void* args)&#123;    sleep(5);    g_var = 1;&#125;int main()&#123;    int i = 0;    pthread_t tid = 0;    pthread_create(&amp;tid, NULL, thread_func, NULL);    for(i=0; i&lt;10; i++) &#123;        printf(&quot;g_var = %d, tid = %ld\n&quot;, g_var, tid);        sleep(1);    &#125;&#125;

13. CatchpointsCatchpoints 叫捕获断点。
14. 调试正在运行的程序GDB 可以对正在执行的程序进行调度，它允许开发人员中断程序并查看其状态，之后还能让这个程序正常地继续执行。
1、 查看可执行程序的进程号 PID:  ps aux | grep xxx.out
2、 attach 可执行程序的进程 PID: gdb attach process-id

另一种方式：gdb -p pid或程序名。-p 表示 program

3、 当attach进程时，会停止进程的运行，这时使进程继续运行需要使用 continue&#x2F;c 命令。
4、 当程序停止时，用其它的命令查看其它信息

bt 查看堆栈信息 
b(break) 设置断点 
watch var 监控变量 var 的值
info thread 查看当前进程的所有线程信息
info proc 显示进程信息
info reg 显示寄存器信息

15. 设置动态库set solib-search-path  动态库路径

16. ReverseGDB7.0 以上的平台开始支持反向调试需要开启记录，调试结束关闭记录，只有在开启记录之后才能完全正常的进行反向调试。
(gdb) record        开启记录(gdb) record stop   关闭记录(gdb) reverse-next  向上走一步(gdb) reverse-continue 向上继续调试set exec-direction [forward | reverse]   设置程序运行方向，能够像正常调试方式一样反向调试

17. 底层原理ptrace 系统函数是 Linux 内核提供的一个用于进程跟踪的系统调用，通过它，一个进程(gdb)可以读写另外一个进程(test)的指令空间、数据空间、堆栈和寄存器的值。而且gdb 进程接管了test 进程的所有信号，也就是说系统向 test 进程发送的所有信号，都被 gdb 进程接收到，这样一来，test 进程的执行就被 gdb 控制了，从而达到调试的目的。
gdb底层的调试机制是怎样的？

系统首先会启动gdb进程，这个进程会调用系统函数fork()来创建一个子进程，这个子进程做两件事情：

调用系统函数ptrace；
通过execc来加载、执行可执行程序 test，那么test程序就在这个子进程中开始执行了。






18. 参考
GDB 官方英文文档：： 重点看 
CS-MCU GDB tutorial
用图文带你彻底弄懂GDB调试原理
100个gdb小技巧
打印STL容器中的内容
线程的查看以及利用gdb调试多线程
YouTube: MyGeekAdventures 临场演示如何使用GBD去调试代码 
 Linux Tools Quick Tutorial

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gdb</tag>
      </tags>
  </entry>
  <entry>
    <title>inode</title>
    <url>/Linux/Linux/inode/</url>
    <content><![CDATA[ 

1. 查看iNode的命令
查看每个硬盘分区的iNode总数和已经使用的数量 df -i
查看当前路径下每个iNode的节点号  ls  -li
查看某个文件的iNode信息  stat test.txt

2. 什么是iNode?概念：存储文件的元数据的区域叫iNode，也叫”索引节点”
3. iNode包含内容
文件的字节数
文件的read、write、execute权限
文件的ID（User ID、Group ID）
文件的时间戳
ctime:  iNode上一次变动的时间
mtime:  文件内容上一次变动的时间
atime:  文件上一次打开的时间


链接数： 有多少文件名指向这个iNode
文件数据block的位置
创建时间

4. 操作系统是如何打开文件的？
操作系统用iNode号码来识别不同的文件。分为三步：
系统找到这个文件名对应的iNode号
通过iNode号得到iNode中存储的信息
根据iNode中的信息，找到文件数据所在的block区，读出数据



5. 目录文件
Unix&#x2F;Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。
每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的iNode号。
根目录/的iNode号是固定的

6. iNode的应用
有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。
移动文件或重命名文件，只是改变文件名，不影响inode号码。
打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。


删除iNode号为 3453534 的文件
find . inum 3453534 -delete 
 find . -inum 3453534 -exec rm -i &#123;&#125; /;




软件更新的机制：在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。

7. 硬链接与符号链接
创建硬链接：ln source  dest_hard_link_file
创建符号链接：ln -s  source  dest_symbolic_link_file


硬链接：用不同的文件名可以访问相同的内容，修改文件里面的内容，会影响所有的文件名，但是，删除一个文件名不会影响另一个文件名。

软连接（或称符号链接）：相当于一个快捷方式。文件A和文件B的inode号不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。

删除文件B，则不能打开文件A，因为文件A依赖于文件B而存在。
文件A指向的是文件B的文件名，而不是文件B的iNode号，因此。文件B的iNode连接数不会改变。
source和destination都必须指定完整的路径，才创建成功，否则创建的是个文本文件。source必须是已存在的文件，destination是没有创建的文件，需要自己指定。



8. 参考
linux中inode包含什么内容？

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>inode</tag>
      </tags>
  </entry>
  <entry>
    <title>introduce-perf</title>
    <url>/Linux/Linux/introduce-perf/</url>
    <content><![CDATA[

perfperf 有时叫 perf_events 或 perf tools，最初的名字是 PCL(Performance Counters for Linux)，是 Linux 下的一个性能分析的工具(Performance analysis tools for Linux)，从 2009 年发行的 Linux 内核 2.6.31 版本开始支持。
Subcommandsperf  使用时支持多个子命令。

stat: measure total event count for single program or for system for some time
top: top-like dynamic view of hottest functions
record: measure and save sampling data for single program[13]
report: analyze file generated by perf record; can generate flat, or graph profile.[13]
annotate: annotate sources or assembly
sched: tracing&#x2F;measuring of scheduler actions and latencies[14]
list: list available events
trace

可选项参数
-e
-a
-p
-t

References
brendangregg 博客 perf Examples: https://www.brendangregg.com/perf.html
Github 源码: https://github.com/brendangregg/perf-tools
Wikipedia 英文解释 perf (Linux)：https://en.wikipedia.org/wiki/Perf_(Linux)
YouTube Brendan Gregg 解释 Linux Performance Tools, Part-I：https://www.youtube.com/watch?v=FJW8nGV4jxY
YouTube Brendan Gregg 解释 Linux Performance Tools, Part-II：https://www.youtube.com/watch?v=zrr2nUln9Kk

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>introduce-perf</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-basic</title>
    <url>/Linux/Linux/linux-basic/</url>
    <content><![CDATA[

1. Linux Basic介绍 Linux 系统的基础使用，包括计算机的硬件知识、Linux常见基础命令的用法。

写文章的初衷：遇见不会的知识和命令，通过网络查找，当时记住了，但过了一段时间后，再一次遇见之前的知识又要查。每次去查不仅要花费很多时间，而且找的东西良莠不齐，因此记下查的知识点，辅助自己，提高效率。
2. 硬件基础知识磁盘阵列（RAID）：利用硬件技术将数个硬盘整合成为一个大硬盘的方法， 操作系统只会看到最后被整合起来的大硬盘。 由于磁盘阵列是由多个硬盘组成， 所以可以达成速度性能、 备份等任务。 
2.1. MBRMBR(Master Boot Record): 主引导记录
引导启动程序记录区与分区表通常放在磁盘的第一个扇区，这个扇区通常大小为 512 bytes。

446字节的MBR安装启动引导程序，64 字节的分区表记录整块硬盘分区的状态。

由于分区表所在区块仅有64 Bytes容量， 因此最多仅能有四组记录区，每组记录区记录了该区段的启始与结束的柱面号码。 

引导启动程序的作用：加载内核文件。




其实所谓的“分区”只是针对那个64 Bytes的分区表进行设置而已！

硬盘默认的分区表仅能写入四组分区信息

这四组分区信息我们称为主要（ Primary） 或延伸（ Extended） 分区

分区的最小单位“通常”为柱面（ cylinder）

当系统要写入磁盘时， 一定会参考磁盘分区表， 才能针对某个分区进行数据的处理


扩展分区

扩展分区并不是只占一个区块，而是会分布在每个分区的最前面几个扇区来记载分区信息的！
扩展分区的目的是使用额外的扇区来记录分区信息， 扩展分区本身并不能被拿来格式化。 然后我们可以通过扩展分区所指向的那个区块继续作分区的记录。

MBR 主要分区(Primary)、 扩展分区(Extend)与逻辑分区(logical) 三者的区别

主要分区与扩展分区最多可以有四个（ 硬盘的限制）
扩展分区最多只能有一个（ 操作系统的限制）
逻辑分区是由扩展分区持续切割出来的分区；
能够被格式化后作为数据存取的分区是：主要分区与逻辑分区，扩展分区无法格式化；
逻辑分区的数量依操作系统而不同，在Linux系统中 SATA 硬盘已经可以突破63个以上的分区限制；

MBR分区的缺点

操作系统无法抓取到 2T 以上的磁盘容量！
MBR 仅有一个区块，若被破坏后，经常无法或很难救援。
MBR 内存放的启动引导程序最大为 446Bytes， 无法容纳较多的程序码。

2.2. GPTGPT: GUID Partition Table，源自EFI标准的一种较新的磁盘分区表结构的标准，支持64位的寻址。
LBA(Logical Block Address): 逻辑区块位址

LBA0(MBR兼容区块)：储存了第一阶段的启动引导程序。
LBA1(GPT表头记录)：记录了分区表本身的位置与大小， 同时记录了备份用的 GPT 分区（在最后 34 个 LBA 区块）放置的位置，同时放置了分区表的检验机制码（ CRC32），操作系统可以根据这个检验码来判断 GPT 是否正确。 
LBA2-33（实际记录分区的信息地方）：从 LBA2 区块开始，每个 LBA 都可以记录 4 组分区记录，所以在默认的情况下，总共可以有 4*32 &#x3D; 128 组分区记录。 因为每个 LBA 有 512Bytes， 因此每组记录用到 128Bytes 的空间， 除了每组记录所需要的识别码与相关的记录之外， GPT 在每组记录中分别提供了 64bits 来记载开始&#x2F;结束的扇区号码。

GPT 分区已经没有所谓的主、 扩展、 逻辑分区的概念，既然每组纪录都可以独立存在，当然每个都可以视为是主分区， 每一个分区都可以拿来格式化使用。
2.3. BIOS与UEFIBIOS：是一个写入到主板上的一个软件程序（仅有16位），采用汇编语言编写的。 
Boot loader的主要任务

提供加载项：用户可以选择不同的启动选项，这也是多重引导的重要功能。

加载内核文件：直接指向可使用的程序区段，来启动操作系统。

转交其它启动引导程序：将启动管理功能转交给其它引导程序负责。

每个分区都有自己的启动扇区(boot sector)。启动引导程序只会认识自己的系统分区内的可开机核心文件， 以及其它启动引导程序而已；



如果要安装多重开机，为什么最好先安装Windows再安装Linux呢？

因为 Linux在安装的时候，你可以选择将启动引导程序安装在 MBR 或其它分区的启动扇区， 而且Linux的启动引导程序可以手动设置选项，所以你可以在Linux的启动引导程序里面加入Windows启动的选项；Windows在安装的时候， 它的安装程序会主动的覆盖掉 MBR 以及自己所在分区的启动扇区，你没有选择的机会， 而且它没有让我们自己选择选项的功能。因此，如果先安装Linux再安装Windows的话，那么 MBR 的启动引导程序就只会有Windows的选项， 而不会有Linux的选项（ 因为原本在MBR内的Linux的启动引导程序就会被覆盖掉） 。

UEFI(Unified Extensible Firmware Interface): 统一可扩展固件接口，采用C语言编写的。其中UEFI可以直接获取GPT的分区表。
为什么在安装系统时，需要将 UEFI 的 secure boot 关闭？ 

因为使用secure boot会使将要启动的操作系统，必须要被UEFI验证，否则就无法启动。

2.4. 分区挂载：利用一个目录当成进入点，将磁盘分区的数据放置在该目录下。其中根目录（&#x2F;）必须挂载到某个分区，其它的目录可以依据用户的的需求挂载到不同的分区。
操作系统开机的流程：BIOS—&gt;MBR—&gt;引导启动程序—&gt;内核文件
swap 分区：磁盘模拟内存的交换分区，当有数据被存放在物理内存里面，但这些数据又不是常被CPU使用时，这些不常被使用的数据将会被扔到硬盘的交换分区当中去，而速度较快的物理内存将被释放出来给真正需要的程序使用。交换分区不会使用目录树的挂载，所有交换分区就不需要指定挂载点。
3. 基础命令3.1. touchtouch fileName：文件不存在新建一个文本；文件存在时，修改文件创建的时间。
touch test.txt

3.2. rmrm fileName(remove)：删除一个文本
rm -rf: 删除一个目录下的所有文件；以下为两个常用的参数参数  -i(interactive)：让系统在执行前确认。  -r(recursive)：递归

3.3. mkdirmkdir(make directory)：新建一个目录。
创建多层的目录加参数 -p(--parents)一次性创建很多个文件夹[root@CentOS7 ~]# mkdir test/bb&#123;1..10&#125;[root@CentOS7 ~]# ls test/bb1  bb10  bb2  bb3  bb4  bb5  bb6  bb7  bb8  bb9

3.4. rmdirrmdir: 移除一个目录
3.5. mvmv 命令用来将文件或目录改名或将文件由一个目录移入另一个目录中。mv source dest 将文件源文件或目录 (source) 移到 目标文件或目录处 (dest)，并重名为 dest。移动文件： mv a.txt /home/Desptop/ 将当前目录下的 a.txt 文件移动到 /home/Desktop/ 路径下移动目录： mv /usr/lib/* /home 将 /usr/lib/ 路径下的所有文件都移动到 /home/ 路径下。参数选项：  -v(verbose)： 显示 move 命令执行的过程。

3.6. cpcp 命令拷贝文件和目录。
cp src dest  将文件src拷贝到当前目录下为dest文件注意：拷贝目录时，要加参数 -r(recursive)

拷贝操作会复制执行者的属性和权限。
3.7. lsls 命令列出文件夹中的内容
参数  -a  显示所有的文件，包含隐藏的  -l  详细的输出文件夹中内容  -h  以人类可读的形式输出文件的大小  --full-time  以完整的时间格式输出  -t  根据最后修改的时间排序，最新的在第一个  -F  在不同的文件结尾输出不同的特殊符号  -d  显示文件夹本生信息，不输出其中的内容  -r(reverse)  逆序排序  -S  默认按照从小到大对文件夹大小排序  -i  显示文件的 inode 信息

例子1：
ls -al: 查看所有隐藏的文件  ls -l | grep &quot;*-&quot; | wc -l 查看当前目录下的文件夹目录个数（不包含子目录中的目录）。ls | wc -l 统计当前目录下总共有多少行

例2：查看当前路径下的链接文件
[root@centos]# ls -lF | grep ^llrwxrwxrwx 1 root root       18 7月   7 2021 libcrypto.so -&gt; libcrypto.so.1.0.0*lrwxrwxrwx 1 root root       12 7月   7 2021 libcurl.so -&gt; libcurl.so.4*lrwxrwxrwx 1 root root       20 7月   7 2021 libmysqlclient.so -&gt; libmysqlclient.so.20*lrwxrwxrwx 1 root root       12 6月   3 2021 libpcre.so -&gt; libpcre.so.1

3.8. statstat 查看文件的详细信息，比 ls 查看的更多
例子：[root@CentOS7 ~]# stat t.txt  File: ‘t.txt’  Size: 149             Blocks: 8          IO Block: 4096   regular fileDevice: fd00h/64768d    Inode: 34955932    Links: 1Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)Context: unconfined_u:object_r:admin_home_t:s0Access: 2021-11-20 21:20:51.966004651 +0800Modify: 2021-11-20 21:20:44.858014426 +0800Change: 2021-11-20 21:20:44.858014426 +0800 Birth: -

3.9. diskdu(disk usage)：显示指定的目录或文件所占用的磁盘空间大小。
参数  -h(human)：以人类容易看懂的方式显示  -M(megabytes): 以1MB为单位  -s(summarize): 仅显示总计

示例：显示指定路径下文件的大小[root@localhost ~]# du -sh 路径名 统计 `~/` 路径下每个文件的大小[root@localhost ~]# du -sh ~/*4.0K    /root/anaconda-ks.cfg0       /root/Desktop0       /root/Documents0       /root/Downloads0       /root/Music0       /root/Pictures0       /root/Public2.2M    /root/redis-6.0.16.tar.gz0       /root/Templates0       /root/Videos统计当前目录下各个文件的大小[root@localhost ~]# du -h --max-depth=1

3.10. fdiskfdisk 操作磁盘分区表
参数：  -l 查看硬盘的情况

3.11. dfdf(disk free): 显示Linux 系统上文件系统的磁盘使用情况 
参数项：  -h(human)：以人类容易看懂的方式显示  -i(inodes): 列出 inode 信息，不列出已使用的 block  -H: 很像 -h, 但是用 1000 为单位而不是用 1024

3.12. mountmount 挂载命令
语法形式  mount 设备名字 挂在目录    mount –t type dev dir参数：  –t type ：是需要挂载的文件系统类型，光盘文件系统类型是：iso9660；  dev：挂载文件系统的设备名称，光盘驱动器的设备名称是/dev/cdrom;   dir：挂载点，即挂载到的文件目录路径示例：  mount -t iso9660 /dev/cdrom /media/drom

3.13. umountumout 设备装载常用命令
示例：  umount dir device […]

3.14. which在 PATH 变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。
示例：`which gcc`

3.15. whereiswhereis: 查找系统中包含可以找到的所有文件
参数 -b : 只能用于搜索程序名和二进制文件示例：whereis gcc

3.16. hostnamehostname 是 Linux 的主机名。而 Linux 的 hostname 位于 /etc/hostname 下，修改此路径下的文件是永久有效的。
若直接在终端使用命令 hostname xxx 修改，修改后仅仅是本次有效，重启后就失效了。 
4. 系统相关
uname -a:  查看 Linux 版本
lscpu: 查看系统 CPU 情况
locale -a： 列出系统支持的所有语言环境
eject: 将光盘驱动器中的光盘轻轻弹出和收回
nslookup 域名 查看域名对应的IP地址

5. 文件查看命令5.1. catcat(concatenate)：从第一行开始显示文件内容，将要显示的内容一次性的输出在屏幕上。
参数项  - n 显示行号示例：  cat &lt; hello.txt &gt; hello2.txt   # 将 hello.txt 文件内容重定向输出到 hello.txt 文件中，相当于 cp 指令的一个副本。  

5.2. tactac：从最后一行开始显示文件内容。
5.3. nlnl ：查看文件时可以显示行号。
5.4. moremore：一页一页的显示文件内容，只能往后翻。
-n：可以显示行号

5.5. lessless 一页一页的显示文件内容，既可以往后翻又可以往前翻，一般用的最多。
参数： -n：可以显示行号

快捷键    空格键：向下翻一页。一般使用上下箭头进行翻页。    /字符串：向下查找字符串。    ?字符串：向上查找字符串。    n：重复前一个查找。    N：反向重复前一个查找。    g：进到这个数据的第一行。    G：进到这个数据的最后一行。    q：退出less程序。

5.6. odod(Octal Dump)：默认以二进制的方式读取文件内容。将指定文件内容以八进制、十进制、十六进制、浮点格式或 ASCII 编码字符方式显示，通常用于显示或查看文件中不能直接显示在终端的字符。
格式：od -t TYPE 文件参数    -A RADIX   --address-radix=RADIX   选择以何种基数表示地址偏移    -j BYTES   --skip-bytes=BYTES      跳过指定数目的字节    -N BYTES   --read-bytes=BYTES      输出指定字节数    -S [BYTES] --strings[=BYTES]       输出长度不小于指定字节数的字符串，BYTES 缺省为 3    -v         --output-duplicates     输出时不省略重复的数据    -w [BYTES] --width[=BYTES]         设置每行显示的字节数，BYTES 缺省为 32 字节    -t TYPE    --format=TYPE           指定输出格式，格式包括 a、c、d、f、o、u 和 x，各含义如下：      a：利用默认的字符来输出。      c：利用ASCII字符来输出。      d[SIZE]：利用有符号的十进制(decimal)来输出数据。每个整数占用 SIZE bytes。      f[SIZE]：利用浮点数(floating)来输出数据。每个浮点数占用 SIZE bytes。      o[SIZE]：利用八进制(octal)来输出数据。每个整数占用 SIZE bytes。      u[SIZE]：利用无符号的十进制(decimal)来输出数据。每个整数占用 SIZE bytes。      x[SIZE]：利用十六进制(hexadecimal)来输出数据。每个整数占用 SIZE bytes。      SIZE 可以为数字，也可以为大写字母。如果 TYPE 是 [doux] 中的一个，那么 SIZE 可以为          C  = sizeof(char)，S = sizeof(short)，I = sizeof(int)，L = sizeof(long)。          如果 TYPE 是 f，那么 SIZE 可以为 F = sizeof(float)，D = sizeof(double) ，L = sizeof(long double)示例：  od -t x testfile  # 以十六进制输出 testfile，默认以四字节为一组（一列）显示。  echo abc | od -t dCc   # 查看字符的 ASCII 表

5.7. head 和 tailhead、tail：取出文件前几行或最后几行的数据。
示例：  在屏幕上列出 /etc/man_db.conf 文件中的第11行到22行之间的内容，并且显示行号。   cat -n /etc/man_db.conf | head -n 20 | tail -n 10

5.8. uniquniq 输出或忽略文件的重复行，常与 sort 排序命令结合使用
参数项  -c, --count    每行前面显示重复出现的次数  -d, --repeated 只显示重复的行  -u, --unique   只显示出现过一次的行

6. 文件 I&#x2F;O6.1. 文件权限CentOS 使用的是 xfs 作为默认的文件系统。
文件权限

可读（Read），可以读取文件的内容。
可写（Write），可以编辑、新增、或修改该文件的内容，但不具备删除该文件的权限。
可执行（eXecute），Linux下，文件是否能够执行，与文件的后缀名无关，仅由是否具备 x 这个权限来决定。注意: X 代表这个文件具有可执行的能力，但能不能执行成功，需要由文件中的内容决定。


对于文件的 rwx 来说，主要都是针对“文件的内容”而言，与文件文件名的存在与否没有关系，因为文件记录的是实际的数据。文件是存放数据的所在，目录则主要记录文件名列表。因此文件名与目录有强烈的关联。

目录权限

r: 具有读取文件目录结构的权限

w: 具有改动该目录结构列表的权限。

x: 目录不能被执行，x 表示用户能否进入该目录并且成为工作目录。

通常一个用户给其它的用户开放目录，至少要具备 rx 权限，其它的用户才能访问当前用户的目录。



6.2. umask
umask: 指定目前用户在建立文件或目录时的默认权限值。

查看当前系统的umask值：0002 ;第一个数值为特殊权限值，后面三个分别对应为 rwx 的值。

一般文件通常用于记录数据，则用户建立的文件默认没有 x 可执行权限，只有 rw 权限，即 -rw-rw-rw-


用户建立目录 时，默认的权限均开放，即 drwxrwxrwx


使用 ls -l 查看的文件或目录权限值为：文件或目录的默认值减去 umask 的值。

例如：umask值为 003文件：(-rw-rw-rw-)  - (-------wx)  = -rw-rw-r目录：(drwxrwxrwx)  - (-------wx)  = drwxrwx-r

6.3. chattr修改文件的隐藏属性：chattr [+-=] [ASacdistu] 该命令一般用于对数据的安全性比较高的地方
选项与参数+ ： 增加某一个特殊参数， 其他原本存在参数则不动。- ： 移除某一个特殊参数， 其他原本存在参数则不动。= ： 设置一定， 且仅有后面接的参数A ： 当设置了 A 这个属性时， 若你有存取此文件（ 或目录） 时， 他的存取时间 atime 将不会被修改，可避免 I/O 较慢的机器过度的存取磁盘。（目前建议使用文件系统挂载参数处理这个项目）S ： 一般文件是非同步写入磁盘的， 如果加上 S 这个属性时，当你进行任何文件的修改， 该更动会“同步”写入磁盘中。a ： 当设置 a 之后， 这个文件将只能增加数据，而不能删除也不能修改数据， 只有root 才能设置这属性c ： 这个属性设置之后， 将会自动的将此文件“压缩”， 在读取的时候将会自动解压缩，但是在储存的时候， 将会先进行压缩后再储存（ 看来对于大文件似乎蛮有用的！）d ： 当 dump 程序被执行的时候， 设置 d 属性将可使该文件（ 或目录） 不会被 dump 备份i ： 这个 i 可就很厉害了！ 他可以让一个文件“不能被删除、 改名、设置链接也无法写入或新增数据！”对于系统安全性有相当大的助益！ 只有 root 能设置此属性s ： 当文件设置了 s 属性时， 如果这个文件被删除， 他将会被完全的移除出这个硬盘空间，所以如果误删了， 完全无法救回来了！u ： 与 s 相反的， 当使用 u 来设置文件时， 如果该文件被删除了， 则数据内容其实还存在磁盘中，可以使用来救援该文件！注意1： 属性设置常见的是 a 与 i 的设置值， 而且很多设置值必须要身为 root 才能设置注意2： xfs 文件系统仅支持 AadiS 而已范例： 请尝试到/tmp下面创建文件， 并加入 i 的参数， 尝试删除看看。  [root@study ~]# cd /tmp  [root@study tmp]# touch attrtest &lt;==创建一个空文件  [root@study tmp]# chattr +i attrtest &lt;==给予 i 的属性  [root@study tmp]# rm attrtest &lt;==尝试删除看看  rm: remove regular empty file `attrtest&#x27;? y  rm: cannot remove `attrtest&#x27;: Operation not permitted  // 看到了吗？连 root 也没有办法将这个文件删除呢！ 赶紧解除设置！范例： 请将该文件的 i 属性取消！[root@study tmp]# chattr -i attrtest

查看文件或目录的隐藏属性：lsattr [-adR] 文件或目录
6.4. 用户与用户组


说明
用户(owner)
用户组(group)
其它用户(other)



权限
读  写  执行
读  写  执行
读  写  执行


符号
r  w  x
r  w  x
r  w  x


权值
4 2 1
4 2 1
4 2 1


ls -l： 查看目录下文件属性的所有信息，每一栏说明如下：

第1栏有10个字符，其中第1个字符描述类型，后边9个字符描述权限
第2栏是硬链接数，删除文件其实是将链接数减1 ，减到0了就真正删除文件内容
第3、4栏分别是文件的拥有者及所属群组。
第5栏是文件大小，单位为字节（Byte）
第6栏是最近访问（修改）时间
第7栏是文件名，对于符号链接

6.5. 用户权限修改6.5.1. chownchown 命令是 change owner（改变拥有者）的缩写，修改文件的拥有者。需要要注意的是，用户必须是已经存在系统中的，也就是只能改变为在 /etc/passwd 这个文件中有记录的用户名称才可以。
基本语法：  chown [-R] 用户名 文件或目录  chown [-R] 用户名:用户组名称 文件或目录参数：  -R : 进行递归( recursive )的持续更改，即连同子目录下的所有文件、目录都更新成为这个用户组。       常常用在更改某一目录的情况。

实例：
[root@DEV ~]# ll test.txt-rw------- 1 root root 0 May 10 23:42 test.txt[root@DEV ~]# chown zhoush test.txt[root@DEV ~]# ll test.txt-rw------- 1 zhoush root 0 May 10 23:42 test.txt

6.5.2. chgrpchgrp 命令是 change group（改变用户组）的缩写，用于修改文件的用户组。需要注意的是要改变成为的用户组名称，必须在 /etc/group 里存在，否则就会显示错误。
基本语法：  chgrp [-R] 用户组名称 dirname/filename ...参数：  -R : 进行递归( recursive )的持续更改，即连同子目录下的所有文件、目录都更新成为这个用户组。       常常用在更改某一目录的情况。

[root@DEV ~]# ll test.txt-rw------- 1 zhoush root 0 May 10 23:42 test.txt[root@DEV ~]# chgrp zhoush test.txt[root@DEV ~]# ll test.txt-rw------- 1 zhoush zhoush 0 May 10 23:42 test.txt

6.5.3. chmodchmod 命令是修改文件的模式权限，SUID、SGID、SBIT等特性

sudo: do as su(super user)

6.5.4. usermod在 Linux 用户系统中存在两类组。第一类是主要用户组，第二类是附加用户组。所有的用户帐户及相关信息都存储在 /etc/passwd 文件中，/etc/shadow 和 /etc/group 文件存储了用户信息。

useradd  增加一个新用户或者更新默认新用户信息

usermod 更改用户帐户属性，例如将其添加到一个已有的组中。


将一个新用户添加到主要用户组：
useradd -g developers zshid zsh

将一个新用户添加到附加用户组：
useradd -G developers cnzhx

将已存在的用户添加到主要用户组中：
usermod -g developers zshid zsh

将一个已存在用户添加到附加用户组：
usermod -G developers cnzhx

如果要将一个用户从某个组中删除:
gpasswd -d user group

但是这个时候需要保证 group 不是 user 的主组。
​    
参考： https://cnzhx.net/blog/linux-add-user-to-group/
6.6. 特殊权限SUID(Set UID)，简写：s，数字：4
对于一个文件的功能：

SUID 权限仅对二进制程序（ binary program）有效；

执行者对于该程序需要具有 x 的可执行权限；

本权限仅在执行该程序的过程中有效 （ run-time）；

执行者将具有该程序拥有者 （ owner） 的权限。

注意：SUID仅可用在二进制程序上，不能用在shell脚本上面，因为shell脚本只是将很多的二进制可执行文件调用执行。也不能用在目录上面。

例如：


steve 对于 &#x2F;usr&#x2F;bin&#x2F;passwd 这个程序来说是具有 x 权限的， 表示 steve 能执行passwd；
passwd 的拥有者是 root 这个帐号；
steve 执行 passwd 的过程中， 会“暂时”获得 root 的权限；
&#x2F;etc&#x2F;shadow 就可以被 steve 所执行的 passwd 所修改。

对于具有 SUID 特殊权限的文件，可以临时的将该文件的权限由steve（执行者） 变为root（拥有者）。
SGID(Set GID)，简写：s，数字：2

当文件或目录中的用大 S 表示时，代表该文件或目录本身没有可执行的 x 权限，因此 S 或 T 表示当前操作的权限为空。

可以针对文件或目录操作。

对文件具备的功能

仅对二进制程序有用。
程序执行者对于该程序来说，需具备 x 的权限；
执行者在执行的过程中将会获得该程序群组的支持！


对目录的功能

使用者若对于此目录具有 r 与 x 的权限时， 该使用者能够进入此目录；
使用者在此目录下的有效群组（ effective group） 将会变成该目录的群组；
用途： 若使用者在此目录下具有 w 的权限（ 可以新建文件） ， 则使用者所创建的新文件， 该新文件的群组与此目录的群组相同。


SBIT(Sticky BIT)：简写：t，数字：1

仅仅只针对目录有作用，对文件没有作用。
对目录的功能
用户对目录具有 w、x 权限时，即具有写入的权限。
当用户在该目录建立文件或目录时，仅有自己与root才有删除该文件，其他人如法操作。






利用数字的方式修改文件权限：将一个文件的权限改为 -rwsr-xr-x，命令为：chmod 4755 filename


利用符号的方式修改文件权限：SUID为 u+s，SGID为 g+s，SBIT 为 o+t

参考： https://blog.csdn.net/hudashi/article/details/7797393
6.7. 文件类型


类型符号
文件类型
分类



-
一般文件(regular)
纯文本文件、二进制文件、数据文件


d
目录文件(directory)
null


c
字符设备文件(character device)
null


l
符号链接文件(symbolic link)
null


p, f
数据传输文件(pipe, FIFO)
null


s
套接文件(socket)
null


Linux 下文件的最大长度：单一文件或目录的最大允许文件名为 255 bytes，以一个 ASCII 英文占用一个字节来说，则可达 255个 字符长度，每个汉字占用  2 个字节，则最大的文件名大约在 128 个汉字之间。
6.8. Linux 系统目录FHS(Filesystem Hierarchy Standard) ：文件系统分层标准

boot：开机启动配置文件。Linux kernel常用的文件名为：vmlinuz，如果使用的是grub2这个开机管理程序， 则还会存在 /boot/grub2/ 这个目录。
dev：存储外部设备文件。比要重要的文件有 &#x2F;dev&#x2F;null, &#x2F;dev&#x2F;zero, &#x2F;dev&#x2F;tty, &#x2F;dev&#x2F;loop, &#x2F;dev&#x2F;sd等等。
etc：存储系统配置文件，只有root权限才可以修改
bin：放置系统的可执行文件
lib：存放开机时会用到的函数库， 以及在 &#x2F;bin 或 &#x2F;sbin 下面的指令会调用的函数库
media：放置媒体文件：软盘、光盘、DVD
mnt：挂载目录，这个目录的用途与&#x2F;media相同，只是有了 &#x2F;media 之后，这个目录就用来暂时挂载用了。
opt：第三方软件放置处
home：系统默认使用者的文件夹
root：系统管理员（root）的主文件夹。
sbin：放置为开机过程中所需要的，里面包括了开机、修复、还原系统所需要的指令。
srv：srv可以视为“service”的缩写，是一些网络服务启动之后存放的位置
proc：是一个虚拟文件系统，它放置的数据都在内存当中，例如系统核心、行程信息（process）、周边设备的状态及网络状态等等。这个文件本身不占任何的硬盘空间。
sys：这个目录其实跟&#x2F;proc非常类似，也是一个虚拟的文件系统，主要也是记录内核(kernel)与系统硬件信息较相关的参数。包括目前已载入的内核模块与内核侦测到的硬件设备信息等等，这个目录同样不占硬盘容量。
tmp：让一般使用者或者是正在执行的程序暂时放置文件的地方，这个目录是任何人都能够存取的
run：早期的 FHS 规定系统开机后所产生的各项信息应该要放置到 &#x2F;var&#x2F;run 目录下，新版的 FHS 则规范到 &#x2F;run 下面。
usr：是Unix Software Resource的缩写，是Unix操作系统软件资源所放置的目录，而不是使用者的数据。这个目录有点类似Windows 系统的C盘。
var：主要针对常态性变动（variable）的文件，包括高速缓存（cache）、登录文件（log file）以及某些软件运行所产生的文件， 包括程序文件（lock file, run file），或者例如MySQL数据库的文件等等。
lib64：支持 64 位的 &#x2F;lib64 函数库
lost+found：是使用标准的ext2&#x2F;ext3&#x2F;ext4文件系统格式才会产生的一个目录，目的在于当文件系统发生错误时， 将一些遗失的片段放置到这个目录下。不过如果使用的是 xfs 文件系统的话，就不会存在这个目录了！
&#x2F;usr&#x2F;bin&#x2F;：所有一般用户能够使用的指令都放在这里，使用链接文件的方式将 &#x2F;bin 链接至此。也就是说， &#x2F;usr&#x2F;bin 与 &#x2F;bin 是一模一样了！另外，FHS 要求在此目录下不应该有子目录。


&#x2F;usr&#x2F;lib&#x2F;：基本上，与 &#x2F;lib 功能相同，所以 &#x2F;lib 就是链接到此目录中的！
&#x2F;usr&#x2F;local&#x2F;：系统管理员在本机自行安装自己下载的软件，非distribution默认提供者的，建议安装到此目录， 这样会比较便于管理。
&#x2F;usr&#x2F;sbin&#x2F;：非系统正常运行所需要的系统指令。最常见的就是某些网络服务器软件的服务指令（daemon）！不过基本功能与 &#x2F;sbin 也差不多， 因此目前 &#x2F;sbin 就是链接到此目录中的。
&#x2F;usr&#x2F;share&#x2F;：共享数据目录，放置的数据几乎是不分硬件架构均可读取的。
&#x2F;usr&#x2F;games&#x2F;：与游戏相关的数据。
&#x2F;usr&#x2F;include&#x2F;：c&#x2F;c++等程序语言的文件开始（header）与包含档（include）放置处。
&#x2F;usr&#x2F;src&#x2F;：Linux源代码源代码放置处。
&#x2F;usr&#x2F;lib64&#x2F;：与 &#x2F;lib64&#x2F;功能相同，因此目前 &#x2F;lib64 就是链接到此目录中
&#x2F;var&#x2F;cache&#x2F;：应用程序本身运行过程中会产生的一些暂存盘。
&#x2F;var&#x2F;lib&#x2F;：程序本身执行的过程中，需要使用到的数据文件放置的目录。
&#x2F;var&#x2F;lock&#x2F;：设备锁存储的目录。目前此目录链接到 &#x2F;run&#x2F;lock 中！
&#x2F;var&#x2F;log&#x2F;：登录文件放置的目录！里面比较重要的文件，如&#x2F;var&#x2F;log&#x2F;messages, &#x2F;var&#x2F;log&#x2F;wtmp（记录登陆者的信息）等。
&#x2F;var&#x2F;mail&#x2F;：放置个人电子邮件信箱的目录，这个目录&#x2F;var&#x2F;spool&#x2F;mail&#x2F;链接到 &#x2F;var&#x2F;mail&#x2F; 目录。
&#x2F;var&#x2F;run&#x2F;：某些程序或者是服务启动后，会将他们的PID放置在这个目录下喔！ 与 &#x2F;run 相同，这个目录链接到 &#x2F;run去了！
&#x2F;var&#x2F;spool&#x2F;：这个目录通常放置一些伫列数据，所谓的“伫列”就是排队等待其他程序使用的数据啦！ 这些数据被使用后通常都会被删除。

一些链接文件之间的关系/bin --&gt; /usr/bin/sbin --&gt; /usr/sbin/lib --&gt; /usr/lib/lib64 --&gt; /usr/lib64/var/lock --&gt; /run/lock/var/run --&gt; /run


6.9. 绝对路径与相对路径绝对路径：一定由跟目录(/)写起。例如：/usr/share/doc  在shell脚本中一般使用绝对路径，防止因为不同的工作环境导致一些问题的发生。
相对路径：不是由根目录(/)写起。例如：../man  相对路径只是相对于当前的工作路径。
7. tartar 命令用于的文件的打包和解压。 tar 支持的压缩文件类型有下面几种类型：

gzip: 压缩文件后缀(*.gz)
bzip2: 压缩文件后缀(*.bz2)
xz: 压缩文件后缀(*.xz)


7.1. tar文件打包参数项：-c(Create): 打包文件-t(lisT): 察看打包文件的内容含有哪些文件名-x(eXtract): 解压打包文件   注意：-c, -t, -x 不可同时出现在一串命令行中。-v(Verbose): 在压缩/解压缩的过程中，将正在处理的文件名显示出来-f(Filename):  后面要立刻接要被处理的文件名！-C(direCtory: 目录): 将文件解压在特定的目录-p(小写):  保存原本文件的权限与属性，不包含根目录 /。-P(大写)：保留绝对路径，即允许备份的数据中中包含根目录。解压后的数据直接从根目录 / 开始。-z：通过 gzip 的支持进行压缩/解压，此时文件名最好为  *.tar.gz-j：通过 bzip2 的支持进行压缩/解压，此时文件名最好为 *.tar.bz2-J ：通过 xz 的支持进行压缩/解压缩：此时文件名最好为 *.tar.xz  注意：-z, -j, -J 不可以同时出现在一串命令行中

7.2. 打包文件或目录
将当前目录下的  anaconda-ks.cfg 文件打包成 A.tar
tar -cvf A.tar anaconda-ks.cfg 

打包多个文件或目录，中间需要用空格分开
tar -cvf B.tar anaconda-ks.cfg /tmp/

7.3. 解压文件只对文件或目录进行打包，没有进行压缩，其通用格式为
tar -xvf 解压的文件 -C 文件解压后的路径

注意：若后面不跟 -C 文件解压后的路径 ，则会默认将压缩包解压到到当前路径下。
例如： 将 test.tar 打包的文件解包到 /tmp 路径下
tar -xvf test.tar -C /tmp

7.4. 打包并压缩
打包压缩所有文件
tar -zcvf 自己创建的文件名(xxx.tar.gz)  要打包压缩的路径(/etc/): 这样压缩的文件连要压缩文件的目录也一起给压缩了。

打包压缩所有文件不包含打包文件的路径
tar -zcvf tmp4.tar.gz -C etc/ .    将etc下所有文件打包为tmp4.tar.gz 不包含etc包的路径。

打包并压缩一个目录，但不含该目录下的某些文件
  tar -zcvf bb.tar.gz --exclude=etc/apt etc   将etc目录下除去apt文件的所有文件打包压缩为 bb.tar.gz，打包压缩时包含etc的路径。

 一定要注意排除目录的最后不要带 /，否则 exclude 目录将不起作用
 压缩目录和排除目录都需要采用同样的格式，如都采用绝对路径或者相对路径



 
7.5. 解压缩包对打包并压缩后的文件进行解压。例如：将 hello.tar.gz 压缩文件解压到~/Exercise_Linux/tmp目录下。
tar -zxvf hello.tar.gz -C ~/Exercise_Linux/tmp

注意：

指定解压的目录必须要首先存在，否则会出错，tar 命令不会自动创建不存在的文件夹。

不加 -C ~/Exercise_Linux/tmp，表示只是解压到当前目录下。


7.6. zcat zlesszcat、zless 命令直接查看压缩文件中的内容。
$ zcat test.gzhello word$ zless test.gzhello word

7.7. zipzip 是压缩指令，unzip 是解压指令。zip 指令既可以压缩文件，也可以压缩目录。压缩会自动保留源文件，解压会自动保留压缩文件。
// 将demo.txt文件和目录mydir压缩成压缩文件yasuo.zip，选项-r表示递归zip -r yasuo.zip demo.txt mydir  // 压缩当前目录下的子目录mydirzip -r  mydir.zip  mydir         // 解压yasuo.zip文件到当前目录unzip   yasuo.zip                // 把压缩文件解压到指定的mydir目录unzip -d /mydir yasuo.zip        // 检查压缩文件是否损坏unzip -t  yasuo.zip              // 显示demo.zip压缩包中有哪些文件，不进行解压unzip  -l  demo.zip              // 解压时不覆盖已存在的文件unzip  -n  demo.zip              

注意：直接使用 unzip 指令（不带选项）解压文件时，如果解压文件中包含有文件与当前目录下的某个文件重名，那么会询问是否要覆盖这个文件。
8. linkLinux 下用 ln 来执行链接。ln 后面不加 -s 参数表示进行硬链接操作，加参数表示软连接操作。
8.1. hard links硬链接: 指向磁盘中文件的节点（node），只有文件才能创建硬链接，目录不能创建。
硬链接会创建独立的虚拟文件，其中包含了原始文件的信息及位置。但是它们从根本上而言是同一个文件。引用硬链接文件等同于引用了源文件。要创建硬链接，原始文件也必须事先存在，只不过这次使用ln命令时不再需要加入额外的参数了。
// 建立硬链接ln 原文件 新文件 

8.2. symbolic links符号链接就是一个实实在在的文件，它指向存放在虚拟目录结构中某个地方的另一个文件。这两个通过符号链接在一起的文件，彼此的内容并不相同。
要为一个文件创建符号链接，原始文件必须事先存在。然后可以使用 ln 命令以及 -s选项来创建符号链接。
// 建立软连接ln -s source  destination 

9. pipepipe 中文翻译过来是管道的意思，用 | 表示。
定义：将一个命令的输出传送给另一个命令，作为另一个命令的输入，常用 | 表示。管道常与grep命令组合使用：grep 命令1|命令2|命令3|·····|命令n
&amp; 和 &amp;&amp;  | 和 || 四者区别

&amp; : 表示将当前任务放在后台执行，如要在后台运行 redis-server，则有  redis-server &amp;
&amp;&amp;: 表示前一条命令执行成功时，才执行后一条命令，如 echo ‘hello‘ &amp;&amp; echo ‘world’    
| : 表示管道，上一条命令的输出，作为下一条命令参数，如 echo ‘hello’ | wc -l
||: 表示上一条命令执行失败后，才执行下一条命令，如 cat nofile || echo “failed”

10. teeman手册英文原意：tee - read from standard input and write to standard output and files

功能：从标准输入读数据，写到标准输出和文件中。
用法：echo hello | tee file 将 hello 字符写到file文件中并显示在标准输出上。

11. wc作用：print newline, word, and byte counts for each file. (用来统计一个文件或者指定的多个文件中的行数，单词数和字符数)
格式  wc [OPTION]... [FILE]...选项参数  -c --bytes 打印字节数  -l --lines 打印行数  -w --words 打印单词数  -m --chars 打印字符数  -L --max-line-length 打印最长行的长度

12. psps 是进程状态（process status）的缩写，用于查看 Linux 系统中进程的状态情况。
~$ ps auxUSER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot          1  0.0  0.3 128324  6960 ?        Ss   13:58   0:02 /usr/lib/systemd/systemd --switched-root --system --deserialize 22root          2  0.0  0.0      0     0 ?        S    13:58   0:00 [kthreadd]root          4  0.0  0.0      0     0 ?        S&lt;   13:58   0:00 [kworker/0:0H]root          5  0.0  0.0      0     0 ?        S    13:58   0:00 [kworker/u256:0]root          6  0.0  0.0      0     0 ?        S    13:58   0:00 [ksoftirqd/0]root          7  0.0  0.0      0     0 ?        S    13:58   0:01 [migration/0]root          8  0.0  0.0      0     0 ?        S    13:58   0:00 [rcu_bh]root          9  0.0  0.0      0     0 ?        S    13:58   0:25 [rcu_sched]

显示格式参数
USER：用户名%CPU：该进程用掉的CPU百分比%MEM：进程占用内存的百分比VSZ：该进程使用的虚拟內存量（KB）RSS：该进程占用的固定內存量（KB）（驻留中页的数量）TTY：表示该进程在那个终端上运行，若与终端无关，则显示? 若为pts/n，则表示由网络连接进入主机的进程，tty1-tty6 表示是本机上面的登录进程。STAT：进程当前的状态    D(uninterruptible sleep) 不可中断的休眠状态（通常 IO 相关的进程）    I(idle)                  空闲的内核线程          R(running or runnable)   在运行队列中进程状态未：正在运行态或可运行状态    S(大写：sleep)            可中断睡眠状态（等待一个事件完成）    T(stopped)               停止状态（stopped by job control signal）    t                        调试追踪过程中被停止的状态（stopped by debugger during the tracing）    W（paging）               进入内存交换 （从内核2.6开始无效）    X(dead)                  死掉的进程 （基本很少看见）    Z(zombie)                僵尸状态，进程已被终止，但无法被删除    &lt;                        高优先级进程（not nice to other users）    N                        低优先级的进程（nice to other users）    L                        页被锁进内存    s                        该进程含有子进程    l                        多线程，克隆线程（使用 CLONE_THREAD, 类似 NPTL pthreads）    +                        位于前台的进程组（foreground process group）START：该进程被触发启动的时间TIME：该进程实际使用CPU运行的时间CMD(command)：执行此进程触发的命令是什么UID：用户ID、但输出的是用户名PID：进程的IDPPID：父进程IDC：CPU使用率，单位为百分比STIME：进程启动到现在的时间PRI(priority)：进程被CPU执行的优先级，数值越小，代表该进程被CPU执行的越快。这个值由内核动态调整，用户无法直接调整PRI的值。NI(nice)：调整进程的优先级。    nice值的可调整的范围在 -20~19 之间。    root用户可以随意调整自己或其它用户进程的 nice值，且范围范围在 -20~19 之间。    一般用户只能调整自己进程的nice值，范围仅为 0-19，避免一般用户去抢占系统的资源。    PRI与NI之间的关系：PRI(new) = PRI(old) + nice    nice值有正负，当nice值为负数时，那么该进程会降低PRI的值，会变得较优先处理。    如何调整nice值？      1. 进程刚开始时就给指定一个特定的nice值。nice -n -5 vim &amp; 启动vim时，给定一个nice值，并将vim放在后台执行。      2. 调整已存在的进程的nice值，需要用 renice 命令：renice 4 2366 将PID=2366 进程的nice值调整为4ADDR：是内核函数，指出该进程在内存中的哪个部分；如果是个running的进程，一般用 - 表示SZ：此进程用掉多少内存WCHAN：目前进程是否在运行，如果为 -，则表示正在运行。

常见参数命令组合

ps –ef|grep 程序名称：查看一个程序是否运行 
ps -Lf 端口号|wc -l ：查看线程个数  
ps -l：查看当前用户的 bash 进程
ps aux：查看系统运行的所有进程，默认按照 PID 的顺序排序。
ps axjf：查看系统运行的所有进程，并带有 PPID 项

查看某个进程已运行的时间
john@ubuntu:~$ ps -p 3578 -o lstart,etime               STARTED     ELAPSEDThu Jun 10 08:33:04 2021       33:48

另外一种方式
[root@ubuntu ~]# ps -eo pid,lstart,etime,cmd | grep cgi86592 Sun Aug 14 04:09:18 2022       00:34 ./spawn-fcgi -a 0.0.0.0 -p 9000 -C 25 -f ./cxxfcgi -F 186593 Sun Aug 14 04:09:18 2022       00:34 ./cxxfcgi 186923 Sun Aug 14 04:09:52 2022       00:00 grep --color=auto cgi参数解释：-o: 格式化输出，用户自定义要输出的格式-e: 等用于all，表示选择所有的时间etime: 进程从启动开始到现在运行的时间，格式为：[[DD-]hh:]mm:sslstart: 命令启动时的时间



13. killall 与 pkill根据进程的名称去杀死进程，而不需要知道进程的 ID 号。
killall bashpkill bash

参考：Linux批量kill进程 - abce - 博客园
14. nohupnohup 命令让程序在后台执行，一般常与 &amp; 符号结合使用。示例：  nohup ping www.baidu.com    让执行 ping 命令的进程在后台运行。

15. pstreepstree 命令是用于查看正在运行的进程之间的关系，用树形图显示，即哪个进程是父进程，哪个是子进程，可以清楚的看出来是谁创建了谁，同时还可以查看一个进程下有多少个子线程。
注：Linux 系统中内核调用的第一个进程为 systemd，该进程的 PID 为 1。
几个重要的参数：-A 各进程树之间的连接以ASCII码字符来连接-U 各进程树之间的连接以utf8字符来连接，某些终端可能会有错误-p 同时列出每个进程的PID-u 同时列出每个进程的所属账号名称

$ pstreeinit─┬─NetworkManager     ├─abrtd     ├─acpid     ├─atd     ├─automount───4*[&#123;automount&#125;]     ├─certmonger     ├─crond     ├─cupsd     ├─dbus-daemon     ├─hald───hald-runner─┬─hald-addon-acpi     │                    └─hald-addon-inpu     ├─irqbalance     ├─master─┬─bounce

// 一个进程下有多个子线程，花括号&#123;&#125; 中的内容表示线程，// 圆括号() 中的内容表示线程ID或进程IDpstree -p 15821a.out(15821)─┬─&#123;a.out&#125;(15835)             ├─&#123;a.out&#125;(15836)             ├─&#123;a.out&#125;(15837)             ├─&#123;a.out&#125;(15838)             ├─&#123;a.out&#125;(15839)             ├─&#123;a.out&#125;(15840)             ├─&#123;a.out&#125;(15841)             ├─&#123;a.out&#125;(15843)             ├─&#123;a.out&#125;(15844)

16. ltrace跟踪进程调用库函数的信息，显示调用哪些库函数。
语法  ltrace [option ...] [command [arg ...]]选项参数-a 对齐具体某个列的返回值。-c 计算时间和调用，并在程序退出时打印摘要。-C 解码低级别名称（内核级）为用户级名称。-d 打印调试信息。-e 改变跟踪的事件。-f 跟踪子进程。-h 打印帮助信息。-i 打印指令指针，当库调用时。-l 只打印某个库中的调用。-L 不打印库调用。-n, --indent=NR 对每个调用级别嵌套以NR个空格进行缩进输出。-o, --output=file 把输出定向到文件。-p PID 附着在值为PID的进程号上进行ltrace。-r 打印相对时间戳。-s STRLEN 设置打印的字符串最大长度。-S 显示系统调用。-t, -tt, -ttt 打印绝对时间戳。-T 输出每个调用过程的时间开销。-u USERNAME 使用某个用户id或组ID来运行命令。-V, --version 打印版本信息，然后退出。示例  ltrace -p pid

示例1：执行程序不带任何参数
$ ltrace ./a.out(0, 0, 176780, -1, 0x7f080f441990)                                                            = 0x304c2221e0__libc_start_main(0x400898, 1, 0x7fff96a76768, 0x400920, 0x400990 &lt;unfinished ...&gt;_ZNSt8ios_base4InitC1Ev(0x600ee0, 65535, 0x7fff96a76778, 64, 0x304c7bbea0)                    = 0__cxa_atexit(0x400704, 0x600ee0, 0x600d98, 6, 0x305a3105e0)                                   = 0_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc(0x600dc0, 0x4009ec, 0x7fff96a76778, 96, 0x304c7bbea0) = 0x600dc0_ZNSolsEPFRSoS_E(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30 &lt;unfinished ...&gt;_ZSt4endlIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30hello &lt;unfinished ...&gt;&lt;... _ZNSolsEPFRSoS_E resumed&gt; )                                                              = 0x600dc0_ZNSt8ios_base4InitD1Ev(0x600ee0, 0, 160, 0x304c7bbf30, 4)                                    = 0x305a30f240+++ exited (status 0) +++

示例2：输出调用时间开销
$ ltrace -T ./a.out(0, 0, 106015, -1, 0x7f3655ca9990)                                                            = 0x304c2221e0 &lt;0.000129&gt;__libc_start_main(0x400898, 1, 0x7fff2085dd98, 0x400920, 0x400990 &lt;unfinished ...&gt;_ZNSt8ios_base4InitC1Ev(0x600ee0, 65535, 0x7fff2085dda8, 64, 0x304c7bbea0)                    = 0 &lt;0.000215&gt;__cxa_atexit(0x400704, 0x600ee0, 0x600d98, 6, 0x305a3105e0)                                   = 0 &lt;0.000110&gt;_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc(0x600dc0, 0x4009ec, 0x7fff2085dda8, 96, 0x304c7bbea0) = 0x600dc0 &lt;0.000221&gt;_ZNSolsEPFRSoS_E(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30 &lt;unfinished ...&gt;_ZSt4endlIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30hello &lt;unfinished ...&gt;&lt;... _ZNSolsEPFRSoS_E resumed&gt; )                                                              = 0x600dc0 &lt;0.000302&gt;_ZNSt8ios_base4InitD1Ev(0x600ee0, 0, 160, 0x304c7bbf30, 4)                                    = 0x305a30f240 &lt;0.000141&gt;+++ exited (status 0) +++

示例3：显示系统调用
$ ltrace -S ./a.outSYS_brk(NULL)                                                                                 = 0x23f8000SYS_mmap(0, 4096, 3, 34, 0xffffffff)                                                          = 0x7f16eaa25000SYS_access(0x304c01dac0, 4, 6, 4, 0x2f7362694c2f564f)                                         = -2SYS_open(&quot;tls/x86_64/libstdc++.so.6&quot;, 524288, 011410421010)                                   = -2SYS_open(&quot;tls/libstdc++.so.6&quot;, 524288, 011410421010)                                          = -2SYS_open(&quot;x86_64/libstdc++.so.6&quot;, 524288, 011410421010)                                       = -2SYS_open(&quot;libstdc++.so.6&quot;, 524288, 011410421010)                                              = -2   ...........SYS_munmap(0x7f16eaa16000, 59833)                                                             = 0__libc_start_main(0x400898, 1, 0x7fff976dc088, 0x400920, 0x400990 &lt;unfinished ...&gt;_ZNSt8ios_base4InitC1Ev(0x600ee0, 65535, 0x7fff976dc098, 64, 0x304c7bbea0)                    = 0__cxa_atexit(0x400704, 0x600ee0, 0x600d98, 6, 0x305a3105e0)                                   = 0_ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc(0x600dc0, 0x4009ec, 0x7fff976dc098, 96, 0x304c7bbea0 &lt;unfinished ...&gt;SYS_fstat(1, 0x7fff976dbdb0, 0x7fff976dbdb0, 0x7fff976dbcd0, 0x304c7bca30)                    = 0SYS_mmap(0, 4096, 3, 34, 0xffffffff)                                                          = 0x7f16eaa24000&lt;... _ZStlsISt11char_traitsIcEERSt13basic_ostreamIcT_ES5_PKc resumed&gt; )                       = 0x600dc0_ZNSolsEPFRSoS_E(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30 &lt;unfinished ...&gt;_ZSt4endlIcSt11char_traitsIcEERSt13basic_ostreamIT_T0_ES6_(0x600dc0, 0x400734, 0x305a2f75d8, 1024, 0x304c7bca30 &lt;unfinished ...&gt;SYS_write(1, &quot;hello\n&quot;, 6hello)                                                                    = 6&lt;... _ZNSolsEPFRSoS_E resumed&gt; )                                                              = 0x600dc0_ZNSt8ios_base4InitD1Ev(0x600ee0, 0, 160, 0x304c7bbf30, 4)                                    = 0x305a30f240SYS_exit_group(0 &lt;no return ...&gt;+++ exited (status 0) +++

参考：ltrace命令详解 
17. strace为什么要用 strace?
看到一个进程调用了哪些API以及其调用顺序，例如我们要参考某个程序的实现，但我们又无法获得该程序的源代码时，使用系统调用跟踪命令不失为一个好办法。另外，在一些无法调试的环境上检查问题时，我们也可以用该命令来查看程序是否按预期执行。strace和dtruss都是同一类型的命令，strace是linux系统上的，而dtruss是mac系统上的。
strace 作用
strace 跟踪一个进程的系统调用或信号产生的信息。（strace  - trace system calls and signals）
参数项-c 统计每一系统调用的所执行的时间，次数和出错的次数等。 -d 输出strace关于标准错误的调试信息。 -f 跟踪由fork调用所产生的子进程。 -ff 如果提供-o filename，则所有进程的跟踪结果输出到相应的filename -F 尝试跟踪vfork调用。在-f时，vfork不被跟踪。 -h 输出简要的帮助信息。 -i 输出系统调用的入口指针。 -q 禁止输出关于脱离的消息。 -r 打印出相对时间关于，每一个系统调用。 -t 在输出中的每一行前加上时间信息。 -tt 在输出中的每一行前加上时间信息，微秒级。 -ttt 微秒级输出，以秒了表示时间。 -T 显示每一调用所耗的时间。 -v 输出所有的系统调用。一些调用关于环境变量，状态，输入输出等调用由于使用频繁，默认不输出。 -V 输出strace的版本信息。 -x 以十六进制形式输出非标准字符串 -xx 所有字符串以十六进制形式输出。 -a column 设置返回值的输出位置。默认 为40。 -e expr  指定一个表达式，用来控制如何跟踪。格式如下:     [qualifier=][!]value1[，value2]。。。     qualifier只能是 trace，abbrev，verbose，raw，signal，read，write其中之一。    value是用来限定的符号或数字。默认的 qualifier是 trace。感叹号是否定符号。    例如: -eopen等价于 -e trace=open，表示只跟踪open调用。    而-etrace!=open表示跟踪除了open以外的其他调用。有两个特殊的符号 all 和 none。 -e trace=set 只跟踪指定的系统 调用。             例如:-e trace=open，close，rean，write表示只跟踪这四个系统调用。默认的为set=all。-e trace=file 只跟踪有关文件操作的系统调用。 -e trace=process 只跟踪有关进程控制的系统调用。 -e trace=network 跟踪与网络有关的所有系统调用。-e strace=signal 跟踪所有与系统信号有关的 系统调用 -e trace=ipc 跟踪所有与进程通讯有关的系统调用 -e abbrev=set 设定 strace输出的系统调用的结果集-e raw=set 将指定的系统调用的参数以十六进制显示。 -e signal=set 指定跟踪的系统信号。默认为all。              如 signal=!SIGIO(或者signal=!io)，表示不跟踪SIGIO信号。 -e read=set  输出从指定文件中读出 的数据。例如: -e read=3，5 -e write=set 输出写入到指定文件中的数据。 -o filename 将strace的输出写入文件filename -p pid 跟踪指定的进程pid。 -s strsize 指定输出的字符串的最大长度，默认为32。 -u username 以username 的UID和GID执行被跟踪的命令

18. pstackpstack 打印正在运行的进程的堆栈信息。
19. findfind 命令：在指定的目录中共去查找文件。 
格式  find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression]选项参数-name：按照名字匹配搜索，搜索的内容要用引号括起来，单引号或双引号都可以，从而避免它受 shell 终端扩展的影响。    例子：按照文件查找 /usr/src 路径下后缀名为 .txt 所有文件    find /usr/src -name &quot;*.txt&quot;-type：按照文件类型查找。       类型包括：f(file), d(directory), l(link), c(char), d(device), s(socket), b(block)     例子：按照文件类型查找 /usr/src 路径下后缀名为 .txt 所有文件     find /usr/src -type &quot;*.txt&quot;-size: 按照文件大小搜索，默认单位为512byte，一个扇区的大小    例子：find /usr/src -size +10M -size -20M 查找大于10M小于20M的文件    例子：find /usr/src -size +10k -size -20k-maxdepth:     例子：统计 /usr 目录下深度为2的所有目录文件     find /usr -maxdepth 2 -type d | wc -l      例子：查找 /usr 路径下深度为 2 除开类型为目录的所有文件    find /usr -maxdepth 2 ! -type d -exec    例子： 列出当前目录下所有的 .sh 文件，并执行ls -l 命令    find ./ -name &quot;*.sh&quot; -exec ls -l &#123;&#125; \;  -print: 将文件或目录名称列出到标准输出。格式为每列一个名称，每个名称前皆有 ./ 字符串；-print0: 就将文件或目录名称列出到标准输出。格式为全部的名称皆在同一行；-atime(access time): 访问时间， +7 超过七天被访问的文件；-7 七天以内访问过的文件; 7 恰好在七天前被访问的文件（那个时间点）    例子；查找当前路径下恰好在七天前被访问的文件    find . atime -7 -amin: 访问时间（按照分钟）-mtime: 上次修改的时间（按照天数）    查找当前路径下 7 天以前的 ErrorLog 文件    find . -name &quot;ErrorLog*.log&quot; -mtime +7    删除当前路径下超过 10 天被修改的文件    find . -name &quot;DataDeal*.log&quot; -mtime +10 | xargs rm -rf    另外一种写法    find . -name &quot;IOV-GBDataDeal*.log&quot; -mtime +10 -exec rm -rf &#123;&#125; \;-mmin(modified minute): 修改时间（按照分钟）-ctime(change time): 最近文件的状态被改变的时间-cmin(change minute): 最近文件的状态被改变的时间（按照分钟）-prune: 忽略指定的文件查找   find . -path &quot;./test&quot; -prune -o -name &quot;*.txt&quot; -print  忽略 test 文件夹去查找当前路径下以 txt 结尾的所有文件-ok 执行的命令：输出的结果确定是否要执行指定的命令    find .  -path &quot;./&quot; -prune -o -name &quot;*.gz&quot; -ok ls -l &#123;&#125; \;-iname    例子：查找当前路径下所有 .log 文件中包含的 open files 字段      find . -iname &#x27;*.log&#x27; | xargs grep &#x27;open files&#x27;    从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 &quot;flower&quot; 的行：    $ find / -type f -name &quot;*.log&quot; | xargs grep &quot;flower&quot;    从当前目录开始查找所有扩展名为 .ini 的文本文件，并找出包含 &quot;dog&quot; 的行：        find . -name &quot;*.ini&quot; | xargs grep &quot;dog&quot;

20. xargsxargs 又称管道命令。是给命令传递参数的一个过滤器，也是组合多个命令的一个工具，它把一个数据流分割成一些足够小的快，方便过滤器和命令进行处理。
参数项  -d 指定一个特定的分隔符显示，默认分隔符为空格  -i 使用 &#123;&#125; 替代传递的参数  -n 限制单个命令行的参数个数  -t 显示详情  -p 交互模式  -0 --null，使用 null 分割，而不是空白，禁用引号和反斜杠处理例子：  多行输入变单行    $ cat a.txt    123    456    789    $ xargs &lt; a.txt    123 456 789  -n 参数的使用    $ cat a.txt    123 111 222 333    456 444 555 666    789 777 888 999    $ xargs -n 2 &lt; a.txt    123 111    222 333    456 444    555 666    789 777    888 999  -d 参数使用    $  echo &quot;helo,AI,DB,CJ,KK&quot;    helo,AI,DB,CJ,KK    $  echo &quot;helo,AI,DB,CJ,KK&quot; | xargs -d &quot;,&quot;    helo AI DB CJ KK    $  echo &quot;helo,AI,DB,CJ,KK&quot; | xargs -d &quot;,&quot; -n 2    helo AI    DB CJ    KK -i参数使用     将当前目录下深度为 1 的所有 .txt 文件移动到当前已存在的 temp 目录下；xargs -i 作为参数传递    $ find . -maxdepth 1 -name &quot;*.txt&quot; | xargs -i mv &#123;&#125; ./temp    $ ls temp/    a.txt  b.txt  -I参数使用      将当前目录下所有为 .txt 的文件移出到上一级已存在的 txt 目录下    [root@CentOS7 temp]# find . -name &quot;*.txt&quot; | xargs -I aa mv aa ../txt    $ ls txt/    a.txt  b.txt

21. grepgrep(global search regular expression and print out the line) 全面搜索正则表达式和打印输出行 
三种形式的 grep 命令

gerp 是标准格式
egrep 是扩展grep命令，其实和grep -E等价，支持基本和扩展的正则表达式。
fgrep 是快速grep命令，其实和grep -F等价，不支持正则表达式，按照字符串表面意思进行匹配。

用法  grep [OPTIONS] PATTERN [FILE...]  grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...]OPTIONS:   通用程序信息（Generic Program Information）    --help 输出帮助信息后退出    -V, --version            输出 grep 版本号后退出  模式语法（Pattern Syntax）    -E, --extended-regexp           匹配扩展正则表达式    -F, --fixed-strings          匹配固定字符串而非正则表达式     -G, --basic-regexp          匹配基本的正表达式，这个是默认选项          grep &#x27;[^0-6]&#x27;  helo.txt    -P, --perl-regexp          匹配 perl 语法的正则表达式  匹配控制（Matching Control）      -i, --ignore-case            查找时忽略大小写：grep -i &quot;book&quot;    --no-ignore-case         匹配时不忽略大小写    -v, --invert-match         选择不包含所匹配文本的行     -w, --word-regexp          匹配整个单词    -x, --line-regexp          匹配整行 通用输出控制   -c, --count         只输出匹配行的数量   -l, --files-with-matches         只列出符合匹配的文件名，不列出具体的匹配行     -q, --quiet, --silent          退出：不写任何的东西到标准输入中。如果找到任何匹配项，立即退出，状态为零，即使检测到错误也是如此。  -s, --no-message         不显示不存在、没有匹配文本的错误信息     -o, --only-matching              与-b结合使用，打印匹配的词据文件头部的偏移量，以字节为单位输出行前缀控制（Output Line Prefix Control）  -b, --byte-offset        打在每行输出之前打印输入文件中从 0 开始的字节偏移量。  -h, --no-filename       查询多文件时不显示文件名        -n, --line-number        列出所有的匹配行，显示行号文件和路径选择（File and Directory Selection）    -a, --text          将处理的二进制文件当作文本文件，等同于 --binary-files=text 操作          例子： 搜索压缩文件中的 open files 关键字          $ zcat Server_log/20220118.tar.gz  | grep -a &quot;open files&quot;    -r, --recursive     递归搜索      例子： 搜索 /usr/src/ 路径下包含 task_struct &#123; 的字符，并显示字符所在的行号      grep -r  &quot;task_struct &#123;&quot; /usr/src/  -n 

查询生产环境下以压缩归档的日志，在不用解压文件的前提下直接进行查询日志，其中压缩的文件格式为 .gz
[root@John]# zgrep -ia &quot;ReportDBTable&quot; ./Server_log/20220411.tar.gz[20220411_204121_750][I]received update config[t_config.ReportDBTable]: old(), new(1)[TID:4661][20220411_204214_321][I]Get ReportDBTable value: 1[TID:3143]

22. pgrep根据进程的名称查找并返回进程的 ID 号到标准输出。与 pidof 功能一样。
pgrep -l program_name  只显示某个进程的PIDpidof program_name  找出某个正在执行的进程的PIDpgrep bash3528pidof bash 3528

23. PID
ps aux | grep xxx(程序名称)  显示某个进程的全部信息，包括PID
ps ajx 显示进程组ID
ulimit -a 查看资源的上限大小

24. dddd 命令根据指定的操作（OPERAND）去转换（convert）和拷贝（copy）一个文件，同时还能打印拷贝的速度。
用法
dd [OPERAND]...dd OPTION



25. ssss 是用于调查套接字的另一个实用程序。
ss 检查端口： 示例：  ss -tunlp

26. lsoflsof(list open files) 列出整个 Linux 系统打开的所有文件描述符。
参数  -p：指定进程ID（ PID）。  -d：允许指定要显示的文件描述符编号。   参看文件描述符为 1 的进程   [root@KF-CFT-AP2 ~]# lsof -d 1   COMMAND     PID      USER   FD   TYPE             DEVICE SIZE/OFF     NODE NAME   init          1      root    1u   CHR                1,3      0t0     3842 /dev/null   udevd       557      root    1u   CHR                1,3      0t0     3842 /dev/null  -i:端口号  查看指定端口占用情况     查看 47462 端口的占用情况  [root@KF]# lsof -i:47462  COMMAND     PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME  L2BU-Boot 27283 root   19u  IPv4 82427778      0t0  TCP 172.26.153.222:47462-&gt;172.26.153.227:12243 (ESTABLISHED)示例：  lsof -nP -iTCP -sTCP:LISTEN 获取所有侦听 TCP 端口的列表 

lsof 命令输出各列信息的意义如下：

COMMAND：进程的名称
PID：进程标识符
USER：进程所有者
FD：文件描述符类型
TYPE：文件类型
DEVICE：指定磁盘的名称
SIZE/OFF：文件的大小
NODE：文件在磁盘上的标识，索引节点
NAME：打开文件的确切名称


Tips：查看 xxx 端口的占用情况，有两种方式。第一采用 lsof -i:xxx 查看；第二：采用 netstat -tunlp | grep xxx 来查看。

27. netcatnetcat（通常缩写为nc）是一种计算机联网实用程序，用于使用TCP或UDP读写网络连接。 该命令被设计为可靠的后端，可以直接使用或由其他程序和脚本轻松驱动。 同时，它是功能丰富的网络调试和调查工具，因为它可以产生用户可能需要的几乎任何类型的连接，并具有许多内置功能。netcat被称为网络工具中的瑞士军刀，体积小巧，但功能强大。
28. socatSocat 是 Linux 下的一个多功能的网络工具，名字来由是 「Socket CAT」。其功能与有瑞士军刀之称的 Netcat 类似，可以看做是 Netcat 的加强版。socat的官方网站： http://www.dest-unreach.org/socat/ 
Socat 的主要特点就是在两个数据流之间建立通道，且支持众多协议和链接方式。如 IP、TCP、 UDP、IPv6、PIPE、EXEC、System、Open、Proxy、Openssl、Socket等。
29. traceroute追踪从出发地（源主机）到目的地（目标主机）之间经过了哪些路由器，以及到达各个路由器之间的消耗的时间。默认发送的数据包大小是40字节。
30. manman是 POSIX(Portable Operating System Interface) 规定的帮助手册程序。
语法格式：man -n 命令参数其中 n 为数字，不同的数字表示如下：    1：普通应用程序或shell命令（Executable programs or shell commands）    2：系统调用（System calls (functions provided by the kernel)）    3：库函数（Library calls (functions within program libraries)）    4：设备文件（Special files (usually found in /dev)）    5：文件格式、或相关协议（File formats and conventions, e.g. /etc/passwd）    6：游戏设备（Games）    7：其它设备（Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7)）    8：root管理命令（System administration commands (usually only for root)）    9：非标准的内核程序（Kernel routines [Non standard]）示例：  查找 socket 文档： man 2 socket

man -k keyword    # 按照关键字搜索与之匹配的相似命令。john@ubuntu:~$ man -k whatgit-blame (1)        - Show what revision and author last modified each line of a filegit-receive-pack (1) - Receive what is pushed into the repositorygit-whatchanged (1)  - Show logs with difference each commit introducesimgtoppm (1)         - convert an Img-whatnot file into a portable pixmaplwp-dump (1p)        - See what headers and content is returned for a URLw (1)                - Show who is logged on and what they are doing.w.procps (1)         - Show who is logged on and what they are doing.whatis (1)           - display one-line manual page descriptions


man 手册中的一些关键字




英文描述
中文描述



NAME
命令名


SYNOPSIS
使用方法大纲


CONFIGURATION
配置xxx


DESCRIPTION
功能说明


OPTIONS
可选参数说明


EXAMPLE
实例


EXIT STATUS
退出状态（返回给父进程的值）


RETURN VALUE
返回值


ERRORS
错误类型


ENVIRONMENT
环境变量


FILES
相关配置文件


VERSIONS
版本


CONFORMING TO
符合的规范


NOTES
注意事项


BUGS
已经发现的 bug


AUTHORS
作者


SEE ALSO
与之功能相近的其它命令



man 中的快捷




名称
用法



&#x2F;string
向“下”搜寻string这个字串


?string
向“上”搜寻string这个字串


n
继续下一个搜寻


N
反向查询


与 man 相似的命令是 info，而info 手册页按照节点（node）组织的，每个手册页文件是一个节点，手册页内支持链接到其它节点，如此组织犹如一张网，和网页类似。

自定义软件安装路径配置 man page。自定义的软件没有安装在 &#x2F;usr/local/ 路径时，需手动配置 man page，否则使用 man 去查找软件相关的手册时，会找不到。例如：你安装的软件放置到/usr/local/software/， 那么 man page 搜寻的设置中， 可能就得要在 /etc/man_db.conf 内的 40~50 行左右处， 写入 MANPATH_MAP /usr/local/software/bin /usr/local/software/man，这样才可以使用 man 来查询该软件的在线文件。

31. ntsysvntsysv 是 CentOS 下图形界面查看系统中有哪些启动的项。
32. wget支持断点下载功能，同时支持FTP和HTTP下载方式，支持代理服务器设置。wget 下载单个文件下载。下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。
参考: wget命令详解
33. SHA
SHA 是安全散列算法（英语：Secure Hash Algorithm，缩写为SHA），它是一个密码散列函数家族，是FIPS所认证的安全散列算法。能计算出一个数字消息所对应到的，长度固定的字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的机率很高。

SHA家族的五个算法，分别是SHA-1、SHA-224、SHA-256、SHA-384，和SHA-512，由美国国家安全局（NSA）所设计，并由美国国家标准与技术研究院（NIST）发布，是美国的政府标准。后四者有时并称为SHA-2。SHA-1在许多安全协定中广为使用，包括TLS和SSL、PGP、SSH、S&#x2F;MIME和IPsec，曾被视为是MD5（更早之前被广为使用的杂凑函数）的后继者。

生成 hash 校验: sha1sum filename
#  直接生成 hash 校验后的结果Tim@computer:~/Downloads$ sha1sum feeds-master.zip 751420b576570fcbfb24e80e47e18168342541e0  feeds-master.zip

feeds-master.zip 文件生成的 hash1 校验码为 751420b576570fcbfb24e80e47e18168342541e0。

为了检验 hash 结果的值是否真确，需要对 hash 结果进行校验。可以将生成 hash 的校验值存入到一个文件中，方便校验，对生成的结果进行校验时，需要加 -c(check) 参数。
Tim@computer:~/Downloads$ sha1sum feeds-master.zip &gt; a.txtTim@computer:~/Downloads$ sha1sum -c a.txt feeds-master.zip: OK

34. md5md5 是 消息摘要算法（英语：MD5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，可以产生出一个128位（16字节）的散列值（hash value），用于确保信息传输完整一致。MD5由美国密码学家罗纳德·李维斯特（Ronald Linn Rivest）设计，于1992年公开，用以取代MD4算法。
MD5 校验的用法与 SHA 校验的用法一样。下面是 MD5 校验的用法
Tim@computer:~/Downloads$ md5sum feeds-master.zip &gt; md.txtTim@computer:~/Downloads$ cat md.txt f273a8295e2c28e598764ed04898a742  feeds-master.zipTim@computer:~/Downloads$ md5sum -c md.txt feeds-master.zip: OK

35. ldconfigldconfig 是一个动态链接库管理命令，其目的为了让动态链接库为系统所共享。
主要是在默认搜寻目录 /lib 和 /usr/lib 以及动态库配置文件 /etc/ld.so.conf 内所列的目录下，搜索出可共享的动态链接库（格式如 lib*.so*），进而创建出动态装入程序(ld.so)所需的连接和缓存文件，缓存文件默认为 /etc/ld.so.cache，此文件保存已排好序的动态链接库名字列表。linux下的共享库机制采用了类似高速缓存机制，将库信息保存在 /etc/ld.so.cache，程序链接的时候首先从这个文件里查找，然后再到 ld.so.conf 的路径中查找。为了让动态链接库为系统所共享，需运行动态链接库的管理命令 ldconfig，此执行程序存放在 /sbin 目录下。
36. ldd作用：判断某个可执行的二进制文件含有什么动态库。
[root@zk_190 etc]# ldd -v /usr/bin/cat        linux-vdso.so.1 =&gt;  (0x00007ffe11572000)        libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f8996748000)        /lib64/ld-linux-x86-64.so.2 (0x00007f8996b16000)        Version information:        /usr/bin/cat:                libc.so.6 (GLIBC_2.3) =&gt; /lib64/libc.so.6                libc.so.6 (GLIBC_2.3.4) =&gt; /lib64/libc.so.6                libc.so.6 (GLIBC_2.14) =&gt; /lib64/libc.so.6                libc.so.6 (GLIBC_2.4) =&gt; /lib64/libc.so.6                libc.so.6 (GLIBC_2.2.5) =&gt; /lib64/libc.so.6        /lib64/libc.so.6:                ld-linux-x86-64.so.2 (GLIBC_2.3) =&gt; /lib64/ld-linux-x86-64.so.2                ld-linux-x86-64.so.2 (GLIBC_PRIVATE) =&gt; /lib64/ld-linux-x86-64.so.2        /lib64/ld-linux-x86-64.so.2 (0x00007faf69eef000)      # 参数 -v 表示该函数来自于哪一个软件

37. chkconfigchkconfig 命令用来更新（启动或停止）和查询系统服务的运行级信息。谨记 chkconfig 不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。
38. LD_LIBRARY_PATHLD_LIBRARY_PATH 是 Linux 下用来处理环境变量的，告诉加载器（loader）在什么路径下去查找非标准库中的共享库。
Linux 运行的时候，是如何管理共享库(*.so)的？
​    在 Linux 下面，共享库的寻找和加载是由 &#x2F;lib&#x2F;ld.so 实现的。 ld.so 在标准路经(&#x2F;lib, &#x2F;usr&#x2F;lib) 中寻找应用程序用到的共享库。但是，如果需要用到的共享库在非标准路经，ld.so 怎么找到它呢？
目前，Linux 通用的做法是将非标准路经加入 &#x2F;etc&#x2F;ld.so.conf，然后运行 ldconfig 生成 &#x2F;etc&#x2F;ld.so.cache。 ld.so 加载共享库的时候，会从 ld.so.cache 查找。传统上，Linux 的先辈 Unix 还有一个环境变量：LD_LIBRARY_PATH 来处理非标准路经的共享库。ld.so 加载共享库的时候，也会查找这个变量所设置的路经。
LD_LIBRARY_PATH 的设置方法：用 export 命令来设置值
// 将 /home/John/IOV/Libs 中的共享库路径添加到环境变量中export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/John/IOV/Libs

参考

LD_LIBRARY_PATH
https://www.csdndocs.com/article/2589063
linux 添加动态链接库路径

39. scpSCP(secure copy) 是基于ssh协议的安全拷贝，用于将文件&#x2F;目录安全地从本地主机传输到远程主机。
一般情况下 Linux 服务器都有 scp 命令，如果没有，可通过如下方式安装：
// centosyum -y install openssh-clients// Ubuntuapt-get install openssh-client 


复制文件&#x2F;目录到远程主机

// 复制文件scp source_file_name user@destination_host:destination_folder//复制目录 scp -r source_directory user@destination_host:destination_folder [root@Client ~]# scp text.txt root@192.168.20.40:/root


从远程主机复制文件&#x2F;目录

// 复制文件scp user@source_host:source_file_name local_destination_folder  // 复制目录scp -r user@source_host:source_file_name local_destination_folder[root@Client ~]# scp root@192.168.20.40:/root/test40.txt /rootroot@192.168.20.40&#x27;s password: test40.txt                                                                                                                   100%   12     4.2KB/s   00:00    [root@Client ~]# ll | grep test40.txt-rw-r--r--   1 root    root          12 7月   6 09:41 test40.txt

40. rsyncRsync (remote synchronize) 实现同步本地主机和远程主机的文件&#x2F;目录，和 SCP 不同之处在于，首次复制时，Rsync 会复制整个目录，在后面的复制中，不会复制相同的内容，只对差异文件做更新，scp 是把所有文件都复制过去。Rsync 广泛用于备份和镜像。
安装 Rsync
// centosyum install rsync// Ubuntuapt-get install rsync  

参数项



参数
功能



-t
将源文件的修改时间(modify time)同步到目标机器


-I
–ignore-times，不跳过时间和大小都匹配的文件，也就是不检查是否有改动，直接复制


-r
递归，用于目录复制


-a(archive)
存档模式，保存所有的元数据，比如修改时间（modification time）、权限、所有者等，并且软链接也会同步过去。


-v
打印复制过程


-l
拷贝符号连接


–delete
删除目标目录中多余的文件，也就是保持两个目录相同，使得目标目录成为源目录的镜像副本



复制文件&#x2F;目录到远程主机。如果复制的目标目录不存在，会自动创建，语法格式和SCP一样：

// 复制文件rsync source_file_name/ user@destination_host:destination_folder// 复制目录rsync -r source_file_name/ user@destination_host:destination_folder [root@Client ~]# rsync test.txt root@192.168.20.40:/rootroot@192.168.20.40&#x27;s password: [root@Client ~]# [root@Client ~]# rsync -rvl test/ root@192.168.20.40:/root/test222root@192.168.20.40&#x27;s password: sending incremental file listcreated directory /root/test222./test2.txttest40.txtsent 187 bytes  received 93 bytes  62.22 bytes/sectotal size is 12  speedup is 0.04


从远程主机复制文件&#x2F;目录

// 复制文件rsync user@source_host:source_file_name local_destination_folder // 复制目录rsync -r user@source_host:source_file_name local_destination_folder [root@Client ~]# rsync root@192.168.20.40:/root/test40.txt /rootroot@192.168.20.30&#x27;s password: [root@Client ~]# ll test40.txt-rw-r--r-- 1 root root 12 7月   8 11:11 test40.txt


排除多个文件或目录

rsync -avP --exclude=&#123;del_file1, del_file2, ...&#125; source_dir dest_dirrsync -avp --exclude=&#123;log,*.so&#125; * root@192.168.153.222:/home/zhoushuhui/IOV/Server

参考

使用SCP或Rsync实现Linux主机之间文件、目录的复制 | HiYong (hiyongz.github.io)

41. 防火墙41.1. ubuntu 下默认的防火墙
sudo ufw status 查看防火墙当前状态
sudo ufw enable 开启防火墙
sudo ufw disable 关闭防火墙
sudo ufw version 查看防火墙版本
sudo ufw default allow 默认允许外部访问本机
sudo ufw default deny 默认拒绝外部访问主机
sudo ufw allow 53 允许外部访问53端口
sudo ufw deny 53 拒绝外部访问53端口
sudo ufw allow from 192.168.0.1 允许某个IP地址访问本机所有端口

41.2. CentOS下默认的防火墙CentOS7下默认的防火墙为 firewalld
firwall-cmd：是 Linux 提供的操作 firewall 的一个工具参数项：    –-permanent：表示设置为持久；    –-add-port：标识添加的端口


启动： systemctl start firewalld
关闭： systemctl stop firewalld
查看系统防火墙状态： systemctl status firewalld
开机禁用： systemctl disable firewalld
开机启用： systemctl enable firewalld
查看firewall状态：firewall-cmd –state
重启防火墙：firewall-cmd –reload
查看版本： firewall-cmd –version
查看帮助： firewall-cmd –help
查看区域信息: firewall-cmd –get-active-zones
查看指定接口所属区域： firewall-cmd –get-zone-of-interface&#x3D;eth0
拒绝所有包：firewall-cmd –panic-on
取消拒绝状态： firewall-cmd –panic-off
查看是否拒绝： firewall-cmd –query-panic
查看开放的端口：firewall-cmd –list-ports
查询 8080 端口是否开放  firewall-cmd –query-port&#x3D;8080&#x2F;tcp
开放 8080 端口 firewall-cmd –permanent –add-port&#x3D;8080&#x2F;tcp
移除 8080 端口 firewall-cmd –permanent –remove-port&#x3D;8080&#x2F;tcp

42. SELinuxSELinux 是 Security Enhanced Linux 的缩写，设计的目的是避免资源的利用。SELinux 是在进行进程、文件等详细权限配置时依据的一个核心模块。由于启动网络服务的也是进程，因此刚好也是能够控制网络服务能否存取系统资源的一道关卡。
SELinux 是通过 MAC(Mandatory Access Control：强制访问控制)的方式来管理进程的，它控制的 subject 是进程，object 是该进程能否读取的文件资源。
43. QAQ43.1. Linux 与 Windows相差 8 小时新版本的 Ubuntu 使用 systemd 启动之后，时间也改成了由 timedatectl 来管理，此方法就不适用了。$sudo timedatectl set-local-rtc 1
重启完成将硬件时间 UTC 改为 CST，双系统时间保持一致。
先在 ubuntu下更新一下时间，确保时间无误：
$sudo apt-get install utpdate$sudo ntpdate time.windows.com

然后将时间更新到硬件上：$sudo hwclock --localtime --systohc
43.2. encaenca 是 Linux 下的文件编码转换工具。
安装：apt install enca查看版本：enca --versioN

查看某个文件编码
enca -L zh_CN file_name

将某个文件转化为 utf-8
enca -L zh_CN -x utf-8 file_name

转化某个文件但如果不想覆盖原文件可以这样
enca -L zh_CN -x UTF-8 &lt; file1 &gt; file2 

查看当前目录下的文件编码
enca -L zh_CN `ls`

将当前目录下所有的文件转换为 UTF-8
enca -L zh_CN -x utf-8 *

源码地址： https://dl.cihar.com/enca/
44. References
Github上Linux工具快速教程 ：这本书专注于Linux工具的最常用用法，以便读者能以最快时间掌握，并在工作中应用
如何在centos上安装clang-tidy
CentOS 8发布下载，附新功能&#x2F;新特性介绍 
linux ldconfig命令,环境变量文件配置详解: https://blog.csdn.net/winycg/article/details/80572735
Linux 基础用法总结: https://mp.weixin.qq.com/s/ioLF8ocrWuASlZRCUqo7KA 自己酌情裁剪，吸收写的好的地方。
修复 apt-key deprecated 警告：https://taoshu.in/unix/apt-key-deprecated.html

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-basic</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-distribution</title>
    <url>/Linux/Linux/linux-distribution/</url>
    <content><![CDATA[

DistributionTerminology

TLS: Long Term Support
ELTS: Extended Long Term Support

DebianDebian is an operating system which is composed primarily of free and open-source software, most of which is under the GNU General Public License, and developed by a group of individuals known as the Debian project. Debian is one of the most popular Linux distributions for personal computers and network servers, and has been used as a base for several other Linux distributions.

Debian 4.0 (Etch) was released in April 2007
Debian 5.0 (Lenny) was released in February 2009
Debian 6.0 (Squeeze) was released in February 2011
Debian 7 (Wheezy) was released in May 2013
Debian 8 (Jessie) was released in April 2015
Debian 9 (Stretch) was released in June 2017
Debian 10 (Buster) was released in July 2019
Debian 11 (Bullseye) was released in August 14, 2021
Debian 12 (Bookworm) was released on June 10, 2023

Distribution Version



Version
Code name
Release date
End of Life (EOL)
EOL LTS
EOL ELTS



Debian 4.0
Etch
2007-04





Debian 5.0
Lenny
2009-02





Debian 6.0
Squeeze
2011-02





Debian 7
Wheezy
2013-05





Debian 8
Jessie
2015-04-25
2018-06-17
2020-06-30
2025-06-30


Debian 9
Stretch
2017-06-17
2020-07-18
2022-07-01
2027-06-30


Debian 10
Buster
2019-07-06
2022-09-10
2024-06-30
2029-06-30


Debian 11
Bullseye
2021-08-14
2024-08-14
2026-08-31
2031-06-30


Debian 12
Bookworm
2023-06-10
2026-06-10
2028-06-30
2033-06-30


Debian 13
Trixie






Debian 14
Forky






UbuntuDistribution Version



Version
Code name
Release date
General support until
Security support (ESM) until



16.04 LTS
Xenial Xerus
2016-04-21
2021-04-30
2026-04


18.04 LTS
Bionic Beaver
2018-04-26
2023-05-31
2028-04


20.04 LTS
Focal Fossa
2020-04-23
2025-05-29
2030-04


22.04 LTS
Jammy Jellyfish
2022-04-21
2027-06-01
2032-04


24.04 LTS
Noble Numbat
2024-04-25
2029-05-31
2034-04-25


24.10
Oracular Oriole
2024-10-10
2025-07



Alpine


版本号
发布日期[12]
支持结束日期[13]
Linux内核版本



3.2
2015-05-26
2017-05-01
3.18.xx


3.3
2016-01-06
2017-11-01
4.1.xx


3.4
2016-05-31
2018-05-01
4.4.xx


3.5
2016-12-22
2018-11-01
4.4.xx


3.6
2017-05-24
2019-05-01
4.9.xx


3.7
2017-11-30
2019-11-01
4.9.xx


3.8
2018-06-26
2020-05-01
4.14.xx


3.9
2019-01-29
2020-11-01
4.19.xx


3.10
2019-06-19
2021-05-01
4.19.xx


3.11
2019-12-19
2021-11-01
5.4.xx


3.12
2020-05-29
2022-05-01
5.4.xx


3.13
2021-01-14
2022-11-01
5.10.xx


3.14
2021-06-15
2023-05-01
5.10.xx


3.15
2021-11-24
2023-11-01
5.15.xx


3.16
2022-05-23
2024-05-23
5.15.xx


3.17
2022-11-22
2024-11-22
5.15.xx


3.18
2023-05-09
2025-05-09
6.1.xx


3.19
2023-12-07
2025-11-01
6.6.xx


3.20
2024-05-22
2026-04-01
6.6.xx


3.21
2024-12-05
2026-11-01
6.12.xx


edge
滚动更新
不适用
不适用


References
Wikipedia Debian: https://en.wikipedia.org/wiki/Debian
Debian official: https://www.debian.org
Debian release: https://www.debian.org/releases
Wikipedia Ubuntu: https://en.wikipedia.org/wiki/Ubuntu
Ubuntu official: https://ubuntu.com
Ubuntu Distributions Timeline: https://upload.wikimedia.org/wikipedia/commons/1/1b/Linux_Distribution_Timeline.svg
Wikipedia Alpine: https://zh.wikipedia.org/wiki/Alpine_Linux
Wikipedia BusyBox: https://zh.wikipedia.org/wiki/BusyBox
Wikipedia musl: https://zh.wikipedia.org/wiki/Musl
musl official: https://musl.libc.org

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-distribution</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-kernal</title>
    <url>/Linux/Linux/linux-kernal/</url>
    <content><![CDATA[

1. 理解内核的秘籍
以一个设计者的角度来阅读内核
先框架再细节
低版本理解原理，高版本理解实现
动手总结，形成自己的智慧
不要走弯路，直接学你要学的东西

2. 如何学习内核Linux 内核学习分为几个阶段

了解操作系统基本概念。
了解 Linux 内核机制，大的框架和架构。
了解 Linux 内核编译环境。下载一套源码，更换源码。
研读内核源码，选择自己感兴趣的方向入手。比如：调度、虚拟化、网络、内存、存储等。
尝试 Linux 内核模块编写。
尝试 Linux 内核模块编译调试。
确定个人发展方向。
内核驱动方向开发（嵌入式）
内核网络方向开发（云计算）
内核虚拟化（云计算）
Linux 应用编程



2.1. 核心的东西：最基础、最原始的概念。2. Linux 内核体系结构
Linux是一个单内核，运行在单独的内核空间上。具有模块化设计、抢占式内核、支持内核线程、动态装载内核模块的能力，让所有事情都运行在内核态，直接调用函数，无须消息传递。
内核开发者通常把那些对时间要求比较高，而本身长度又比较短的函数定义成内联函数。若果一个函数较大，会被反复调用，且没有特别的时间上的限制，并赞成把它做成内联函数。
在内核中，为了类型的的安全和易读性，优先使用内联函数而不是复杂的宏。
gcc 内建了一条用于优化的的指令：likely()和 unlikely()。编译器会根据这条指令对条件分支进行优化：判断该条件是经常出现还是很少出现。
内核中的内存都不分页，若你每用掉一个byte时，物理内存就会减少一个byte。
若果一个用户程序试图进行一次非法的内存访问，内核就会出现 SIGSEGV 信号，并结束整个进程。若内核自己非法访问了内存，则内核中会发生内存错误，导致oops。因此，在内核中，不应该去做访问非法的内存地址，引用空指针等，否则可能会死掉。   

Linux 内核架构
Linux Architecture and features
2.1. 内核模式与体系结构操作系统的工作方式

操作系统从用户态态切换到内核态，即用户应用程序到内核程序。
实现操作系统的系统调用。
应用操作系统提供的底层函数，进行功能的实现。
从内核态切换到用户态。

操作系统内核中各级模块之间的关系

Linux内核模块整体分为：进程调度模块、内存管理模块、文件系统模块、进程间通信模块、驱动管理模块。
每个模块之间的关系
内存管理和驱动管理模块 。
虚拟内存的缓存和回存机制。
虚拟文件系统 (VFS) 把硬件当成文件来使用。



操作系统结构的独立性

为什么要把 Linux 内核分成管理层和实现层：易于代码的升级和维护。
高版本内核与低版本内核的区别
内核驱动的种类变多了，但内核驱动的管理模式并没有发生巨大的改变，比如：一段时间的三个跳段：零散型、分层型、设备树（Android操作系统）。
进程的调度算法发生了改变，但进程的管理方式没有发生巨大的改变。



2.2. struct内核中常见的 struct 结构体

task_struct
mm_task

2.3. 内核中断2.4. 内核进程task_struct 进程描述符：https://blog.csdn.net/lf_2016/article/details/54347820
每一个进程都有一个 task_struct。
2. Linux 内核源码结构2.1. Linux 内核源码宏观结构2.2. Linux 内核源码各级源码分类2.3. Linux 内核源码解析第一刀2. Linux 内核引导程序2.1. Linux 内核启动程序分析2.2. Linux 内核初始化程序分析2.3. Linux 第一个进程分析2. The Linux Storage Stack Diagram

来源：https://en.wikipedia.org/wiki/Linux_kernel#/media/File:The_Linux_Storage_Stack_Diagram.svg
内核优化
对 kernel 的调教。

kernel 与 框架的优化

内存的管理 

内存碎片的优化



Linux 内核社区

理解内核补丁的生命周期。
补丁的合并是严谨、严格的。
遵循社区的规则和原则，对于新手建议可以从一个小的补丁开始。
提交解决问题的标准。

不要犹豫、不要害怕，一步一步的去解决问题。
信任的建立。无论做什么，都需要一些信任的建立。信任的建立都是很难的，一但建立，与人之间的交流会简单很多。
3. References
英文WIKI: https://en.wikipedia.org/wiki/Linux_kernel
Wiki Linux kernel version history: https://en.wikipedia.org/wiki/Linux_kernel_version_history
维基百科中文解释Linux内核: https://zh.wikipedia.org/wiki/Linux%E5%86%85%E6%A0%B8
官方 Linux kernel 英文 API 手册: https://www.kernel.org/doc/html/latest
在线查看Linux kernel 源码: https://elixir.bootlin.com/linux/latest/source
在线man-pages手册: https://man7.org/linux/man-pages/index.html由 man-pages 的维护者 Michael Kerrisk 维护的在线 man-pages 手册。其中除了 man-pages 手册外，还有许多丰富的内容，像 The Linux Programming Interface 等，值得日常重点查阅。
Linux kernel 周刊 LWN net: https://lwn.net/Kernel
Github 上零声学院开源的 Linux 内核学习的方法，很全面: https://github.com/0voice/linux_kernel_wiki
Linux 优化大师–布伦丹·格雷格的网站: http://www.brendangregg.com/index.html
Linux操作系统内核学习: https://ty-chen.github.io/categories作者自己搭建的一个博客，里面记录了自己学习 Linux 内核方面的一些知识点。
Linux内核中双向链表的经典实现: https://www.cnblogs.com/skywang12345/p/3562146.html
What every programmer should know about memory: https://lwn.net/Articles/250967博客写了关于 Memory、CPU caches、Virtual memory、NUMA systems、cache optimization、multi-threaded optimizations、Memory performance tools 等各个方面的知识，质量很高，需要细细的琢磨。
Linux0号进程，1号进程，2号进程: https://cloud.tencent.com/developer/article/1603977

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-kernal</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-lock</title>
    <url>/Linux/Linux/linux-lock/</url>
    <content><![CDATA[Linux lockLinux 内核设计了多种锁机制，比如 读写锁、自旋锁 和 信号量 等。为什么要设计这么多锁机制呢？这是因为不同的锁机制适用于不同的场景。

读写锁：适用于读多写少的场景。读写锁对于写操作较多的场景，性能会非常差。
信号量：适用于进程长时间占用锁，并且允许上下文切换的场景。信号量上锁失败的进程将会切换上下文，从而导致系统的性能下降。
自旋锁：获得锁的 CPU 将会阻塞其他 CPU 的允许，从而导致系统的并行能力下降。

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-lock</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-network</title>
    <url>/Linux/Linux/linux-network/</url>
    <content><![CDATA[


Linux NetworkNetfilterNetfilter 是 Linux 内核内部的包过滤和处理框架。





官方 netfilter 文档：https://www.netfilter.org/
微信公众号深入理解netfilter框架：https://mp.weixin.qq.com/s/WplVOafIn4dI3wmZLYPHFA

IptablesIptables Tutorial 1.2.2: https://www.frozentux.net/iptables-tutorial/iptables-tutorial.html)
References
Github Linux 4.4.0内核源码分析——TCP实现  真的是宝贝啊！！！！

个人博客：ARTHURCHIAO’S BLOG  主要是 Linux 和 Linux 网络相关的文章，也是宝贝啊！！！

官方Github Linux kernel network: https://linux-kernel-labs.github.io/refs/heads/master/labs/networking.html 很权威！！！

Linux 网络栈监控和调优：接收数据（2016）

 Linux 网络栈监控和调优：发送数据（2017）

[译] NAT - 网络地址转换（2016）

Github Linus 介绍 Scaling in the Linux Networking Stack

Introduction to Linux interfaces for virtual networking  介绍虚拟网络：Bridge、VLAN等

Linux 基金开源协会讲解 napi 

经典书籍
《The Linux Networking Architecture》
《Understanding Linux Network Internals》

Wikipedia 解释 Network scheduler：https://en.wikipedia.org/wiki/Network_scheduler

Linux 线上系统调优备忘: https://skywind.me/blog/archives/1893


]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-network</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-tricks</title>
    <url>/Linux/Linux/linux-tricks/</url>
    <content><![CDATA[linux system tricks and tips系统# uname -a        # 查看内核/操作系统/CPU信息# head -n 1 /etc/issue  # 查看操作系统版本# cat /proc/cpuinfo   # 查看CPU信息# hostname        # 查看计算机名# lspci -tv       # 列出所有PCI设备# lsusb -tv       # 列出所有USB设备# lsmod         # 列出加载的内核模块# env          # 查看环境变量

资源# free -m        # 查看内存使用量和交换区使用量# df -h         # 查看各分区使用情况# du -sh &lt;目录名&gt;    # 查看指定目录的大小# grep MemTotal /proc/meminfo  # 查看内存总量# grep MemFree /proc/meminfo  # 查看空闲内存量# uptime         # 查看系统运行时间、用户数、负载# cat /proc/loadavg   # 查看系统负载

磁盘和分区# mount | column -t   # 查看挂接的分区状态# fdisk -l        # 查看所有分区# swapon -s       # 查看所有交换分区# hdparm -i /dev/hda   # 查看磁盘参数(仅适用于IDE设备)# dmesg | grep IDE    # 查看启动时IDE设备检测状况

网络# ifconfig        # 查看所有网络接口的属性# iptables -L      # 查看防火墙设置# route -n        # 查看路由表# netstat -lntp     # 查看所有监听端口# netstat -antp     # 查看所有已经建立的连接# netstat -s       # 查看网络统计信息

进程# ps -ef         # 查看所有进程# top          # 实时显示进程状态

用户# w           # 查看活动用户# id &lt;用户名&gt;      # 查看指定用户信息# last          # 查看用户登录日志# cut -d: -f1 /etc/passwd  # 查看系统所有用户# cut -d: -f1 /etc/group  # 查看系统所有组# crontab -l       # 查看当前用户的计划任务

服务# chkconfig --list    # 列出所有系统服务# chkconfig --list | grep on  # 列出所有启动的系统服务

程序# rpm -qa        # 查看所有安装的软件包

查看CPU信息（型号） 
# cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c    8 Intel(R) Xeon(R) CPU      E5410  @ 2.33GHz (看到有8个逻辑CPU, 也知道了CPU型号) # cat /proc/cpuinfo | grep physical | uniq -c    4 physical id   : 0    4 physical id   : 1 (说明实际上是两颗4核的CPU) # getconf LONG_BIT   32 (说明当前CPU运行在32bit模式下, 但不代表CPU不支持64bit) # cat /proc/cpuinfo | grep flags | grep &#x27; lm &#x27; | wc -l   8 (结果大于0, 说明支持64bit计算. lm指long mode, 支持lm则是64bit) 

内存信息# cat /proc/meminfo # uname -a Linux euis1 2.6.9-55.ELsmp #1 SMP Fri Apr 20 17:03:35 EDT 2007 i686 i686 i386 GNU/Linux (查看当前操作系统内核信息) # cat /etc/issue | grep Linux Red Hat Enterprise Linux AS release 4 (Nahant Update 5) (查看当前操作系统发行版信息) 

机器型号# dmidecode | grep &quot;Product Name&quot; 

网卡信息# dmesg | grep -i eth

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux-tricks</tag>
      </tags>
  </entry>
  <entry>
    <title>microsoft-wsl</title>
    <url>/Linux/Linux/microsoft-wsl/</url>
    <content><![CDATA[

1. WSL1.1. 安装Microsoft 官方 docs: https://docs.microsoft.com/zh-cn/windows/wsl/
1.2. WSL 中修改 hostname默认情况下 wsl 的 hostname 是和当前 windows 系统的主机名称保持一致的，有时候 Windows 系统的主机名太长了，在 wsl 中显示太长，感觉不是很舒服，觉得有洁癖，但又不好改 windows 的主机名，那么只能改 wsl 的主机名了。在 wsl 下使用 /etc/hostname  命令修改主机名时，发现并不能完全修改，在重新进入 wsl 后又会恢复成原来的样子，发现这种方式在 wsl 中不能永久生效。因此需要通过另外一种方式来改变。
进入 /etc 目录， 编辑 wsl.conf，如果没有该文件就创建一个，在文件中加入下面的内容
[user]default=root[network]generateHosts=falsehostname=WSL2


user 组下面，default 后面的数值表示进入 wsl 后默认启动的用户，当前设置为 root；
network 组下面，generateHosts 表示是否自动生成 hosts 文件，hostname 表示 wsl 主机名。

设置完参数后保存退出， window 终端执行 wsl --shutwown 关闭 wsl，然后用 wsl 命令启动系统，进入 wsl 系统后，发现 hostname 已被修改为 WSL2。
1.3. wsl 下安装 zsh
在WSL中安装zsh终端：https://www.cnblogs.com/hongdada/p/11087557.html
oh my zsh github themes: https://github.com/ohmyzsh/ohmyzsh/wiki/Themes
agnoster 主题安装 powerline 字体: https://github.com/powerline/fonts

1.4. Trouble Shooting1.4.1. WSL莫名奇怪不能连接网络终端执行下面的命令，重启机器，解决网络问题。
wsl --shutdownnetsh winsock resetnetsh int ip reset allnetsh winhttp reset proxyipconfig /flushdns



References
Development Containers
https://www.youtube.com/@code/videos

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>microsoft-wsl</tag>
      </tags>
  </entry>
  <entry>
    <title>ntp</title>
    <url>/Linux/Linux/ntp/</url>
    <content><![CDATA[简介ntpd 是传统的时间同步守护进程，用于让系统的时间与远程 NTP（Network Time Protocol）服务器持续保持同步。它适合长期在线的服务器，能逐步调整系统时钟，保持时间的精准性。以下是 ntpd 的使用方法，包括安装、配置和监控。
1. 安装 ntpd在大多数 Linux 发行版上，ntpd 都可以通过包管理器安装：
# Debian/Ubuntusudo apt updatesudo apt install ntp# CentOS/RHELsudo yum install ntp# Fedorasudo dnf install ntp

2. 配置 ntpdntpd 的配置文件通常位于 /etc/ntp.conf。打开文件，指定 NTP 服务器来同步时间。可以添加公共 NTP 服务器或局域网内的 NTP 服务器。例如，添加阿里云的 NTP 服务器：
server ntp.aliyun.com iburst

常用的配置选项包括：

server：指定 NTP 服务器地址。
iburst：当服务器首次不可用时，它会快速请求，提升同步速度。
restrict：用于控制访问权限和网络范围。

可以添加多个 NTP 服务器以提高同步稳定性。例如：
server 0.pool.ntp.org iburstserver 1.pool.ntp.org iburstserver 2.pool.ntp.org iburstserver 3.pool.ntp.org iburst

3. 启动并启用 ntpd完成配置后，启动 ntpd 服务，并将其设置为开机自启：
# 启动 ntpd 服务sudo systemctl start ntp# 设置开机自启sudo systemctl enable ntp

4. 检查同步状态
查看 NTP 服务器的同步状态：
ntpq -p

输出会显示已连接的 NTP 服务器、延迟和偏差等信息。

查看系统时间的同步状态：
ntpstat

此命令会告诉你系统时间是否与 NTP 服务器同步。


5. 手动同步时间如果系统时间偏差较大，可以在启动 ntpd 之前使用 ntpd 的一次性命令手动同步。注意在执行以下命令时必须停止 ntpd 服务：
sudo systemctl stop ntpsudo ntpd -gqsudo systemctl start ntp


-g：允许大幅度调整时间。
-q：表示一次性查询时间并退出。

6. 常见问题排查
NTP 服务未同步：检查防火墙设置是否允许 UDP 端口 123（NTP 使用的端口）。
时间漂移过大：可以使用 ntpd -gq 强制一次性同步。

总结ntpd 适合长期在线的服务器，尤其适用于需要长时间稳定时间同步的环境。
示例在 ntpq -p 命令的输出中，各字段提供了 NTP 服务器和同步状态的详细信息。以下是这些字段的含义：

remote：远程 NTP 服务器的地址或主机名，表示当前同步的 NTP 源。
*：代表这是当前使用的主服务器（系统的同步源）。
+：代表备选服务器，即如果主服务器不可用，将选择此服务器。
-：该服务器已被排除，不参与时间同步。
x：代表该服务器有问题，不参与同步。


refid：远程服务器的参考 ID，即该服务器所使用的上游时间源。通常是 IP 地址或名称。
st（stratum）：层级，表示时间源的层级。值越小，表示时间源越靠近时钟源。常见值：
0：表示服务器直接连接到原子钟或 GPS 时钟源。
1：表示时间来自高精度设备（如 GPS）。
2-15：表示服务器层级（层级越高，精度越低）。


t：远程服务器的类型。
u：unicast（单播），最常见的类型。
m：multicast（多播）。
b：broadcast（广播）。


when：上次从该服务器获取时间的时刻（以秒为单位），在下一次查询前不断递增。
poll：当前的查询间隔（以秒为单位），表示客户端每隔多长时间请求一次该服务器。值会在 64 到 1024 秒之间动态调整。
reach：到达计数器，显示客户端最近是否成功与服务器通信。reach 的值是一个 8 位二进制数（以八进制显示），每一位表示一次轮询的结果，成功为 1，失败为 0。例如 377 表示最近 8 次轮询全部成功（11111111）。
delay：网络延迟（以毫秒为单位），即客户端与服务器之间的往返时间。
offset：偏移量（以毫秒为单位），表示客户端时间与该服务器时间的差异。偏移值越小，同步越精确。
jitter：抖动，表示偏移量的变化情况，即最近几次轮询的偏移量波动程度，数值越小越好，说明时间源的稳定性越高。

例子分析remote           refid      st t when poll reach   delay   offset  jitter==============================================================================*172.25.254.1    202.118.1.46     2 u    9 1024  377    3.652    1.614   6.546 +172.25.254.2    202.118.1.46     2 u   91 1024  377    1.616    2.829   7.224


172.25.254.1 是当前的同步源，因为前面带有 *。
172.25.254.2 是备选同步源，因为前面带有 +。
st 是 2，表示这是第二层的 NTP 服务器，比较常见。
delay 和 offset 表明与服务器的网络延迟和时间偏移都在合理范围内。

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ntp</tag>
      </tags>
  </entry>
  <entry>
    <title>package-manager</title>
    <url>/Linux/Linux/package-manager/</url>
    <content><![CDATA[
1. 包管理RedHat&#x2F;CentOS8 【国内&#x2F;本地&#x2F;私有 Yum 源】制作和使用
Debian&#x2F;Ubuntu 采用 dpkg 进行软件包的管理，使用 apt 进行在线软件的升级。
CentOS&#x2F;Red Hat&#x2F;Fedora 采用 rpm 进行软件包的管理，使用 yum 进行在线软件的升级。
1.1. 软件仓库Windows

常有文件程序自解压、选定安装组件和安装路径（个别不让选择路径）、添加注册表项等等，完成以后双击启动运行，卸载时找安装路径下的uninstall或者控制面板里卸载

Linux 或 Unix

软件包组织方式上，是将可执行程序、程序库、手册页等多种类型文件打包压缩提供，内容上一般分为预先编译好的二进制包和程序源码包两种；
软件包管理方式上，不同开发者开发的软件，被打包集中统一存放在官方维护的软件仓库中，这个软件仓库就是一个软件源，和iOS&#x2F;Android系统上的AppStore&#x2F;应用市场等概念很像，Windows也开始使用“Windows Store”；除此外，第三方在遵守相关协议的前提下镜像（mirror）官方软件仓库成为镜像源，系统提供专门的软件包管理器用于从软件源下载、安装和卸载软件包。

1.2. RPMrpm（RPM Package Manager）叫RPM包管理器。
rpm包：把二进制程序文件、配置文件以和帮助文档等程序资源打包在一起形成的文件。安装软件需要手动解决依赖关系。
仓库源位置：/etc/yum.repos.d/，查看中重点关注是基础的 CentOS-Base.repo
RPM 包安装包的格式，下面以 autoconf-2.63-5.1.el6.noarch.rpm 安装包为例子。

# 参数项-q|--query  -V|--verify-i|--install-U|--upgrade-e|--erase# 常见命令rpm -ql  列出软件中安装的软件包rpm -e xxx 卸载 xxx 包rpm -qa xxx 查询安装包rpm -ivh --force --nodeps *rpm  一次性安装多个软件包

1.3. EpelEPEL (Extra Packages for Enterprise Linux), 是由 Fedora Special Interest Group 维护的 Enterprise Linux（RHEL、CentOS）中经常用到的包。

官方主页：https://fedoraproject.org/wiki/EPEL
阿里云 epel 镜像配置

1.4. Yumyum源（rpm软件仓库）：集中存储rpm包的服务器，通常以http、nfs、ftp、file等协议提供rpm包下载安装服务。互联网中的yum源一般分为发行方和第三方提供。CentOS默认使用发行方yum源。安装软件时会自动解决依赖关系。
yum配置文件：CentOS中用于定义yum源位置和使用协议的配置文件，存放在 /etc/yum.repo.d目录下的 *.repo 文件，为所有仓库提供公共配置。
CentOS8默认开启的yum配置文件有：CentOS-AppStream.repo、CentOS-Base.repo、CentOS-Extras.repo；
CentOS7及以下版本默认开启的yum配置文件有：CentOS-Base.repo、CentOS-Extras.repo、CentOS-Updates.repo。

dnf&#x2F;yum命令：CentOS中用于从yum源下载rpm包、自动处理包依赖关系，并且能够一次安装所有所依赖rpm包的命令工具。CentOS8建议使用dnf工具，CentOS7及以下只能使用yum工具。两个工具的用法、参数一致。
reposync：用于同步互联网yum源的rpm包到本地磁盘中的命令工具。通过yum源下载yum-utils安装。
createrepo：用于扫描本地磁盘中的rpm包并生成元数据文件，建立本地yum源的命令工具。建成本地yum源后，服务器可以通过file协议使用本地yum源。
modifyrepo：用于导入yum源模块文件的命令工具。

参数项repolistgrouplist   可用组

1.5. apt1.5.1. apt-cache
apt-cache search 搜索包
apt-cache show  获取包的相关信息，如说明、大小、版本等
apt-cache depends 查看软件包的依赖关系
apt-cache rdepends 了解某个具体的依赖,当是查看该包被哪些包依赖吧

1.5.2. apt-get
apt-get install  安装xxxx包
// 离线安装或下载包缓存sudo apt-get --download-only install &lt;packagename&gt;// 下载的包存在 /var/cache/apt/archives 目录下，然后将下载的包移动到指定目录下，打包并发送到离线环境的机器上// 使用 sudo apt clean 清除缓存

apt-get reinstall   重新安装包

apt-get -f install  强制安装，”-f &#x3D; –fix-missing”

apt-get remove 删除包

apt-get remove --purge 删除包，包括删除配置文件等

apt-get autoremove --purge 删除包及其依赖的软件包、配置文件等

apt-get update  更新源(软件列表)

apt-get upgrade 升级已安装的包

apt-get clean &amp;&amp; apt-get autoclean  清理下载文件的缓存和只清理过时的包

apt-get dist-upgrade 升级系统

apt-get dselect-upgrade 使用 dselect 升级

apt-get build-dep 安装相关的编译环境

apt-get source  下载该包的源代码

apt-get check 检查是否有损坏的依赖

apt-get remove softname1 softname2  卸载软件

apt-get purge sofname1 softname2      卸载软件同时清除配置文件


1.5.3. apt-file
apt-file search filename 查找filename属于哪个软件包
apt-file list packagename 列出软件包的内容
apt-file update 更新apt-file的数据库

1.6. dpkg
dpkg --info soft_name  列出软件包解包后的包名称.
dpkg -l  列出当前系统中所有的包.可以和参数less一起使用在分屏查看. (类似于rpm -qa)
dpkg -l |grep -i “软件包名” –查看系统中与”软件包名”相关联的包.
dpkg -s 查询已安装的包的详细信息.
dpkg -L 查询系统中已安装的软件包所安装的位置. (类似于rpm -ql)
dpkg -S 查询系统中某个文件属于哪个软件包. (类似于rpm -qf)
dpkg -I 查询deb包的详细信息,在一个软件包下载到本地之后看看用不用安装(看一下呗).
dpkg -i 手动安装软件包(这个命令并不能解决软件包之前的依赖性问题),如果在安装某一个软件包的时候遇到了软件依- 赖的问题,可以用apt-get -f install在解决信赖性这个问题.
dpkg -r 卸载软件包.不是完全的卸载,它的配置文件还存在.
dpkg -P 全部卸载(但是还是不能解决软件包的依赖性的问题)
dpkg -reconfigure 重新配置
dpkg -S filename —–查找filename属于哪个软件包
找到安装的软件
dpkg -S softwarename 显示包含此软件包的所有位置
dpkg -L softwarename 显示安装路径
dpkg -l softwarename 查看软件版本
用 find 或 whereis 命令查找文件位置



1.7. packages repository
Ubuntu offical nginx: https://nginx.org/packages/ubuntu/pool/nginx/n/
Packages for Linux and Unix: https://pkgs.org/
CentOS旧版本软件包的镜像站点: https://vault.centos.org/
阿里云CentSO7镜像: https://mirrors.aliyun.com/centos/7/os/x86_64/Packages/
Docker repository: https://download.docker.com/linux/
CentOS Vault Mirror: https://vault.centos.org/7.9.2009/
Centos Linux 更换源，原官方源已经不再提供服务: https://www.cnblogs.com/007sx/p/18351813
Devtoolset 安装与使用: https://weiyan.cc/yuque/%E5%BC%80%E5%8F%91%E8%BF%90%E7%BB%B4/%E7%B3%BB%E7%BB%9F%E4%B8%8E%E7%BC%96%E8%AF%91/2021-09-02-scl-devtoolset-note/

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>package-manager</tag>
      </tags>
  </entry>
  <entry>
    <title>performance-tools</title>
    <url>/Linux/Linux/performance-tools/</url>
    <content><![CDATA[

1. Linux 下常用性能分析工具1.1. gprofgprof 是 GNU 工具链之一，编译的时候，它在每个函数的出入口加入了 profiling 的代码，运行时统计程序在用户态的执行信息，可以得到每个函数的调用次数，执行时间，调用关系等信息，简单易懂。适合于查找用户级程序的性能瓶颈，然而对于很多耗时在内核态执行的程序，gprof 不适合。
1.2. oprofileoprofile 是一个开源的 profiling 分析工具，它使用硬件调试寄存器来统计信息，进行 profiling 的开销比较小，而且可以对内核进行 profiling。它统计的信息非常多，可以得到 cache 的缺失率，memory 的访存信息，分支预测错误率等等，这些信息 gprof 得不到，但是对于函数调用次数，它无能为力。
1.3. gperftoolsGoogle 开发的一款性能分析工具，提供整个程序的热点分布图，找到性能瓶颈，然后可以针对性的进行性能优化。
1.4. mpstatmpstat 是多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。
参数项    -P: 输出哪个处理器的数据，后面跟 CPU 的数字号码或者是 ON 或 ALL；ON 表示输出统计每个在运行的处理器；ALL 表示输出统计所有的处理器// 监控所有 CPU，每隔5秒输出一组数据[root@CentOS7 ~]# mpstat -P ALL 5Linux 3.10.0-1160.49.1.el7.x86_64 (CentOS7)     12/15/2021      _x86_64_        (2 CPU)10:55:54 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle10:55:59 PM  all   50.10    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   49.9010:55:59 PM    0    0.00    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   99.8010:55:59 PM    1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00

1.5. pidstatpidstat 是进程性能分析工具，监视当前被 Linux 内核管理的单个任务，用来实时查看进程的 CPU、内存、I&#x2F;O 以及上下文切换等性能指标。
参数项    -u 输出 CPU 的利用率，utilization 缩写为 u    -t 显示所选线程的统计信息，很常用，thread 缩写为 t    -r 显示缺页错误（page faults）和内存利用信息    -w 任务活动切换的信息，只有在 Linux kernels 大于等于 2.6.23 才有效// 每隔 5 秒输出一组数据[root@CentOS7 ~]# pidstat -u 5 1Linux 3.10.0-1160.49.1.el7.x86_64 (CentOS7)     12/15/2021      _x86_64_        (2 CPU)10:57:36 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command10:57:41 PM     0         3    0.00    0.20    0.00    0.20     0  kworker/0:010:57:41 PM     0       745    0.00    0.20    0.00    0.20     0  vmtoolsd10:57:41 PM     0      6791  100.00    0.00    0.00  100.00     1  stress10:57:41 PM     0      6914    0.00    0.20    0.00    0.20     0  pidstatAverage:      UID       PID    %usr %system  %guest    %CPU   CPU  CommandAverage:        0         3    0.00    0.20    0.00    0.20     -  kworker/0:0Average:        0       745    0.00    0.20    0.00    0.20     -  vmtoolsdAverage:        0      6791  100.00    0.00    0.00  100.00     -  stressAverage:        0      6914    0.00    0.20    0.00    0.20     -  pidstat

1.6. iostatiostat 工具用于通过观察设备相对于其平均传输速率的活动时间来监视系统输入&#x2F;输出设备负载。
// 每隔 1 秒中显示I/O设备信息$ iostat -xz 1Linux 2.6.32-358.el6.x86_64 (KF-CFT-AP2)        2022年01月27日  _x86_64_        (4 CPU)avg-cpu:  %user   %nice %system %iowait  %steal   %idle           1.34    0.00    0.79    0.02    0.00   97.86Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %utilsda               0.02     2.91    0.13    1.49     6.62    35.20    25.74     0.00    2.22   0.69   0.11sdb               0.01     0.69    0.09    0.40     2.59     8.75    23.19     0.00    2.96   0.67   0.03dm-0              0.00     0.00    0.24    5.49     9.06    43.93     9.24     0.05    8.85   0.23   0.13dm-1              0.00     0.00    0.00    0.00     0.00     0.01     8.00     0.00    3.74   0.28   0.00avg-cpu:  %user   %nice %system %iowait  %steal   %idle           3.31    0.00    2.54    0.00    0.00   94.15Device:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %utilsdb               0.00     0.00    0.00    3.00     0.00    24.00     8.00     0.01    4.00   4.00   1.20dm-0              0.00     0.00    0.00    3.00     0.00    24.00     8.00     0.01    4.00   4.00   1.20

输出结果各个字段说明

r&#x2F;s, w&#x2F;s, rkB&#x2F;s, wkB&#x2F;s：这些表示设备上每秒钟的读写次数和读写的字节数（单位是k字节）。这些可以看出设备的负载情况。性能问题可能就是简单的因为大量的文件加载请求。
await(r_await、w_await)：平均每次设备 I&#x2F;O 请求操作的等待时间(ms)，包含请求排列在队列中和被调度服务的时间之和；过大的平均等待时间就预示着设备超负荷了或者说设备有问题了。
avgqu-sz：发送给设备 I&#x2F;O 请求的等待队列平均长度，对于单个磁盘如果值&gt;1表明设备饱和，对于多个磁盘阵列的逻辑磁盘情况除外
%util：设备的使用率，表明每秒中用于 I&#x2F;O 工作时间的占比，单个磁盘当 %util&gt;60% 的时候性能就会下降(体现在 await 也会增加)，当接近100%时候就设备饱和了，但对于有多个磁盘阵列的逻辑磁盘情况除外
svctm：发送给设备 I&#x2F;O 请求的平均服务时间(ms)，如果 svctm 与 await 很接近，表示几乎没有 I&#x2F;O 等待，磁盘性能很好，否则磁盘队列等待时间较长，磁盘响应较差；

1.7. vmstatvmstat是 Virtual Meomory Statistics（虚拟内存统计）的缩写，可对操作系统的processes、 memory、paging、 block IO、 traps、CPU等活动进行监控。他是对系统的整体情况进行统计，不足之处是无法对某个进程进行深入分析。vmstat 工具提供了一种低开销的系统性能观察方式。因为 vmstat 本身就是低开销工具，在非常高负荷的服务器上，你需要查看并监控系统的健康情况,在控制窗口还是能够使用vmstat 输出结果。
1.7.1. 虚拟内存原理在系统中运行的每个进程都需要使用到内存，但不是每个进程都需要每时每刻使用系统分配的内存空间。当系统运行所需内存超过实际的物理内存，内核会释放某些进程所占用但未使用的部分或所有物理内存，将这部分资料存储在磁盘上直到进程下一次调用，并将释放出的内存提供给有需要的进程使用。
在Linux内存管理中，主要是通过“调页Paging”和“交换Swapping”来完成上述的内存调度。调页算法是将内存中最近不常使用的页面换到磁盘上，把活动页面保留在内存中供进程使用。交换技术是将整个进程，而不是部分页面，全部交换到磁盘上。
分页(Page)写入磁盘的过程被称作Page-Out，分页(Page)从磁盘重新回到内存的过程被称作Page-In。当内核需要一个分页时，但发现此分页不在物理内存中(因为已经被Page-Out了)，此时就发生了分页错误（Page Fault）。
当系统内核发现可运行内存变少时，就会通过Page-Out来释放一部分物理内存。尽管Page-Out不是经常发生，但是如果Page-out频繁不断的发生，直到当内核管理分页的时间超过运行程式的时间时，系统效能会急剧下降。这时的系统已经运行非常慢或进入暂停状态，这种状态亦被称作thrashing(颠簸)。
1.7.2. 格式vmstat [-a] [-n] [-S unit] [delay [ count]]vmstat [-s] [-n] [-S unit]vmstat [-m] [-n] [delay [ count]]vmstat [-d] [-n] [delay [ count]]vmstat [-p disk partition] [-n] [delay [ count]]vmstat [-f]vmstat [-V]


1.7.3. 参数-m：显示slabinfo-n：只在开始时显示一次各字段名称。-s：显示内存相关统计信息及多种系统活动数量。delay：刷新时间间隔。如果不指定，只显示一条结果。  count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。  -d：显示磁盘相关统计信息。  -p：显示指定磁盘分区统计信息  -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）  -V：显示vmstat版本信息。

示例：每隔 1 秒打印一条统计信息
$ vmstat 1procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st10  0   8320 3822308 427996 2263180    0    0     1     6    0    3  1  1 98  0  0 0  0   8320 3822176 427996 2263184    0    0     0     0 5889 20478  2  1 97  0  0 1  0   8320 3822176 427996 2263184    0    0     0     0 6126 20785  3  1 97  0  0 3  0   8320 3822176 427996 2263184    0    0     0    48 6459 21076  2  1 96  0  0

虚拟内存模式（VM mode）下，显示结果中各个字段的含义

procs

r：CPU 上的等待运行时（run time）的进程数。这个指标提供了判断 CPU 饱和度的数据，因为它不包含 I&#x2F;O 等待的进程。
b：不可中断睡眠状态（uninterruptible sleep）的进程数；


Memory

swpd 表示使用到的虚拟内存数量
free：空闲内存，单位是 k。如果这个数比较大，就说明你还有充足的空闲内存。“free -m” 和下面第 7 个命令，可以更详细的分析空闲内存的状态。


swap

si：从磁盘交换进来和交换出去的内存数。
so：从磁盘交换出去的内存数。


IO 

bo： 每秒钟发送到块设备的块数目，单位：blocks&#x2F;s。
bi  每秒钟从块设备收到的块数目，单位：blocks&#x2F;s。


system 

in：每秒钟的系统中断数，包括时钟中断（clock）。
cs：每秒钟上下文切换的数。


cpu
下面这些是占总 CPU 时间的百分比。

us：运行非内核代码花费的时间，用户空间的时间，包括 nice time。（user time）
sy：运行内核代码花费的时间。（system time）
id：空闲 CPU 花费的时间。在 Linux 内核版本 2.5.41 之前，还包括 IO-wait 时间。（idle）
wa：等待 IO 花费的时间。（waitting）
st：从虚拟机器偷走的时间，在 Linux 内核 2.6.11之前，为unknown。（stolen）有虚拟机的情景下才有意义，因为虚拟机下 CPU 也是共享物理 CPU 的，所以这段时间表明虚拟机等待 hypervisor 调度 CPU 的时间，也意味着这段时间 hypervisor 将 CPU 调度给别的 CPU 执行，这个时段的 CPU 资源被“stolen”了。



参考： https://www.apim.cn/html/5375
1.8. netstatnetstat 是一个查看系统中端口使用情况的命令，显示自从系统启动以来，各个协议的总体数据信息。

侦听端口：应用程序或进程侦听的网络端口，充当通信端点。
注意：同一个 IP 地址上不能用两个不同的服务去侦听同一端口

下面是 netstat 命令的用法解释：
语法格式  netstat 检查端口参数项  -a --all       显示所有的连接，包括监听状态和非监听状态的连接（sockets）。  -t --tcp       显示 TCP 连接信息。该选项将显示所有的 TCP 连接，包括建立连接和监听状态。  -u --udp       显示所有的 UDP 连接信息。  -n --numeric   显示数字形式的 IP 地址和端口号，而不尝试进行主机名和服务名的反解析。  -l --listening 仅显示处于监听状态的套接字（sockets）。  -p --program   显示每个连接（sockets）的进程的 PID 和名称（name）。

示例
netstat -tunlp | grep 端口号   # 列出正在侦听的所有TCP或UDP端口，                              # 显示程序的PID和name，同时以数字形式显示IP，最常用[root@KF]# netstat -tunlp | grep 22tcp        0      0 0.0.0.0:22          0.0.0.0:*         LISTEN      1919/sshdtcp        0      0 :::22               :::*              LISTEN      1919/sshd  netstat -apn | grep 端口号     # 查看指定端口号的所有进程在TCP、UDP传输中的所有状态  netstat -antp                 # 列出所有TCP的连接  netstat -nltp                 # 列出本地所有TCP侦听套接字  netstat -nat

Tips:
Linux中查看内核中设置的 TIME_WAIT 时间：
sysctl net.ipv4.tcp_fin_timeout

在大多数 Linux 发行版中，TIME_WAIT 时间的默认值通常为 60 秒。 
1.9. stressstress 是linux 下的压力测试小工具，可以用来模拟 CPU、IO、内存、磁盘等资源耗尽的问题，但这也仅仅只是用来模拟进行简单的资源耗尽问题，用它模拟产生的结果和业务真实场景差别还是很大的，真实业务场景下不建议使用。
参数项    -t: 等同于 --timeout N，在 N 秒后超时    -c: 等同于 --cpu N，产生 N 个 CPU 工作    -i: 等同于 --io N，产生 N 个 IO 工作// 模拟 CPU1 使用率为 100% 的情况[root@CentOS7 ~]# stress --cpu 1 --timeout 600stress: info: [6790] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd


1.10. uptimeuptime 命令显示当前系统运行了多长时间，当前有多少个用户登录，系统在过去 1分钟、5分钟、15分钟的负载均衡信息，是一种快速展示系统平均负载的手段。
$ uptime 10:32:25 up 21 days, 22:36,  5 users,  load average: 0.00, 0.00, 0.00


1.11. dmesgdmesg 工具被用来检查和控制内核的环形缓冲区（ring buffer），分析内核产生的一些信息，该程序帮助用户打印出启动消息。
系统在启动的时候，内核会去检测系统的硬件，你的某些硬件到底有没有被识别，就与这个时候的侦测有关。 但是这些侦测的过程要不是没有显示在屏幕上，就是很飞快的在屏幕上一闪而逝。能不能把内核检测的信息识别出来看看？ 可以使用 dmesg 。所有内核检测的信息，不管是启动时候还是系统运行过程中，反正只要是内核产生的信息，都会被记录到内存中的某个保护区段。 dmesg 这个指令就能够将该区段的信息读出来。
// 打印启动消息日志中的最后 10 信息$ dmesg | tail[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0[...][1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.


1.12. sarsar 工具用来检测网络接口的吞吐：rxkB/s 和 txkB/s，作为收发数据负载的度量，也是检测是否达到收发极限。
参数项  -n 主要用来分析网络活动，虽然网络中它还给细分了 NFS、IP、ICMP、SOCK 等各种层次各种协议的数据信息。// 每隔1秒中显示网络接口的吞吐量，$ sar -n DEV 1Linux 2.6.32-358.el6.x86_64 (KF-CFT-AP2)        2022年01月27日  _x86_64_        (4 CPU)11时24分52秒     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s11时24分53秒        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.0011时24分53秒      eth1      3.06      0.00      0.18      0.00      0.00      0.00      0.0011时24分53秒     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s11时24分54秒        lo      2.04      2.04      0.11      0.11      0.00      0.00      0.0011时24分54秒      eth1      8.16      6.12      0.51      0.75      0.00      0.00      0.00// 示例2：每隔1秒显示tcp统计的信息$ sar -n TCP,ETCP 1Linux 2.6.32-358.el6.x86_64 (KF-CFT-AP2)        2022年01月27日  _x86_64_        (4 CPU)11时30分03秒  active/s passive/s    iseg/s    oseg/s11时30分04秒      0.00      0.00      3.09      3.0911时30分03秒  atmptf/s  estres/s retrans/s isegerr/s   orsts/s11时30分04秒      0.00      0.00      0.00      0.00      0.00

显示结果解释

TCP

active&#x2F;s：本地发起的 TCP 连接，比如通过 connect()，TCP 的状态从CLOSED -&gt; SYN-SENT
passive&#x2F;s：由远程发起的 TCP 连接，比如通过 accept()，TCP 的状态从LISTEN -&gt; SYN-RCVD
retrans&#x2F;s(tcpRetransSegs)：每秒钟 TCP 重传数目，通常在网络质量差，或者服务器过载后丢包的情况下，根据 TCP 的确认重传机制会发生重传操作
isegerr&#x2F;s(tcpInErrs)：每秒钟接收到出错的数据包(比如 checksum 失败)


UDP

noport&#x2F;s(udpNoPorts)：每秒钟接收到的但是却没有应用程序在指定目的端口的数据报个
idgmerr&#x2F;s(udpInErrors)：除了上面原因之外的本机接收到但却无法派发的数据报个数



1.13. topTop 是 linux 下动态监控各个进程资源占用状况的工具，默认按照CPU使用率为排序的依据，类似于 Windows 中的任务管理器。
参数项：    %us 用户空间程序的 cpu 使用率（没有通过 nice 调度）    %sy 系统空间的 cpu 使用率，主要是内核程序。    %ni 用户空间且通过 nice 调度过的程序的 cpu 使用率。    %id 空闲cpu    %wa cpu运行时在等待io的时间    %hi cpu处理硬中断的数量    %si cpu处理软中断的数量    %st 被虚拟机偷走的cpu 例子：    top -bn 1 -i -c

利用一张图来解释各个参数的用法。


CPU 占用率高很多情况下意味着一些东西，这也给服务器 CPU 使用率过高情况下指明了相应地排查思路：

当 user 占用率过高的时候，通常是某些个别的进程占用了大量的 CPU，这时候很容易通过 top 找到该程序；此时如果怀疑程序异常，可以通过 perf 等思路找出热点调用函数来进一步排查；
当 system 占用率过高的时候，如果 IO 操作(包括终端 IO)比较多，可能会造成这部分的 CPU 占用率高，比如在 file server、database server 等类型的服务器上，否则(比如&gt;20%)很可能有些部分的内核、驱动模块有问题；
当 nice 占用率过高的时候，通常是有意行为，当进程的发起者知道某些进程占用较高的 CPU，会设置其 nice 值确保不会淹没其他进程对 CPU 的使用请求；
当 iowait 占用率过高的时候，通常意味着某些程序的 IO 操作效率很低，或者 IO 对应设备的性能很低以至于读写操作需要很长的时间来完成；
当 irq&#x2F;softirq 占用率过高的时候，很可能某些外设出现问题，导致产生大量的irq请求，这时候通过检查 &#x2F;proc&#x2F;interrupts 文件来深究问题所在；
当 steal 占用率过高的时候，黑心厂商虚拟机超售了吧！

Buffers 与 Cached 对比说明

Buffers 是针对 raw disk 的块缓存，主要是以 raw block 的方式缓存文件系统的元数据(比如超级块信息等)，这个值一般比较小(20M左右)；
Cached 是针对于某些具体的文件进行读缓存，以增加文件的访问效率而使用的，可以说是用于文件系统中文件缓存使用。

1.14. htophtop是 top工具命令的“进化版本”，它的一大特色在于可视化交互方面做得很优秀。它不是 Linux 系统默认自带的，使用它需要额外的安装。它也是Linux系统下的一个交互式进程浏览器，可以替代上面的top命令，与top命令对比，htop有如下优点：

支持鼠标点按交互
画面可以水平&#x2F;垂直滚动，更像一个窗口
可以跟踪进程，显示进程打开的文件等
支持进程的树状图显示
支持按名称查找进程
…等等

1.15. iftopiftop是 Linux 系统上的网络流量和带宽监控工具，可用于查看（监控）实时的网络流量、网络TCP&#x2F;IP连接等等，它不是 Linux 系统默认自带的，使用它需要额外的安装。
常用参数项-i 指定网卡，如：iftop -i eth0-B 以bytes为单位显示，如：iftop -B-n host信息显示IP，如：iftop -n-N 端口信息显示端口号，如: iftop -N-F 指定网段，如iftop -F 10.10.1.0/24-h 帮助信息


1.16. iotopiotop 是 Linux 系统默认自带的一个用来监控磁盘 I&#x2F;O 使用情况的工具。
1.17. vmtouchvmtouch  是一个了解和管理（controlling ） unix 和类 Unix 系统的文件缓存（cache）工具，它是 BSD 证书许可的。
用法
Usage: vmtouch [OPTIONS] ... FILES OR DIRECTORIES ...Options:  -e(evict pages from memory)  将某个文件从 Cache 中移除  -t(touch pages into memory)  将文件加载到 Cache 中  -v(verbose)                  查看文件有多少内容在 Cache 中  -l lock pages in physical memory with mlock(2)  -L lock pages in physical memory with mlockall(2)  -d daemon mode  -m &lt;size&gt; max file size to touch  -p &lt;range&gt; use the specified portion instead of the entire file  -f follow symbolic links  -F don&#x27;t crawl different filesystems  -h also count hardlinked copies  -i &lt;pattern&gt; ignores files and directories that match this pattern  -I &lt;pattern&gt; only process files that match this pattern  -b &lt;list file&gt; get files or directories from the list file  -0 in batch mode (-b) separate paths with NUL byte instead of newline  -w wait until all pages are locked (only useful together with -d)  -P &lt;pidfile&gt; write a pidfile (only useful together with -l or -L)  -q quiet

1.18. pmappmap 命令是显示进程的内存映射信息。
用法：
// 格式pmap [options] pid [...]OPTIONS  -x, --extended  Show the extended format.  -d, --device  Show the device format.  -q, --quiet  Do not display some header or footer lines.  -A, --range low,high  Limit results to the given range to low and high address range.  Notice that the low and high arguments are single string separated with comma.  -X     Show even more details than the -x option. WARNING: format changes according to /proc/PID/smaps  -XX    Show everything the kernel provides  -p, --show-path  Show full path to files in the mapping column  -c, --read-rc  Read the default configuration  -C, --read-rc-from file  Read the configuration from file  -n, --create-rc  Create new default configuration  -N, --create-rc-to file  Create new configuration to file  -h, --help  Display help text and exit.  -V, --version  Display version information and exit.

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>performance-tools</tag>
      </tags>
  </entry>
  <entry>
    <title>performance</title>
    <url>/Linux/Linux/performance/</url>
    <content><![CDATA[
1. Performance optimization(性能优化)1.1. 怎样做性能优化？在做性能优化之前，需要了解性能优化指标。从应用负载的视角来看，有两个核心指标：吞吐量和延时，这两个指标直接影响了产品终端的用户体验。从系统资源的角度看，有资源利用率、饱和度等指标。
性能问题的本质，就是系统资源已经达到瓶颈，但请求的处理却还不够快，无法支撑更多的请求。而性能分析，就是找出应用或系统的瓶颈，并设法去避免或者缓解它们，从而更高效地利用系统资源处理更多的请求。
从运行时性能的开销和编译时性能的开销角度思考
消除运行期的开销？
1.2. 如何去分析如何去思考去分析性能，该从哪些方面入手？

当前应用程序或系统有哪些指标可以衡量性能？
怎么样去设置应用程序或系统的性能指标？
使用什么样的性能工具来观察指标？
导致这些指标变化的因素是什么？
怎样进行性能基准测试？
怎样进行性能分析定位瓶颈？
性能监控和告警是怎样的？

学习的黄金准则

勤思考
多反思
善总结
多问为什么

1 分钟之内在命令行模式下用已有的 Linux 标准工具进行性能优化检测。
在 1 分钟之内只需要通过运行下面的 10 个命令就可以对系统资源使用和运行进程有一个很高程度的了解，寻找错误信息和饱和度指标，显示为请求队列的长度，或者等待时长、显示资源利用率。

饱和度是指一个资源已经超过了它自己的负荷能力。

uptimedmesg | tailvmstat 1mpstat -P ALL 1pidstat 1iostat -xz 1free -msar -n DEV 1sar -n TCP,ETCP 1top

有些命令需要安装 sysstat 工具包。这些命令展示的指标会帮助你完成一些 USE（Utilization，Saturation，Errors） 方法：定位性能瓶颈的方法论。包括了检查使用率（Utilization），饱和度（Saturation），所有资源（比如 CPU，内存，磁盘等）的错误指标（Errors）。同样也要关注你什么时候检查和排除一个资源问题，因为通过排除可以缩小分析范围，同时也指导了任何后续的检查。
1.2.1. 工具性能工具选择的黄金准则：一个正确的选择胜过千百次的努力。 选用合适的性能工具，可以大大简化整个性能优化的过程。
性能分析可以用哪些工具来衡量？
下图是常见的性能分析工具，来自性能领域的大师布伦丹·格雷格（Brendan Gregg）绘制，这个图是 Linux 性能分析最重要的参考资料之一，它告诉你，在 Linux 不同子系统出现性能问题后，应该用什么样的工具来观测和分析。


优化工具的使用具体请看：Linux 下常用系统性能优化工具
1.2.2. 代码编写优化编写的代码。
1.3. 优化到多少？1.4. 其它打印行和文件：stream(__FILE__, __LINE__)

判断是运行时变量还是编译时变量？
​    使用 static_assert()
应用：
​    替换宏（为什么要替换宏？）
​    宏运行在什么时候？（编译？运行？）
2. CPU Performanceload average（平均负载）：单位时间内，系统处于可运行状态（runnable state）或不可中断状态（uninterruptable state）的平均进程数，与 CPU 使用率并没有直接关系。
可运行状态的进程：正在使用 CPU 或正在等待 CPU 的进程。也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。
不可中断状态的进程：正处于内核态关键流程中的进程，并且这些流程是不可打断的。比如最常见的是正在等待磁盘（disk），也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。
正确区分平均负载和 CPU 使用率
CPU 使用率指单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如下面的情况：

CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
I&#x2F;O 密集型进程，等待 I&#x2F;O 也会导致平均负载升高，但 CPU 使用率不一定很高；
大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。

3. Memory Performance4. I&#x2F;O Performance5. Network Performance6. References
Linux Performance

如何 60 秒内进行 Linux 性能分析

CodeSheep 列出常用监控工具

如何查看 Linux 服务器性能参数指标？

面试官：如何优化你的程序

简书：Linux 问题故障定位的小技巧


]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>performance</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>systemd</title>
    <url>/Linux/Linux/systemd/</url>
    <content><![CDATA[

systemdSystemd（系统管理守护进程），最开始以GNU GPL协议授权开发，现在已转为使用GNU LGPL协议。字母d是daemon的缩写它取替并兼容传统的SysV init。事实上，CentOS和Debian，现在默认都是使用Systemd：

CentOS 7开始预设并使用Systemd
Ubuntu 15.04开始并预设使用Systemd

使用Systemd的优点：

按需启动进程，减少系统资源消耗
并行启动进程，提高系统启动速度

UnitSystemd引入了一个核心配置：Unit（单元配置）。事实上，Systemd管理的每个进程，都是一个Unit。相当于任务块。一个有12种模式：
Service unit：系统服务Target unit：多个Unit构成的一个组Device Unit：硬件设备Mount Unit：文件系统的挂载点Automount Unit：自动挂载点Path Unit：文件或路径Scope Unit：不是由 Systemd 启动的外部进程Slice Unit：进程组Snapshot Unit：Systemd 快照，可以切回某个快照Socket Unit：进程间通信的 socketSwap Unit：swap 文件Timer Unit：定时器
配置 Uinit 地址
&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;：推荐地址。
&#x2F;run&#x2F;systemd&#x2F;system&#x2F;：系统执行过程中所产生的服务脚本,这些脚本的优先级比上面的高。
&#x2F;etc&#x2F;systemd&#x2F;system&#x2F;：管理员根据主机系统的需求所建立的执行脚本，优先级比上面的高。

- Unit   - Description，服务的描述   - Documentation，文档介绍   - After，该服务要在什么服务启动之后启动，比如Mysql需要在network和syslog启动之后再启动- Install   - WantedBy，值是一个或多个Target，当前Unit激活时(enable)符号链接会放入/etc/systemd/system目录下面以Target名+.wants后缀构成的子目录中   - RequiredBy，它的值是一个或多个Target，当前Unit激活(enable)时，符号链接会放入/etc/systemd/system目录下面以Target名+.required后缀构成的子目录中   - Alias，当前Unit可用于启动的别名   - Also，当前Unit激活(enable)时，会被同时激活的其他Unit- Service   - Type，定义启动时的进程行为。它有以下几种值。   - Type=simple，默认值，执行ExecStart指定的命令，启动主进程   - Type=forking，以 fork 方式从父进程创建子进程，创建后父进程会立即退出   - Type=oneshot，一次性进程，Systemd 会等当前服务退出，再继续往下执行   - Type=dbus，当前服务通过D-Bus启动   - Type=notify，当前服务启动完毕，会通知Systemd，再继续往下执行   - Type=idle，若有其他任务执行完毕，当前服务才会运行   - ExecStart，启动当前服务的命令   - ExecStartPre，启动当前服务之前执行的命令   - ExecStartPost，启动当前服务之后执行的命令   - ExecReload，重启当前服务时执行的命令   - ExecStop，停止当前服务时执行的命令   - ExecStopPost，停止当其服务之后执行的命令   - RestartSec，自动重启当前服务间隔的秒数   - Restart，定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog   - TimeoutSec，定义 Systemd 停止当前服务之前等待的秒数   - Environment，指定环境变量

重载配置
systemctl daemon-reload

启动服务
systemctl start service_name

停止服务
systemctl stop service_name

systemctl设置开机自启
systemctl enable service_name

查看Unit单元是否设置了开机自启
systemctl is-enable service_name

systemctl取消开机自启
systemctl enable service_name

查看所有的单元服务
systemctl list-units

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title>tools</title>
    <url>/Linux/Linux/tools/</url>
    <content><![CDATA[

1. 通用
DBeaver：一款基于Java 开发，免费开源的通用数据库管理和开发工具。DBeaver适用于所有开发人员、SQL程序员、数据库管理员和分析人员等，它支持任何具有JDBC驱动程序的数据库，EE版本还支持非JDBC数据源（MongoDB，Cassandra，Redis，DynamoDB等）。
SysMonTask: 可视化的任务管理器。

2. 日志框架
spdlog：一个快速的 C++ 日志库，只包含头文件，兼容 C++11。
log4cxx：Java 社区著名的 Log4j 的 C++ 移植版，用于为 C++ 程序提供日志功能，以便开发者对目标程序进行调试和审计。
log4cplus：一个简单易用的 C++ 日志记录 API，它提供了对日志管理和配置的线程安全、灵活和任意粒度控制（也基于 Log4j）。
Log4cpp：一个 C++ 类库，可以灵活地记录到文件、syslog、IDSA 和其他目的地（也基于 Log4j）。
google-glog：一个 C++ 语言的应用级日志记录框架，提供了 C++ 风格的流操作和各种辅助宏。
Pantheios：一个类型安全、高效、泛型和可扩展性的 C++ 日志 API 库（号称 C++ 领域速度最快的日志库）。
POCO：还提供了一个 好的日志支持文档。
ACE：ACE 也有日志支持。
Boost.Log：设计的非常模块化，并且可扩展。
Easylogging++：轻量级高性能 C++ 日志库（只有一个头文件）。
G3log：一个开源、支持跨平台的异步 C++ 日志框架，支持自定义日志格式。基于 g2log 构建，提升了性能，支持自定义格式。
Plog：可移植、简单和可扩展的 C++ 日志库。

3. 内存泄漏检测工具
valgrindvalgrind.md 
mtrace
AddressSanitizer(ASan) : 该工具为 gcc 自带，4.8以上版本都可以使用，支持Linux、OS、Android等多种平台，不止可以检测内存泄漏，它其实是一个内存错误检测具，可以检测的问题有：内存泄漏、堆栈和全局内存越界访问、free后继续使用、局部内存被外层使用、Initialization order bugs。
VLD (Visual Leak Detector) 是一款开源检测内存泄露软件，Windows 下 visual studio 中非常好用的内存泄漏检测工具。

Magical Command
ncdu: 具有文本模式用户界面的磁盘使用情况分析器。安装 sudo apt install ncdu
mv: 终端下面的 NotePad++
Midnight Commander provides an internal text editor (mc -e,mcedit)

apt-get install mc
icdiff：分屏显示 diff
glances：更强大的 htop &#x2F; top 代替者
multitail：多重 tail
dstat：vmstat 代替者
ranger：内容浏览&#x2F;预览

References
https://skywind.me/blog/archives/3087

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tools</tag>
      </tags>
  </entry>
  <entry>
    <title>valgrind</title>
    <url>/Linux/Linux/valgrind/</url>
    <content><![CDATA[

1. 简介Valgrind 是 Linux 下进行内存泄露检测和性能分析的工具。
2. 用法
Valgrind包含下列工具

Memcheck：是一个内存错误检测器(detector)，检查程序中的内存问题，如泄漏、越界、非法指针等，让你的程序更正确。
Cachegrind：是一Cache和分支预测分析器(branch-prediction profiler)，分析CPU的cache命中率、丢失率，用于进行代码优化，让你的程序运行的更快。
Callgrind：是一个图形化调用生成Cache的分析器(profiler)，检测程序代码的运行时间和调用过程，以及分析程序性能。
Helgrind：是一个线程错误检测器(detector)，用于检查多线程程序的竞态条件。
DRD：是一个线程错误检测器(detector)，跟 Helgrind 工具是相似的，但是它是使用不用的分析技术去找到很多不同的问题。
Massif：是一个堆(heap)分析器(profiler)，分析程序中使用了多少堆内存等信息，让你的程序使用更少的内存。
DHAT(dynamic heap analysis tool)：是一个动态堆分析工具，让你理解内存块的生命周期(block lifetimes)，块的利用率(block utilisation)以及内存分布的效率(layout inefficiencies)。
BBV：是一个实验性的 SimPoint 基本的 vector 产生器(generator)。可以做电脑架构的研究和开发。
Lackey：是一个很小的 example tool，阐述了一些基本的指令。
Nulgrind：是Valgrind中最小的工具，不能分析(analysis)或 仪器测量(instrumentation)，只能用于测试。


Valgrind中使用不同的工具，则是通过命令：valgrand --tool=name 来指定调用， name 为工具的名称，当不指定tool参数时默认是 --tool=memcheck。



2.1. Valgrind 工具详解
Memcheck
Memcheck 是最常用的工具，用来检测程序中出现的内存问题，所有对内存的读写都会被检测到，一切对 malloc、free、new、delete 的调用都会被捕获，但是它也不能检测静态分配或 stack上 超出数组 read&#x2F;write 的范围(Memcheck cannot detect every memory error your program has. For example, it can&#39;t detect out-of-range reads or writes to arrays that are allocated statically or on the stack. But it should detect many errors that could crash your program (eg. cause a segmentation fault))。所以，它能检测以下问题：

Use of uninitialised memory：使用未初始化的内存。
Reading&#x2F;writing memory after it has been free ：读&#x2F;写释放后的内存块 。
Reading&#x2F;writing off the end of malloc blocks：读&#x2F;写超出 malloc 分配的内存块。
Reading&#x2F;writing inappropriate areas on the stack：栈中读写不适当的区域。
Memory leaks – where pointers to malloc blocks are lost forever：内存泄漏，指向一块内存的指针永远丢失。
Mismatched use of malloc&#x2F;new&#x2F;new [] vs free&#x2F;delete&#x2F;delete [] ：不正确的malloc&#x2F;free或new&#x2F;delete匹配。
Overlapping src and dst pointers in memcpy() and related functions)： memcpy() 相关函数中的 dst 和 src 指针重叠。


The stack trace tells you where the leaked memory was allocated. Memcheck cannot tell you why the memory leaked, unfortunately. 


这些问题往往是 C&#x2F;C++ 程序员最头疼的问题，Memcheck 能在这里帮上大忙。例如：
#include &lt;stdlib.h&gt;  #include &lt;malloc.h&gt;  #include &lt;string.h&gt;  void test()  &#123;      int *ptr = malloc(sizeof(int)*10);      ptr[10] = 7; // 内存越界      memcpy(ptr +1, ptr, 5); // 踩内存      free(ptr);       free(ptr);// 重复释放      int *p1;      *p1 = 1; // 非法指针  &#125;  int main(void)  &#123;      test();      return 0;  &#125;  



valgrind 的检测信息将内存泄漏分为如下几类：

definitely lost：确定产生内存泄漏
indirectly lost：间接产生内存泄漏
possibly lost：可能存在内存泄漏
still reachable：即使在程序结束时候，仍然有指针在指向该块内存，常见于全局变量

3. Options- --track-origins=yes 生成更多的信息，找到条件跳转或move 指令 问题的原始出处- --num-callers  让stack trace 范围更大

Clang-Tidy 和 CLazy 对你的代码进行静态检查
4. References
valgrind官方文档说明
Stack overflow解释：How to install valgrind good?
valgrind的介绍、安装和使用
自动生成Makefile
valgrind 内存泄漏分析 - 广漠飘羽 - 博客园

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>valgrind</tag>
      </tags>
  </entry>
  <entry>
    <title>GreekAlphabet</title>
    <url>/Markdown/Markdown/GreekAlphabet/</url>
    <content><![CDATA[
希腊字母表小写希腊字母$\alpha$  \alpha
$\beta$  \beta
$\gamma$  \gamma
$\delta$  \delta
$\epsilon$  \epsilon
$\zeta$  \zeta
$\eta$  \eta
$\theta$  \theta
$\iota$  \iota
$\kappa$ \kappa
$\lambda$  \lambda
$\mu$  \mu
$\nu$  \nu
$\xi$  \xi
$\omicron$  \omicro
$\pi$  \pi
$\rho$  \rho
$\sigma$  \sigma
$\tau$  \tau
$\upsilon$  \upsilon
$\phi$  \phi
$\chi$  \chi
$\psi$  \psi
$\omega$  \omega
大写希腊字母$\Alpha$  \Alpha
$\Beta$  \Beta
$\Gamma$  \Gamma
$\Delta$  \Delta
$\Epsilon$  \Epsilon
$\Zeta$  \Zeta
$\Eta$  \Eta
$\Theta$  \Theta
$\Iota$  \Iota
$\Kappa$ \Kappa
$\Lambda$  \Lambda
$\Mu$  \Mu
$\Nu$  \Nu
$\Xi$  \Xi
$\Omicron$  \Omicro
$\Pi$  \Pi
$\Rho$  \Rho
$\Sigma$  \Sigma
$\Tau$  \Tau
$\Upsilon$  \Upsilon
$\Phi$  \Phi
$\Chi$  \Chi
$\Psi$  \Psi
$\Omega$  \Omega

References
维基百科希腊字母表

]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>greekAlphabet</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter</title>
    <url>/Markdown/Markdown/Jupyter/</url>
    <content><![CDATA[

1. jupyter 基础1.1. 命令模式下的单元格操作
L: 显示代码的行号
m: 将单元格变为 markdown 类型，在 markdown 类型的单元格内可以编写文档
y: 将单元格变为代码类型，在代码类型的单元格中输入 Python 代码
d: 按两下 d 按键删除单元格（删除当前的 cell：dd）
z: 撤销最后删除单元格操作
a: 在当前单元格之上创建一个新的单元格
b: 在当前单元格之下创建一个新的单元格
x: 剪切当前单元格
c: 复制当前单元格
v: 在当前单元格之下粘贴剪切板中的单元格
shift+k: 将当前单元格上移
shift+j: 将当前单元格下移
shift+m: 与下面的单元合并
将当前的 cell 转化为具有一级标题的 maskdown：数字键 1
将当前的 cell 转化为具有二级标题的 maskdown：数字键 2
将当前的 cell 转化为具有三级标题的 maskdown：数字键 3

1.2. 编辑和运行
执行当前 cell，并自动跳到下一个 cell：Shift Enter
执行当前 cell，执行后不自动调转到下一个 cell：Ctrl-Enter  （Ctrl+Enter：结束编辑，对于代码单元将运行其中的代码，对于标题单元和 markdown 单元将格格式化显示）
当前 cell 进入编辑模式：Enter
退出当前 cell 的编辑模式：Esc
Alt+Enter：运行当前的代码并在下面插入新的单元
为一行或者多行添加&#x2F;取消注释：Crtl &#x2F;
撤销对某个 cell 的删除：z
浏览器的各个 Tab 之间切换：Crtl PgUp 和 Crtl PgDn
快速跳转到首个 cell：Crtl Home
快速跳转到最后一个 cell：Crtl End
在命令模式下按 Enter 键进入编辑模式即可查看本段文字的 Markdown 代码
编辑模式下单元使用绿色边框显示，在命令模式时按 Enter 即可进入编辑模式
在行内的数学公式使用单个 $ 括起
单独占一行的数学公式使用  $$括起

1.3. 操作运算核
如果进入了 Python 的死循环，可以在命令模式下按两下 i 按键终止循环。
如果 i 按键不能终止编译代码中的死循环，可以按两次** 0**（是零不是 o）按键重新启动运算核心，当前运行环境中的所有对象都将消失

注意：右上角图标从空心圈变为实心圈，表示运算核正在工作，无法执行新的代码。请按两下 i 按键终止循环，注意右上角的图标变回空心圈
2. jupyter notebook 命令2.1. 无序列表
1
2
3

2.2. 有序列表
ok
ok
ok

2.3. 链接的使用百度
2.4. 字体斜体
粗体
2.5. 图片的引用插入图片不需要其他按钮，你只需要使用  这样的语法即可

2.6. 引用
种豆南山下草盛豆苗稀

2.7. 代码引用需要引用代码时，如果引用的语句只有一段，不分行，可以用 &#96; 将语句包起来。如果引用的语句为多行，可以将 &#96;&#96;&#96; 置于这段代码的首行和末行。
print(work)
print(work)


2.8. Multicursor support（支持多光标）按住 Alt 进行点击和拖拽鼠标即可
3. 导入 python 代码3.1. 本地导入 python 代
%load+文件路径（文件的路径可以是相对地址也可以是绝对地址）

%load 蟒蛇图形绘制。py
# %load 蟒蛇图形绘制.py#蟒蛇图形绘制.pyimport turtleturtle.setup(650,350,200,200)        #窗体的绘制turtle.penup()                  #画笔控制函数turtle.fd(-250)turtle.pendown()turtle.pensize(25)turtle.pencolor(&quot;green&quot;)turtle.seth(-40)                #改变海龟（面对方向）的行进方向，但不行进for i in range(4):    turtle.circle(40,80)    turtle.circle(-40,80)turtle.circle(40,80/2)turtle.fd(40)turtle.circle(16,180)turtle.fd(40*2/3)turtle.done


3.2. 网络导入代码从网络中导入 python 代码，使用%load 网址   
4. jupyter 中运行 python 文件
%run + python 文件
直接在 cell 中输入：%run xxx.py 按 Ctrl+Enter 后，执行结果直接在这个 cell 的下面显示如下图所示
%run 温度转换.py %run 温度转换.py


！ + Python 文件
在 command 前面加入一个感叹号! 。 例如： ! 蟒蛇图形绘制.py ! 蟒蛇图形绘制.py



5. matplotlib 绘图当在程序中使用了 matplotlib 绘图，不能直接显示时，需要加%matplotlib inline
# %matplotlib inlineimport matplotlib.pylab as pltimport numpy as npx = np.arange(20)y = x**2plt.plot(x,y)
[&lt;matplotlib.lines.Line2D at 0x213fd214cc0&gt;]

6. magic 命令6.1. magic 命令用法
魔法命令都以 % 或者 %% 开头，以 % 开头的成为行命令，**%%** 开头的称为单元命令。行命令只对命令所在的行有效，而单元命令则必须出现在单元的第一行，对整个单元的代码进行处理。
在 Jupyter 中执行 %lsmagic 可以列举所有的魔法命令；
%magic 可以查看关于各个命令的说明，
在%命令之后添加 ? 可以查看该命令的详细说明（例如：%magic?）

6.2. 常用的魔术命令有
%quickref	显示 IPython 快速参考
%magic	显示所有魔术命令的详细文档
%debug	从最新的异常跟踪的底部进入交互式调试器
%pdb	在异常发生后自动进入调试器
%reset	删除 interactive 命名空间中的全部变量
%run script.py	执行 script.py
%prun statement	通过 cProfile 执行对 statement 的逐行性能分析
%time statement	测试 statement 的执行时间
%timeit statement	多次测试 statement 的执行时间并计算平均值
%who、%who_ls、%whos	显示 interactive 命名空间中定义的变量，信息级别&#x2F;冗余度可变
%xdel variable	删除 variable，并尝试清除其在 IPython 中的对象上的一切引用
!cmd	在系统 shell 执行 cmd
output&#x3D;!cmd args	执行 cmd 并赋值
%bookmark	使用 IPython 的目录书签系统
%cd direcrory	切换工作目录
%pwd	返回当前工作目录（字符串形式）
%env	返回当前系统变量（以字典形式）

%lsmagic
Available line magics:
%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode

Available cell magics:
%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile

Automagic is ON, % prefix IS NOT needed for line magics.

%magic

%magic?

%pwd

&#39;C:\\Users\\Jhon\\Desktop\\Python\\MachineLearning&#39;

7. 调试与异常7.1. 错误异常与代码调试
执行 %xmode Plain 可以设置为当异常发生时只展示简单的异常信息
执行 %xmode Verbose 来还原显示详细异常信息的模式
使用 %debug 进入调试模式，输入** quit 退出调试模，调试模式下，我们也可以通过输入 up **来对外层函数进行调试，查看其中的变量情况。
执行 %pdb on 可以设置为当异常发生时自动进入调试式 2

7.2. 使用 pdb 进行调试pdb 是 python 自带的一个包，为 python 程序提供了一种交互的源代码调试功能，主要特性包括设置断点、单步调试、进入函数调试、查看当前代码、查看栈片段、动态改变变量的值等
pdb 常用的调试命令



命令
解释



break 或 b
设置断点


continue 或 c
继续执行程序


list 或 l
查看当前行的代码段


step 或 s
进入函数


return 或 r
执行代码直到从当前函数返回


exit 或 q
中止并退出


next 或 n
执行下一行


pp
打印变量的值


help
帮助


8. 在线帮助和自动完成Notebook 支持显示函数和方法的文档和源代码，以及自动完成对象的属性。

输入代码时，按 [TAB] 键可以显示自动完成提示框。自动完成支持当前执行环境中已知的模块名、变量名、对象的属性名，以及文件和目录名
对于当前环境中已知的对象，可以在其后面添加问号 ? 查看相应的说明信息和文档，添加两个问号 ?? 可以查看对象对应的源程序。按 Ctrl+Enter 显示文档的内容
调用函数时，按 [shift+tab] 组合键可以显示函数的调用参数和说明文档，按 一次 组合键显示基本信息，两次 显示详细信息，三次 延时停留信息框，四次 则将信息显示在下方的滑动窗口中。

list?

get_ipython??

import numpy as npnp.add

9. Jupyter notebook 其它工具结合
IPython 与 Jupyter notebook 安装与配置，插件扩展，主题，PDF 输出
jupyter notebook 转化为 pdf

10. References
jupyter notebook 的安装与使用
来自 DataQuest 博客分享： Jupyter Notebook tips, tricks, and shortcuts 快捷键
Jupyter notebook 小技巧
MarkDown 参考学习：w3cshool
关于 jupyter notebook 编程的书籍 nbviewer
有趣的 notebook A gallery of interesting Jupyter Notebooks
如何优雅地使用 Jupyter
Python 代码调试技巧

]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title>LaTex</title>
    <url>/Markdown/Markdown/LaTex/</url>
    <content><![CDATA[

1. LaTex1.1. 插入公式LaTeX 公式有两种，一种是用在正文中的，一种是单独命令的。正文中的公式用$...$ 来定义，单独显示的用 $$...$$ 来定义，其中 ... 表示的是LaTeX 的公式命令。
例如：

定义$f(x) &#x3D; \sum_{i&#x3D;0}^{N}\int_{a}^{b} g(t,i) \text{ d}t$. (行内公式)


定义$f(x)$如下（行间公式）:$$f(x) &#x3D; \sum_{i&#x3D;0}^{N}\int_{a}^{b} g(t,i) \text{ d}t{6}\tag{1}$$

\iint \limits_{-\infty}^{+\infty}  $\Longrightarrow$  $\iint \limits_{-\infty}^{+\infty}$
\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}f(x,y) ,dx,dy $\Longrightarrow$ $\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}f(x,y) ,dx,dy$
\int_1^2 \int_3^4{x}dx $\Longrightarrow$  $\int_1^2 \int_3^4{x}dx$
\sqrt[3]{2}   $\Longrightarrow$ $\sqrt[3]{2}$
1.2. 上下标^表示上标，_表示下标，如果上（下）标内容多于一个字符就需要使用&#123;&#125;，注意不是( ), 因为( )经常是公式本身组成部分，为避免冲突，所以选用了&#123; &#125; 将其包起来
示例：$x^{y^z}&#x3D;(1+e^x)^{-2xy^w}$
希腊字母



命令
显示
命令
显示



\alpha
α
\beta
β


\gamma
γ
\delta
δ


\epsilon
ϵ
\zeta
ζ


\eta
η
\theta
θ


\iota
ι
\kappa
κ


\lambda
λ
\mu
μ


\xi
ξ
\nu
ν


\pi
π
\rho
ρ


\sigma
σ
\tau
τ


\upsilon
υ
\phi
ϕ


\chi
χ
\psi
ψ


\omega
ω
\Omega
$\omega$



如果使用大写的希腊字母，把命令中的首字母变成大写即可，例如 \Gamma 输出的是 $\Gamma$
如果使用斜体大写希腊字母，再在大写希腊字母的LaTeX命令前加上var，例如 $\Gamma$ 生成 $\varGamma$

例如：$$ \varGamma(x) &#x3D; \frac{\int_{\alpha}^{\beta} g(t)(x-t)^2\text{ d}t }{\phi(x)\sum_{i&#x3D;0}^{N-1} \omega_i} \tag{2}$$
1.3. 指定字体
{\rm text}如： 
使用罗马字体：text $&#123;\rm text&#125;$
其他的字体还有： \rm　　罗马体　　　　　　　\it　　意大利体 \bf　　黑体　　　　　　　　\cal 　花体 \sl　　倾斜体　　　　　　　\sf　　等线体 \mit 　数学斜体　　　　　　\tt　　打字机字体 \sc　　小体大写字母

1.4. 和号和积分号列出常用的和号和积分号



显示
命令



$\sum$
\sum


$\int$
\int


$\sum_{i&#x3D;1}^{N}$
\sum_{i&#x3D;1}^{N}


$\int_{a}^{b}$
$int_{a}^{b}


$\prod$
\prod


$\iint$
\iint


$\prod_{i&#x3D;1}^{N}$
\prod_{i&#x3D;1}^{N}


$\iint_{a}^{b}$
iint_{a}^{b}


$\bigcup$
\bigcup


$\bigcap$
\bigcap


$\bigcup_{i&#x3D;1}^{N}$
\bigcup_{i&#x3D;1}^{N}


$\bigcap_{i&#x3D;1}^{N}$
\bigcap_{i&#x3D;1}^{N}


$\pm$
\pm


$\times$
\times


$\div$
\div


$\mid$
\mid


$\cdot$
\cdot


$\circ$
\circ


$\ast$
\ast


$\bigodot$
\bigodot


$\bigotimes$
\bigotimes


$\bigoplus$
\bigoplus


$\leq$
\leq


$\geq$
\geq


$\neq$
\neq


$\approx$
\approx


$\equiv$
\equiv


$\sum$
\sum


$\prod$
\prod


$\coprod$
\coprod


1.5. 集合运算符


显示
命令



$\emptyset$
\emptyset


$\in$
\in


$\notin$
\notin


$\subset$
\subset


$\supset$
\supset


$\subseteq$
\subseteq


$\supseteq$
\supseteq


$\bigcap$
\bigcap


$\bigcup$
\bigcup


$\bigvee$
\bigvee


$\bigwedge$
\bigwedge


$\biguplus$
\biguplus


$\bigsqcup$
\bigsqcup


1.6. 对数运算符


显示
命令



$\log$
\log


$\lg$
\lg


$\ln$
\ln


1.7. 三角运算符


显示
命令



$\bot$
\bot


$\angle$
\angle


$30^\circ$
30^\circ


$\sin$
\sin


$\cos$
\cos


$\tan$
\tan


$\cot$
\cot


$\sec$
\sec


$\csc$
\csc


1.8. 微积分运算符


显示
命令



$\prime$
\prime


$\int$
\int


$\iint$
\iint


$\iiint$
\iiint


$\oint$
\oint


$\lim$
\lim


$\infty$
\infty


$\nabla$
\nabla


1.9. 逻辑运算符


显示
命令



$\because$
\because


$\therefore$
\therefore


$\forall$
\forall


$\exists$
\exists


$\not&#x3D;$
\not&#x3D;


$\not&gt;$
\not&gt;


$\not\subset$
\not\subset


1.10. 戴帽符号


显示
命令



$\hat{y}$
\hat{y}


$\check{y}$
\check{y}


$\breve{y}$
\breve{y}


1.11. 箭头符号


显示
命令



$\uparrow$
\uparrow


$\downarrow$
\downarrow


$\Uparrow$
\Uparrow


$\Downarrow$
\Downarrow


$\rightarrow$
\rightarrow


$\leftarrow$
\leftarrow


$\Rightarrow$
\Rightarrow


$\Leftarrow$
\Leftarrow


$\longrightarrow$
\longrightarrow


$\longleftarrow$
\longleftarrow


$\Longrightarrow$
\Longrightarrow


$\Longleftarrow$
\Longleftarrow


1.12. 连线符号


显示
命令



$\overline{a+b+c+d}$
\overline{a+b+c}


$\underline{a+b+c+d}$
\underline{a+b+c}


$\overbrace{a+\underbrace{b+c}_{1.0}+d}^{2.0}$
\overbrace{a+\underbrace{b+c}_{1.0}+d}^{2.0}


2. References
用Python学《微积分B》

]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>laTex</tag>
      </tags>
  </entry>
  <entry>
    <title>TyporaMarkdown</title>
    <url>/Markdown/Markdown/TyporaMarkdown/</url>
    <content><![CDATA[

1. Typora使用手册1.1. Markdown 语法
段落：Ctrl + 0
一级到六级标题：Ctrl + 1 到 Ctrl + 6
加粗： Ctrl/Cmd + B
测试


斜体：Ctrl + I 
测试


下划线：Ctrl + U 
测试


删除线：Shift + Alt + 5
~~ 测试 ~~


插入链接：Ctrl/Cmd + K
支持超链接 ：百度
本地链接：本地
文章内锚点，制作文章目录：第一章


行内代码：Ctrl/Cmd + Shift + `hello word!
代码块： Ctrl/Cmd + Shift + K#include &lt;stdio.h&gt;int main() &#123;    return 0;&#125;
插入图片： Ctrl/Cmd + Shift + I  
插入表格：Ctrl + T
表格支持拖拽移动、网页端表格复制转换


2
5




1
4



3
6






无序列表： Ctrl/Cmd + Shift + ]
有序列表：Ctrl/Cmd + Shift + [
任务列表。任务列表使您可以创建带有复选框的项目列表。在支持任务列表的Markdown应用程序中，复选框将显示在内容旁边。要创建任务列表，请在任务列表项之前添加破折号 - 和方括号 [ ]，并在 [ ] 前面加上空格。要选择一个复选框，请在方括号 [x] 之间添加 x 。
 001
 002
 003


引用：Ctrl + Shift + Q
  少年易老学难成，一寸光阴不可轻。
  未觉池塘春草梦，阶前梧叶已秋声 。
  ​                         —朱熹《劝学诗》


LeTex 公式块，行内公式：Shift + Ctrl + M$$  e^{i\pi} + 1 &#x3D; 0$$
内联公式：$ e^{i\pi} + 1 &#x3D; 0 $
文献引用Linux，全称GNU&#x2F;Linux，是一种免费使用和自由传播的类UNIX操作系统&lt;span class&#x3D;”hint–top hint–error hint–medium hint–rounded hint–bounce” aria-label&#x3D;”Linux防火墙脚本化管理研究．万方．2019[引用日期2019-08-04]
上标：X^3^
下标：H2O
高亮：&#x3D;&#x3D;测试&#x3D;&#x3D;
注释：&lt;!--这是一段注释--&gt;
分隔线（三条短横线）：—
Emoji 图标。表情符号短代码，以冒号开头和结尾，并包含表情符号的名称。
:arrow_backward:
:aries:
:closed_book:
:fork_and_knife:
:joy:


目录生成：[TOC]
流程图``````sequence">[1]。

1.2. 通用快捷键
撤销： Ctrl/Cmd + Z
切换原文和语法：Ctrl/Cmd + /
返回Typora顶部 ：Ctrl + Home
返回Typora底部 ：Ctrl + End
选中某句话 ：Ctrl + L
选中某个单词 ：Ctrl + D
搜索：Ctrl + F 
选中相同格式的文字：Ctrl + E
搜索并替换： Ctrl + H

1.3. 表格 
  背景色 浅紫色





表头1
表头2


row 1, cell 1
row 1, cell 2


row 2, cell 1
row 2, cell 2



References
Markdown 教程：https://markdown.com.cn/intro.html
在线生成表格代码：https://www.tablesgenerator.com

1.Linux防火墙脚本化管理研究．万方．2019[引用日期2019-08-04]
- 上标：X^3^
- 下标：H~2~O
- 高亮：==测试==
- 注释：&lt;!--这是一段注释--&gt;
- 分隔线（三条短横线）：---
- Emoji 图标。表情符号短代码，以冒号开头和结尾，并包含表情符号的名称。
- :arrow_backward:
- :aries:
- :closed_book:
- :fork_and_knife:
- :joy:
- 目录生成：[TOC]
- 流程图
&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sequence ↩]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>typoraMarkdown</tag>
      </tags>
  </entry>
  <entry>
    <title>ConnectPool</title>
    <url>/MySQL/MySQL/ConnectPool/</url>
    <content><![CDATA[连接池为什么要连接池？ 一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的性能低下。使用数据库连接池可以节约资源，程序更加高效。
数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并将这些连接组成一个连接池(简单说：在一个“池”里放了好多半成品的数据库连接对象)，由应用程序动态地对池中的连接进行申请、使用和释放。对于多于连接池中连接数的并发请求，应该在请求队列中排队等待。并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。连接池技术尽可能多地重用了消耗内存地资源，大大节省了内存，提高了服务器地服务效率，能够支持更多的客户服务。通过使用连接池，将大大提高程序运行效率，同时，我们可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。
原理连接池基本的思想：在系统初始化的时候，将数据库连接作为对象存储在内存中，当用户需要访问数据库时，并非建立一个新的连接，而是从连接池中取出一个已建立的空闲连接对象。使用完毕后，用户也并非将连接关闭，而是将连接放回连接池中，以供下一个请求访问使用。而连接的建立、断开都由连接池自身来管理。同时，还可以通过设置连接池的参数来控制连接池中的初始连接数、连接的上下限数以及每个连接的最大使用次数、最大空闲时间等等。也可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。
通俗的来讲：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去
数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数制约。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。
1. 最小连接数
连接池事先会和MySQL服务器创建一定数量的连接数（min_size），当应用发起MySQL访问时，不用再创建和MySQL服务器新的连接，直接从连接池中获取一个可用的连接就可以，使用完成后，并不去释放 connection，而是把当前 connection再归还到连接池当中 。
2. 最大连接数
 当并发访问MySQL服务器的请求增多时，初始连接量已经不够使用了，此时会根据新的请求数量去创建更多的连接给应用去使用，但是新创建的连接数量上限是max_size，不能无限制的创建连接。因为每个连接都会占用一个socket资源，一般连接池和服务器程序是部署在一台主机上的，如果连接池占用过多的socket资源，那么服务器就不能接收更多的客户端请求了。当这些连接使用完成后，再次归还到连接池当中来维护。
3.最大空闲时间
当访问MySQL的并发请求多了以后，连接池里面的连接数量会动态增加，上限是 max_size个，当这些连接用完再次归还到连接池当中。如果在指定的 max_idle_time 里面，这些新增加的连接都没有被再次使用过，那么新增加的这些连接资源就要被回收，只需要保持初始连接量 min_size 个连接就可以了。
4.连接超时时间
当MySQL的并发请求量过大，连接池中的连接数量已经到达max_size了，而此时没有空闲的连接可供使用，那么此时应用无法从连接池获取连接，它通过阻塞的方式等待获取连接的时间如果超过connection_timeout时间，那么连接失败，无法访问数据库。
5.超时重试连接次数
连接池的设计连接池在程序初始化时，创建最小数量的的连接数，等待客户端去连接服务器。当创建的连接数不够时，则需要再创建连接数，但不能超过规定的最大连接数。若创建的连接数超过最小连接数但小于最大连接数时，连接池中的连接存在有未全部使用的情况，有空闲的连接（没有与服务器发生连接），需要动态的去把未使用的连接释放掉，可采用超时的机制。即计算从连接创建到未使用整个期间的时间，超过规定的最大空闲时间时，释放连接，达到让连接池中的数量维持一定的数目，以节省资源。
连接池中已创建的连接数：

已与服务端建立连接的
空闲未建立连接的

要设计一个数据库连接池，我们需要实现以下几个功能点：

连接池只需要一个实例，所以连接池类应该是一个单例模式的类

所有的数据库连接应该维护到一个安全的队列中

使用队列的目的是方便连接的添加和删除
所谓的安全指的是线程安全，也就是说需要使用互斥锁来保护队列数据的读写。


当有数据库访问请求时，直接从连接池的容器中得到一个连接，这里出现三种情况：
(a)当容器中的还有连接时，则返回给数据库访问请求者一个连接
(b)当容器中没有连接时，并且当前建立的连接数没有达到系统定义的最大连接数，则创建一个新的数据库连接。
(c)当容器中的没有连接并且当前建立的连接数达到系统定义的最大连接数，则当前访问数据库请求就要等待其他访问请求释放连接，阻塞等待一定时长然后再重试。

如果队列中没有多余的可用连接，需要动态的创建新连接

如果队列中空闲的连接太多，需要动态的销毁一部分

数据库操作完毕，需要将连接放回到连接池的容器中。

当服务停止时，需要先释放数据库连接池中的所有数据库连接，然后再释放数据库连接池对象。


细节分析
数据库连接的存储：可用使用 STL 中的队列 queue。在并发情况下，STL的queue不是线程安全的，可使用互斥锁实现线程安全。

连接池连接的动态创建：这部分工作需要交给一个单独的线程来处理

连接池连接的动态销毁：这部分工作需要交给一个单独的线程来处理

数据库连接的添加和归还：这是一个典型的生产者和消费者模型。考虑并发情况，使用互斥锁和条件变量实现线程安全和同步。
 当用户请求数据库连接时，首先查看连接池中是否有空闲连接，如果存在空闲连接，则将连接分配给用户使用；如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，如果没达到就重新创建一个连接给请求的用户；如果达到就按设定的最大等待时间进行等待，如果超出最大等待时间，则抛出异常给用户。

消费者：需要访问数据库的线程，数据库连接被取出（消费）
生产者：专门负责创建数据库连接的线程
处理生产者和消费者模型需要使用条件变量阻塞线程


连接池的默认连接数量：连接池中提供的可用连接的最小数量

如果不够就动态创建
如果太多就动态销毁


连接池的最大连接数量：能够创建的最大有效数据库连接上限。

最大空闲时间：创建出的数据库连接在指定时间长度内一直未被使用，此时就需要销毁该连接。

连接超时：消费者线程无法获取到可用连接是，阻塞等待的时间长度


讨论连接池中数据库连接存放的方式可以用队列存放，先放进来的先取出来，也可以用栈来存放，先放进来的后取出来，具体用那种方式，要看需要实现的功能。
根据要实现的第三种功能得出，我们需要在存放数据库连接的时候记录连接的上一次使用时间，如果上一次使用时间超过一定时间，则关闭此连接。
如果我们使用队列来存储连接，我们会发现每次新放入的连接都放到了队尾，每次取出来的都是队列前面的最老的数据库连接，所以在不断的存取的过程中，队列里面每一个连接的上一次使用时间都会不断刷新。

一个使用队列的连接池如果有十个连接，每隔10秒取出一个连接使用并放回，则连接池的连接队列会不断从头部取出来，刷新使用时间，放回队列尾部，这样队列每一个连接的上次使用时间都不会超过当前10秒，队列里面所有连接都不能因为超时被释放。

所以我们应当使用栈来存放数据库连接，每次都从上面取出连接，使用完也放回上面。假如使用的频率特别低会导致栈底部的连接长时间未使用，则可以直接释放以节省资源。
连接容器中超时连接的释放有两种方式：

在往容器中添加或者取出连接的时候释放。
单独开一个线程不断轮询所有连接释放超时的连接。

我们采用的是第一种方式，在往容器中添加连接的时候释放超时连接，有以下三个原因：

单独开一个线程需要耗费更多的资源，也更加难以管理
使用栈来存储连接的话，实际上在不断的存取过程中，栈一直保持着从顶部到底部上次使用时间越来越长的规律，即栈中连接的使用时间是有序的。所以每次释放的时候，只需要从底部向上开始扫描，遇到超时的连接则进行释放，遇上非超时的连接则停止扫描，如果栈中连接均未超时，则只需要扫描最后一个就可以了。
使用数据库连接的时候，取出来使用应当比放回去的优先级更高，所以释放超时连接的操作应当放在放回连接池中的部分。
这种方法最坏的情况为：程序开始运行时打开了若干个数据库连接，放置回连接池中，后面则不再进行任何数据库操作（即不再往连接池中取出或存放连接）。这样会导致之前建立的连接一直存放在连接池中，得不到超时释放。但是这种情况出现的几率较少，严格来说这种情况可以通过程序编写避免，所以为了简单和稳定性可以忽略这种情况。

注意点
并发问题

事务处理

连接池的分配与释放
连接池的分配与释放，对系统的性能有很大的影响。合理的分配与释放，可以提高连接的复用度，从而降低建立新连接的开销，同时还可以加快用户的访问速度。 

设置多少连接，性能最佳？
最小连接数是系统启动时连接池所创建的连接数。如果创建过多，则系统启动就慢，但创建后系统的响应速度会很快；如果创建过少，则系统启动的很快，响应起来却慢。


Reference
C++实现MySQL数据库连接池
基于 C++11 的数据库连接池
MySQL API 使用详解
自己动手实现数据库连接池：https://blog.csdn.net/deginch/article/details/70059409
C&#x2F;C++数据库连接池项目：https://blog.51cto.com/BugMaker/5588483
MySQL Connection Handling and Scaling

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mySQL</tag>
        <tag>connectPool</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL</title>
    <url>/MySQL/MySQL/MySQL/</url>
    <content><![CDATA[

1. MySQL 介绍1.1. RDBMS（关系型数据库）一个关系型数据库由一个或数个表格组成。

冗余：存储两倍数据，冗余降低了性能，但提高了数据的安全性
主键：主键是唯一的。一个数据表中只能包含一个主键。使用主键来查询数据
外键：用于关联两个表。
复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引
索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构
参照完整性: 要求关系中不允许引用不存在的实体。目的是保证数据的一致性
DDL(Data Definition Languages) 语句：数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 create、drop、alter 等。
DML(Data Manipulation Language) 语句：数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字主要包括 insert、delete、udpate 和 select 等。
DCL(Data Control Language) 语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 grant、revoke 等。

1.2. 语句规范
关键字与函数名称全部大写
数据库名、表名称、字段名称全部小写
SQL 语句默认是以 分号 结尾，SQL 不区分大小写
每个表保存一个实体信息

1.3. 安装操作
windows 下以管理员身份运行 cmd，进入到 MySQL 的 bin 目录，执行初始化命令：mysqld --initialize --user=mysql --console
执行命令进行 MySQL 服务安装：mysqld –install mysql
Windows 启动 MySQL 服务：net start mysql
Windows 停止 mysql 服务：net stop mysql
卸载 MySQL 服务：sc delete MySQL/mysqld -remove
显示当前日期：select now();
清除命令行 buffer： mysql \c
记录能够按照字段竖着排列:  \G
改变 MySQL 的分隔符 (默认为 ;)：delimiter 任意的字符 

1.4. 用户管理1.5. 密码与登录
登录 MySQL 客户端
mysql -u root -p

改密码：MySQL 提供了各种可用于更改用户密码的语句，包括 UPDATE，SET PASSWORD 和 GRANT USAGE 语句。
第一种
ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;新密码&#x27;;

第二种
SET PASSWORD FOR &#x27;root&#x27;@&#x27;localhost&#x27; = PASSWORD(&#x27;新密码&#x27;);

8.0 以上版本修改密码使用:
  ALTER user &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;你的密码&#x27;;  // 例子  mysql&gt; ALTER user &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;123456&#x27;;mysql&gt; FLUSH PRIVILEGES;

1.6. 权限管理创建新用户
create user &#x27;username&#x27;@&#x27;%&#x27; identified by &#x27;你的密码&#x27;;

给指定的用户授予权限
GRANT ALL PRIVILEGES ON your_database.your_table TO &#x27;username&#x27;@&#x27;host&#x27; identified by &quot;password&quot;;权限类型- all privileges：所有权限。- select：读取权限。- delete：删除权限。- update：更新权限。- create：创建权限。- drop：删除数据库、数据表权限。// your_database 为 * 时，表示用户拥有所有库访问的权限// your_table 为 * 时，表示用户拥有某个库的所有表权限或者所有库的所有表权限// username@host表示授予的用户以及允许该用户登录的IP地址。其中Host有以下几种类型：- localhost：只允许该用户在本地登录，不能远程登录。- %：允许在除本机之外的任何一台机器远程登录。- 192.168.52.32：具体的IP表示只允许该用户从特定IP登录。

刷新权限
flush privileges;
查看用户拥有的权限
show grants for &#x27;username&#x27;;

取消用户权限
// 取消用户username对数据库your_database的所有权限REVOKE ALL PRIVILEGES ON your_database.* FROM &#x27;username&#x27;@&#x27;localhost&#x27;;

查看数据库中存在的用户
SELECT DISTINCT CONCAT(&#x27;User:&#x27;&#x27;&#x27;,user,&#x27;&#x27;&#x27;@&#x27;&#x27;&#x27;,host,&#x27;&#x27;&#x27;;&#x27;) AS query FROM mysql.user;

查看数据的端口
show global variables like &#x27;port&#x27;;

显示当前用户
select user();

显示当前服务器版本
select version();

常用命令

创建用户并授予指定数据库全部权限：适用于Web应用创建MySQL用户
// 创建了用户zhangsan，并将数据库zhangsanDB的所有权限授予zhangsan。create user zhangsan identified by &#x27;zhangsan&#x27;;grant all privileges on zhangsanDb.* to zhangsan@&#x27;%&#x27; identified by &#x27;zhangsan&#x27;;flush  privileges;

使zhangsan可以从本机登录，那么可以多赋予localhost权限：
grant all privileges on zhangsanDb.* to zhangsan@&#x27;localhost&#x27; identified by &#x27;zhangsan&#x27;;

1.7. MySQL 配置文件
数据文件

数据库文件：Linux 下默认路径：/var/lib/mysql


.frm 文件：存放表结构
.myd 文件：存放表数据
.myi 文件：存放表索引
innodb 引擎下 .ibd 文件存放索引和表数据；MyISAM 引擎下索引和数据的存放是分开的，在不同的文件夹中。


二进制日志：log-bin，用于主重复制。

错误日志：log-error，默认是关闭的，记录严重的警告和错误信息，每次启动和关闭的详细信息等。

查询日志：log，默认关闭，记录查询的 sql 语句，如果开启会减低 mysql 的整体性能，因为记录日志也是需要消耗系统资源的。


1.8. MySQL 分层结构
连接层
服务层
引擎层
存储层

1.9. MySQL 部件
Connectors：指的是不同语言中与 SQL 的交互。
Management Serveices &amp; Utilities： 系统管理和控制工具
Connection Pool：连接池
管理缓冲用户连接，线程处理等需要缓存的需求。负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。
每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。而连接线程的主要工作就是负责 MySQL Server 与客户端的通信。接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等。


SQL Interface：SQL 接口。接受用户的 SQL 命令，并且返回用户需要查询的结果。比如 select from 就是调用 SQL Interface。
Parser：解析器
QL 命令传递到解析器的时候会被解析器验证和解析。解析器是由 Lex 和 YACC 实现的，是一个很长的脚本。
在 MySQL 中我们习惯将所有 Client 端发送给 Server 端的命令都称为 Query，在 MySQL Server 里面，连接线程接收到客户端的一个 Query 后，会直接将该 Query 传递给专门负责将各种 Query 进行分类然后转发给各个对应的处理模块。
解析器的主要功能：
将 SQL 语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后 SQL 语句的传递和处理就是基于这个结构的。
如果在分解构成中遇到错误，那么就说明这个 sql 语句是不合理的




Optimizer：查询优化器
Cache 和 Buffer：查询缓存
存储引擎接口

2. SQL 语句2.1. 数值
TINYIN：1 字节    范围：-128~127
SMALLINT: 2 字节  范围：-32768~32767
MEDIUMINT: 3 字节
BIGINT: 8 字节
INT: 4 字节
int(M): M 表示宽度， 常与 zerofill 连用

显示宽度，如果某个数不够定义字段时设置的位数，则前面以 0 补填，zerofill 属性修改。例如：int(5)   插入一个数’123’，补填后为’00123’




浮点数
FLOAT: 4 字节
DOUBLE: 8 字节
定点数：用 decimal 表示。



2.2. 日期和时间
DATE(3 字节)；表示：日期值  YYYY-MM-DD

TIME(3 字节)；表示：时间值或持续时间  HH:MM:SS

YEAR(1 字节)；表示：年份值  YYYY

DATETIME: 8 字节；表示：混合日期和时间值  YYYY-MM-DD HH:MM:SS；要记录年月日时分秒，并且记录的年份比较久远，那么最好使用 DATETIME。

TIMESTAMP：记录的日期需要让不同时区的用户使用，那么最好使用 TIMESTAMP，因为日期类型中只有它能够和实际时区相对应。

需要经常插入或者更新日期为当前系统时间，则通常使用 TIMESTAMP 来表示。TIMESTAMP 值返回后显示为 “YYYY-MM-DD HH:MM:SS” 格式的字符串，显示宽度固定为 19 个字符。如果想要获得数字值，应在 TIMESTAMP 列添加 + 0。



2.3. 字符串
CHAR: 固定长度的字符类型，范围：0-255

VARCHAR: 可变长度的字符类型，范围：0-65535

TINYBLOB: 0-255  不超过 255 个字符的二进制字符串

TEXT: 存储更大的文本文件， TEXT 只能保存字符数据。

BLOB: 也是存储更大的文本文件，BLOB 能用来保存二进制数据，比如照片等。
BLOB 和 TEXT 值会引起一些性能问题，特别是在执行了大量的删除操作时。删除操作会在数据表中留下很大的 “空洞”，以后填入这些“空洞” 的记录在插入的性能上会有影响。为了提高性能，建议定期使用 OPTIMIZE TABLE 功能对这类表进行碎片整理，避免因为 “空洞” 导致性能问题。


MySQL 5.0 以上的版本：1、一个汉字占多少长度与编码有关：2、UTF－8：一个汉字＝3 个字节; 3、GBK：一个汉字＝2 个字节
CHAR 是固定长度的，所以它的处理速度比 VARCHAR 快得多，但是其缺点是浪费存储空间，程序需要对行尾空格进行处理，所以对于那些长度变化不大并且对查询速度有较高要求的数据可以考虑使用 CHAR 类型来存储。在 MySQL 中，不同的存储引擎对 CHAR 和 VARCHAR 的使用原则是不同的。
2.4. SHOW在 MySQL 中，SHOW 命令是用于查看数据库对象和系统信息的命令，并不是针对用户级别的。SHOW 命令用于查看数据库服务器的各种信息，例如数据库列表、表信息、列信息、用户权限、服务器状态等。
以下是一些常用的 SHOW 命令及其用途：

SHOW DATABASES;：显示 MySQL 数据库管理系统的所有数据库列表。
SHOW TABLES;：显示当前数据库中所有表的列表。
SHOW COLUMNS FROM table_name;：显示指定表的所有列信息。包括数据表的属性，属性类型，主键信息 ，是否为 NULL，默认值等其他信息，即查看表的结构。
SHOW INDEX FROM 数据表 :  显示数据表的详细索引信息，包括 PRIMARY KEY（主键）
SHOW GRANTS FOR user_name@host_name;：显示指定用户的权限信息。
SHOW STATUS;：显示当前服务器状态信息。
SHOW VARIABLES;：显示 MySQL 服务器的各种配置变量。

2.5. USEUSE 数据库名 : 选择要操作的 Mysql 数据库，使用该命令后所有 Mysql 命令都只针对该数据库操作。
2.6. 数据库操作
三种方式查看当前数据库
// 第 1 种select database();// 第 1 种status;// 第 1 种select tables;

显示当前时间、用户名、数据库版本: select now(), user(), version();

创建库
create database[if not exists] 数据库名 数据库选项;

数据库选项：

CHARACTER SET charset_name
COLLATE collation_name


查看已有库
show databases[like &#x27;pattern&#x27;];

查看当前库信息
show create database 数据库名;

修改库的选项信息
alter database 库名 选项信息;

删除该数据库相关的目录及其目录内容
drop database[if exists] 数据库名;

2.7. 数据表操作2.7.1. 创建数据表 (create)
创建数据表
CREATE TABLE [temporary] [IF NOT EXISTS] table_name(column_name data_type, ...);


table_name 可以为 [库名]. 表名 
每个字段必须有数据类型
字段的定义：
字段名
数据类型： [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT &#39;string&#39;]




最后一个字段后不能有逗号
temporary 为临时表，会话结束时表自动消失



2.7.2. 查看数据表 (show)
查看某个数据库中所有的表
SHOW TABLES [FROM db_name]

查看数据表结构，有四种方式。
// 第 1 种SHOW COLUMNS FROM tab_nmae// 第 2 种DESC tab_name// 第 3 种DESCRIBE tab_name// 第 3 种EXPLAIN tab_name

查看表详细信息
SHOW CREATE TABLE 表名

获取表信息
SHOW TABLE STATUS [FROM db_name] [LIKE &#x27;pattern&#x27;]

查看记录（数据表内容）
SELECT expr, ... FROM tabl_name

2.7.3. 删除数据表 (drop)
删除数据表
DROP TABLE table_name;

清空数据表
TRUNCATE [TABLE] tab_name;

复制表结构
CREATE TABLE 新表名称 LIKE 要复制的表名;

复制表结构和数据
CREATE TABLE 新表名称 [AS] SELECT * FROM 要复制的表名;

检查表是否有错误
CHECK TABLE tbl_name [, tbl_name] ... [option] ...

优化表
OPTIMIZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...

修复表
REPAIR [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ... [QUICK] [EXTENDED] [USE_FRM];

分析表
ANALYZE [LOCAL | NO_WRITE_TO_BINLOG] TABLE tbl_name [, tbl_name] ...

2.7.4. 统计数据表
查询数据采用 SELECT 命令
// 查询数据表中不重复的行SELECT DISTINCT col_name FROM tab_name;

// 从行 5 开始取 4 行SELECT col_name FROM tab_name LIMIT 5, 4;

统计某个数据库中有多少张表
select count(*) TABLES, table_schema FROM information_schema.TABLES where table_schema = &#x27;数据库名&#x27; GROUP BY table_schema;

2.7.5. 修改数表 (alter)
修改数据表

对表进行重命名
RENAME TABLE 原表名 TO 新表名// 可将表移动到另一个数据库）RENAME TABLE 原表名 TO 库名. 表名
尽量少去更改表和列的名称，在某些情况下可能导致一些视图不能使用

修改表的字段结构：ALTER TABLE 表名 操作名

添加单列
ALTER TABLE tab_name ADD [COLUMN] column_name column_definition[FIRST | AFTER col_name];

添加多列 ALTER TABLE tab_name ADD [COLUMN] (col_name col_definition, ...) 不能指定位置关系，只能在列的最下方

删除列
ALTER TABLE tab_name DROP [COLUMN] col_name_1,DROP [COLUMN] col_name_2;


增加主键
ALTER TABLE tab_name ADD [CONSRTAINT [symbol]] PRIMARY KEY [index_type](index_col_name);

删除主键约束 (删除主键前需删除其 AUTO_INCREMENT 属性): ALTER TABLE tab_name DROP PRIMARY KEY

创建唯一索引: ALTER TABLE tab_name ADD UNIQUE [索引名] (字段名)

删除唯一索引: ALTER TABLE tab_name DROP &#123;UNIQUE | KEY&#125; index_name

创建普通索引: ALTER TABLE tab_name ADD INDEX [索引名] (字段名) 

删除索引: ALTER TABLE tab_name DROP INDEX 索引名 

添加外键约束 ALTER TABLE tab_name ADD [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name, ...) reference_definition

例如：ALTER TABLE county ADD FOREIGN KEY(pid) REFERENCES provinces(id); pid 为子键，id 为父键




删除外键约束
  ALTER TABLE tab_name DROP FOREIGN KEY 约束名称;




添加和删除默认约束
ALTER TABLE tab_name ALTER [COLUMN] col_name &#123;SET DEFAULT 设置的值 | DROP DEFAULT&#125;;

修改列属性和参数
ALTER TABLE tab_name MODIFY [COLUMN] col_name column_definition [FIRST | AFTER col_name];

改变列的位置和数据类型，数据类型的改变会导致数据的丢失。

对字段属性进行修改，不能修改字段名 (所有原有属性也需写上)。
对字段名修改
ALTER TABLE tab_name CHANGE[COLUMN] 原字段名 新字段名 新字段属性 新参数;

2.8. 数据操作2.8.1. 插入数据 (insert)
单条插入数据
INSERT INTO table_name (field1, field2,...fieldN)    VALUES (value1, value2,...valueN);

如果省略字段列表，要插入数据的值与字段顺序一致，不能任意调整位置

可同时插入多条数据记录
INSERT INTO table_name (field1, field2,...fieldN)    VALUES    (value1, value2,...valueN),    (value1, value2,...valueN),    (value1, value2,...valueN);

   多条数据的插入，节省了网络开销、提高了插入效率


2.8.2. 更新表数据 (update)
单表更新记录
UPDATE tab_name SET 字段名 = 新值 1 [, 字段名 = 新值 N]... WHERE [where_condition];


若省略 WHERE 语句，表里面的内容都要更新
组成
列名和它们的新值
要更新的表
确定要更新行的过滤条件




清空某列的数据值
update tab_name set 字段名 = null where 执行的条件;

多表更新:。更新表 emp_1 与表 emp_2 的 deptno 列相等的值，使表 emp_1 的 sal 列的值为 emp_1.sal * emp_2.deptno，表 emp_2 列 deptname 的值为 emp_1.name
update emp_1, emp_2 set emp_1.sal = emp_1.sal * emp_2.deptno, emp_2.deptname = emp_1.name where emp_1.deptno=emp_2.deptno;


常用于根据一个表的字段来动态的更新另外一个表的字段属性



2.8.3. 删除表数据 (delete)
删除单表数据 (对行操作): DELETE FROM tab_name WHERE 删除条件 

多行 (删除 age&#x3D;-127 和 age&#x3D;127 的两行)：delete from info where age in (-128, 127);


删除多表数据 (对行操作): DELETE FROM tab1_name, tab2_name, ... tabn_name WHERE 删除条件 

删除原来的表并重新创建一个表，而不是逐行删除表中的数据: TRUNCATE

删除表信息的方式有两种

truncate table table_name;

delete * from table_name;

注 : truncate 操作中的 table 可以省略，delete 操作中的 * 可以省略




truncate、delete 清空表数据的区别

truncate 是整体删除 (速度较快)，delete 是逐条删除 (速度较慢)
truncate 不写服务器 log，delete 写服务器 log，也就是 truncate 效率比 delete 高的原因
truncate 不激活 trigger (触发器)，但是会重置 Identity (标识列、自增字段)，相当于自增列会被置为初始值，又重新从 1 开始记录，而不是接着原来的 ID 数。而 delete 删除以后，identity 依旧是接着被删除的最近的那一条记录 ID 加 1 后进行记录。如果只需删除表中的部分记录，只能使用 DELETE 语句配合 where 条件



2.8.4. 查询 (检索) 表数据(select)
查看表中所有数据: SELECT * FROM tab_name WHERE [CONDITION]

去掉重复数据显示使用关键字 distinct
SELECT DISTINCT (co_name1, col_name2, ..., col_nameN) FROM tab_name WHERE [CONDITION]

where 语句对数据表中的数据进行条件筛选，能与运算符组合后进行高级筛选行

在聚合前就对记录进行过滤筛选
采用 AND、 OR 关键字; 注意：在计算机中 AND 的优先级高于 OR 运算
关键字 IN: 对指定范围的内容进行匹配，与 OR 等效；
关键字 NOT: 对 IN 、BETWEEN 和 EXISTS 子句取反
like , not like (‘%’匹配任何字符出现任意次数,’_’匹配任意单个字符) SELECT col_name FROM tab_name WHERE tab_name LIKE &#39;char%&#39; 
检查是否为空值 (is null 或 is not null): SELECT col_name1, col_name2, ..., col_nameN FROM tab_name WHERE [CONDITION] IS NULL


分组 (group by)：表示要进行分类聚合的字段，通常与聚合函数一起使用

分组列中具有 NULL 值，则 NULL 将作为一个分组返回。如果列中有多行 NULL 值，它们将分为一组。
GROUP BY 子句必须出现在 WHERE 子句之后，ORDER BY 子句之前。
GROUP BY 子句可以包含任意数目的列
WITH ROLLUP: 是否对分类聚合后的结果进行再汇总
聚合函数：
AVG(): 求某列的平均值；忽略了列值为 NULL 的行
COUNT(): 返回某列的行数
COUNT(*)：对表中行的数目进行计数，不管表列中包含的是空值（NULL）还是非空值
COUNT(column)：对指定列并有值的行进行计数，得到行的总数，忽略 NULL 值。


MAX(): 求某列的最大值
MIN(): 求某列的最小值
SUN(): 对某列值之和 SELECT SUN(column) FROM tab_name;




 注意：select 选择的列 (a,b,c) 必须在 group by 分组的列名 (a, b, c, d, e) 中，否则会报错。但是 select 中可以包含聚合函数和别名


HAVING: 对聚合分类后的  结果集  合再进行条件的筛选，过滤分组

与 where 功能、用法相同，执行时机不同。
where 在开始时执行检测数据，对原数据进行过滤。
having 对筛选出的结果再次进行过滤。
having 字段必须是查询出来的，where 字段必须是数据表存在的。
where 不可以使用字段的别名，having 可以。因为执行 where 代码时，可能尚未确定列值。
where 不可以使用聚合函数。一般使用聚合函数才会用 having
SQL 标准要求 HAVING 必须引用 GROUP BY 子句中的列或用聚合函数中的列。


 order by: 对最终结果集进行排序，在 where&#x2F;group by&#x2F;having 等之后，顺序不能乱

DESC: 降序排序;  ASC: 升序排序
order by 列名 1 desc, 列名 2 asc;    多个排序之间使用 , 号隔开


limit 限制条件

limit [offset, N]
offset(偏移量): 跳过 offset 行；
N：实际取得 N 条数据




where、group by、having、order by、limit 这些关键字查询的使用顺序？

使用的顺序：where—group by—having—order by—limit



2.8.4.1. 子查询
where 型子查询: 内层查询的结果作为外层的条件

from 型子查询：内层 SQL 查询的结果当成一张临时表，供外层的 SQL 再次查询。

exist 型子查询：把外层 SQL 查询的结果拿到内层 SQL 中去测试，如果内层 SQL 成立，则该行取出。

 NULL 说用 

null 是一种类型，比较时只能用 is null 或 is not null; 碰见运算符时，一律返回为 null。使用 null 效率不高，影响索引的效果



子查询关键字

all：与子查询返回的所有值比较为 true 则返回 true。
any
some
in：用于判断某个记录的值，是否在指定的集合中，关键字前边加上 not 可以将条件反过来。
exist

注意事项

子查询在主查询前执行一次
主查询使用子查询的结果
子查询是在外层查询执行之前执行;
子查询要加上括号;
子查询不能随便写, 子查询返回的内容要和外层查询比较的内容相匹配;
子查询一般单独成行 (格式)

2.8.4.2. 连接
使用两表相乘生成第三个表的方法，再进行查询。这样做的方法效率很低，对内存的开销很大。

mysql 中不支持外链接

左连接: A left join B on 条件 。返回左表中的所有记录和右表中连接字段相等的记录。

若条件为真，则 B 表对应的行取出
可以查询 A、B 表中所有的列
可以把 A left join B on 条件  看成一个新的表 C


右连接:B right join A on 条件 。返回右表中的所有记录和左表中连接字段相等的记录。

与左连接 A left join B on 条件  等价
在 mysql 中，尽量使用左连接，具有很好的移植性。


内连接 (inner)：是左右连接的交集。

联合 (union): 合并 2 条或多条语句的结果集

可以多张表操作
多张表的列名称不一致时也可以用，以第一张表的 字段名为基石。
只要结果集中列的数量一致就可以。
内层的 order by 语句单独使用，不会影响结果集，在执行期间被 mysql 的代码分析器优化掉了。
若果 order by 与 limit 配合使用，会影响返回的结果集，有作用。
使用 union 后返回的结果集有重复，默认会去除结果集重复的数据；若果不想去除重复的数据，使用  union all 关键字



3. Function(函数)3.1. countcount() 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是 ** 统计符合查询条件的记录中，函数指定的参数不为 NULL 的记录有多少个 **。

count(column_name) 函数：统计 table_name 表中 column_name  列字段不为 NULL 的行数。
select count(column_name) FROM table_name

column_name 列明为主键时，

count(*) 返回表中所有列对应的行数，不会忽略 NULL 值。
select count(*) FROM table_name

count(1)
小林 coding： https://www.cnblogs.com/xiaolincoding/p/15769721.html
3.2. cancatcancat() 函数 : 拼接两个列:
3.3. RtrimRTrim() 函数 : 去掉值右边的所有空格
3.4. LTrimLTrim() 函数 : 去掉值左边的所有空格
3.5. UpperUpper(): 将文本转换为大写
4. 视图 (View)
什么是视图？

可以看成一张虚拟的表，是表通过某种运算得到的一个投影。



4.0.1. 视图创建
创建视图 create view 视图名 as select 语句
作用：
简化查询：统计复杂的结果时，先用视图生成一个中间结果，再查询视图。
精确的权限控制。
分表时使用


表的变化直接影响视图的变化
视图压根不能改。
视图在某些条件下也可以改变 (drop、delete、alter)，必须是视图的数据与表的数据呈现一一对应才可以改变。若使用 order by  和 limit 之后，表里面的数据域视图里的数据不是一一对应关系。
algorithm 用法
有三个参数组成
merge：条件合并。（简单的视图，并没有建立临时表，而是把条件存储起来，下次查询时再把条件合并，然后再去查表）
undefined：未定义，由系统决定采用创建临时表还是简单的组合语句。
temptable：创建临时表





4.0.2. 视图删除
 drop view view_name 删除视图时，只能删除视图的定义，不会删除数据，删除一个或多个视图时，视图中间使用逗号分隔开

5. 编码问题
字符集: CHARSET = charset_name
查看数据库的编码方式：show variables like &#39;%char%&#39;;
四个概念
client(客户端)
connection(连接器)
server(服务器)
result(返回客户端的结果)


解决不想乱码
正确选择客户端的编码
合理选择连接器的编码
正确选择返回内容的编码
如果 client、connection、result 三者的编码都为 GBK，则可以简写为：set names gbk;



6. 存储架构
和其它数据库相比，MySQL 有点与众不同，它的架构可以在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上。
Pluggable Storage Engines. 插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取分离。这种架构可以根据业务的需求和实际需求选择合适的存储引擎。

6.1. Engine
存储引擎: ENGINE = engine_name
表在管理数据时采用的不同的数据结构，结构不同会导致处理方式、提供的特性操作等不同


常见的引擎：InnoDB, MyISAM, Memory&#x2F;Heap, BDB, Merge, Example, CSV, MaxDB, Archive
不同的引擎在保存表的结构和数据时，采用不同的方式
MyISAM 表文件含义：.frm 表定义，.MYD 表数据，.MYI 表索引
InnoDB 表文件含义：.frm 表定义，表空间数据和日志文件


查看 mysql 支持什么引擎信息： SHOW ENGINES
查看 mysql 当前默认的存储引擎：  show variables like &#39;%storage_engine%&#39;;
查看某个表用了什么引擎： show create table 表名;
显示存储引擎的日志或状态信息: SHOW ENGINE 引擎名 &#123;LOGS|STATUS&#125;
修改表引擎方法: alter table table_name engine=InnoDB;

6.2. table
在 InnoDB 引 擎中，表都是根据主键顺序组织存放的，这种存储方式称为索引组织表 (index organized table)。

6.3. index
Innodb 引擎支持下面的几种引擎？
B + 树：是关系型数据库职工查找最为常用和最有效的索引。
全文索引
哈希



7. lock
什么是 latch？
latch 一般叫为闩锁（轻量级的锁）。在 innodb 引擎中，latch 有分为 mutex 和 rwlock。目的是：用来保证并发线程操作临界资源的正确性，并且通常没有死锁检测的机制。

什么是 lock？
锁是数据库系统中区别于文件系统的一个关键特性。

为什么要有 lock?
用于管理对共享资源的并发问题，提供数据的完整性和一致性。

lock 的对象是事务，用来锁定数据库中的对象，如 tables，pages，rows，一般的 lock 的对象仅在事务 commit 和 rollback 后进行释放，lock 是有死锁机制的。

查看当前数据库中锁的请求。
show engine innodb status \G;

8. transaction
什么叫 transaction？
一个 SQL 语句或者一组复杂的 SQL 语句就是一个事务（transaction）。事务时访问并更新数据库中各数据项的一个程序执行单元。

为什么要有 transaction？
事务会把数据库从一种一致状态转换为另一种一致状态，在数据库提交工作时，可以确保要么所有修改都已经保存了，要么所有修改都不保存。

事务的四大特性（ACID）

原子性（Atomicity）：用于保证数据的一致性，由一组相关的 DML 语句组成，修改的操作要么全部成功，要么全部失败。（失败的时候要进行回滚操作 [rollback]）
一致性（Consistency）：一个事务执行之前和执行之后都必须处于一致性状态，即操作前后值得变化，逻辑上保持一致。
隔离性（Isolation）：如果多个事务同时并发执行，但每个事务会各自独立执行，不能被其他事务的操作所干扰。
持久性（Durability）：事务一旦完成，无法撤销。一个事务一旦被提交了，对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。通过 redo log(重做日志) 和 undo log 操作来保证事务的一致性。
redo: 通常是物理日志，记录页的物理修改操作；redo 是恢复提交事务修改的页操作。
undo：通常是逻辑日志，根据每行记录来进行记录；undo 是回滚行记录到某个特定的版本。




事务的操作

start transaction：显式开启事务
commit：提交事务
rollback：回滚用户的事务，撤销正在进行的所有未提交的修改。
savepoint identifier：允许在事务中创建一个保存点，一个事务中可以有多个 savepoint
release savepoint identifier：删除一个事务的保存点，当没有一个保存点执行这条语句时，会抛出一个异常。
rollback to [savepoint] identifier：把事务回滚到某个标记点。
set transaction：设置事务的隔离级别



9. 文件
数据文件目录: DATA DIRECTORY = &#39;目录&#39;
索引文件目录: INDEX DIRECTORY = &#39;目录&#39;
表注释: COMMENT = &#39;string&#39;
分区选项: PARTITION BY ... (详细见手册)

10. 数据的导入与导出10.1. 基础导入与导出mysqldump 导出固定条件的数据库

导出整个数据库: mysqldump -u 用户名 -p 数据库名 &gt; 导出的文件名 

mysqldump -u wcnc -p smgp_apps_wcnc &gt; wcnc.sql


导出一个表: mysqldump -u 用户名 -p 数据库名 表名 &gt; 导出的文件名 

mysqldump -u wcnc -p smgp_apps_wcnc users&gt; wcnc_users.sql


导出一个数据库结构: mysqldump -u wcnc -p -d --add-drop-table smgp_apps_wcnc &gt;d:\wcnc_db.sql

#-d 不导出数据只导出结构 –add-drop-table 在每个 create 语句之前增加一个 drop table


批量导出多个数据库：mysqldump  -u root -p --databases db_1 db_2


使用 source 命令导入数据库  #进入 mysql 数据库控制台mysql -u root -pmysql&gt;use 数据库mysql&gt;set names utf8; （先确认编码，如果不设置可能会出现乱码，注意不是 UTF-8）#然后使用 source 命令，后面参数为脚本文件（如这里用到的. sql）mysql&gt;source d:\wcnc_db.sql
10.2. txt 文件导入和导出
导入 txt 文件，设置导入的编码格式为 utf8，防止乱码，可选项目。
mysql&gt; load data infile &#x27;d.txt&#x27; into table table_name  -&gt; CHARACTER SET utf8,  -&gt; fields terminated by&#x27;,&#x27;  -&gt; lines terminated by&#x27;\r\n&#x27;;

导出 txt 文件
mysql&gt; select * from table_name into outfile &#x27;d.txt&#x27;  -&gt; fields terminated by&#x27;,&#x27;  -&gt; lines terminated by&#x27;\r\n&#x27;;

只导入部分字段的数据
// name 为字段名，可以为多个mysql&gt; load data infile &#x27;d.txt&#x27; into table tt  -&gt; lines terminated by&#x27;\r\n&#x27;  -&gt; (name);

11. References
MySQL 5.7 reference manual
MySQL 安装教程参考文章
MySQL 压缩包安装参考
MySQL 卸载参考
MySQL 5.1 安装和配置过程中遇到的问题
社区版下载网站：https://dev.mysql.com/downloads/
MySQL 在 Linux 下密码默认安全等级问题
MySQL 修改密码（三种方法示例）
数据库事务的四大特性以及事务的隔离级别
Mysql 备份还原数据库之 mysqldump 实例及参数详细说明
查看与提交 bug 网站：https://bugs.mysql.com/
MySQL 团队博客：https://mysqlserverteam.com/

学习网站

MySQL Tutorial 英文档
国外的 Planet MySQL
W3school SQL 教程

博客

万乐荣 MySQL 讲解
何登成的技术博客
orczhou 博客
追风刀 · 丁奇 - ITeye 技术网站
阿里云数据库高级专家彭立勋
国外 Percona’s MySQL &amp; InnoDB performance and scalability blog
格物：MySQL 学习笔记

版本发行说明手册，其中有各版本新增内容：

https://dev.mysql.com/doc/relnotes/mysql/5.7/en/
https://dev.mysql.com/doc/relnotes/mysql/8.0/en/

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>AbbrNetworkTerms</title>
    <url>/Network/Network/AbbrNetworkTerms/</url>
    <content><![CDATA[

常用网络术语缩写
URL: 统一资源定位符 (Uniform Resource Locator)
DNS: 域名系统 (Domain Name System)
ADSL: 非对称数字用户线路 (Asymmetric Digital Subscriber Line) 。它是一种利用架设在电线杆上的金属电话线来进行高速通信的技术，它的上行方向 (用户到互联网)和下行方向 (互联网到用户)的通信速率是不对称的。
FTTH: 光纤到户 (Fibre To The Home)
IX: 互联网交换 (Internet eXchange)
FTP: 文件传输协议 (File Transfer Protocol)
HTTP: 超文本传送协议 (Hyper Text Transfer Protocol)
协议: 通信操作的规则定义称为协议 ( protocol)
URI: 统一资源标识符 (Uniform Resource Identifier)
ARP: 地址解析协议 (Address Resolution Protocol) 根据已知 IP 地址查询出相应的以太网 MAC 地址 
RARP: 逆地址解析协议 (Reverse Address Resolution Protocol) 允许局域网的物理机器从网关服务器的 ARP 表或者缓存上请求其 IP 地址。
TCP: 传输控制协议 (Transmission Control Protocol)
UDP: 用户数据报协议 (User Datagram Protocol)
IP: 网络协议 (Internet Protocol)
ICMP: 网络控制消息协议 (Internet Control Message Protocol)  用于告知网络包传送过程中产生的错误以及各种控制消息，
DNS服务器: 根据 Web 服务器的域名来查询 IP 地址
IP地址: 用来识别连接在互联网上的计算机和服务器的地址
MIME: 多用途因特网邮件扩充 (Multipurpose Internet Mail Extensions)
协议栈: 操作系统内部的网络控制软件，也叫“协议驱动”“TCP&#x2F;IP 驱动”等。
IANA: 互联网编号管理局 (Internet Assigned Number Authority)。统一分配端口号 (1~1023)的机构。
PID: 进程标识符 (Process IDentification) 操作系统为了标识程序而分配的编号 
MTU: 最大传输单元 (Maximum Transmission Unit)。一个网络包的最大长度，以太网中一般为1500字节。
MSS: 最大分段大小 (Maximum Segment Size)。TCP传往另一端的最大块数据的长度。除去头部后，一个网络包所能容纳的TCP数据的最大长度。TCP 和 IP 的头部加起来一般是 40 字节。
以太网数据帧: 分为以太网头部 (14字节)、IP头部、TCP头部、应用数据、以太网尾部 (4字节)。长度在46~1500字节之间。
SFD: 起始帧分界符 (Start Frame Delimiter)
FCS: 帧校验序列 (Frame Check Sequence)
集线器: 在子网中将网络包传输到下一个路由器，按照以太网规则传输包的设备
路由器: 根据目标地址判断下一个路由器的位置，按照IP规则传输包的设备。
MAC: 媒体存取控制位地址 (Media Access Control)，也叫以外网地址或物理地址
MAU: 介质连接单元 (Medium Attachment Unit)，低速方式的信号收发模块
PHY: 物理层装置 (Physical Layer Device)， 100 Mbit&#x2F;s 以上的以太网中信号收发模块
MDI: 媒体相关接口 (Media Dependent Interface)
MDI-X: 交叉接线 (Media Dependent Interface Crossover)
TTL: 生存时间 (Time To Live), 表示包的有效期。设置了数据报可以经过的最多路由器数。
PPPoE: 以太网上的点对点协议 (Point-to-Point Protocol Over Ethernet)
PPP: 点到点协议 (Point-to-Point Protocol)
BAS: 宽带接入服务器 (Broadband Access Server)。负责将 ATM 信元还原成网络包并转发到互联网内部
ATM: 异步传输 (Asynchronous Transfer Mode)。以信元为单位传输
IDF: 中间配线盘 (Intermediate Distribution Frame)
MDF: 主配线盘 (Main Distribution Frame)
DSLAM: 数字用户线接入复用设备 (Digital Subscriber Line Access Multiplexer)
ONU: 光网络单元 (Optical Network Unit)
OLT: 光线路终端 (Optical Line Terminal)
RADIUS: 远程认证拨号用户服务 (Remote Authentication Dial-in User Service)
RAS: 远程访问服务器 (Remote Access Server)
HDLC: 高级数据联接控制 (High-level Data Link Control)
CHAP: 挑战握手认证协议 (Challenge Handshake Authentication Protocol)
PAP: 密码验证协议 (Password Authentication Protocol)
DHCP: 动态主机配置协议 (Dynamic Host Configuration Protocol)
POP: 接入点 (Point Of Presense)
NOC: 网络运营中心 (Network Operation Center)
BGP: 边界网关协议 (Broder Gateway Protocol)
WAN: 广域网 (Wide Area Network)
LAN: 局域网 (Local Area Network)
CIDR: 无类别域间路由 (Classless inter-domain routing) 
ICANN: 互联网名称与数字地址分配机构 (The Internet Corporation for Assigned Names and Numbers)
CNNIC: 中国互联网络信息中心 (China Internet Network Information Center)
InterNIC: 互联网络信息中心 (Internet Network Information Centre)。 只分配网络号，主机号的分配由系统管理员来负责。
NAT: 网络地址转换 (Network Address Translation)。在同个公司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。
NAPT: 网络端口地址转换 (Network Address Port Translation)
IGMP: Internet 组管理协议 (Internet Group Management Protocol)。作用在主机 (组播成员)和最后一跳路由之间，用来把一个UDP数据报多播到多个主机。
RFC: 请求意见稿 (Request For Comment)
SNAP: 子网接入协议 (Sub-network Access Protocol)
DSAP: 目的服务访问点 (Destination Service Access Point)
SSAP: 源服务访问点 (Source Service Access Point) 
令牌环网 (Token-ring network)
RTT: 往返时延 (Round-Trip Time)。它的值是收到应答时的时间值减去发送请求时的时间值。
RTO: 重传超时时间 (Retransmission TimeOut)
MSL: 最大段生命时间 (Maximum Segment Lifetime)。是任何的报文在被丢弃前，网络中的最长时间。
ISN: 初始序号 (Initial Sequence Number) 
FIN: TCP首部中的结束标志 (FINish) 
ACK: TCP首部中的确认标志 (ACKnowledgment) 
RIP: 路由信息协议 (Routing Information Protocol)
IOT: 物联网 (英语: Internet of Things)
3GPP: 第三代合作伙伴计划 (英语: 3rd Generation Partnership Project，即3GPP)
GSM: 全球移动通信系统 (Global System for Mobile Communications) 
UMTS: 通用移动通讯系统 (Universal Mobile Telecommunications System，缩写: UMTS)
MIMO: 多输入多输出 (Multi-input Multi-output ; MIMO)
LTE: 长期演进技术 (英语: LTE，Long Term Evolution)
HSPA: 高速分组接入 (英语: High Speed Packet Access)
CPS: 信息物理融合系统 (Cyber-Physical Systems)
IMT:  (International Mobile Telecommunication)
mMTC: 海量机器类通信
uMTC: 超可靠机器类通信
NVF: 网络功能虚拟化 (英语: Network Functions Virtualization)
SDN: 软件定义网络 (英语: software-defined networking)
RAN: 无线接入网 (Radio Access Network)
VoLTE: 长期演进语音承载 (Voice over Long Term Evolution)

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>abbrNetworkTerms</tag>
      </tags>
  </entry>
  <entry>
    <title>sql-optimization</title>
    <url>/MySQL/MySQL/sql-optimization/</url>
    <content><![CDATA[慢SQL慢 SQL 产生的表现：

索引缺失
索引失效
无有效查询条件或条件缺失
多层临时表嵌套
强制使用性能差的索引

对线上环境产生的影响：出现事故偶发、用户体验差。
对数据库产生的影响：SQL 执行的越慢，消耗 CPU 资源或 IO 资源也会越大，大量的慢 SQL 查询可直接引发业务故障。
开启慢SQL查询日志
MyQL 默认是没有开启慢查询日志的，可以通过命令行或者修改 my.cnf 来开启。开启后对性能有一定的影响，生产环境不建议开启。
使用命令行开启，重启服务后慢查询就会失效；修改配置文件的方式，会一直生效。

首先是进入到 MySQL 的服务中查看下关于慢查询的配置 show variables like &#x27;slow_query_log%&#x27;;查看下默认的超时时间配置 show variables like &#x27;long_query_time%&#x27;;

命令行中修改
# 执行步骤先将超时时间修改为 3 秒 set global long_query_time=3;然后开启配置 set global slow_query_log=1;退出 MySQL 并重新进入测试一下 select sleep(5);去看下慢查询的日志

修改MySQL配置的方式修改 my.cnf，在 [mysqld] 添加下面配置
slow_query_log=1slow_query_log_file=/var/lib/mysql/slow-log.loglong_query_time=3

References
mysql cpu 占用超过 100%：https://xie.infoq.cn/article/a274e214af9b43f77119b1d90

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mySQL</tag>
        <tag>sql-optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>CustomTCPProtocol</title>
    <url>/Network/Network/CustomTCPProtocol/</url>
    <content><![CDATA[

基于TCP自定义协议References
基于传输层TCP协议，自定义实现一个应用层协议：https://www.cnblogs.com/ssyfj/p/14016931.html

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>customTCPProtocol</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL-API</title>
    <url>/MySQL/MySQL/MySQL-API/</url>
    <content><![CDATA[c++ connect APImysql_affected_rows() 返回被最新的UPDATE, DELETE或INSERT查询影响的行数。mysql_close() 关闭一个服务器连接。mysql_connect() 连接一个MySQL服务器。该函数不推荐；使用mysql_real_connect()代替。mysql_change_user() 改变在一个打开的连接上的用户和数据库。mysql_create_db() 创建一个数据库。该函数不推荐；而使用SQL命令CREATE DATABASE。mysql_data_seek() 在一个查询结果集合中搜寻一任意行。mysql_debug() 用给定字符串做一个DBUG_PUSH。mysql_drop_db() 抛弃一个数据库。该函数不推荐；而使用SQL命令DROP DATABASE。mysql_dump_debug_info() 让服务器将调试信息写入日志文件。mysql_eof() 确定是否已经读到一个结果集合的最后一行。这功能被反对; mysql_errno()或mysql_error()可以相反被使用。mysql_errno() 返回最近被调用的MySQL函数的出错编号。mysql_error() 返回最近被调用的MySQL函数的出错消息。mysql_escape_string() 用在SQL语句中的字符串的转义特殊字符。mysql_fetch_field() 返回下一个表字段的类型。mysql_fetch_field_direct () 返回一个表字段的类型，给出一个字段编号。mysql_fetch_fields() 返回一个所有字段结构的数组。mysql_fetch_lengths() 返回当前行中所有列的长度。mysql_fetch_row() 从结果集合中取得下一行。mysql_field_seek() 把列光标放在一个指定的列上。mysql_field_count() 返回最近查询的结果列的数量。mysql_field_tell() 返回用于最后一个mysql_fetch_field()的字段光标的位置。mysql_free_result() 释放一个结果集合使用的内存。mysql_get_client_info() 返回客户版本信息。mysql_get_host_info() 返回一个描述连接的字符串。mysql_get_proto_info() 返回连接使用的协议版本。mysql_get_server_info() 返回服务器版本号。mysql_info() 返回关于最近执行得查询的信息。mysql_init() 获得或初始化一个MYSQL结构。mysql_insert_id() 返回有前一个查询为一个AUTO_INCREMENT列生成的ID。mysql_kill() 杀死一个给定的线程。mysql_list_dbs() 返回匹配一个简单的正则表达式的数据库名。mysql_list_fields() 返回匹配一个简单的正则表达式的列名。mysql_list_processes() 返回当前服务器线程的一张表。mysql_list_tables() 返回匹配一个简单的正则表达式的表名。mysql_num_fields() 返回一个结果集合重的列的数量。mysql_num_rows() 返回一个结果集合中的行的数量。mysql_options() 设置对mysql_connect()的连接选项。mysql_ping() 检查对服务器的连接是否正在工作，必要时重新连接。mysql_query() 执行指定为一个空结尾的字符串的SQL查询。mysql_real_connect() 连接一个MySQL服务器。mysql_real_query() 执行指定为带计数的字符串的SQL查询。mysql_reload() 告诉服务器重装授权表。mysql_row_seek() 搜索在结果集合中的行，使用从mysql_row_tell()返回的值。mysql_row_tell() 返回行光标位置。mysql_select_db() 连接一个数据库。mysql_shutdown() 关掉数据库服务器。mysql_stat() 返回作为字符串的服务器状态。mysql_store_result() 检索一个完整的结果集合给客户。mysql_thread_id() 返回当前线程的ID。mysql_use_result() 初始化一个一行一行地结果集合的检索。

同步同步连接池维护的是短链接，

connect_times 连接次数
read_timeout
write_timeout

需要考虑连接池的伸缩性问题

最小连接数：限制池的大小。
最大连接数：限制打开的连接数量。

同步连接池数量的初始大小如何设置？
​	若 CPU 的核心数为 8 核，则数量为：从 2*n + 2 开始测试，直到找到最优的数。
异步回调函数接收 DB的返回值
异步连接池维护的是长连接。
怎样实现异步的连接
同步连接池需要创建多个线程。
异步连接不需要创建额外的线程，复用主线程、复用网络模块。

创建一个非阻塞的连接
接入数据库的协议。若数据库提供异步的接口，则只需要适配事件的框架就可以了。

References
max_connections
MySQL服务器最大连接数怎么设置才合理

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mySQL</tag>
        <tag>mySQL-API</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP</title>
    <url>/Network/Network/HTTP/</url>
    <content><![CDATA[ 

1. http
http协议下cookie是明文传递的，https协议下cookie是密文传递的。
总线拓扑结构采用一个信道作为传输媒体,所有站点都通过相应的硬件接口直接连到这一公共传输媒体上,该公共传输媒体即称为总线。任何一个站发送的信号都沿着传输媒体传播,而且能被所有其它站所接收。




1.1. GET和POST的区别1、概括

对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）

2、区别：

1、get参数通过url传递，post放在request body中。
2、get请求在url中传递的参数是有长度限制的，而post没有。
3、get比post更不安全，因为参数直接暴露在url中，所以不能用来传递敏感信息。
4、get请求只能进行url编码，而post支持多种编码方式。
5、get请求会浏览器主动***，而post支持多种编码方式。
6、get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留。
7、GET和POST本质上就是TCP链接，并无差别。但是由于HTTP的规定和浏览器&#x2F;服务器的限制，导致他们在应用过程中体现出一些不同。
8、GET产生一个TCP数据包；POST产生两个TCP数据包。

1.2. cookie 和session 的区别
1、cookie数据存放在客户的浏览器上，session数据放在服务器上。
2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用session。
3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用COOKIE。
4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。
5、所以个人建议：
将登陆信息等重要信息存放为SESSION
其他信息如果需要保留，可以放在COOKIE中


6、cookie依赖于session

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>hTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>How‘sTheNetworkConnected</title>
    <url>/Network/Network/How%E2%80%98sTheNetworkConnected/</url>
    <content><![CDATA[ 

1. 浏览器生成消息的步骤
生成HTTP请求消息


对URL进行解析(URL开头表示：访问方法)
IP地址
IP地址&#x3D;网络号+主机号
是一串32bit的数字，按照 8 比特（ 1 字节） 为一组分成 4 组，分别用十进制表示然后再用圆点隔开。


子网掩码：用来指明一个IP地址的哪些位标识的是主机所在的子网，以及哪些位标识的是主机的位掩码，即用来指定网络号和主机号比特数的值。
不能单独存在，必须与IP地址一起使用
是一个32位的地址
子网掩码为 1 的部分表示网络号， 子网掩码为 0 的部分表示主机号。
主机号部分比特全为0，代表整个子网而不是子网中的某台设备。10.11.12.0/24
主机号部分全部为 1， 代表这个地址向子网上所有设备发送包，即广播。10.11.12.255/24




向DNS服务器查询Web服务器的IP地址


DNS服务器
基本工作：接收来自客户端的查询消息，然后根据消息的内容返回响应。
客户端的三种查询消息
域名
Class：用来识别网络的信息（互联网的值为：IN）
记录类型：表示域名对应何种类型的记录。(A: Address; MX: Mail eXchange 邮件交换)




DNS 服务器会从域名与 IP 地址的对照表中查找相应的记录，并返回 IP 地址。


委托操作系统内部的协议栈将消息发送给Web服务器


Socket库：用于调用网络功能的程序组件集合。
解析器(resolver)在操作系统的Socket库中。
向操作系统内部的协议栈发出委托时，需要按照指定的顺序来调用 Socket 库中的程序组件。
Socket库收发数据流程
创建套接字
将管道连接到服务器端的套接字上
发送数据
断开管道并删除套接字(根据应用种类不同，客户端和服务器哪一方先执行 close 都有可能)


描述符：应用程序用来识别套接字的机制
IP 地址和端口号：客户端和服务器之间用来识别对方套接字的机制

2. 协议栈（操作系统中的网络控制软件）工作流程 TCP操作的整体流程 

创建套接字


套接字的实体：通信控制信息
协议栈是根据套接字中记录的控制信息来工作的
套接字的作用：套接字中记录了用于控制通信操作的各种控制信息，协议栈需要根据这些信息判断下一步的行动


连接服务器


连接的实质：通信双方交换控制信息
头部(网络包头部)：用来记录和交换控制信息
两类控制信息
客户端和服务器相互联络时交换的控制信息，即头部记录的信息。(整个通信过程都需要)
保存在套接字中，用来控制协议栈操作的信息，即套接字(协议栈中的内存空间)中记录的信息。




收发数据


通过“序号”和“ACK 号”可以确认接收方是否收到了网络包。通过这一机制，可以采取相应的错误补偿机制。

根据网络包平均往返时间调整 ACK 号等待时间。TCP采用动态调整等待时间的方法。这个等待时间是根据 ACK 号返回所需的时间来判断的。

采用滑动窗口方式来有效管理ACK号。

滑动窗口：在发送一个包之后， 不等待 ACK 号返回， 而是直接发送后续的一系列包。 
采用滑动窗口的方式，将数据存储到缓存区。首先， 接收方需要告诉发送方自己最多能接收多少数据，然后发送方根据这个值对数据发送操作进行控制。 


更新窗口大小时机：接收方从缓冲区中取出数据传递给应用程序的时候，导致接收缓冲区剩余容量增加时，需要要告知给发送方。

ACK号：当接收方收到数据时，如果确认内容没有问题，应该向发送方返回ACK号。

 注意：需要连续发送ACK号和连续发生窗口更新时，只需要发送最终的结果，可以提高效率。



从服务器断开连接并删除套接字


数据发送完数据后断开连接。例如：服务一方先发送断开连接。
删除套接字
套接字并不会立即被删除， 而是会等待一段时间之后再被删除。
等待这段时间 是为了防止误操作，




IP 与以太网的包收发操作


包：由头部和数据两部分构成。头部记录了各种控制信息

TCP&#x2F;IP包

MAC头部：用于以太网协议 
IP头部：用于IP协议
两个头部的作用：
将要访问的服务器的 IP 地址写入 IP 头部中，然后，IP 协议会委托以太网协议将包传输过去。 这时， IP 协议会查找下一个路由器的以太网地址（ MAC 地址），并将这个地址写入 MAC 头部中。




网络包在传输过程中经过集线器。集线器里有一张表（ 用于以太网协议的表）， 可根据以太网头部中记录的目的地信息查出相应的传输方向。![IP 网络包的传输方式](.&#x2F;figures&#x2F;IP 网络包的传输方式.png)

转发设备中有一张记录了什么地址要往哪里发送的表。按照头部里记录的目的地址在表里进行查询， 并根据查到的信息判断接下来应该发往哪个方向。

IP模块负责的功能

(1)添加MAC 头部：以太网用的头部，包含 MAC 地址
(2)添加IP 头部：IP 用的头部，包含 IP 地址


IP 模块根据路由表 Gateway 栏的内容判断应该把包发送给谁。

IP地址长度：32比特，即4字节

MAC地址长度：48比特，即6字节

MAC头部字段(14 byte)

接收方MAC地址48比特
发送方MAC地址48比特
以太网类型16比特


以太网三个基本性质

将包发送到 MAC 头部的接收方
用发送方 MAC地址识别发送方
用以太类型识别包的内容



 网卡结构 

网卡中保存的 MAC 地址会由网卡驱动程序读取并分配给 MAC模块。
用 UDP 协议收发数据的操作
应用场景
发送音频和视频数据 
不需要重发的数据，例如：用DNS 查询等交换控制信息


UDP可发送的数据最大长度等于IP包最大长度减去IP头部和UDP头部

3. 交换机( switching hub)、路由器(router)、集线器(repeater hub)
交换机端口的 MAC 模块不具有 MAC 地址。（内置用于实现管理等功能的处理器的交换机除外）

交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。

交换机的全双工模式可以同时发送和接收信号

路由器是基于 IP 设计的， 而交换机是基于以太网设计的 

路由器工作原理：主要有两部分模块

转发模块：负责判断包的转发目的地
端口模块：负责包的收发操作



路由器的各个端口都具有 MAC 地址和 IP 地址

交换机是通过 MAC 头部中的接收方 MAC 地址来判断转发目标， 而路由器则是根据 IP 头部中的 IP 地址来判断。 

路由器会忽略主机号，只匹配网络号。

路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃

通过路由器转发的网络包，其接收方 MAC 地址为路由器端口的MAC 地址。

交换机与路由器之间关系

IP（ 路由器） 负责将包发送给通信对象这一整体过程， 而其中将包传输到下一个路由器的过程则是由以太网（ 交换机） 来负责的。

地址转换：转发网络包时对 IP 头部中的 IP 地址和端口号 进行改写。

用于区分公有IP地址和私有IP地址的分界线



改写端口号的目的：提高公有地址的利用率，不需要私有地址和公有地址必须一一对应。

路由器包过滤：根据MAC头部、IP头部、TCP头部的内容 ，按照事先设置好的规则决定是转发这个包， 还是丢弃这个包。


4. 通过接入网进入互联网内部
互联网接入路由器会在网络包前面加上 MAC 头部、PPPoE 头部、PPP 头 部 总 共 3 种 头 部， 然 后 发 送 给 ADSL Modem（PPPoE 方式下）。

分离器的作用：过滤高频信号，防止ADSL对电话产生干扰，还防止电话对ADSL产生干扰。

 网络包进入互联网流程

PPPoE 是将 PPP 消息装入以太网包进行传输的方式-互联网接入路由器通过 PPPoE 的发现机制查询 BAS 的 MAC 地址。

BAS 在收到用户路由器发送的网络包之后，会去掉 MAC 头部和PPPoE 头部，然后用隧道机制将包发送给网络运营商的路由器。

PPoE方式的ADSL接入网：先将 PPP 消息装入以太网包中， 然后再将以太网包拆分并装入信元

DHCP原理


互联网内部使用 BGP 机制在运营商之间交换路由信息。


5. 服务器端的局域网
防火墙

包过滤方式的防火墙可根据接收方 IP 地址、发送方 IP 地址、接收方端口号、发送方端口号、控制位等信息来判断是否允许某个包通过。


通过将请求平均分配给多台服务器来平衡负载，提高服务器的性能。

对多台 Web 服务器分配访问的负载均衡器  

采用缓存服务器的方法实现分担负载。

缓存服务器是一台通过代理机制对数据进行缓存的服务器。


缓存服务工作流程图

缓存服务器的3种部署方式

将缓存服务器部署在Web服务器之前：降低Web服务器的负载，但是无法减少网络流量。
部署在客户端：减少网络流量较好，但Web服务器运营者无法控制位于客户端的缓存服务器
部署在互联网的边缘：降低网络流量，而且网络运营者也可以控制缓存服务器。


DNS服务器的工作流程



6. 请求到达Web服务器，响应返回浏览器
网卡的 MAC 模块将网络包从信号还原为数字信息，校验 FCS并存入缓冲区。

网卡驱动会根据 MAC 头部判断协议类型，并将包交给相应的协议栈。 

协议栈的 IP 模块会检查 IP 头部

(1)判断是不是发给自己的；
(2)判断网络包是否经过分片;
(3)将包转交给 TCP 模块或 UDP模块


TCP模块收到是发起连接的包，如何处理？

(1)确认 TCP 头部的控制位 SYN
(2)检查接收方端口号
(3)为相应的等待连接套接字复制一个新的副本
(4)记录发送方 IP 地址和端口号等信息。


TCP模块收到数据包时，如何处理？

(1)根据收到的包的发送方 IP 地址、发送方端口号、接收方 IP 地址、接收方端口号找到相对应的套接字
(2)将数据块拼合起来并保存在接收缓冲区中；
(3)向客户端返回 ACK



7. References
豆瓣 网络是怎样连接的：https://book.douban.com/subject/26941639/

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>how‘sTheNetworkConnected</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkPrimer</title>
    <url>/Network/Network/NetworkPrimer/</url>
    <content><![CDATA[

1. Principles and Terminology掌握基本的原理 (principles)、网络术语 (terminology)。
1.1. OSI七层模型
物理层(Physical Layer)
数据链路层(Data Link Layer)
网络层(Network Layer)
传输层(Transport Layer)
会话层(Session Layer)
表示层(Presentation Layer)
应用层(Application Layer)

1.2. TCP&#x2F;IP五层模型
物理层(Physical Layer)

数据链路层(Data Link Layer) : 处理与电缆接口的物理细节

网络层(Network Layer)

也称作互联网层，处理 packet 在网络中的活动。
ARP
IP
ICMP


传输层(Transport Layer) ：为两台主机上的应用程序提供端到端的通讯。

TCP：把应用程序交给它的数据分成合适的小块交给下面的网络层，确认收到的 packet ，设置发送，最后确认 packet 的超时时间。TCP为两台主机提供可靠的数据通信。
UDP：只是把数据报的 packet 从一台主机发送到另一台主机，但并不保证该数据报能安全无误的抵达到另一端。


应用层(Application Layer)

负责处理特定的应用程序细节。 
常见的通用应用程序
Telnet 远程登录。
FTP 文件传输协议。
SMTP 简单邮件传送协议。
SNMP 简单网络管理协议。





1.3. Port
port (端口号) 
TCP和UDP采用 16  bit 的端口号来识别应用程序
端口号用来标识互相通信的应用程序。
服务器使用的是知名端口号，一般小于1024。
客户端的端口号叫 临时端口号，范围在 1024~5000之间。


以太网协议号
IP：0800
ARP：0806
PPPOE：8863、8864
IPV6：86DD


IP协议号
ICMP：1
TCP：6
UDP：17
GRE：47
ESP：50
AH：51


端口号
SSH：22
Telnet：23
TACACS：49
IKE：500
Radius：1645、1646、1812、1813
Web：80
邮件(mailto)：25
Windows 文件服务器使用的端口：139
TCP
FTP：20、21
SMTP：25
HTTP：80
HTTPS：443


UDP
DNS
TFTP: 69
RIP: 520
DHCP: 547, 546
SNMP: 162、161
NFS: 2049





1.4. Protocols
HTTP (Web),
streaming video
TCP
IP
WiFi
4G
Ethernet

1.5. Terminology(术语)
数据包进入网络中之前需要进行封装，封装过程是操作系统处理的，而不是用户处理的。

TCP传输过程中，数据包只会寻找一次的传输路径，并将其记下，下次的传输会使用以保存的传输路径，因此传输数据比较稳定。而UDP在网路传输过程中，每次传输的路径都不一样，每次传输需要重新寻找路径，因此传输数据没有TCP稳定。

寻路：寻找下一个路由节点。

packet 交换(也叫蓄积交换)：让连接到通信电路中的计算机，将要发送的数据包分成多个数据包，按照一定的顺序排列之后分别发送。

吞吐量：主机之间实际的传输速率，其单位与带宽相同，都是bps( bits Per Second)。

网桥：是在链路层上对网络进行互连，网桥使得多个局域网(LAN)组合在一起。

路由器：是在网络层上对网络进行互连。

数据报：是指从发送方传输到接收方的一个信息单元。

TCP报文段(TCP segment)：TCP传给IP的数据单元。

packet ：在IP层和数据链路层之间传送的数据单元。

默认网关：通向外部网路的第一跳路由器。

Internet standards

RFC: Request for Comments
IETF: Internet Engineering Task Force



2. Application Layer2.1. DNSDNS是指：域名服务器(Domain Name Server)。在Internet上域名与IP地址之间是一一对应的，域名虽然便于人们记忆，但机器之间只能互相认识IP地址，它们之间的转换工作称为域名解析，域名解析需要由专门的域名解析服务器来完成，DNS就是进行域名解析的服务器。
把域名翻译成IP地址的软件称为域名系统，即DNS。它保存了一张域名(domain name)和与之相对应的IP地址 (IP address)的表，以解析消息的域名。
域名是由一串用点分隔的名字组成的，通常包含组织名，而且始终包括两到三个字母的后缀，以指明组织的类型或该域所在的国家或地区。
工作方式：DNS 服务器用来将域名转换成 IP 地址。当 DNS 服务器收到一条请求后，它会检查它有没有该请求需要的转换信息。如果没有这条转换信息，那么 DNS 服务器会把这条请求转发给其他的 DNS 服务器。通过这种方式，就完成了从域名到 IP 地址的转换。转换结果随后会发回到发出请求的计算机。

它提供主机名字和 IP地址之间的转换及有关电子邮件的选路信息。

从应用的角度上看，对 DNS的访问是通过一个地址解析器( resolution)来完成的。

DNS报文格式

报文 (message) 由 12字节长 的首部和 4个长度可变 的字段组成。 
DNS报文中最后的三个字段，回答字段、授权字段和附加信息字段，均采用一种称为资源记录 RR( Resource Record)的相同格式。


DNS报文首部中的标志字段

QR 是 1 bit 字段： 0表示查询报文， 1表示响应报文。

opcode是一个4 bit 字段：通常值为0(标准查询)，其他值为1(反向查询)和2(服务器状态请求)。
AA 是 1 bit 标志，表示“授权回答 (authoritative answer)”。该名字服务器是授权于该域的。
TC是 1 bit字段，表示“可截断的 (truncated)”。使用UDP时，它表示当应答的总长度超过512字节时，只返回前512个字节。
RD是 1 bit 字段表示“期望递归(recursion desired)”。该比特能在一个查询中设置，并在响应中返回。这个标志告诉名字服务器必须处理这个查询，也称为一个递归查询。如果该位为 0，且被请求的名字服务器没有一个授权回答，它就返回一个能解答该查询的其他名字服务器列表，这称为迭代查询。在后面的例子中，我们将看到这两种类型查询的例子。
RA是 1 bit 字段，表示“可用递归”。如果名字服务器支持递归查询，则在响应中将该比特设置为 1。在后面的例子中可看到大多数名字服务器都提供递归查询，除了某些根服务器。
随后的 3 bit 字段必须为0。
rcode是一个 4 bit 的返回码字段。通常的值为 0(没有差错)和 3(名字差错)。名字差错只有从一个授权名字服务器上返回，它表示在查询中制定的域名不存在。


指针查询：给定一个IP地址，返回与该地址对应的域名。 

资源记录(RR: resource record)

A: 记录了一个IP地址，存储32 bit的二进制数
PTR: 用于指针查询。
CNAME: 规范名字 (canonical name)，表示一个域名。
HINFO: 表示主机信息：包括说明主机 CPU和操作系统的两个字符串。
MX:  邮件交换记录，用于以下一些场合。
一个没有连到Internet的站点能将一个连到Internet的站点作为它的邮件交换器。这两个站点能够用一种交替的方式交换到达的邮件，而通常使用的协议是UUCP协议。 
MX记录提供了一种将无法到达其目的主机的邮件传送到一个替代主机的方式。 
MX记录允许机构提供供他人发送邮件的虚拟主机
防火墙网关能使用MX记录来限制外界与内部系统的连接。





3. Transport Layer(传输层)3.1. TCP(Transmission Control Protocol) TCP 的特点：提供一种面向连接的、可靠的字节流传输。

TCP 工作流程&gt; TCP将用户的数据打包成报文段 (segment)，发送报文后将启动一个定时器 (timer)，另一端对收到的数据进行确定，对失序的数据进行重新排序，丢弃数据，TCP提供端到端的流量控制 (flow control)，并计算和验证一个强制性的端到端校验和(checksum)。
  
TCP包的长度最大可达 60 bytes，最小为 20 bytes。 

TCP能在两个方向上进行传输，属于全双工传输。

序号(Sequence number)

占32  bits。
传输层的每个 segment 都包含一个序列号，该序列号是该段 (segment) 中第一个数据字节的字节流编号。用来标识从TCP源端向目的端发送的字节流，发起方发送数据时对此进行标记。
一条TCP连接的双方均可随机地选择初始序号。


确认号(acknowledge number)

占32  bits。
只有ACK标志位为1时，确认序号字段才有效，Ack&#x3D;Seq+1。
注意：不要将 确认序号Ack 与 标志位中的ACK 搞混了。


TCP的首部(head)

TCP数据在IP数据报中的封装
TCP包的首部数据格式
TCP首部中的 6个 bit标志位
URG(urgent) 紧急指针(urgent pointer)，是一个正的偏移量。
ACK(acknowledgement) 确认序号。
PSH(push) 接收方应该尽快将这个报文段交给应用层。
RST(reset) 重建连接。
SYN(synchronous) 同步序号用来发起一个连接。
FIN(finish) 发送方完成数据发送




TCP流量控制：由连接的每一方通过窗口大小来确认。 窗口大小是一个 16 bit 的字节数。

校验和：覆盖了整个TCP的报文段，包括TCP首部和TCP数据，是一个强制性的字段。一定是发送端进行校验和计算，接收端进行校验和 验证。


3.1.1. TCP的建立与终止为什要使用TCP的三次握手和四次挥手这种机制？

因为IP是在网络层，与底层的硬件接触比较紧密，导致传输不稳定。传输层中TCP是面向连接可靠的字节流传输完全弥补了这种问题，而UDP是无连接不可靠的报文传输弥补了部分的这种问题。

3.1.1.1. ESTABLISHED需要三次握手，即连接必须是一方主动打开，另一方被动打开的。

SYN_RECV 状态：服务端被动打开后,接收到了客户端的SYN并且发送了ACK时的状态。再进一步接收到客户端的ACK就进入ESTABLISHED状态。


第一次握手：Client将标志位 SYN 置为 1，随机产生一个值 seq=x，并将该数据包发送给Server，Client进入 SYN_SENT 状态，等待Server确认。

标记位为 SYN，表示 请求建立新连接
序号为 seq=X
客户端进入 SYN-SENT阶段


第二次握手：Server收到数据包后由标志位 SYN=1 知道Client请求建立连接，Server将标志位 SYN 和ACK 都置为 1，ack=x+1，随机产生一个值 seq=y，并将该数据包发送给Client以确认连接请求，Server进入 SYN_RCVD 状态。

标志位为 SYN和ACK，表示 确认客户端的报文Seq序号有效，服务器能正常接收客户端发送的数据，并同意创建新连接(即告诉客户端，服务器收到了你的数据) 
序号为 seq=y
确认号为 ack=x+1，表示收到客户端的序号 seq 并将其值加1作为自己确认号 ack 的值；随后服务器端进入SYN-RCVD 阶段。


第三次握手：Client收到来自server端的确认收到数据的TCP报文后，检查 ack 是否为 x+1，ACK是否为 1，如果正确则将标志位 ACK 置为 1，ack=y+1，并将该数据包发送给Server，Server检查 ack  是否为 y+1，ACK 是否为 1，如果正确则连接建立成功，Client和Server结束 SYN-SENT 阶段，进入 ESTABLISHED 状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

标志位为 ACK，表示“确认收到服务器端同意连接的信号”(即告诉服务器，我知道你收到我发的数据了)
序号为 seq=x+1，表示收到服务器端的确认号 ack，并将其值作为自己的序号值；
确认号为 ack=y+1，表示收到服务器端序号 seq，并将其值加 1 作为自己的确认号 ack 的值；
客户端进入 ESTABLISHED 阶段。


为什么要进行第三次握手？

为了防止服务器端开启一些无用的连接增加服务器开销
防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。
也可以这样理解：“第三次握手”是客户端向服务器端发送数据，这个数据就是要告诉服务器，客户端有没有收到服务器“第二次握手”时传过去的数据。若发送的这个数据是“收到了”的信息，接收后服务器就正常建立TCP连接，否则建立TCP连接失败，服务器关闭连接端口。由此减少服务器开销和接收到失效请求发生的错误。





3.1.1.2. CLOSE需要四次挥手。由于TCP的半关闭造成的。必须是一方主动释放，另一方被动释放。
四次握手的简单过程描述：假设客户端准备中断连接，首先向服务器端发送一个FIN的请求关闭包(FIN&#x3D;final)，然后由established状态过渡到FIN-WAIT1状态。服务器收到FIN包以后会发送一个ACK，然后自己由established状态进入CLOSE-WAIT状态。此时通信进入半双工状态，即留给服务器一个机会将剩余数据传递给客户端，传递完后服务器发送一个FIN+ACK的包，表示我已经发送完数据可以断开连接了，就这便进入LAST_ACK阶段。客户端收到以后，发送一个ACK表示收到并同意请求，接着由FIN-WAIT2进入TIME-WAIT阶段。服务器收到ACK，结束连接。客户端发送完ACK包之后，客户端还要等待2MSL(MSL&#x3D;maxinum segment lifetime最长报文生存时间，2MSL就是两倍的MSL)才能真正的关闭连接。

第一次挥手：client想要释放连接，向server发送一段TCP报文。

标记位为 FIN，表示“请求释放连接“；
序号为 seq=U；
随后客户端进入 FIN-WAIT-1 阶段，即半关闭阶段。并且停止在客户端到服务器端方向上发送数据，但是客户端仍然能接收从服务器端传输过来的数据。


第二次挥手：server接收到从client发出的TCP报文后，确认了client想要释放连接，随后server结束 ESTABLISHED 阶段，进入 CLOSE-WAIT阶段(半关闭状态)并返回一段TCP报文，client收到从server发出的TCP报文后，确认sever收到了client发出的释放连接的请求，随后client结束 FIN-WAIT-1 阶段，进入 FIN-WAIT-2 阶段

标记位为 ACK，表示“接收到客户端发送的释放连接的请求”；
序号为 seq=V；
确认号为 ack=U+1，表示是在收到客户端报文的基础上，将其序号 seq 值加 1 作为本段报文确认号ack 的值； 
随后服务器端开始准备释放服务器端到客户端方向上的连接。
 前”两次挥手”既让服务器端知道了客户端想要释放连接，也让客户端知道了服务器端了解了自己想要释放连接的请求。于是，可以确认关闭客户端到服务器端方向上的连接了




第三次挥手：server自从发出 ACK 确认报文之后，经过 CLOSED-WAIT 阶段，做好了释放server到client方向上的连接准备，再次向client发出一段TCP报文，随后server结束 CLOSED-WAIT 阶段，进入 LAST-ACK 阶段，并且停止从server到client方向上发送数据，但是server任然能够接受从client传输过来的数据。

标记位为FIN，ACK，表示“已经准备好释放连接了”。注意：这里的ACK并不是确认收到服务器端报文的确认报文。
序号为 seq=W；
确认号为 ack=U+1；表示是在收到客户端报文的基础上，将其序号 seq 值加 1 作为本段报文确认号ack 的值。


第四次挥手：client结束从server发出的TCP报文，确认了server已经做好释放连接的准备了，则结束 FIN-WAIT-2 阶段，进入 TIME_WAIT 阶段，并向server发送一段报文，随后client开始在 TIME-WAIT 阶段等待 2MSL。server收到client发出的TCP报文后，则结束 LAST_ACK 阶段，进入 CLOSE 阶段，即正式确认关闭server到client方向上的连接。client等待完 2MSL 之后，结束 TIME-WAIT 阶段，进入 CLOSED 阶段，由此完成“四次挥手”。



后“两次挥手”既让客户端知道了服务器端准备好释放连接了，也让服务器端知道了客户端了解了自己准备好释放连接了。于是，可以确认关闭服务器端到客户端方向上的连接了，由此完成“四次挥手”。


为什么“握手”是三次，“挥手”却要四次？

TCP建立连接时之所以只需要”三次握手”，是因为在第二次”握手”过程中，服务器端发送给客户端的TCP报文是以SYN与ACK作为标志位的。SYN 是请求连接标志，表示服务器端同意建立连接；ACK是确认报文，表示告诉客户端，服务器端收到了它的请求报文。即SYN建立连接报文与ACK确认接收报文是在同一次”握手”当中传输的，所以”三次握手”不多也不少，正好让双方明确彼此信息互通。
TCP释放连接时之所以需要“四次挥手”,是因为FIN释放连接报文与ACK确认接收报文是分别由第二次和第三次”握手”传输的。为何建立连接时一起传输，释放连接时却要分开传输？
建立连接时，被动方服务器端结束CLOSED阶段进入“握手”阶段并不需要任何准备，可以直接返回SYN和ACK报文，开始建立连接。
释放连接时，被动方服务器，突然收到主动方客户端释放连接的请求时并不能立即释放连接，因为还有必要的数据需要处理，所以服务器先返回ACK确认收到报文，经过CLOSE-WAIT阶段准备好释放连接之后，才能返回FIN释放连接报文。




为什么客户端在TIME-WAIT阶段要等2MSL?

当客户端发出最后的ACK确认报文时，并不能确定服务器端能够收到该段报文。所以客户端在发送完ACK确认报文之后，会设置一个时长为2MSL的计时器。MSL指的是Maximum Segment Lifetime：一段TCP报文在传输过程中的最大生命周期。2MSL即是服务器端发出为FIN报文和客户端发出的ACK确认报文所能保持有效的最大时长。
服务器端在1MSL内没有收到客户端发出的ACK确认报文，就会再次向客户端发出FIN报文；
如果客户端在2MSL内，再次收到了来自服务器端的FIN报文，说明服务器端由于各种原因没有接收到客户端发出的ACK确认报文。客户端再次向服务器端发出ACK确认报文，计时器重置，重新开始2MSL的计时；
否则客户端在2MSL内没有再次收到来自服务器端的FIN报文，说明服务器端正常接收了ACK确认报文，客户端可以进入CLOSED阶段，完成“四次挥手”。


所以，客户端要经历时长为2SML的TIME-WAIT阶段；这也是为什么客户端比服务器端晚进入CLOSED阶段的原因


如果已经建立了连接，但是客户端突然出现故障了怎么办？

答：TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。


为什么不能用两次握手进行连接？

答：3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。
现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求 packet ，S收到了这个 packet ，并发送了确认应答 packet 。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据 packet 。可是，C在S的应答 packet 在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求 packet 。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据 packet ，只等待连接确认应答 packet 。而S在发出的 packet 超时后，重复发送同样的 packet 。这样就形成了死锁。




TCP半关闭

概念：客户端以结束向服务器端发送数据后，还能接收服务器端数据的能力。  
rsh工作原理
将标准输入(datafile)复制给TCP连接，将结果从TCP连接中复制给标准输出。

TCP状态变迁
TIME_WAIT 状态也称为 2 MSL 等待状态。

最大生存时间(Maximum Segment Lifetime)
处理的原理：当 TCP执行一个主动关闭，并发回最后一个 ACK，该连接必须在 TIME _ WAIT 状态停留时间为 2倍的MSL。
在连接处于 2MSL 等待时，任何迟到的报文将被丢弃。



平静时间(quit time)：TCP在重启后的MSL时间内都不能建立任何的连接。
异常终止一个连接

正常终止一个连接的方式是发送一个 FIN
异常终止一个连接的优点
丢弃任何待发的数据，立即发送复位报文段。
RST的接收方会区分另一端执行的是异常关闭还是正常关闭。



半打开(half-open)：一端正常关闭或异常终止连接而另一方却还不知道。
同时打开：两个应用程序同时执行主动打开，每一方必须发送 SYN，这些 SYN 必须发送给对方。&lt;&gt;
TCP选项
3.1.2. TCP交互数据流
交互数据总是以小于最大报文段长度的 packet 发送。
小 packet (tinygram)：20字节IP头部，20字节TCP头部，1字节数据
Nagle算法: 
要求： 一个TCP连接上只能有一个未被确认的未完成的 packet 
为了解决在广域网上由于小 packet 而导致网络拥塞的问题。
优点：它是自适应的，确认到达的越快，数据也就发送的越快，减少了小包发送的数量。
缺点：增加了时延



3.1.3. TCP成块数据流滑动窗口机制
TCP滑动窗口的可视化表示
PUSH标志

发送方使用该标志位：通知接收方将接受到的数据全部提交给接收进程。

慢启动：通过观察到新 packet 进入网络的速率应该与另一端返回确认的速率相同而进行工作。

发送一个packet的时间
传播时延
发送时延(取决于带宽)


URG标志
TCP的一端告诉TCP的另一端数据流中有紧急数据报需要处理。



3.1.4. TCP Timeout or Retransmit
TCP管理4个定时器
重传定时器(Retransmission Timer)：希望收到另一端的确认
坚持定时器(Persistent Timer)：使窗口大小信息保持不断流动，即使另一端关闭了接收窗口。
保活定时器(Keeplive Timer)：检测到一个空闲连接的另一端何时崩溃或重启。
时间等待定时器(Timer Wait Timer) ：测量一个连接处于 TIME_ WAIT 状态的时间。
Linux下查看2MSL的时间 /proc/sys/net/ipv4/tcp_fin_timeout





3.1.5. TCP坚持定时器
接收方等待接收数据(因为它已经向发送方通告了一个非 0的窗口) ，而发送方在等待允许它继续发送数据的窗口更新。为防止这种死锁情况的发生，发送方使用一个坚持定时器 (persist timer)来周期性地向接收方查询，以便发现窗口是否已增大。

连接的一方需要发送数据但对方已通告窗口大小为0时，就需要设置TCP的坚持定时器。


3.1.6. TCP保活定时器
保活定时器的例子
一端崩溃
另一端崩溃并重新启动、
另一端不可达



3.1.7. Reliable Data Transfer(可靠数据传输)
TCP 在 IP 不可靠的尽力而为服务之上创建了一种可靠数据传输服务 (reliable data transfer service)。TCP 的可靠数据传输服务确保一个进程从接收缓存中读出的数据流 (data stream) 是无损坏、 无间隙、 非冗余和按序的数据流 (uncorrupted, without gaps, without duplication, and in sequence)； 即该字节流与连接的另一方端系统发送出的字节流是完全相同。 

TCP 怎样保证数据的可靠性传输？

通过使用流量控制 (flow control)、 序号 (sequence numbers)、 确认 (acknowledgments) 和定时器 (timers)来实现。



单个重传定时器 (a single retransmission timer)， 即使有多个已发送但还未被确认的报文段 (multiple transmitted but not yet acknowledged segments)。

TCP 发送方使用重传定时器实现的流程
  /* Assume sender is not constrained by TCP flow or congestion control, that data from above is lessthan MSS in size, and that data transfer is in one direction only. (假设发送方不受TCP流量和拥塞控制的限制， 来自上层数据的长度小于MSS,且数据传送只在一个方向进行)*/NextSeqNum=InitialSeqNumber  // 下一个要发送字节的序号SendBase=InitialSeqNumber    // 已发送过但未被确认字节的最小序号loop (forever) &#123;    switch(event)        event: data received from application above            create TCP segment with sequence number NextSeqNum            if (timer currently not running)                start timer            pass segment to IP            NextSeqNum=NextSeqNum+length(data)            break;        event: timer timeout            retransmit not-yet-acknowledged segment with                smallest sequence number            start timer            break;        event: ACK received, with ACK field value of y            if (y &gt; SendBase) &#123;                SendBase=y            if (there are currently any not-yet-acknowledged segments)                start timer    &#125;    break;&#125; /* end of loop forever */

Doubling the Timeout Interval(双倍超时间隔)

每当超时事件发生时，TCP 重传带有有最小序号并还未被确认的报文段 (segments)。只是每次 TCP 重传时都会将下一次的超时间隔设为先前值的两倍， 而不是用从 EstimatedRTT 和 DevRTT 推算出的值。例如，假设当定时器第一次过期时，与最早的未被确认的 segment 相关联的 Timeoutinterval 是 0. 75 秒， TCP 就会重传该segment，并把新的过期时间设置为1.5秒。如果 1.5 秒后定时器又过期了，则TCP将再次重传该 segment，并把过期时间设置为 3.0 秒。因此，超时间隔在每次重传后会呈指数型增长。 然而，每当定时器在另两个事件（即收到上层应用的数据和收到ACK）中的任意一个启动时， Timeoutinterval 由最近的 EstimatedRTT 值与 DevRTT 值推算得到。


定时器过期很可能是由网络拥塞引起的，即太多的 packet 到达源与目的地之间路径上的一台（或多台） 路由器的队列中，造成 packet 丢失或长时间的排队时延。在拥塞的时候，如果来源端持续重传 packet，会使拥塞更加严重。相反，TCP 使用更文雅的方式，每个发送方的重传都是经过越来越长的时间间隔后进行的。



Fast Retransmit(快速重传)

超时重传存在的问题：超时的周期相对较长。当一个报文段丢失时，这种长超时周期迫使发送方延迟重传丢失的 packet， 因而增加了端到端时延。可以在发送方通过冗余ACK (duplicate ACK) 来检测丢包的情况。

Duplicate ACK (重复 ACK): 是重新确认发送方已经收到较早确认报文段的 ACK。

发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个冗余的ACK。如果 TCP 发送方接收到对相同数据的3个冗余ACK，它把这当作一种指示，说明跟在这个已被确认过 3 次的报文段之后的报文段已经丢失。一旦收到 3 个冗余 ACK, TCP就执行快速重传（fast retransmit） [RFC 5681]，即在该报文段的定时器过期之前重传丢失的报文段。



采用快速重传的 TCP 中 ACK 接受事件的执行流程。
event: ACK received, with ACK field value of y    if (y &gt; SendBase) &#123;        SendBase=y    if (there are currently any not yet acknowledged segments) &#123;        start timer        &#125;    &#125;    else &#123;/* a duplicate ACK for already ACKed segment */        increment number of duplicate ACKs        received for y    if (number of duplicate ACKS received for y==3) &#123;        /* TCP fast retransmit */        resend segment with sequence number y        &#125;    &#125;    break;


对 TCP 提岀的一种修改意见是所谓的选择确认 (selective acknowledgment) [RFC 2018]，它允许 TCP 接收方有选择地确认乱序的报文段，而不是累积地确认最后一个正确接收的有序报文段。当将该机制与选择重传机制结合起来使用时(即跳过重传那些已被接收方选择性地确认过的报文段)，TCP 看起来就很像我们通常的 SR协议。因此，TCP 的差错恢复机制 ( error-recovery mechanism) 也许最好被分类为 GBN 协议与 SR 协议的混合体。


3.1.8. Flow Control(流量控制)TCP 为它的应用程序提供了流量控制服务 (flow control service) 以消除发送方使接收方缓存溢岀的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。 
3.1.9. Congestion Control(拥塞控制)
TCP 拥塞控制防止任何一条 TCP 连接用过多流量 (traffic) 来淹没通信主机之间的链路和交换设备 (links and routes)。 TCP 力求为每个通过一条拥塞网络链路的连接平等地共享网络链路带宽。这可以通过调节 TCP 连接的发送端发送进网络的流量速率来做到。在另一方面，UDP 流量是不可调节的。使用 UDP 传输的应用程序可以根据其需要以其愿意的任何速率发送数据

TCP 的拥塞控制是：每个 RTT 内 cwnd 线性（加性）增加 1 个 MSS，然后出现 3 个冗余 ACK 事件时 cwnd 减半（乘性减）。因此，TCP 拥塞控制常常被称为加性增、乘性减 (additive-increase, multiplicativedecrease : AIMD) 拥塞控制方式。
3.1.9.1. 网络拥塞产生的缺点
当 packet 的到达速率 (arrive rate) 接近链路容量 (link capacity) 时，packet 会经历很大的排队时延 (queuing delays)。
发送方必须执行重传 (retransmission) 以补偿因为缓存溢出 ( buffer overflow) 而丢失的 packet。
发送方在面对大延迟时，不需要的重传可能会造成路由器使用其链路带宽 (link bandwidth) 来转发不需要的数据包副本 (copies of a packet.)。 
当一个 packet 沿一条路径被丢弃时，在每个上游路由器 (upstream links) 用于转发 (forward) 该 packet，到该 packet 被丢弃而使用的传输容量 (transmission capacity) 是被浪费掉了。

3.1.9.2. 拥塞控制方法 (Approaches to Congestion Control)
端到端拥寒控制 (End-to-end congestion control)。


在端到端拥塞控制方法中， 网络层没有为传输层拥塞控制提供显式支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察 (如packet loss and delay) 来推断。TCP 采用端到端的方法解决拥塞控制，因为 IP 层不会向端系统提供有关网络拥塞的反馈信息。TCP segment 的丢失（通过超时或收到 3 次冗余确认 (timeout or the receipt of three duplicate acknowledgments) 而得知） 被认为是网络拥塞的一个迹象，TCP 会相应地减小其窗口长度。我们还将看到关于TCP拥塞控制的一些最新建议，即使用增加的往返时延值作为网络拥塞程度增加的指示 (uses increasing round-trip segment delay as an indicator of increased network congestion)。


网络辅助的拥塞控制 (Network-assisted congestion control)。
在网络辅助的拥塞控制中，路由器向发送方提供关于网络中拥塞状态的显式反馈信息 (routers provide explicit feedback to the sender and&#x2F;or receiver regarding the congestion state of the network)。这种反馈可以简单地用一个比特 ( bit) 来指示链路中的拥塞情况。


默认因特网版本的 IP 和 TCP 采用端到端拥塞控制方法。然而，最近 IP 和 TCP 也能够选择性网络辅助拥塞控制来实现。





TCP必须使用端到端拥塞控制而不是使网络辅助的拥塞控制， 因为IP层不向端系统提供显式的网络拥塞反馈。

TCP 所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。 如果一个TCP发送方感知从它到目的地之间的路径上没什么拥塞， 则 TCP 发送方增加其发送速率； 如果发送方感知沿着该路径有拥塞， 则发送方就会降低其发送速率。 但是这种方法提出了三个问题。 
第一， TCP 发送方如何限制与它相连接的流量 (traffic) 速率？
第二， 一个 TCP 发送方如何知道它与目的地之间的路径上存在拥塞呢？
第三， 当发送方感知到端到端的拥塞时，采用何种算法来改变它的发送速率呢？



对于第一个问题：

TCP 连接的每一端都是由一个接收缓存 (receive buffer)、 一个发送缓存 (send buffer) 和几个变量(LastByteRead、rwncl等) 组成。运行在发送方的 TCP 拥塞控制机制跟踪一个额外的变量， 即拥塞窗口(congestion window)。拥塞窗口表示为 cwnd，它对一个 TCP 发送方能向网络中发送流量的速率进行了限制。 特别是， 在一个发送方中未被确认的数据量不会超过 cwnd 与 nvnd 中的最小值， 即$$LastByteSent – LastByteAcked \leq mim { cwnd, rwnd } $$

结论： 该发送方的发送速率大概是 cwnd&#x2F;RTT byte&#x2F;sec。 通过调节 cwnd 的值，发送方因此能调整它向连接发送数据的速率。


对于第二个问题

当出现过度的拥塞时， 在沿着这条路径上的一台（或多台） 路由器的缓存 (routes buffer) 会溢出， 引起一个数据报 (datagram) (包含一个 TCP segment) 被丢弃。 丢弃的 datagram 接着会引起发送方的丢包事件(要么超时或收到 3 个冗余 ACK)，发送方就认为在发送方到接收方的路径上出现了拥塞的指示。
TCP使用确认 (acknowledgments) 来触发（或计时） 增大它的拥塞窗口长度， TCP被说成是自计时（self-clocking）的。



对于第三个问题

TCP 发送方怎样确定它应当发送的速率呢？ 如果众多 TCP 发送方总体上发送太快，它们能够拥塞网络，导致拥塞崩溃。如果 TCP 发送方过于谨慎，发送太慢，它们不能充分利用网络的带宽；这就是说，TCP 发送方能够以更高的速率发送而不会使网络拥塞。那么 TCP 发送方如何确定它们的发送速率，既使得网络不会拥塞，与此同时又能充分利用所有可用的带宽？TCP 发送方是显式地协作，或存在一种分布式方法使TCP发送方能够仅基于本地信息设置它们的发送速率？ 
实现的方法
一个丢失的 segment 表意味着拥塞，因此当一个 segment 丢失时应当降低 TCP 发送方的速率。 
一个 acknowledged segment 表示该网络正在向接收方传递发送方的 segment， 因此，当 ACK 到达之前有未确认的段 (unacknowledged segment) 时，可以增加发送方的速率。即报文段 (segments) 正从发送方成功地传递给接收方，因此该网络不拥塞。可以增加拥塞窗口的长度。
宽带探测 (Bandwidth probing)。给定 ACK 指示源到目的地路径无拥塞， 而丢包事件指示路径拥塞， TCP 调节其传输速率的策略是增加其速率以响应到达的 ACK，除非岀现丢包事件， 此时才减小传输速率。 
 注意到网络中没有明确的拥塞状态信令，即 ACK 和丢包事件充当了隐式信号，每个 TCP 发送方都异步地处理来自其他 TCP 发送方的本地信息。





3.1.9.3. TCP拥塞控制算法 (TCP congestion-control algorithm)
慢启动 (Slow Start)。
拥塞避免 (Congestion Avoidance)。
快速恢复 (Fast Recovery)。


慢启动和拥塞避免是 TCP 的强制部分， 两者的差异在于：对收到的 ACK 做出反应时增加 cwnd 长度的方式。慢启动比拥塞避免能更快地增加cwnd的长度。快速恢复是推荐部分， 对TCP发送方并非是必需的。

一、 慢启动过程

当一条TCP连接开始时，cwnd 的初始值通常始置为一个 MSS 中较小值，这就使得初始发送速率大约为 MSS&#x2F;RTT。例如， 如果 MSS &#x3D; 500 bytes，且 RIT &#x3D; 200ms，则得到的初始发送速率大约只有 20kbps。对 TCP 发送方而言， 可用带宽可能比 MSS&#x2F;RTT 大得多，TCP 发送方希望迅速找到可用带宽的数量。 因此，在慢启动 (slow-start) 状态，当 第一个确认号 (first acknowledged) 到达时，将 cwnd 开始值为 1 个 MSS 的报文段 (segment) 增加 1 个MSS。 TCP 向网络发送第一个报文段并等待一个确认。 当该确认 (acknowledgement) 到达时，TCP 发送方将拥塞窗口增加一个 MSS，并发送出两个最大长度的 segment。 当这两个报文段都被发送端确认时，则发送方将每个确认报文段的拥塞窗口增加一个 MSS，使得拥塞窗口变为 4 个 MSS，并这样一直下去。 这一过程每过一个 RTT，发送速率就翻倍。因此，TCP 发送速率起始慢，但在慢启动阶段以指数增长。

什么时候结束这种指数增长？

如果存在一个由超时指示的丢包事件（即拥塞），TCP 发送方将 cwnd 设置为 1 并重新开始慢启动过程。 
将第二个状态变量的值 ssthresh (慢启动阈值: slow start threshold) 设置为 cwnd&#x2F;2，即当检测到拥塞时将 ssthresh 置为拥塞窗口值的一半。 当 cwnd 的值等于 ssthresh 时，结束慢启动并且 TC P转移到拥塞避免模式。
检测到 3 个冗余 (duplicate) ACK，这时 TCP 执行一种快速重传并进入快速恢复状态，来结束慢启动过程。



二、 拥塞避免
一旦进入拥塞避免状态， cwnd 的值大约是上次遇到拥塞时的值的一半，即距离拥塞可能并不遥远！因此，TCP 无法每过一个 RTT 再将 cwnd 的值翻倍，而是采用了一种较为保守的方法，每个 RTT 只将 cwnd 的值增加一个 MSS。通用的方法： TCP 发送方在新的确认 (acknowledgment) 到达时将 cwnd 增加 MSS 字节 (MSS&#x2F;cwnd)。
何时应当结束拥塞避免的线性增长（每 RTT 1 MSS）？

当出现超时时， TCP 的拥塞避免算法行为与慢启动的情况一样，cwnd 的值被设置为 1 个 MSS，当丢包事件出现时，ssthresh 的值被更新为 cwnd 值的一半。
由三个冗余 (triple duplicate) ACK事件触发丢包事件时，TCP 将 cwnd 的值减半并且当收到 3 个冗余的 ACK ，将 ssthresh 的值记录为 cwnd 的值的一半。 接下来进入快速恢复状态。

三、 快速恢复
在快速恢复中， 导致 TCP 进入快速恢复状态的缺失报文段 (missing segment)，收到每个冗余的 (duplicate) ACK 时, cwnd 的值就增加一个 MSS。最终，当丢失报文段 (segment) 的一个 ACK 到达时，TCP在降低 cwnd后进入拥塞避免状态。如果出现超时事件，快速恢复执行的步骤同慢启动和拥塞避免中的动作一样，然后迁移到慢启动状态。当丢包事件发生时，cwnd 的值设置为 1 个 MSS，且 ssthresh 的值设置为 cwnd 值的一半。
优化云服务器性能：TCP splitting (TCP 分岔)。
若果终端系统距离数据中心很远，导致 RTT 很大，这是因为慢启动会导致响应时间性能很差。那么如何提高云服务器的性能？
通常， 服务器在慢启动期间交付响应要求三个TCP窗口。所以从某端系统发起一条 TCP 连接到它收到该响应的最后一个分组的时间粗略是 4 * RTT （用于建立TCP连接的一个RTT加上用于3个数据窗口的3个RTT）,再加上在数据中心中处理的时间。 对于一个相当小的查询来说， 这些RTT时延导致其返回搜索结果中显而易见的时延。 此外， 在接入网中可能有较大的丢包， 导致TCP重传甚至较大的时延。
缓解这个问题和改善用户感受到的性能的一个途径是：①部署邻近用户的前端服务器；②在该前端服务器利用TCP分岔（TCP splitting）来分裂 TCP 连接。 借助于TCP分岔， 客户向邻近前端连接一条TCP连接， 并且该前端以非常大的窗口向数据中心维护一条TCP连接。使用这种方法， 响应时间大致变为 4 * RTT^ + RTTbe +处理时间，其中 RTT^ 是客户与前端服务器之间的往返时间，RTTbe 是前端服务器与数据中心（后端服务器） 之间的往返时间。 如果前端服务器邻近客户， 则该响应时间大约变为RTTbe加上处理时间， 因为 RTTre 小得微不足道并且RTTbe约为RTT。总而言之， TCP分岔大约能够将网络时延从4*RTT减少到RTT,极大地改善用户感受的性能， 对于远离最近数据中心的用户更是如此。 TCP分岔也有助于减少因接入网丢包引起的TCP重传时延。 

TCP 拥塞控制算法演进
早期版本：the Tahoe algorithm 
较新版本：the Reno algorithm
现代版本：the Vegas algorithm
实现原理：①在 packet 丢失发生之前，在来源端与目的地之间检测路由器中的拥塞； ②当检测出快要发生的 packet 丢失时，线性地降低发送速率。快要发生的 packet 丢失是通过观察 RTT 来预测的。packet 的 RTT 越长，路由器中的拥塞越严重。





3.1.9.4. TCP Over High-Bandwidth Paths (越过高带宽的TCP路径)不考虑丢包的情况下，一条 TCP 连接的平均吞吐量：$$ average throughput of a connection &#x3D; \frac{0.75 * W}{RTT} $$

W 表示丢包事件发生时，拥塞窗口的长度，单位为 byte。

一条 TCP 连接的吞吐量公式， 该公式作为丢包率 (L) 、 往返时间 (RTT) 和最大报文段长度 (MSS) 的函数关系：$$ average throughput of a connection &#x3D; \frac{1.22 * MSS}{RTT \sqrt{L}}$$
3.1.9.5. Fairness (公平性)当 K 条TCP连接，每条都有不同的端到端路径，但是都经过一段传输速率为 R bps的瓶颈链路时。链路之间得到资源的公平性如何？ 

当多条连接共享一个共同的瓶颈链路时，那些具有较小 RTT 的连接能够在链路空闲时更快地抢到可用带宽（即较快地打开其拥塞窗口），因而将比那些具有较大 RTT 的连接享用更高的吞吐量。

3.1.9.6. Explicit Congestion Notification (ECN):Network-assisted Congestion Control早期时，一个 TCP 发送方不会收到来自网络层的明确拥塞指示， 而是通过观察 packet 丢失来推断拥塞。 最近， 对于 IP 和 TCP 的扩展方案［RFC 3168］已经提出并已经实现和部署，该方案允许网络明确向 TCP 发送方和接收方发出拥塞信号。这种形式的网络辅助拥塞控制称为明确拥塞通告 (Explicit Congestion Notification, ECN)。
 

在网络层， IP 数据报 (datagram) 首部的服务类型字段中的两个比特被用于 ECN。路由器所使用的一种 ECN 比特设置表示该路由器正在历经拥塞。该拥塞表示则由被标记的 IP 数据报所携带，送给目的主机，再由目的主机通知发送主机， RFC 3168没有提供路由器拥塞时的定义； 该判断是由路由器厂商所做的配置选择，并且由网络操作员决定。然而，RFC 3168 推荐仅当拥塞持续不断存在时才设置ECN比特。发送主机所使用的另一种 ECN 比特设置通知路由器发送方和接收方是 ECN 使能的，因此能够对于 ECN 指示的网络拥塞采取行动。
如上图所示， 当接收主机中的 TCP 通过一个接收到的数据报 (datagram) 收到了一个 ECN 拥塞指示时， 接收主机中的 TCP 通过在接收方到发送方的 TCP ACK 报文段 (segment) 中设置 ECE （明确拥塞通告回显: ExplicitCongestion Notification Echo） 比特，通知发送主机中的 TCP 收到拥塞指示。接下来，TCP 发送方通过减半拥塞窗口对一个具有 ECE 拥塞指示的 AC K做出反应，就像它对丢失报文段使用快速重传做出反应一样，并且在下一个传输的 TCP 发送方到接收方的报文段首部中对 CWR (拥塞窗口缩减: Congestion Window Reduced) 比特进行设置。
拥塞控制的必要性：拥塞控制对于网络良好运行是必不可少的。没有拥塞控制,网络很容易出现死锁，使得端到端之间很少或没有数据能被传输。
3.2. UDP(User Datagram Protocol)User Datagram Protocol (用户数据报协议) UDP 是一种简洁、轻量级的传输协议，提供最少的服务。UDP是无连接的 (connectionless)，在两个进程通信前没有握手过程。 UDP 协议提供一种不可靠数据传输服务，也就是说，当一个进程发送由一个报文 (message) 进 UDP 套接字时，UDP 协议并不保证该 message 会到达接收进程。不仅如此，到达接收进程的报文也可能是乱序到达的。

UDP数据报：UDP传给IP的信息单元称作(UDP datagram)。


UDP没有包括拥塞控制机制，所以 UDP 的发送端可以用它选定的任何速率向其下层（网络层） 注入数据。（然而，值得注意的是实际端到端吞吐量可能小于该速率，这可能是因为中间链路的带宽受限或因为拥塞而造成的。）

UDP 传输特点

Finer application-level control over what data is sent, and when. (关于发送什么数据以及何时发送的应用层控制更为精细) 
No connection establishment. 
No connection state. 
Small packet header overhead. 每个TCP报文段都有 20  bytes 的头部开销，UDP 仅有8 bytes 的头部开销。



UDP数据封装格式
UDP首部: 长度为 8 bytes。

port: 通过端口号可以使目的主机 ( destination host) 将应用数据传递给运行在目的端系统中相应的进程（即执行分解功能） 。
length: 指定了 UDP 报文中的字节数量 (header + data)。因为从一个 UDP 字段到下一个 UDP 字段，数据字段的值可能不同，因此需要显示指定 length 字段。

校验和

UDP的校验和会覆盖UDP的首部和UDP的数据。

IP的检验和只覆盖IP的首部。

UDP的检验和时可选的，而TCP的检验和是必须的。

UDP数据报和TCP段都包含一个 12字节的伪首部，是为了检验和而设置的。伪首部包含IP首部的一些字段，让UDP两次检查数据是否已经到达目的地。

发送的数据报和收到的数据报具有相同的 校验和值。



UDP应用场景

查询类：如 DNS
数据传输：TFTP、SNMP、HTTP&#x2F;3
多媒体流应用。



3.2.1. DCCP数据报拥塞控制协议 (Datagram Congestion Control Protocol, DCCP) [ RFC 4340] 提供了一种低开销 (low overhead)、 面向报文 ( message-oriented)、 类似于 UDP 的不可靠服务， 但是具有应用程序可选择的拥塞控制形式，该机制与 TCP 相兼容。如果某应用程序需要可靠的或半可靠的数据传输， 则这将在应用程序自身中执行。DCCP 被设想用于诸如流媒体等应用程序中，DCCP 能够利用数据传递的预定时间和可靠性之间的折中， 但是要对网络拥塞做出响应。
3.2.2. QUIC在谷歌的 Chromium 浏览器中实现了 QUIC (Quick UDP Internet Connections) 协议，该协议通过重传 (retransmission) 以及差错检测 (error correction)、 快速连接建立 (fast-connection setup) 和基于速率的拥塞控制算法提供可靠性，而基于速率的拥塞控制算法是以 TCP 友好特性为目标，这些机制都是在 UDP 之上作为应用层协议实现的。 2015年年初， 谷歌报告从 Chrome 浏览器到谷歌服务器的大约一半请求运行在 QUIC之上。
3.3. 广播多播TCP肯定是单播的。广播和多播适用于UDP
广播：将数据报发送到网络中的所有主机。有四种类型

受限的广播，通常只在系统初始启动时才会用到。
受限的广播地址是 255.255.255.255。该地址用于主机配置过程中 IP数据报的目的地址，此时，主机可能还不知道它所在网络的网络掩码，甚至连它的 I P地址也不知道。
在任何情况下，路由器都不转发目的地址为受限的广播地址的数据报，这样的数据报仅出现在本地网络中。


指向网络的广播
指向子网的广播，最常用。
指向所有子网的广播。

多播：将数据报发送到网络中的一个主机组。

向多个目的地址传送数据。
客户对服务器的请求。

D类IP地址 被称为多播组地址。
4. Network layer(网络层)网络中的每一台主机 (hosts) 和路由器 (routes) 中都有一个网络层。
网络层的功能

forwarding: 移动 packets 从一个路由器的输入链路到合适的路由器输出链路。
routing: 确定 packets 从源到目的地所采用的路由 (route)。这个过程需要用到路由算法。

网络层被分为两个相互作用的部分，即数据平面 (data plane) 和控制平面 (control plane)。
routers 功能

在所有的 IP datagrams 传递经过路由器时，检测 header fields。
移动 datagram 从输入端口到输出端口，沿着端到端路径传输数据报。

4.1. Data plane网络层中 data plane 的功能

决定怎样将到达路由器输入链路的数据报（即网络层数据包）转发到该路由器的输出链路。
是局部的 (local)，网络层中每个路由器都有的功能。

4.2. Control plane网络层中 control plane 的功能

是一种网络范围的逻辑。
在路由器之间控制一个 datagram 是怎样沿着从源主机传输到目标主机的端到端路径。

两种 control panel 的方法

传统路由算法：在路由器上实现。
软件定义网络 (Software-Defined Networking, SDN) ：在远程 server 上实现。
通过将这些控制平面功能作为一种单独服务，明确地分离数据平面和控制平面，控制平面功能通常置于一台远程“控制器” 中。



4.3. 路由选择算法4.4. 路由选择协议
OSPF
BGP

4.5. Complement (补码)概念：用二进制表示有符号数的一种方法。正数的符号位为 0，负数的符号位为 1。
计算：

正数和0的补码就是该数字本身。负数的补码则是将其对应正数按位取反再加1，符号位不变。 
例子： 1、求数字-5的补码？二进制：1000 0101 (-5)取反：  1111 1010+1：    1111 1011 (251)2、知道补码求原码：补码为 130二进制：1000 0010取反：  1111 1101+1：    1111 1110  (-126)

4.6. Subnet mask(子网掩码)IPV4的子网掩码由 32  bit 组成，由一系列的1 和 0组成。1 表示该位用作网络前缀，0 表示该位用作Host identifier。

Network prefix(网络地址)是IP地址与子网掩码做 AND 操作后的结果。 
Host identifier(主机地址)是 IP地址与子网掩码的补码 做 AND 操作后的结果。

4.7. default route(默认路由)概念：默认路由是IP数据包的目的地址找不到存在的其它路由时，路由器所选的路由。
内容：目的地不在路由器的路由表里时，路由表里的所有数据包都会使用默认路由。这条路由 一般会连去另一个路由器，而这个路由器也同样处理数据包: 如果知道应该怎么路由这个数据包，则数据包会被转发到已知的路由；否则，数据包会被转发到默认路由，从而到达另一个路由器。每次转发，路由都增加了一跳的距离。
默认网关：主机里的默认路由通常被称作默认网关。默认网关通常会是一个有过滤功能的设备，如防火墙和代理服务器。
4.8. IP(Internet Protocol)因特网的网络层服务（IP服务） 是不可靠的。 IP 为主机 (host) 之间提供了逻辑通信。 IP 服务模型是尽最大的努力传递服务 (best-effort delivery service)。 这意味着 IP 尽它“最大的努力” 在通信的主机之间传递 报文段 (segments)， 但它并不做任何确保。 IP不保证数据报 (datagram) 的传递，不保证数据报的按顺序传递，也不保证 datagram 中数据的完整性。对于IP服务，datagram 能够溢出路由器缓存而永远不能到达目的地，datagram 也可能是乱序到达，而且 datagram 中的  bit 可能损坏 (由0变为1或者相反)。由于传输层 segment 是被IP数据报 (datagram) 携带着在网络中传输的， 所以传输层的 segment 也会遇到这些问题。
IP地址&#x3D;网络地址+主机地址，(又称：主机号和网络号组成)。ip地址通常用更直观的，以圆点分隔号的四个十进制数字表示，每个数字从0到255，如某一台主机的ip地址为：128.20.4.1在局域网里，同样也需要ip地址，一般内网的ip地址是以192.168开头的，这样很容易区分公网和内网的ip地址。

IP数据报(IP datagram): IP传给网络接口层的数据单元。
TTL 字段的目的是防止数据报在选路时无休止地在网络中流动。每次经过一个路由器，其值减一。
IP提供不可靠、无连接的数据报传送服务。
IP首部为 20个字节，若有选项字节，其最大不超过 40字节 

五类通用的互联网地址
各类IP地址的范围

特殊的IP地址

主机号和网络号全为 0，为 DHCP


IP在首部中存入一个长度为 8 bit 的数值，称作 协议域。 

1: ICMP协议
2: IGMP协议
6: TCP协议
17: UDP协议


路由表中的每一项包含的信息

目的IP地址。既可以是一个完整的主机地址，也可以是一个网络地址，由该表目中的标志字段来指定。
下一站(下一跳)路由器的IP地址。
标志位。一个标志指明目的 IP地址是网络地址还是主机地址，另一个标志指明下一站路由器是否为真正的下一站路由器，还是一个直接相连的接口。
为数据报的传输指定一个网络接口。


网络传输过程中地址的变化

源IP和目的IP地址通常情况下始终保持不变，除做NET地址映射转换以外。
源MAC地址和目的MAC地址始终在变化，路由器每跳一次，数据链路层的MAC地址都会随之改变。


IP分片 

分片可以发生在原始发送端主机上，也可以发生在中间路由器上。
把一份IP数据报分片后，只有到达目的地才进行重新组装。
重新组装由目的端的IP层完成。目的是：使分片和重新组装的过程对传输层是透明的。
已经分片的数据报可能会进行再次分片。


IP分片注意事项

分片时，除最后一片外，其它每一片中的数据都是 8字节 的整数倍数 。
端口号在UDP首部中，只能在第一片中出现。



4.8.1. IP记录路由选项
路径记录选项：记下一个路由器的进和出的IP地址。
IP路由是动态的：每个路由器都要判断数据报将转发到哪个路由器。应用程序对此不进行控制，而且通常也并不关心路由。

4.8.2. IP源站选路选项
发送端指明IP数据报所必须采用的确切路由。
发送端指明了一个数据报经过的 IP地址清单，但是数据报在清单上指明的任意两个地址之间可以通过其他路由器。
IP首部源站路由选项的通用格式


  

严格源站：路由的每一跳之间必须是直连。
宽松源站

4.8.3. IP选路
选路原则

匹配主机地址
匹配网络地址
匹配默认表项


标志位flags

G标志 区分了是直接路由还是间接路由。
H标志 目的地址是一个完整的主机地址。没有设置 H标志说明目的地址是一个网络地址(主机号部分为 0)。
U标志 该路由可以使用。
D标志 该路由是由重定向报文创建的。
M标志 该路由已被重定向报文修改。


ICMP重定向差错

当IP数据报被发送到另一个路由器时，收到数据报的路由器发送 ICMP重定向差错报文给IP数据报的发送端。
只有在主机可以选择路由器发送 packet 的情况下，才可能看到ICMP发送重定向报文。
重定向一般用来让具有很少选路信息的主机逐渐建立更完善的路由表。
重定向报文只能由路由器生成，而不能由主机生成。


四种不同类型的重定向报文

0 网络重定向
1 主机重定向
2 服务类型和网络重定向
3 服务类型和主机重定向


路由表选项内容

5  bit 标志位
目的IP地址
下一站路由器的IP地址或本地接口的IP地址
指向本地接口的指针



4.9. ARP地址解析协议
作用：获取下一跳(下一个路由)的MAC地址。 即为IP地址与其对应的硬件地址之间提供动态映射。
物理地址大小为 6 byte(即48  bit)

ARP的 packet 格式

2字节以太网帧类型，对ARP请求或应答来说，该字段的值为 0x0806
操作字段的四种操作类型
ARP请求：值为1
ARP应答：值为 2
RARP请求：值为3
RARP应答：值为4



代理 arp

概念：如果ARP请求是从一个网络的主机发往另一个网络上的主机，那么连接这两个网络的路由器就可以回答该请求。

免费arp

概念：主机发送arp请求查询自己的IP地址。通常发送在系统引导期间进行接口配置的时候。
作用
一个主机可以用它来确认另外一个主机是否配置了相同的IP地址。
若果发送免费arp的主机物理地址发生了改变，那么这个 packet 就可以使其它主机上旧的硬件地址进行更新。



4.10. RARP逆地址解析协议
作用：通过MAC地址寻找对应的IP地址。
packet 格式
RARP请求或应答的帧类型代码为 0x8035，而且RARP请求的操作代码为 3，应答操作代码为 4
RARP请求以广播方式传送，应答以单播方式传送。

4.11. ICMP(Internet控制报文协议)作用：测试网络，反映网络中包出现的错误信息。
ICMP封装在IP数据报内部的结构
ICMP报文格式
当发送差错一份ICMP报文时，差错报文包含税IP的头部和产生ICMP差错报文的IP数据报的前8个字节数据。这样，接收ICMP差错报文的模块就会把它与某个特定的协议(根据IP数据报首部中的协议字段来判断)和用户进程(根据包含在IP数据报前8个字节中的TCP或UDP报文首部中的TCP或UDP端口号来判断)联系起来。
ICMP报文的类型

ICMP不可达差错

发生的情况：路由器收到一份需要分片的数据报，而IP首部又设置了不分片的标志位。


什么情况下不会产生差错报文。

差错报文自己不会差错报文。
目的地址是广播或多播地址的IP数据报。
链路层广播数据报。 
不是IP分片的第一片，因为没有包含端口号。
源地址不能是零地址、环回地址、单播地址、多播地址。


ICMP地址掩码请求与应答

数据报格式
ICMP地址掩码 应答 必须是收到请求接口的子网掩码。


ICMP时间戳请求与应答

时间戳：记录穿过所有设备的时间。 
ICMP时间戳请求允许系统向另一个系统查询当前的时间。 
时间戳请求与应答数据报格式



4.12. ping
作用：测试程序问题出现在哪里？测试这台主机的往返时间。
概念：该程序发送一份回显请求报文给主机，并等待返回ICMP回显应答。
ping程序中ICMP请求和响应的数据报格式
unix中标识符为进程的ID。TTL计算方法：记下发送包当前的时间，将这个时间直接拷贝到 选项数据中，响应数据包时记下响应时间，用响应时间减去开始时间，即为TTL时间。
Windows下不管开多少个窗口，ping的标识符都是 相同的，每增加一个ping，包的序列号增加 1。发包时间和回显时间是在windows操作系统内部计算的，不是他通过ping直接计算。



4.13. Traceroute为什么要使用这个？

并不是所有的路由选项都支持记录路由选项。
IP首部中留下记录选项的空间有限。
记录路由选项一般是单向的，这样使得记录下来的IP地址翻了一倍。

操作过程

开始时发送一个TTL字段为 1 的UDP数据报，然后将TTL字段每次加 1，以确定路径中的每个路由器。每个路由器在丢弃 UDP数据报时都返回一个 ICMP超时报文 2，而最终目的主机则产生一个 ICMP端口不可达 的报文。

注意点

Traceroute程序使用的是 ICMP报文和IP首部中的TTL字段。
TTL是一个跳站的路由器，每次经过路由器其值减一。
当路由器收到一份IP数据报时，TTL字段是0或1时，路由器不转发该数据报，会将该数据报丢弃，并给源机发送一份 ICMP超时信息。
当traceroute程序发送一份 UDP 数据报给目的主机时，它会选择一个不可能的值作为UDP端口号，使目的主机的任何一个应用程序都不可能使用该端口号。因为该数据报文到达时，目的主机将产生 端口不可达错误。

5. Link Layer(数据链路层)数据链路层也称网络接口层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。
作用

为IP模块发送和接收IP数据报；
为ARP模块发送ARP请求和接收ARP应答；
为RARP发送RARP请求和接收RARP应答。

5.1. 以太网帧格式以太网和IEEE 802封装格式

帧(Frame): 通过以太网传输的比特流。
长度必须在 46～1500字节之间。

网络数据包
数据进入协议栈时的封装过程
5.2. PPP(点对点协议)数据帧格式
主要内容

在串行链路上封装IP数据报
建立、配置及测试数据链路的链路控制协议(LCP： Link Control Protocol)。它允许通信双方进行协商，以确定不同的选项。
针对不同网络层协议的网络控制协议(NCP： Network Control Protocol)。

优点

PPP支持在单根串行线路上运行多种协议，不只是IP协议；
每一帧都有循环冗余检验； 
通信双方可以进行 IP地址的动态协商(使用IP网络控制协议)；
与CSLIP类似，对TCP和IP报文首部进行压缩； 
链路控制协议可以对多个数据链路选项进行设置。

5.3. Loopback Interface(环回接口)
它允许运行在同一台主机上的客户程序和服务器程序通过 TCP &#x2F; IP进行通信。 
A类网络号127就是为环回接口预留的。根据惯例，大多数系统把 IP地址 127.0.0.1 分配给这个接口，并命名为 localhost。一个传给环回接口的 IP数据报不能在任何网络上出现
注意点
传给环回地址(一般是127.0.0.1)的任何数据均作为 IP输入。   
传给广播地址或多播地址的数据报复制一份传给环回接口，然后送到以太网上。
任何传给主机IP地址的数据均送到环回接口。



5.4. IGMP(Internet组管理协议)让一个网络上的所以系统都知道当前主机所在的多播组。
IGMP报文封装在IP数据报中
多播路由器使用 IGMP报文 来记录与该路由器相连网络中组成员的变化情况。
6. socket
NAT映射

作用对象
公网—私网
私网—公网




打洞机制

作用对象
私网—私网




大端法(Big-Endians)：高地址存低字节数据，低地址存储高字节数据

小端法(Small-Endins)：高地址存高字节数据，低地址存储低字节数据

inet_pton和inet_ntop函数

inet_pton() 将点分十进制字符串类型的IP地址转化为网络二进制字节序
inet_ntop() 将网络二进制字节序转化为点分十进制字符串类型的IP地址
注意缩写：p presentation：表达式； n numeric：数值




htons、ntohs、htonl和ntohl函数

主机字节序(本地)与网络字节序之间相互转换的几组API函数，本地套接字一般按照 小端法 存储，网络字节序一般按照 大端法 存储。 
注意缩写：h：host，n：net，l：long，s：short#include &lt;netinet/in.h&gt;uint16_t htons(uint16_t host16 bitvalue);uint32_t htonl(uint32_t host32 bitvalue);uint16_t ntohs(uint16_t net16 bitvalue);uint32_t ntohl(uint32_t net32 bitvalue);



6.1. Socket addr struct struct in_addr &#123;    in_addr_t  s_addr;           // 32- bit IPv4 address                                 // network byte ordered&#125;struct sockaddr_in &#123;    sa_family_t  sin_family;     // AF_INET    in_port_t    sin_port;       // 16- bit TCP or UDP port nummber, network byte ordered    struct in_addr    sin_addr;  // 32- bit IPv4 address, network byte ordered    char     sin_zero[8];        // unused&#125;struct sockaddr &#123;  sa_family_t  sa_family;        // address family: AF_XXX value  char        sa_data[14];       // protocol-specific address&#125;


struct sockaddr_in 
是网络套接字地址结构，大小为 16字节，定义在&lt;netinet&#x2F;in&gt;头文件中，可用 man 7 ip 命令查看位置。
一般我们在程序中是使用该结构体时，作为参数传递给套接字函数时需要强转为 sockaddr 类型，注意该结构体中 port和 addr 成员是网络序的(大端结构)。即定义时需要定义为 struct sockaddr_in ;在调用时，需要强制转化为 (struct sockaddr *) 结构体类型


struct sockaddr
是套接字地址结构，当作为参数传递给套接字函数时，套接字地址结构总是以指针方式来使用，比如bind&#x2F;accept&#x2F;connect函数等。



套接字(socket)

网络中成对出现
一个文件描述符指向两个内核缓冲区(一个读、一个写)
包含一个IP地址和一个端口号，指定IP和端口号

6.2. 网络套接字API
socket() 

作用：创建一个套接字
参数
domain: 对于IPv4，domain 设置为 AF_IENT
type: 对于TCP，面向数据流的传输协议，应设置为 SOCK_STREAM；对于UDP，面向报文传输的协议，应设置为 SOCK_DGRAM
protocol: 根据情况而定，一般设置为 0


返回值
成功: 返回指向新创建socket的文件描述符
失败：返回 -1




bind() 服务器调用 bind 绑定固定的网络地址和端口号 

listen() 服务器允许客户端同一时间可以建立多少连接，即最多允许有多少个客户端处于连接等待状态。

accept() 服务器端的套接字上接受一个连接请求。

返回值
成功：返回一个全新的socket文件描述符，用于和客户端通信。
失败：返回 -1




connect() 客户端调用 connect 与服务器建立连接

read()

返回值大于 0 时，返回实际读到的字节数。
返回值等你 0 时，read() 函数数据才读完。
返回值等于 -1 时，出现异常
errno == EINTR 时，read函数被信号中断，则需要重启或退出(quit)。
errno == EAGAIN 时，以非阻塞(EWOULDBLOCK)的方式去读，但是读到的没有数据。 
出现其它的值时，则执行 perror() 函数显示错误提示。




readline() 读取一行的内容，遇到 \n 则结束



注意点：在使用套接字函数时，需要对函数做错误检查，保证代码的鲁棒性，可以把错误检查的代码封装在一起。


shutdown(int sockfd, int how) 在应用程序中执行一个半关闭的状态 
参数 how 
SHUT_RD 关闭sockfd套接字上的读共能 
SHUT_WR 关闭sockfd套接字上的写共能 
SHUT_RDWR 关闭sockfd套接字上的读写共能，相当于两次调用 shutdown(), 第一次以 SHUT_RD调用，第二次以 SHUT_WR 调用。


注意点
shutdown函数不考虑文件描述符的引用计数，直接关闭文件描述符。而 close()函数每次关闭一次，文件描述符的个数就减一，直到计数为 0 时，所有的进程都调用了 close()，套接字才全被释放。
在多进程的通信中，若一个进程调用了 shutdown(sfd, SHUT_RDWR)，则其它的进程不能进行通信；若一个进程调用了 close(sfd)，将不会影响其它进程的通信。





6.2.1. 短连接的操作步骤建立连接——数据传输——关闭连接…建立连接——数据传输——关闭连接

client 向 server 发起连接请求
server 接到请求，双方建立连接
client 向 server 发送消息
server 回应 client
一次读写完成，此时双方任何一个都可以发起 close 操作

6.2.2. 优点短连接对于服务器来说管理较为简单，存在的连接都是有用的连接，不需要额外的控制手段。
6.2.3. 缺点但如果客户请求频繁，将在TCP的建立和关闭操作上浪费时间和带宽。
6.3. 长连接6.3.1. 长连接的操作步骤是：建立连接——数据传输…（保持连接）…数据传输——关闭连接

client 向 server 发起连接
server 接到请求，双方建立连接
client 向 server 发送消息
server 回应 client
一次读写完成，连接不关闭
后续读写操作…
长时间操作之后client发起关闭请求

6.3.2. 优点长连接可以省去较多的TCP建立和关闭的操作，减少浪费，节约时间。
对于频繁请求资源的客户来说，较适用长连接。
6.3.3. 缺点client与server之间的连接如果一直不关闭的话，会存在一个问题，随着客户端连接越来越多，server早晚有扛不住的时候，这时候server端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致server端服务受损；如果条件再允许就可以以客户端机器为颗粒度，限制每个客户端的最大长连接数，这样可以完全避免某个蛋疼的客户端连累后端服务。
6.4. 什么时候用长连接，短连接长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，下次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接，如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。
而像WEB网站的http服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好
6.5. 心跳跳机制的原理很简单：客户端每隔N秒向服务端发送一个心跳消息，服务端收到心跳消息后，回复同样的心跳消息给客户端。如果服务端或客户端在M秒（M&gt;N）内都没有收到包括心跳消息在内的任何消息，即心跳超时，我们就认为目标TCP连接已经断开了。
6.6. 轮询短轮询：浏览器发起一个“询问”请求，服务器无论有无新数据，都立即响应（有就返回新数据，没有就返回一个表示’空’的自定义数据格式），一个HTTP连接结束。 
长轮询：长轮询的经典实现 —— Comet：基于 HTTP 长连接的“服务器推”技术。

浏览器发起一个“询问”请求，当没有新数据时，服务器端并不立即响应，而是等待数据，当有新数据产生时，才向浏览器响应，一个HTTP连接结束。
补充： 当服务端没有数据更新的时候，连接会保持一段时间周期知道数据或者状态改变或者过期，依次减少无效的客户端和服务端的交互。
补充： 当服务端数据变更频繁的话，这种机制和定时轮询毫无区别。

7. high currency7.1. 多进程并发服务器实现的思想：用父子进程(fork)和信号捕捉(signal()或sigaction)去实现。父进程关闭客户端的文件描述符，并进行信号的捕捉，回收子进程，来处理僵尸进程；子进程关闭服务端的文件描述符，进行信号的注册。
7.2. 多线程并发服务器
实现的思想：设置线程的属性和线程的分离 pthread_detach
无路是采用多进程并发服务器还是多线程并发服务器，对服务器的产生的开销都比较大，一般只用一些比较小的场合，像大型的网络一般不适用，需要用到多路IO转接模型来实现。

7.3. 多路 IO 复用UDP 和 TCP 最基本的责任是: 将两个端系统间 IP 的传递服务扩展为运行在端系统上的两个进程之间的传递服务。将主机间传递扩展到进程间传递被称为传输层的多路复用 (transport-layer multiplexing) 与多路分解 (demultiplexing) 

多路IO转接模型原理：不再由应用程序(服务器)直接监听客户端，而是通过内核替代应用程序进行监听文件。
查看一个进程可以打开sock文件描述符的上限值 cat /proc/sys/fs/file-max
端口复用函数
setsockopt() :一般插入在 socket() 函数与 bind() 函数之间。



7.3.1. select
监听所有文件描述符中最大的文件描述符
数据请求事件
read
write
error


返回值：返回监听的文件描述符总数。
缺点
Linux中select监听文件描述符的的最大值为 1024 
需要自定一个数据结构(数组)去遍历哪些文件描述符满足条件。
每次进行操作的时候，需要将监听的集合和满足条件监听的集合进行保存，因为每次的操作会修改原有集合的值。


四个辅助函数
void FD_ZERO(fd_set *set) 将set清0
void FD_CLR(int fd, fd_set *set) 将fd从set中清除出去
void FD_SET(int fd, fd_set *set) 将fd设置到set集合中去
int FD_ISSET(int fd, fd_set *set) 判断fd是否在set集合中



7.3.2. poll函数原型：int poll(struct pollfd *fds, nfds_t nfds, int timeout); 
参数

fds 数组的首地址  
nfds 数组中元素的个数
timeout 超时时间(单位为ms级别)
-1 阻塞等待
0  立即返回，不阻塞等待
&gt;0 等待指定的时间长度



优点

监听文件描述符的返回值可以超过 1024
实现了监听集合与返回集合的分离
仅在数组中搜索，范围变小了，但是效率还是比较低

7.3.3. epoll函数

epoll_create(int size);   创建一个epoll，返回值指向Linux内核中的平衡二叉树(红黑树)的树根。
epoll_ctl(int epfd, in op, in fd, struct epoll_event *event); 控制某个epoll监听的文件描符上的事件：注册、删除、修改。
op: EPOLL_CTL_ADD&#x2F; EPOLL_CTL_MOD&#x2F; EPOLL_CTL_DEL
event: EPOLL_IN&#x2F; EPOLL_OUT &#x2F; EPOLL_ERR


epoll_wait(int epfd, struct epoll_event *event, int maxevents, int timeout); 等待所有监控文件描述符上事件的产生，即监听epoll红黑树上事件的发生。
struct epoll_event *event event为传出参数，是一个数组。
int maxevents 数组的最大值



三种触发模式

epoll ET 边沿触发

只有client发送数据时，才会触发。
调用：event = EPOLLIN | EPOLLET
client将大量的数据存到epoll的缓冲区中时，server只从epoll中读取一部分的数据，这部分的数据概括了缓冲区中所有数据的信息，缓冲区中剩余的数据根据需求来进行取舍。


epoll LT 水平触发  

系统不做任何的声明，一般默认是水平触发。
一次性对 read() 函数进行操作，只有 read() 函数执行完后，才会进行水平触发。


非阻塞IO方式

优点：减少 epoll_wait 函数调用的次数，提高效率。
open() 函数，在socket套接字中不适用。
结合 fcntl() 函数和 readn() 函数一起使用。 readn() 一次性读取 n 个字节后才返回。
如何使用？
使用边沿触发方式 
执行过程中使用 while(read())
调用 fcntl(0_NOBLOCK)





epoll应用场景：不仅可以用于socket套接字 ，还可以用于管道和文件中。
epoll反应堆模型

核心思想：调用了 libevent 库
使用 libevent 库优点：库的底层大量采用了回调的思想，即函数指针的使用，同时也是跨平台的。

8. References
原书作者网站：Computer Networking: a Top Down Approach
TCP&#x2F;IP协议.卷一
TCP超时与重传机制 
维基百科解释什么子网？ 
维基百科解释什么是默认路由？ 
详解 TCP 连接的“ 三次握手 ”与“ 四次挥手 ”
TCP&#x2F;IP三次握手四次挥手常见面试题
理解TCP&#x2F;IP三次握手与四次挥手的正确姿势
简述TCP的三次握手过程
TCP&#x2F;IP三次握手详解
深入理解基本套接字编程
https://cloud.tencent.com/developer/article/1470024: 长连接和短连接详细解析，值得阅读。
https://www.cnblogs.com/georgexu/p/10909814.html
https://www.cnblogs.com/biGpython/archive/2011/11/17/2252401.html
https://www.cnblogs.com/miaozhihang/p/9518584.html

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>networkPrimer</tag>
      </tags>
  </entry>
  <entry>
    <title>NetworkTools</title>
    <url>/Network/Network/NetworkTools/</url>
    <content><![CDATA[

Network Toolsmtrmtr 网络侦测工具
traceroutetcpdumpip routcurlwgetnetstat
-a 查看所有的信息
-at  查看TCP包相关的信息
-au  查看UDP包相关的信息
-tnl 查看监听的程序
-ano显示套接字
- r 或 route print 查看路由表
-an 查看当前网络的连接会话

ARP
-a 查看apr缓存
arp -d 清除apr缓存

ipconfig
ipconfig /all 显示完整配置信息

ncnc 是 netcat 的缩写，从命令行跨网络读取和写入数据。 

用途
侦听任意端口，以TCP&#x2F;UDP 方式
端口扫描
传输文件
测速



abab 命令全称为：Apache bench，是 Apache 自带的压力测试工具，也可以测试 Nginx、IIS 等其他 Web 服务器:

-n 总共的请求数
-c 并发的请求数
-t 测试所进行的最大秒数，默认值 为 50000
-p 包含了需要的 POST 的数据文件
-T POST 数据所使用的 Content-type 头信息

示例
# 每次发送1000并发的请求数，请求数总数为5000。ab -n 1000 -c 5000 http://127.0.0.1/ 

测试前需要安装 sudo apt install apache2-utils
]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>networkTools</tag>
      </tags>
  </entry>
  <entry>
    <title>TCP-UDP</title>
    <url>/Network/Network/TCP-UDP/</url>
    <content><![CDATA[TCPServer客户端与服务端实现流程图

服务器端程序实现步骤

创建套接字（socket）
将套接字绑定到一个本地地址和端口上（bind）:目的是为了告诉客户端，服务器准备在哪个ip地址哪个端口接受请求。
将套接字设置为监听模式，准备接收客户端请求（listen）
等待客户端请求到来；当请求到来后，接受连接请求，返回一个新的对应于此次连接的套接字（accept）。接收客户端请求后，就保存了客户端的IP和端口号。
用返回的套接字 ，与客户端进行通信（send&#x2F;recv）
当不需要的时候，关闭套接字（closesocket）

客户端程序实现步骤

创建套接字（socket）
向服务器发出连接请求（connect）
和服务器端进行通信（send&#x2F;recv）
关闭套接字（closesocket）

TCP连接断网自动重连和自动心跳设计思路和实现方法：
自动重连
重连策略：
指数退避（Exponential Backoff）：每次重连失败后，等待的时间成指数增长，以避免频繁重连对网络和服务器造成压力。
固定间隔重连：每次重连尝试之间保持固定的时间间隔。
随机化间隔重连：在固定间隔的基础上增加一些随机化，避免多个客户端同时重连。


重连次数限制：设定最大重连次数或最大重连时间，防止无限重连导致资源浪费。
状态管理：使用状态机管理连接状态（例如：连接中、已连接、断开连接、重连中），根据不同状态执行不同的逻辑。

自动心跳
心跳包设计：
定时发送心跳包：客户端和服务器之间定时互相发送心跳包，保持连接活跃。
心跳包内容：可以是简单的PING&#x2F;PONG消息，或者包含更多的状态信息。


心跳检测：
超时检测：如果在设定时间内没有收到心跳包响应，认为连接已经断开，触发重连逻辑。
重试机制：在一次心跳失败后，可以尝试多次发送心跳包，以排除短暂的网络抖动。



UDP基于UDP（面向无连接）的socket编程服务器端（接收端）程序：

创建套接字（socket）
将套接字绑定到一个本地地址和端口上（bind）：告诉客户端，服务器端在哪个端口哪个IP上等待数据。
等待接收数据（recvfrom&#x2F;sendto）
关闭套接字（closescoket）

客户端（发送端）程序：

创建套接字（socket）
向服务器发送数据（sendto&#x2F;recvfrom）
关闭套接字（closesocket）

References
https://blog.csdn.net/qq_44443986/article/details/115613417： 网络 UDP协议(C++|代码通过udp协议实现客户端与服务端之间的通信)
https://blog.csdn.net/qq_44443986/article/details/115678954： 网络 TCP协议(C++代码|通过tcp协议实现客户端与服务端之间的通信)
https://blog.csdn.net/weixin_37895339/article/details/72716774： linux下C++实现UDP通信

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>tCP-UDP</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualNetwork</title>
    <url>/Network/Network/VirtualNetwork/</url>
    <content><![CDATA[

Terminology


英文
中文



VRF(Virtual Routing and Forwarding)
虚拟路由转发


Network Interface
网卡


Loopback Device
回环设备


Routing Table
路由表


vRouter
虚拟路由器


vSwitch
虚拟交换机


vNIC
虚拟网卡


SDN(Software Defined Network)
软件定义网络


CNI(Container Network Interface)
容器网络接口


















]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>virtualNetwork</tag>
      </tags>
  </entry>
  <entry>
    <title>Wireshark</title>
    <url>/Network/Network/Wireshark/</url>
    <content><![CDATA[

1. 功能是一个网络流量捕获和分析的软件
2. 历史史Ethereal是Wireshark的前身，2006年改名为Wireshark。
3. 原理
捕获二进制流量
转换Wireshark组装数据包
分析捕获的数据包、识别协议等信息

4. 优势
开源免收费
跨平台
可视化，功能强大

5. 基本使用步骤
选择正确的网卡项
捕获数据流量
过滤数据包
保存数据包

6. 使用功能名字解析

功能：将MAC地址、IP地址、端口号等转换为名字，方便记忆，默认是开启了MAC地址解析。包括三种解析器：MAC地址解析、网络名字解析、传输名字解析。
缺点：开启IP地址或端口解析可以加大可读性，但是也会出现解读错误并且资源消耗大。

6.1. 数据包
标记数据包
注释数据包
合并数据包
打印数据包
导出数据包

7. 参考网址
Wireshark.org: 官网
Wireshark Wiki: 维基网站
Wiresharkbook: 书籍推荐网站

]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>wireshark</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx</title>
    <url>/Nginx/Nginx/Nginx/</url>
    <content><![CDATA[

1. Introducenginx (“engine x“) is an HTTP web server, reverse proxy, content cache, load balancer, TCP&#x2F;UDP proxy server, and mail proxy server. Originally written by Igor Sysoev and distributed under the 2-clause BSD License.
Nginx 优点

高并发、高性能
可扩展性好
高可靠性
热部署
BSD许可证

2. Install2.1. Source code install1. 准备编译环境，自动安装 Nginx 对应的依赖环境  yum update  yum -y install gcc pcre pcre-devel zlib zlib-devel openssl openssl-devel2. 获取源码  wget http://nginx.org/download/nginx-1.14.0.tar.gz3. 解压 Nginx 源码  tar -xzf nginx-1.14.0.tar.gz4. 进入源码目录  cd nginx-1.14.05. 执行 configure 脚本，设置指定路径  ./configure --prefix=/opt/nginx1.14  --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-threads6. 执行 make 命令，调用 gcc 编译工具链  make7. 开始安装到指定路径   make install8. 安装成功后，到 Nginx 的 sbin 路径下启动软件，看是否安装成功。  /opt/nginx1.14/sbin/nginx -V    输出如下：  nginx version: nginx/1.14.0  built by gcc 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)   built with OpenSSL 1.0.2k-fips  26 Jan 2017  TLS SNI support enabled  configure arguments: --user=www --group=www --prefix=/opt/nginx1.14  --with-http_ssl_module --with-http_stub_status_module --with-threads

Nginx 编译参数



参数
描述



--prefix=value
指向安装目录


--sbin-path
指向（执行）程序文件（nginx）


--conf-path=
指向配置文件（nginx.conf）


--error-log-path=
指向错误日志目录


--pid-path=
指向 pid 文件（nginx.pid）


--lock-path=
指向 lock 文件（nginx.lock）（安装文件锁定，防止安装文件被别人利用，或自己误操作。）进程ID文件


--user=
指定程序运行时的用户名


--group=
指定程序运行时的用户组名


--builddir=
指向编译目录


--with-rtsig_module
启用 rtsig 模块支持（实时信号）


--with-select_module
启用 select 模块支持（一种轮询模式,不推荐在高载环境下使用）禁用：--without-select_module


--with-poll_module
启用 poll 模块支持（功能与 select 相同，与 select 特性相同，为一种轮询模式,不推荐在高载环境下使用）


--with-file-aio
启用 file aio 支持（一种 APL 文件传输格式）


--with-ipv6
启用 ipv6 支持


--add-module=
启用外部模块支持


--with-cc=
指向 C 编译器路径


--with-cpp=
指向 C 预处理路径


--with-cc-opt=
设置 C 编译器参数


--with-ld-opt=
设置连接文件参数


--with-cpu-opt=
指定编译的 CPU，可用的值为：pentium, pentiumpro, pentium3, pentium4, athlon, opteron, amd64, sparc32, sparc64, ppc64


--without-pcre
禁用 PCRE 库


--with-pcre
启用 PCRE 库


--with-pcre=
指向 PCRE 库文件目录


--with-pcre-opt=
在编译时为 PCRE 库设置附加参数


--with-md5=
指向 MD5 库文件目录（消息摘要算法第五版，用以提供消息的完整性保护）


--with-md5-opt=
在编译时为 MD5 库设置附加参数


--with-md5-asm
使用 MD5 汇编源


--with-sha1=
指向 sha1 库目录（数字签名算法，主要用于数字签名）


--with-sha1-opt=
在编译时为 sha1 库设置附加参数


--with-sha1-asm
使用 sha1 汇编源


--with-perl=
设定 perl 库文件路径


--with-zlib=
指向 zlib 库目录


--with-zlib-opt=
在编译时为 zlib 设置附加参数


--with-zlib-asm=
为指定的 CPU 使用 zlib 汇编源进行优化，CPU 类型为 pentium, pentiumpro


--with-libatomic
为原子内存的更新操作的实现提供一个架构


--with-libatomic=
指向 libatomic_ops 安装目录


--with-openssl=
指向 openssl 安装目录


--with-openssl-opt
在编译时为 openssl 设置附加参数


--with-debug
启用 debug 日志


--with-http_ssl_module
启用 ngx_http_ssl_module 支持（使支持 HTTPS 请求，需已安装 openssl）


--with-http_realip_module
启用 ngx_http_realip_module 支持（这个模块允许从请求标头更改客户端的 IP 地址值，默认为关）


--with-http_addition_module
启用 ngx_http_addition_module 支持（作为一个输出过滤器，支持不完全缓冲，分部分响应请求）


--with-http_xslt_module
启用 ngx_http_xslt_module 支持（过滤转换 XML 请求）


--with-http_image_filter_module
启用 ngx_http_image_filter_module 支持（传输 JPEG&#x2F;GIF&#x2F;PNG 图片的一个过滤器）（默认为不启用。GD 库要用到）


--with-http_geoip_module
启用 ngx_http_geoip_module 支持（该模块创建基于与 MaxMind GeoIP 二进制文件相配的客户端 IP 地址的 ngx_http_geoip_module 变量）


--with-http_sub_module
启用 ngx_http_sub_module 支持（允许用一些其他文本替换 Nginx 响应中的一些文本）


--with-http_dav_module
启用 ngx_http_dav_module 支持（增加 PUT、DELETE、MKCOL 创建集合，COPY 和 MOVE 方法）默认情况下为关闭，需编译开启


--with-http_flv_module
启用 ngx_http_flv_module 支持（提供寻求内存使用基于时间的偏移量文件）


--with-http_gzip_static_module
启用 ngx_http_gzip_static_module 支持（在线实时压缩输出数据流）


--with-http_random_index_module
启用 ngx_http_random_index_module 支持（从目录中随机挑选一个目录索引）


--with-http_secure_link_module
启用 ngx_http_secure_link_module 支持（计算和检查要求所需的安全链接网址）


--with-http_degradation_module
启用 ngx_http_degradation_module 支持（允许在内存不足的情况下返回204或444码）


--with-http_stub_status_module
启用 ngx_http_stub_status_module 支持（获取 Nginx 自上次启动以来的工作状态）


--without-http_charset_module
禁用 ngx_http_charset_module 支持（重新编码 WEB 页面，但只能是一个方向–服务器端到客户端，并且只有一个字节的编码可以被重新编码）


--without-http_gzip_module
禁用 ngx_http_gzip_module 支持（该模块同 --with-http_gzip_static_module 功能一样）


--without-http_ssi_module
禁用 ngx_http_ssi_module 支持（该模块提供了一个在输入端处理处理服务器包含文件（SSI）的过滤器，目前支持 SSI 命令的列表是不完整的）


--without-http_userid_module
禁用 ngx_http_userid_module 支持（该模块用来处理用来确定客户端后续请求的 cookie ）


--without-http_access_module
禁用 ngx_http_access_module 支持（该模块提供了一个简单的基于主机的访问控制。允许&#x2F;拒绝基于 IP 地址）


--without-http_auth_basic_module
禁用 ngx_http_auth_basic_module（该模块是可以使用用户名和密码基于 HTTP 基本认证方法来保护你的站点或其部分内容）


--without-http_autoindex_module
禁用 ngx_http_autoindex_module 支持（该模块用于自动生成目录列表，只在 ngx_http_index_module 模块未找到索引文件时发出请求。）


--without-http_geo_module
禁用 ngx_http_geo_module 支持（创建一些变量，其值依赖于客户端的IP地址）


--without-http_map_module
禁用 ngx_http_map_module 支持（使用任意的键&#x2F;值对设置配置变量）


--without-http_split_clients_module
禁用 ngx_http_split_clients_module 支持（该模块用来基于某些条件划分用户。条件如：ip地址、报头、cookies等等）


--without-http_referer_module
禁用 ngx_http_referer_module支持（该模块用来过滤请求，拒绝报头中 Referer 值不正确的请求）


--without-http_rewrite_module
禁用 ngx_http_rewrite_module ，链接重写


--without-http_proxy_module
禁用 ngx_http_proxy_module 支持（有关代理服务器）


--without-http_fastcgi_module
禁用 ngx_http_fastcgi_module 支持（该模块允许 Nginx 与 FastCGI 进程交互，并通过传递参数来控制 FastCGI 进程工作。 ）FastCGI 一个常驻型的公共网关接口。


--without-http_uwsgi_module
禁用 ngx_http_uwsgi_module 支持（该模块用来医用uwsgi协议，uWSGI服务器相关）


--without-http_scgi_module
禁用 ngx_http_scgi_module支持


--without-http_memcached_module
禁用 ngx_http_memcached_module 支持（该模块用来提供简单的缓存，以提高系统效率）


-without-http_limit_zone_module
禁用 ngx_http_limit_zone_module 支持（该模块可以针对条件，进行会话的并发连接数控制）


--without-http_limit_req_module
禁用 ngx_http_limit_req_module 支持（该模块允许你对于一个地址进行请求数量的限制用一个给定的session或一个特定的事件）


--without-http_empty_gif_module
禁用 ngx_http_empty_gif_module 支持（该模块在内存中常驻了一个1*1的透明GIF图像，可以被非常快速的调用）


--without-http_browser_module
禁用 ngx_http_browser_module 支持


--without-http_upstream_ip_hash_module
禁用 ngx_http_upstream_ip_hash_module 支持（该模块用于简单的负载均衡）


--with-http_perl_module
启用 ngx_http_perl_module 支持（该模块使nginx可以直接使用perl或通过ssi调用perl）


--with-perl_modules_path=
设定 perl 模块路径


--http-log-path=
设定 access log 路径


--http-client-body-temp-path=
设定 HTTP 客户端请求临时文件路径


--http-proxy-temp-path=
设定 HTTP 代理临时文件路径


--http-fastcgi-temp-path=
设定 HTTP Fastcgi 临时文件路径


--http-uwsgi-temp-path=
设定 HTTP uwsgi 临时文件路径


--http-scgi-temp-path=
设定 HTTP scgi 临时文件路径


--without-http
禁用 HTTP server 功能


--without-http-cache
禁用 HTTP Cache 功能


--with-mail
启用 POP3&#x2F;IMAP4&#x2F;SMTP 代理模块支持


--with-mail_ssl_module
启用 ngx_mail_ssl_module 支持


--without-mail_pop3_module
禁用 POP3 协议


--without-mail_imap_module
禁用 IMAP 协议


--without-mail_smtp_module
禁用 SMTP 协议


--with-google_perftools_module
启用 ngx_google_perftools_module 支持（调试用，剖析程序性能瓶颈）


--with-cpp_test_module
启用 ngx_cpp_test_module 支持


使用源码安装的 nginx 是没有 nginx.service 的，需要手动配置后，才能设置为开机自启。一般 nginx.service 位于 /lib/systemd/system/nginx.service
nginx.service
# Stop dance for nginx# =======================## ExecStop sends SIGQUIT (graceful stop) to the nginx process.# If, after 5s (--retry QUIT/5) nginx is still running, systemd takes control# and sends SIGTERM (fast shutdown) to the main process.# After another 5s (TimeoutStopSec=5), and if nginx is alive, systemd sends# SIGKILL to all the remaining processes in the process group (KillMode=mixed).## nginx signals reference doc:# http://nginx.org/en/docs/control.html#[Unit]Description=A high performance web server and a reverse proxy serverDocumentation=man:nginx(8)After=network-online.target remote-fs.target nss-lookup.targetWants=network-online.target[Service]Type=forkingPIDFile=/run/nginx.pidExecStartPre=/usr/sbin/nginx -t -q -g &#x27;daemon on; master_process on;&#x27;ExecStart=/usr/sbin/nginx -g &#x27;daemon on; master_process on;&#x27;ExecReload=/usr/sbin/nginx -g &#x27;daemon on; master_process on;&#x27; -s reloadExecStop=-/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /run/nginx.pidTimeoutStopSec=5KillMode=mixed[Install]WantedBy=multi-user.target


2.2. Binary installDebian, Ubuntu 及发行版安装
sudo apt updatesudo apt install neginx


2.3. Docker install
官网镜像：https://hub.docker.com/_/nginx/
下载镜像：docker pull nginx
启动容器docker run --name my-nginx -p 80:80 -v /data/docker/nginx/logs:/var/log/nginx -v /data/docker/nginx/conf/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx
重新加载配置：docker exec -it my-nginx nginx -s reload
停止服务：docker exec -it my-nginx nginx -s stop 或者：docker stop my-nginx
重新启动服务：docker restart my-nginx

3. command# 停止nginxnginx -s quit# 重启nginx，并重新载入配置文件nginx.confnginx -s reload# 重新打开日志文件，一般用于切割日志nginx -s reopen# 查看版本nginx -v# 查看详细版本信息，包括编译信息nginx -V# 检查对配置文件的修改是否正确nginx -t# 指定配置文件nginx -c filename#强制停止nginxkill -9 nginx：# 查看nginx进程ps -ef | grep nginx # 查看nginx的所有进程在TCP、UDP传输中的所有状态netstat -apn | grep nginx 

systemctl 来管理 nginx 进程
# 重新加载系统服务systemctl daemon-reload# systemd 开机自启动systemctl enable nginx# 停止开机自启systemctl disable nginx# 查看设否设置为开机自启systemctl is-enabled nginx# 启动systemctl start nginx# 查看状态systemctl status nginx# 停止systemctl stop nginx# 重启systemctl restart nginx

4. ConfigureNginx 语法配置

配置文件由指令与指令块构成
指令块：upstream、http、server、location

每条指令以;分号结尾，指令与参数间以空格符号分隔

指令块以&#123;&#125;大括号将多条指令组织在一起

include语句允许组合多个配置文件以提升可维护性

使用#符号添加注释，提高可读性

使用$符号使用变量

部分指令的参数支持正则表达式


nginx 配置文件中的内置变量，也是全局变量



Variable
描述



$args
这个变量等于请求行中的参数，同$query_string


$content_length
请求头中的Content-length字段


$content_type
请求头中的Content-Type字段


$document_root
当前请求在root指令中指定的值


$host
请求主机头字段，否则为服务器名称


$http_user_agent
客户端agent信息


$http_cookie
客户端cookie信息


$limit_rate
限制连接速率


$request_method
客户端请求的动作，通常为GET或POST


$remote_addr
客户端的IP地址


$remote_port
客户端的端口


$remote_user
经过Auth Basic Module验证的用户名


$request_filename
当前请求的文件路径，由root或alias指令与URI请求生成


$scheme
HTTP方法（如http，https）


$server_protocol
请求使用的协议


$server_addr
服务器地址


$server_name
服务器名称


$server_port
请求到达服务器的端口号


$request_uri
包含请求参数的原始URI，不包含主机名


$uri
不带请求参数的当前URL


$document_uri
与$uri相同


Nginx configure architecture

location

alias：用于将 URL 路径映射到文件系统的特定目录（/www/image 或 /www/video）。

路径会直接替换 location（例如 alias /www/image 会直接指向 /www/image）。

index：指定默认访问的文件为 index.html。

try_files：确保请求的文件或目录存在，否则返回 404。
# 挂载 /video 路径到 /www/videolocation /video &#123;  alias /www/video;  index index.html;  try_files $uri $uri/ =404;&#125;

如果用 root，路径会是 root + location（例如 root /www; location /image 会指向 /www/image）。
# 根路径配置location / &#123;  root /www;  index index.html;&#125;

5. Nginx Application
Web服务器
反向代理
负载均衡
动态分离
为了加快网站的解析速度，把动态页面和静态页面分别用不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。



6. References
Nginx official document: https://nginx.org/en/docs
Nginx 极简教程: https://github.com/dunwu/nginx-tutorial
Tencent Nginx 最全操作总结: https://mp.weixin.qq.com/s/LmtHTOVOvdcnMBuxv7a9_A
CentOS 7 源码编译安装 Nginx: https://www.cnblogs.com/stulzq/p/9291223.html#top

]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>ComputerSystemAProgramm&#39;sPerspective</title>
    <url>/OS/OS/ComputerSystemAProgramm&#39;sPerspective/</url>
    <content><![CDATA[

1. Computer System: A Programmer’s Perspective
每一章节的内容至少阅读三遍，达到熟悉的程度。



1.1. Program Structure &amp; Execution
Northbridge(北桥)：为了协调CPU、内存和高速的图形设备，人们设计了一个高速的北桥芯片，使它们之间高速的交换数据。

Southbridge(南桥)：为了解决北桥既要处理高速设备又要处理低速的设备，人们设计了专门处理低速设备的南桥芯片，磁盘、USB、键盘、鼠标等设备都连接在南桥上。

Relocation(重定位)：重新计算各个目标地址的的过程。


1.1.1. 典型的计算机底层硬件组织架构
CPU: central processing unit
ALU: arithmetic&#x2F;logic unit
PC: program counter
USB:Universal Serial Bus
DRAM: dynamic random access memory
register file： a small storage device that consists of a collection of word-size registers, each with its own unique name.  


buses(总线)
总线是贯穿整个系统的一组电子导管，携带字节信息并负责在各个部件间传递。 
被设计用来传输固定大小的字节块(fixed-size chunks of bytes)，也就是字(word)。
word: 32 bit 的机器中为 4 bytes，64 bit的机器中为 8 bytes


I&#x2F;O Devices 
I&#x2F;O设备是系统与外部世界联系的通道。每一个I&#x2F;O设备都通过一个控制器或适配器与I&#x2F;O总线先连。
适配器(adapter): 是一块插在主板插槽上的卡。
控制器(controller)：是I&#x2F;O设备本身或系统的主控电路板上的芯片组。


Main Memory(主存)
主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。
物理上， 主存是由一组动态随机存储(DRAM)芯片组成的；
逻辑上来讲，存储器是一个线性的字节数组，每个地址都有其唯一的地址（数组索引）。


Processor(处理器)
central processing unit (CPU)，简称处理器，是执行存储在主存中指令的引擎。
处理器的核心是一个大小为字(word-size)的寄存器，称为 program counter (PC)。任何时刻，PC都指向主存中的某条机器语言指令。
从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令。处理器看上去是按照一个非常简单的指令执行模型来操作的，这个模型是由指令集架构决定的。在这个模型中，指令按照严格的顺序执行，而执行一条指令包含执行一系列的步骤。处理器从程序计数器指向的内存处读取指令，解释指令中的位(bit)，执行该指令指示的简单操作，然后更新程序计数器(PC)，使其指向下一条指令，而这条指令并不一定和在内存中刚刚执行的指令相邻。


Load: Copy a byte or a word from main memory into a register, overwriting the previous contents of the register.
Store: Copy a byte or a word from a register to a location in main memory, overwriting the previous contents of that location.
Operate: Copy the contents of two registers to the ALU, perform an arithmeti coperation on the two words, and store the result in a register, overwriting the previous contents of that register.
Jump: Extract a word from the instruction itself and copy that word into the program counter (PC), overwriting the previous value of the PC.



1.1.2. 一个 hello 可执行程序的底层调用过程
初始时，shell程序执行它的指令，等待我们输人一个命令。在键盘上输人字符串 ./hello 后，shell程序将字符逐一读入register，再把它存放到memory中。


当在键盘上敲 enter 键时，shell程序就知道我们已经结束了命令的输人。然后shell执行一系列指令来加载可执行的 hello 文件，这些指令将 hello 目标文件中的代码和数据从磁盘(disk)复制到主存(main memory)。数据包括最终会被输出的 hello,world \n 字符串。利用直接存储器存取(direct memory access : DMA)技术，数据可以不通过处理器(processor)而直接从磁盘(disk)到达主存(main memory)。


一旦目标文件hello中的代码和数据被加载到主存(main memory)，处理器就开始执行hello程序的main程序中的机器语言指令。这些指令将 hello,world \n 字符串中的 bytes 从主存复制到寄存器文件(register file)，再从寄存器文件中复制到显示设备，最终显示在屏幕上。


1.1.3. cache(缓存)




context switching: 操作系统通过处理器在进程间切换，来实现在同一时间上执行多个程序。
The operating system performs this interleaving with a mechanism known as context switching. 


context: 操作系统会跟踪进程运行时所需的所有状态信息，叫做上下文。包括的信息有以下部分：
the current values of the PC
the register file
the contents of main memory



当操作系统决定要把控制权从当前进程转移到某个新的进程时，就会进行上下文切换，即保存当前进程的上下文、恢复新进程的上下文，然后将控制权传递到新的进程，新进程就会从它上次停止的地方开始。
1.2. References
Computer Systems: A Programmer’s Perspective, 3&#x2F;E (CS:APP3e): 官方英文书籍网站。
Lab Assignments: 书籍中实验的部分。
https://fengmuzi2003.gitbook.io/csapp3e: CSAPP 重点解读
18-613&#x2F;14-513: Computer Systems, Summer 2020 2020学期新版讲义的网站，在2016学期的基础上增添了一些内容。
15-213: Intro to Computer Systems, Spring 2016: CMU(卡耐基梅隆大学) 2016 年的 CS:APP 课程资源。包括在线视频、课件，资源不是最新的。
15-213: Intro to Computer Systems, Spring 2016-video:  YouTube上一个UP主上传的课程视频。
2015 CMU 15-213 CSAPP 深入理解计算机系统 课程视频: B站对该课程的翻译。
深入理解计算机系统（英文版·第3版）: 豆瓣网对该书籍的评价。

]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>computerSystemAProgramm&#39;sPerspective</tag>
      </tags>
  </entry>
  <entry>
    <title>OS</title>
    <url>/OS/OS/OS/</url>
    <content><![CDATA[

1. Architecture计算机组成的整体架构入下




Processor： 控制计算机的操作、执行数据处理功能。Processor 的一种功能：与存储器(memory) 交换数据。各个部分的功能如下：  

Memory Address Register (存储器地址寄存器： MAR )：用于确定下一次读&#x2F;写的内存地址。
Memory Buffer Register(存储器缓冲寄存器： MBR )：存放要写入内存的数据或从内存中读取的数据。
I&#x2F;O Address Register (输入输出地址寄存器：I&#x2F;OAR)：用于确定一个特定的输入输出设备。
I&#x2F;O Buffer Register (输出输出缓冲寄存器：I&#x2F;OBR)：用于在输入、输出模块和处理器间交换数据。
PC(Program Counter：程序计数器)：保存下一次要取的指令地址。
IR(Instruction Register：指令寄存器)：令存放的是处理器取到的指令。而这些指令中包含确定处理器将要执行操作的位，处理器解释指令并执行对应的操作。这些操作大体上可分为 4 类：
Processor-memory:  数据可以从 processor 到 memory 或者 从 memory 到 processor 之间转移。
Processor-I&#x2F;O:   数据可以从处理器到外围设备或从外围设备到处理器之间转移。
Data processing: 处理器可以执行很多与数据相关的算法和逻辑运算。  
Control:   指令可以指定更改执行顺序。例如：处理器从地址为 149的位置取指令，下条指令从指定地址为 182的位置处取指令，而不是地址为 150 的位置处，此时处理器将程序计数器设置为 182。


base register(基址寄存器)：保存该内存区域的开始地址。
limit register(界限寄存器)：保存该区域的大小，单位：bytes 或 word
process index register(进程索引寄存器)：当前正在控制处理器的进程在 process list 中的 索引(index)。


Main memory： Stores data and programs.   This memory is typically volatile; 计算机关机时，内存中内容会丢失；对比磁盘内存时，计算机关机时，磁盘中保存的内容不会丢失。Main memory 也叫  real memory or primarymemory  。

内存模块由一系列被定义为有顺序号的地址块组成。每个地址块包含一个二进制数，表示是指令或数据。


I&#x2F;O modules: 在计算机与外部环境之间移动移动数据。外部环境由很多设备组成：包括二级存储设备(secondarymemory devices : disk)、通信设备、终端。

模块中还包含内存缓冲区(buffers)，用于临时保存数据，直到它们被发送出去。


System bus: 系统总线为处理器、主存和 I&#x2F;O 模块之间提供通信。


2. Instruction execution一个程序被处理器执行由一系列存储在 memory 中的指令组成。最简单的指令包括两步：处理器从 memory 中取(fetches)一条指令，然后执行(Execute)指令。
程序执行是由不断重复的取指令和执行指令的过程组成的。指令执行涉及很多操作，具体取决于指令本身。

指令周期：单个指令所需要的处理为一个指令周期。

在单个指令周期开始，处理器从内存中取一条指令。每次取指令后，PC 值增加，以便能按照顺序取下一条指令。例如：程序计数器(PC) 的地址为 300，处理器下一次将在地址为 300 处取指令，而在后面的指令周期中，处理器将在地址为 301,302,303处取指令。
AC(Accumulator ：累加器)：指令与数据都为 16 bits ，作为临时存储。

操作码(pcode)：定义了处理器执行的操作。

下面是一个简单程序执行的例子：将地址为 940 处内容和地址为 941 处内容相加，并将结果保存在后一个地址中。


上面图中程序执行的步骤：

PC 中包含第一条指令的地址 300，该指令(指令中内容为 16 进制的 1940)被加载到 IR 寄存器中，PC 值增加 1。
IR 寄存器中第一个 16 进制数表示需要加载的  AC，后三位 16 进制的数表示地址，且为 940。
从地址为 301 处取下一条指令(5941)，同时 PC 值增加 1。
AC 寄存器中原来的值加上地址为 941 处的值，得到的结果存在 AC 寄存器中。
从地址为 302 处取下一条指令(2941)，同时 PC 值增加 1.
AC 寄存器中的值存储在地址为 941 的内存中。

3. Interrupt中断分类(Classes of Interrupts  )

Program(程序中断)：在某些情况下由指令执行的结果产生。入：算术溢出(arithmetic overflow)、除数为 0(division by zero)、试图执行一些非法机器指令、访问用户不允许访问的内存空间。
Timer(定时器中断)：由处理器内部的计数器产生，允许操作系统以一定的规律执行函数。
I&#x2F;O(I&#x2F;O中断)：由 I&#x2F;O 控制器产生，用于信号通知一个操作的正常完成后各种错误条件。
Hardware failure(硬件失效中断)：由掉电或内存奇偶校验出错产生。

Interrupt handler(中断处理)：外部设备准备好从处理器接收更多的的数据时，外部设备的 I&#x2F;O 模块给处理器发送一个中断请求信号，这时处理器会做出响应，暂停当前程序的运行，转去处理服务于特定 I&#x2F;O 设备的程序，这种程序称为 中断处理。
4. Memory Hierarchynonvolatile memory：非易失性存储也称为**二级存储器(secondary memory  )或辅助存储器(auxiliary memory  )**。用于存储程序和数据文件，其表现形式是程序员看到的是文件(file) 和 记录(record)，而不是独立的 bytes 和 words。硬盘还可以作为内存的扩展，即虚拟存储器(virtual memory  )。

memory: 一般指易失性的RAM和非易失性的磁盘。非易失性存储器通常是 硬盘(hard disk)和可移动的存储介质(removable media：可移动磁盘、磁盘、光盘) 。 

Buffer(缓冲区)：用于临时保存从磁盘中读出的数据。也叫磁盘高速缓存(disk cache)。
4.1. Cache局部性原理(principle of locality )： 在处理器和内存之间提供一个容量小且速度快的存储器，称为高速缓存(CaChe)。
Cache： 高速缓存用于 main memory 和  processer registers 之间分段移动数据，以提高数据访问的性能。通常对程序员是不可见的，对处理器也是不可见。
目的： 是的访问速度接近现有的最快存储器，同时支持价格较低的大存储器。
现代处理器Cache的设计为多级结构。一般分为 L1级(cache最接近处理器)、L2级、L3级，其中 Cache 与 Main Memory 的分布情况如下



Cache&#x2F;Main-memory 之间结构分布



高速缓存设计考虑的问题

Cache size
block size(块大小)：Cache 与 main memory 之间数据交换的单位。
Mapping function (映射函数)：确定这个 block 将占据 Cache的哪个位置。
Replacement algorithm (置换算法)：选择替换在不久的将来被访问可能性最小的 block。
LRU(Least Recently Used 最近最少使用)：需要硬件机制来识别最近使用最少的块。


Write policy(写策略)：表明什么时候发生内存写操作。
Number of cache levels (高速缓存的级数)



]]></content>
      <categories>
        <category>OS</category>
      </categories>
      <tags>
        <tag>oS</tag>
      </tags>
  </entry>
  <entry>
    <title>JsonCpp</title>
    <url>/OpenSource/OpenSource/JsonCpp/</url>
    <content><![CDATA[JsonCppon简介JsonCpp是一个序列化反序列JSON格式的开源C++库，被C++程序广泛使用（包括Chromium项目）。JsonCpp还有一个重要特性是其支持在JSON格式内注释，这对于使用JSON格式作为配置文件很有意义，可以给配置添加注释说明其用途。
用法JsonCpp三个核心类 Reader、FastWriter、Value基本可以满足项目对JSON构造解析的要求。

类Reader，用来将一个JSON文件或JSON格式的字符串解析成Value对象。
parse()接口第一个参数为JSON格式字符串，第二个参数是解析后Value对象，如果JSON格式正确将解析成功。

类FastWriter，用来将一个Value对象格式化为JSON格式的字符串。
write()接口的参数是一个Value对象，返回值为JSON格式的字符串。

类Value，是JsonCpp库最为重要的类，它代表JSON格式字符串在内存中的状态，修改JSON格式字符串需先修改其Value对象，然后序列化输出，其提供四类接口：

第一， 判断类型，接口名字为isXXX()，其中XXX为类型，包括Bool、Int、Int64、UInt、UInt64、Double、String、Array、Object，与JSON格式的类型是对应的，isNull用来判断是否为空。
第二， 取值，接口名字为asXXX()，其中XXX与判断类型的接口一样，取值前务必先确保类型是对的，否则会抛出逻辑错误的异常。类型为Array的时候，size()接口获取Array的个数，然后遍历获取Array每个值（注意遍历时下标从0开始）。类型为Object的时候，isMember()接口用来判断对象是否有某个key，访问该key前务必先确保有该key，否则会抛出逻辑错误的异常，访问某个key时使用操作符[]，参数为key值，有时候不知道对象都有哪些key，就得先调用getMemberNames()接口获取key列表（它是vector对象），然后遍历key列表逐个访问。
第三， 新增&#x2F;修改值，新增&#x2F;修改值时使用操作符&#x3D;，其参数为Value对象，Value类构造函数支持上面提到的所有类型，所以操作符&#x3D;右侧可以直接使用上面提到的类型变量，无需转换。修改某个JSON值时，务必保证新旧的类型一致，否则会抛出逻辑错误的异常。Array时比较特殊，是调用append()接口追加，使用下标修改。
第四， 删除，Object时删除某个key使用removeMember()接口，Array时删除某个元素使用removeIndex接口指定元素的下标。



Reference
官网：https://jsoncpp.sourceforge.net/old.html
用法参考：https://www.cnblogs.com/ZY-Dream/p/10054074.html

]]></content>
      <categories>
        <category>OpenSource</category>
      </categories>
      <tags>
        <tag>openSource</tag>
        <tag>jsonCpp</tag>
      </tags>
  </entry>
  <entry>
    <title>License</title>
    <url>/OpenSource/OpenSource/License/</url>
    <content><![CDATA[License 开源许可证MITApache 2.0Apache 2.0 许可证约定

遵循许可的前提下，你可以自由地对代 码进行修改，再发布，可以将代码用作商业用途。
但要求你： 署名：在原有代码和衍生代码中，保留原作者署名及代码来源信息。 
保留许可证：在原有代码和衍生代码中，保留 Apache 2.0 协议文件。

]]></content>
      <categories>
        <category>OpenSource</category>
      </categories>
      <tags>
        <tag>openSource</tag>
        <tag>license</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenSourceProject</title>
    <url>/OpenSource/OpenSource/OpenSourceProject/</url>
    <content><![CDATA[ 




1. GitHub开源项目
2. C
3. C++
4. Java
5. 网络
6. Linux
7. Go
8. 数据结构与算法
9. 有价值的开源库
10. 其它

 


1. GitHub开源项目2. C
ip2region：准确率99.9%的离线IP地址定位库，0.0x毫秒级查询
explainshell：解析 Linux 命令的网站
Tinyhttpd：一个不到 500 行的超轻量型 HTTP Server
db_tutorial：用 C 从零创建一个简单的数据库
reading-code-of-nginx-1.9.2：nginx源码阅读分析中文注
write-a-hash-table
Tutorial - Write a System Call
Let’s code a TCP&#x2F;IP stack, 1: Ethernet &amp; ARP
Tutorial - Write a Shell in C
Writing a Unix Shell
libhv：快速的编写 HTTP 客户端&#x2F;服务端，简单易用的非阻塞 IO 事件循环库

3. C++
JSON for Modern C++
现代 C++ 教程
C++ 风格指南 - 内容目录
modern-cpp-features：该项目介绍了现代 C++（C++11 以及之后的版本）语言和库的新特性。
ThreadPool：一个简单的 C++11 线程池实现
indicators：一个使用 C++ 编写的进度条库，你可以用它在命令行中实现美观的进度条。
Flameshot 开源的截图工具，使用C++和Qt工具开发的。
notepanda  简单的Notepanda编辑器的实现，采用C++和Qt工具开发。
MyTinySTL 基于C++11的tinySTL，其中实现了大部分STL中的容器与函数。
libevent libevent 是广泛应用的 C++ 网络库，也是现在很多 C&#x2F;C++ 网络库的雏形，想了解 C&#x2F;C++ 网络库最初的形态、设计与演化思想一定要好好学习一下这个库。
uWebSocket uWebSocket 是一款开源的 WebSocket 库，最新版使用了大量 C++17 的语法，代码量非常少。

4. JavaJavaGuide：「Java学习+面试指南」一份涵盖大部分 Java 程序员所需要掌握的核心知识。作者该项目跟新的频率很高，写得文章很好，值得向人家学习写开源项目。
5. 网络
WebServer：牛客大佬健康成长天线宝宝写的『HTTP』的服务器。
NetServer：本项目为C++11编写的基于『epoll』的多线程网络服务器框架，应用层实现了简单的HTTP服务器HttpServer和一个回显服务器EchoServer，其中『HTTP』服务器实现了HTTP的解析和get方法请求，目前支持静态资源访问，支持HTTP长连接；该框架不限于这两类服务器，用户可根据需要编写应用层服务。通过该项目你可以了解到部分C++11的语法和编码规范、学习巩固网络编程、网络IO模型、多线程、git使用、Linux命令、性能分析、TCP&#x2F;IP、HTTP协议等知识。
Sylar：这是一个『C++』高性能分布式服务器框架 的项目。该项目主要有 13 大模块组成，分别是日志模块、配置模块、线程模块、协程模块、协程调度模块、IO协程调度模块、Hook模块、Socket模块、ByteArray序列化模块、TcpServer模块、Stream模块、HTTP模块、Servlet模块。B站视频
MIT6.828：《CSAPP》课后lab
Drogon: 是一个基于C++14&#x2F;17的Http应用框架，使用Drogon可以方便的使用C++构建各种类型的Web应用服务端程序。

6. Linux
Linux内核揭秘：分享对 Linux 内核内在机理的一点知识，帮助对 Linux 内核内在机理感兴趣的人，和其他低级话题。
命令行的艺术：常用命令行总结
Commit messages guide：git 提交信息说明
**Netdata**：Linux 系统性能实时监控工具

7. Go
Go语言高级编程  《Go语言高级编程》开源图书，涵盖CGO、Go汇编语言、RPC实现、Protobuf插件实现、Web框架实现、分布式系统等高阶主题。
Go语言圣经（中文版）

8. 数据结构与算法
The-Art-Of-Programming-By-July 七月博主开源的《编程之法：面试和算法心得》，文章比较有深度，值得慢慢读。

9. 有价值的开源库
Abseil: Abseil已在Google历经十多年的开发，它的目的是为Google编程人员在各种项目上的工作需求提供支持，这些项目包括Protocol Buffers、gRPC和TensorFlow等。Google评价Abseil为：它是从Google内部代码块中抽取出来的一系列最基础的软件库。作为基本的组成部分，这些软件库支撑了几乎全部Google在运行的项目。以前这些API是零零散散地嵌入在Google的大部分开源项目中，现在我们将它们规整在一起，形成这样一个全面的项目。Abseil是Google代码库的最基本构建模块，其代码经过了生产环节测试，此后还会继续得到完全的维护。

protobuf: Google出品，protobuf一个具有高效的协议数据交换格式工具库(类似Json)，但相比于Json，Protobuf有更高的转化效率，时间效率和空间效率都是JSON的3-5倍。

folly: Facebook开源的基于C++14的库，在facebook内部广泛使用。Folly的全称为Facebook Open-source Library，目的不是为了替代标准库，而是对标准库的一种补充，尤其是大规模下的性能。中文文档可能太少，需要多看源码。

zeromq: 一个为可伸缩的分布式或并发应用程序设计的高性能异步消息库。它提供一个高性能消息队列，该库设计成常见的套接字风格的API。

asio: 一个跨平台的C++网络编程框架，通过先进的C++方法为开发人员提供连续异步模型。

POCO: POCO是一个开源的C++类库的集合，它主要提供简单的、快速的网络和可移植应用程序的C++开发，这个类库和C++标准库可以很好的集成并填补C++标准库的功能空缺。POCO库的模块化、高效的设计及实现使得特别适合嵌入式开发。

libevent: Libevent 是一个用C语言编写的、轻量级的开源高性能事件通知库，主要有以下几个亮点：事件驱动，高性能，轻量级，专注于网络，不如 ACE 那么臃肿庞大；源代码相当精炼、易读；跨平台；支持多种 I&#x2F;O 多路复用技术：epoll、poll、select 和 kqueue 等；支持 I&#x2F;O，定时器和信号等事件；注册事件优先级等。

workflow: 搜狗公司C++服务器引擎，支撑搜狗几乎所有后端C++在线服务，包括所有搜索服务，云输入法，在线广告等，每日处理超百亿请求。这是一个设计轻盈优雅的企业级程序引擎，可以满足大多数C++后端开发需求。

Eigen: 是一个线性算术的C++模板库，功能强大、快速、优雅以及支持多平台。想找关于数学运算的三方库，首选Eigen就对了！直接使用 JupyterNoteBook，以 Python 的方式会更好。

腾讯 Tars 框架: https://github.com/TarsCloud/TarsCpp

腾讯Go 实现的grpc: https://github.com/trpc-group/trpc-go


参考：程序喵：推荐几个开源库
10. 其它
annie：Go 编写的快速、简单、干净的视频下载程序
most-frequent-technology-english-words：程序员工作中常见的英语词汇	
NPS：一款功能强大、轻量级的内网穿透代理服务器。
0voice2019 年各互联网大厂最新内部技术分享的文档、PDF、PPT 集合。从程序员到 CTO，从专业走向卓越
manim：一个生成数学教学视频的动画引擎。它用编程的方式创建精美的数学动画，让数学更加易懂。
AutoPiano)：利用HTML5技术开发的在线钢琴应用，致力于为钢琴爱好者、音乐爱好者以及其他所有的创造者提供一个优雅、简洁的平台，在学习工作之余可以享受钢琴、音乐的美好。
微信公众号排版编辑器：转化 Markdown 到给微信特制的 HTML

]]></content>
      <categories>
        <category>OpenSource</category>
      </categories>
      <tags>
        <tag>openSource</tag>
        <tag>openSourceProject</tag>
      </tags>
  </entry>
  <entry>
    <title>Rapidjson</title>
    <url>/OpenSource/OpenSource/Rapidjson/</url>
    <content><![CDATA[


1. rapidjson
2. 基础用法
2.1. 是什么
2.2. 特征
2.3. 怎么用
2.3.1. 解析
2.3.2. 创建


2.4. 注意事项
2.5. 查询 Value
2.5.1. 查询 Array
2.5.2. 查询 Object
2.5.3. 查询 String




3. 内部原理
3.1. Reader
3.2. Writer
3.3. Document
3.4. Value
3.5. Allocator


4. Reference




1. rapidjson2. 基础用法2.1. 是什么rapidjson 是腾讯的开源 Json解析框架，用 C++ 代码实现，用于解析和生成 JSON 由于全部代码仅用头文件实现，因此很容易集成在项目中。根据其作者 Milo Yipz 所做的比较，可以看出 rapidjson 的性能非常可观。通过使用 DOM（Document Object Model）可以很方便的将 Json 转化成 DOM，然后查询修改，再转化为一个 Json。通过 rapidjson 库，可以方便我们进行参数的传递，解析的工作。Json 非常便捷的支持键值对、数组、以及深入的嵌套，在编写程序时，可以帮助我们聚焦于业务，而对于参数的传递，则可以较少的投入精力。
2.2. 特征优点

RapidJSON 库仅由头文件组成，只需把头文件复制至你的项目中。

独立、最小依赖。不需依赖 STL、Boost 库等。

没使用 C++ 异常、RTTI。

支持跨平台。
编译器：Visual Studio、gcc、clang 等架构：x86、x64、ARM 等操作系统：Windows、Mac OS X、Linux、iOS、Android 等

RapidJSON 解析和生成速度快。使用模版及内联函数去降低函数调用开销。内部经优化的 Grisu2 及浮点数解析实现。

RapidJSON 是一个C++ 的 JSON 解析器及生成器，它的灵感来自 RapidXml

RapidJSON 对 Unicode 友好。它支持 UTF-8、UTF-16、UTF-32 (大端序／小端序)，并内部支持这些编码的检测、校验及转码。
例如，RapidJSON 可以在分析一个 UTF-8 文件至 DOM 时，把当中的 JSON 字符串转码至 UTF-16。它也支持代理对（surrogate pair）及 ”\u0000”（空字符），这些特征使得我们，可以很好的把 rapidjson 集成到项目代码之中，提高开发的效率。


缺点

RapidJSON 库较难使用，源码使用了大量的模板类和模板函数。
RapidJSON 库的 SAX 风格接口较难使用，因此使用 DOM 接口即可。

2.3. 怎么用Rapidjson 官网 非常详细的介绍了如何去使用，自己就不再把官方的文档般到这里来了。只总结一些使用的心得。
2.3.1. 解析json 字符串
static constexpr auto json = &quot;&#123;\&quot;Info\&quot;:[&#123;\&quot;lots\&quot;:10,\&quot;order_algorithm\&quot;:\&quot;01\&quot;,\&quot;buy_close\&quot;:9000,\&quot;spread_shift\&quot;:0,\&quot;position_b_sell\&quot;:0,\\&quot;position_a_buy_today\&quot;:0,\&quot;position_a_buy_yesterday\&quot;:0,\&quot;sell_open\&quot;:-9000,\&quot;list_instrument_id\&quot;:[\&quot;rb1705\&quot;,\&quot;rb1701\&quot;],\\&quot;position_b_buy_today\&quot;:0,\&quot;buy_open\&quot;:-9000,\&quot;position_a_sell_yesterday\&quot;:0,\&quot;strategy_id\&quot;:\&quot;02\&quot;,\&quot;position_b_buy\&quot;:0,\\&quot;a_wait_price_tick\&quot;:1,\&quot;trade_model\&quot;:\&quot;boll_reversion\&quot;,\&quot;b_wait_price_tick\&quot;:0,\&quot;sell_close\&quot;:9000,\&quot;only_close\&quot;:0,\\&quot;order_action_limit\&quot;:400,\&quot;is_active\&quot;:1,\&quot;lots_batch\&quot;:1,\&quot;position_a_sell\&quot;:0,\&quot;position_b_buy_yesterday\&quot;:0,\\&quot;user_id\&quot;:\&quot;063802\&quot;,\&quot;position_a_buy\&quot;:0,\&quot;trader_id\&quot;:\&quot;1601\&quot;,\&quot;position_a_sell_today\&quot;:0,\&quot;stop_loss\&quot;:0,\\&quot;position_b_sell_today\&quot;:0,\&quot;position_b_sell_yesterday\&quot;:0,\&quot;on_off\&quot;:0&#125;,&#123;\&quot;lots\&quot;:20,\&quot;order_algorithm\&quot;:\&quot;02\&quot;,\\&quot;buy_close\&quot;:9000,\&quot;spread_shift\&quot;:0,\&quot;position_b_sell\&quot;:0,\&quot;position_a_buy_today\&quot;:0,\&quot;position_a_buy_yesterday\&quot;:0,\\&quot;sell_open\&quot;:-9000,\&quot;list_instrument_id\&quot;:[\&quot;ni1705\&quot;,\&quot;ni1701\&quot;],\&quot;position_b_buy_today\&quot;:0,\&quot;buy_open\&quot;:-9000,\\&quot;position_a_sell_yesterday\&quot;:0,\&quot;strategy_id\&quot;:\&quot;01\&quot;,\&quot;position_b_buy\&quot;:0,\&quot;a_wait_price_tick\&quot;:1,\&quot;trade_model\&quot;:\&quot;boll_reversion\&quot;,\\&quot;b_wait_price_tick\&quot;:0,\&quot;sell_close\&quot;:9000,\&quot;only_close\&quot;:0,\&quot;order_action_limit\&quot;:400,\&quot;is_active\&quot;:1,\&quot;lots_batch\&quot;:1,\\&quot;position_a_sell\&quot;:0,\&quot;position_b_buy_yesterday\&quot;:0,\&quot;user_id\&quot;:\&quot;063802\&quot;,\&quot;position_a_buy\&quot;:0,\&quot;trader_id\&quot;:\&quot;1601\&quot;,\\&quot;position_a_sell_today\&quot;:0,\&quot;stop_loss\&quot;:0,\&quot;position_b_sell_today\&quot;:0,\&quot;position_b_sell_yesterday\&quot;:0,\&quot;on_off\&quot;:0&#125;],\\&quot;MsgSendFlag\&quot;:0,\&quot;MsgErrorReason\&quot;:\&quot;IDorpassworderror\&quot;,\&quot;MsgRef\&quot;:1,\&quot;MsgType\&quot;:3,\&quot;MsgResult\&quot;:0&#125;&quot;;

代码解析实现
rapidjson::Document doc;doc.Parse(json);// 2. Modify it by DOM.rapidjson::Value&amp; s = doc[&quot;MsgSendFlag&quot;];s.SetInt(s.GetInt() + 1);rapidjson::Value&amp; infoArray = doc[&quot;Info&quot;];if (infoArray.IsArray()) &#123;    for (int i = 0; i &lt; infoArray.Size(); i++) &#123;        const rapidjson::Value&amp; object = infoArray[i];        int lots = object[&quot;lots&quot;].GetInt();        std::string order_algorithm = object[&quot;order_algorithm&quot;].GetString();        std::cout &lt;&lt; &quot;int lots = &quot; &lt;&lt; lots &lt;&lt; std::endl;        std::cout &lt;&lt; &quot;string order_algorithm = &quot; &lt;&lt; order_algorithm &lt;&lt; std::endl;        const rapidjson::Value&amp; info_object = object[&quot;list_instrument_id&quot;];        if (info_object.IsArray()) &#123;            for (int j = 0; j &lt; info_object.Size(); j++) &#123;                std::string instrument = info_object[j].GetString();                std::cout &lt;&lt; &quot;instrument[&quot; &lt;&lt; j &lt;&lt; &quot;] = &quot; &lt;&lt; instrument &lt;&lt; std::endl;            &#125;        &#125;    &#125;&#125;// 3. Stringify the DOMrapidjson::StringBuffer buffer;rapidjson::Writer&lt;rapidjson::StringBuffer&gt; writer(buffer);doc.Accept(writer);std::cout &lt;&lt; buffer.GetString() &lt;&lt; std::endl;

2.3.2. 创建组建一个json字符串
std::cout &lt;&lt; json &lt;&lt; std::endl;std::cout &lt;&lt; &quot;|==================|&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;||rapidjson output||&quot; &lt;&lt; std::endl;std::cout &lt;&lt; &quot;|==================|&quot; &lt;&lt; std::endl;rapidjson::Document doc; // doc 对象默认类型为 nulldoc.SetObject(); // 改变类型rapidjson::Document::AllocatorType&amp; allocator = doc.GetAllocator();doc.AddMember(&quot;MsgSendFlag&quot;, 1, allocator);doc.AddMember(&quot;MsgErrorReason&quot;, &quot;IDorpassworderror&quot;, allocator);doc.AddMember(&quot;MsgRef&quot;, 1, allocator);rapidjson::Value info_array(rapidjson::kArrayType);for (int i = 0; i &lt; 2; i++) &#123;    rapidjson::Value info_object(rapidjson::kObjectType); // 调用构造函数，参数类型为：json vale type    info_object.SetObject();    info_object.AddMember(&quot;lots&quot;, 10 + i, allocator);    info_object.AddMember(&quot;order_algorithm&quot;, &quot;01&quot;, allocator);    rapidjson::Value instrument_array(rapidjson::kArrayType);    for (int j = 0; j &lt; 2; j++) &#123;        rapidjson::Value instrument_object(rapidjson::kObjectType);        instrument_object.SetObject();        instrument_object.SetString(&quot;cu1701&quot;);        instrument_array.PushBack(instrument_object, allocator);    &#125;    info_object.AddMember(&quot;list_instrument_id&quot;, instrument_array, allocator);    info_array.PushBack(info_object, allocator);&#125;doc.AddMember(&quot;Info&quot;, info_array, allocator);// 3. Stringify the DOMrapidjson::StringBuffer buffer; // 输出流，它分配一个内存缓冲区，供写入整个 JSONrapidjson::Writer&lt;rapidjson::StringBuffer&gt; writer(buffer);doc.Accept(writer);std::cout &lt;&lt; buffer.GetString() &lt;&lt; std::endl; // GetString() 获取缓冲区的内容

2.4. 注意事项
RapidJSON 在类型转换时会检查数值的范围。

字符串字面量的优化

只储存指针，不作复制


优化“短”字符串

在 Value 内储存短字符串，无需额外分配。
对 UTF-8 字符串来说，32 位架构下可存储最多 11 字符，64 位下 21 字符（x86-64 下 13 字符）。


可选地支持 std::string（定义 RAPIDJSON_HAS_STDSTRING=1）

最小化 DOM 的内存开销。
对大部分 32／64 位机器而言，每个 JSON 值只占 16 或 20 字节（不包含字符串）。

支持快速的预设分配器。

它是一个堆栈形式的分配器（顺序分配，不容许单独释放，适合解析过程之用）。
使用者也可提供一个预分配的缓冲区。（有可能达至无需 CRT 分配就能解析多个 JSON）


部分 C++11 支持

右值引用（rvalue reference）
支持 noexcept 修饰符
支持简洁的范围 for 循环


Value 赋值使用move语义，而不是 copy 语义。也就是说，拷贝构造和拷贝赋值函数都是用 move 语义实现的。

当 string 的生命周期不足时，Value 应该使用 Copy-string 存储策略，否则 value 无法长期存储字符串。

StringBuffer 是一个简单的输出流，当该缓冲区满溢时会自动增加容量（默认为 256 个字符）。

FileReadStream &#x2F; FileWriteStream，和IStreamWrapper &#x2F; OStreamWrapper，它们都是字节流，不处理编码。若输入流或输出流数据是非 UTF-8 编码时，输入流数据需要用 EncodedInputStream 或AutoUTFInputStream 包装，而输出流数据需要用 EncodedOutputStream 或 AutoUTFOutputStream 包装。

不建议使用 wistream 和 wostream。


2.5. 查询 Value2.5.1. 查询 Array缺省情况下，SizeType 是 unsigned 的 typedef。在多数系统中，Array 最多能存储 $2^{32}-1$ 个元素。
用法与 std::vector 类似，同时也支持 C++11 的 for 循环迭代。
2.5.2. 查询 Object
FindMember():  检查成员是否存在并返回它的 Value。
用于查询 Object ，比普通的迭代遍历对象要高效。因为当 operator[](const char*) 找不到成员，它会断言失败。若我们不确定一个成员是否存在，便需要在调用 operator[](const char*) 前先调用 HasMember()，这会导致两次查找，降低了效率。
// 普通查询static const char* kTypeNames[] =     &#123; &quot;Null&quot;, &quot;False&quot;, &quot;True&quot;, &quot;Object&quot;, &quot;Array&quot;, &quot;String&quot;, &quot;Number&quot; &#125;; for (Value::ConstMemberIterator itr = document.MemberBegin();    itr != document.MemberEnd(); ++itr) &#123;    printf(&quot;Type of member %s is %s\n&quot;,        itr-&gt;name.GetString(), kTypeNames[itr-&gt;value.GetType()]);&#125;// 采用FindMember()Value::ConstMemberIterator itr = document.FindMember(&quot;hello&quot;);if (itr != document.MemberEnd()) &#123;    printf(&quot;%s\n&quot;, itr-&gt;value.GetString());&#125;

rapidjson 为了最大化性能，大量使用了浅拷贝，使用之前一定要了解清楚。如果采用了浅拷贝，特别要注意局部对象的使用，以防止对象已被析构了，却还在被使用。
2.5.3. 查询 StringRapidJSON 提供两个 String 的存储策略。

copy-string: 分配缓冲区，然后把来源数据复制至它。
const-string: 简单地储存字符串的指针。


支持处理包含 \0 的字符。
根据 RFC 4627，JSON String 可包含 Unicode 字符 U+0000，在 JSON 中会表示为 &quot;\u0000&quot;。问题是，C&#x2F;C++ 通常使用空字符结尾字符串（null-terminated string），这种字符串把 ‘\0’ 作为结束符号。为了符合 RFC 4627，RapidJSON 支持包含 U+0000 的 String。若要获取这种字符串的 长度，调用  GetStringLength() 函数即可。

API

GetString()
GetStringLength()



3. 内部原理简称

SAX 是 Simple API for XML 的缩写。
DOM 是 Document Object Model(文件对象模型)的缩写。

核心 API。

源码路径 include/rapidjson 下有很多的文件，掌握下面几个核心的文件就能用好 rapidjson 常用的功能。
allocators.h
document.h
rapidjson.h
reader.h
writer.h
stringbuffer.h



3.1. ReaderReader: （GenericReader&lt;...&gt; 的 typedef）是 JSON 的 SAX 风格解析器。
Reader 从输入流解析一个 JSON。当它从流中读取字符时，它会基于 JSON 的语法去分析字符，并向处理器发送事件。
Reader 是 GenericReader 模板类的别名，位于 reader.h 文件中。 
namespace rapidjson &#123;template &lt;typename SourceEncoding, typename TargetEncoding, typename Allocator = MemoryPoolAllocator&lt;&gt; &gt;class GenericReader &#123;    // ...&#125;;typedef GenericReader&lt;UTF8&lt;&gt;, UTF8&lt;&gt; &gt; Reader;&#125; // namespace rapidjson



3.2. WriterWriter: （GenericWriter&lt;...&gt; 的 typedef）是 JSON 的 SAX 风格生成器。Writer 将数据生成 Json 格式数据。
Writer 是一个模板类，而不是一个 typedef，并没有 GenericWriter，位于 writer.h 中。下面是 Write 模板类的声明：
namespace rapidjson &#123;    template&lt;typename OutputStream, typename SourceEncoding = UTF8&lt;&gt;, typename TargetEncoding = UTF8&lt;&gt;, typename StackAllocator = CrtAllocator, unsigned writeFlags = kWriteDefaultFlags&gt;class Writer &#123;public:    typedef typename SourceEncoding::Ch Ch;    static const int kDefaultMaxDecimalPlaces = 324;    //! Constructor    /*! \param os Output stream.        \param stackAllocator User supplied allocator. If it is null, it will create a private one.        \param levelDepth Initial capacity of stack.    */    explicit    Writer(OutputStream&amp; os, StackAllocator* stackAllocator = 0, size_t levelDepth = kDefaultLevelDepth) :         os_(&amp;os), level_stack_(stackAllocator, levelDepth * sizeof(Level)), maxDecimalPlaces_(kDefaultMaxDecimalPlaces), hasRoot_(false) &#123;&#125;    explicit    Writer(StackAllocator* allocator = 0, size_t levelDepth = kDefaultLevelDepth) :        os_(0), level_stack_(allocator, levelDepth * sizeof(Level)), maxDecimalPlaces_(kDefaultMaxDecimalPlaces), hasRoot_(false) &#123;&#125;#if RAPIDJSON_HAS_CXX11_RVALUE_REFS    Writer(Writer&amp;&amp; rhs) :        os_(rhs.os_), level_stack_(std::move(rhs.level_stack_)), maxDecimalPlaces_(rhs.maxDecimalPlaces_), hasRoot_(rhs.hasRoot_) &#123;        rhs.os_ = 0;    &#125;&#125;;    &#125;

生成 json 格式的数据有两种方式。

用字符串缓冲结合 Writer。
#include &quot;rapidjson/writer.h&quot;#include &quot;rapidjson/stringbuffer.h&quot;#include &lt;iostream&gt; using namespace rapidjson;using namespace std; void main() &#123;    StringBuffer s;    Writer&lt;StringBuffer&gt; writer(s);        writer.StartObject();    writer.Key(&quot;hello&quot;);    writer.String(&quot;world&quot;);    writer.Key(&quot;t&quot;);    writer.Bool(true);    writer.Key(&quot;f&quot;);    writer.Bool(false);    writer.Key(&quot;n&quot;);    writer.Null();    writer.Key(&quot;i&quot;);    writer.Uint(123);    writer.Key(&quot;pi&quot;);    writer.Double(3.1416);    writer.Key(&quot;a&quot;);    writer.StartArray();    for (unsigned i = 0; i &lt; 4; i++)        writer.Uint(i);    writer.EndArray();    writer.EndObject();     cout &lt;&lt; s.GetString() &lt;&lt; endl;&#125;

// 输出&#123;&quot;hello&quot;:&quot;world&quot;,&quot;t&quot;:true,&quot;f&quot;:false,&quot;n&quot;:null,&quot;i&quot;:123,&quot;pi&quot;:3.1416,&quot;a&quot;:[0,1,2,3]&#125;

用 Document 类、分配器(Allocator)结合 AddMember() 函数。


3.3. DocumentDocument: 是模板类 GenericDocument&lt;UTF8&lt;&gt; &gt; 的别名，位于 document.h 文件中。
namespace rapidjson &#123;template &lt;typename Encoding, typename Allocator = RAPIDJSON_DEFAULT_ALLOCATOR, typename StackAllocator = RAPIDJSON_DEFAULT_STACK_ALLOCATOR &gt;class GenericDocument : public GenericValue&lt;Encoding, Allocator&gt; &#123;public:    ...&#125;;//! GenericDocument with UTF8 encodingtypedef GenericDocument&lt;UTF8&lt;&gt; &gt; Document;    &#125;

3.4. ValueValue: 是 DOM API 的核心，它是模板类 GenericValue&lt;UTF8&lt;&gt; &gt; 的别名，位于 document.h 中。
namespace rapidjson &#123;    template &lt;typename Encoding, typename Allocator = RAPIDJSON_DEFAULT_ALLOCATOR &gt;class GenericValue &#123;public:    ...&#125;;//! GenericValue with UTF8 encodingtypedef GenericValue&lt;UTF8&lt;&gt; &gt; Value;&#125;

Value 是一个可变类型。在 RapidJSON 的上下文中，一个 Value 的实例可以包含6种 JSON 数据类型。

Null
String
Bool
Object
Array
Number

注意点：

为了减少在64位架构上的内存消耗，SizeType 被定义为 unsigned 而不是 size_t。

32位整数的零填充可能被放在实际类型的前面或后面，这依赖于字节序。这使得它可以将32位整数不经过任何转换就可以解释为64位整数。

Int 永远是 Int64

Handler: 用于处理来自 Reader 的事件（函数调用）。处理器必须包含以下的成员函数。
class Handler &#123;    bool Null();    bool Bool(bool b);    bool Int(int i);    bool Uint(unsigned i);    bool Int64(int64_t i);    bool Uint64(uint64_t i);    bool Double(double d);    bool RawNumber(const Ch* str, SizeType length, bool copy);    bool String(const Ch* str, SizeType length, bool copy);    bool StartObject();    bool Key(const Ch* str, SizeType length, bool copy);    bool EndObject(SizeType memberCount);    bool StartArray();    bool EndArray(SizeType elementCount);&#125;;

3.5. AllocatorAllocator(分配器)，位于 allocators.h 文件中。
MemoryPoolAllocator 是 DOM 的默认内存分配器。它只申请内存而不释放内存。这对于构建 DOM 树非常合适。
在它的内部，它从基础的内存分配器申请内存块（默认为 CrtAllocator）并将这些内存块存储为单向链表。当用户请求申请内存，它会遵循下列步骤来申请内存：

如果可用，使用用户提供的缓冲区。（见 User Buffer section in DOM）
如果用户提供的缓冲区已满，使用当前内存块。
如果当前内存块已满，申请新的内存块。

namespace rapidjson &#123;class CrtAllocator &#123;public:    static const bool kNeedFree = true;    void* Malloc(size_t size) &#123;         if (size) //  behavior of malloc(0) is implementation defined.            return RAPIDJSON_MALLOC(size);        else            return NULL; // standardize to returning NULL.    &#125;    void* Realloc(void* originalPtr, size_t originalSize, size_t newSize) &#123;        (void)originalSize;        if (newSize == 0) &#123;            RAPIDJSON_FREE(originalPtr);            return NULL;        &#125;        return RAPIDJSON_REALLOC(originalPtr, newSize);    &#125;    static void Free(void *ptr) RAPIDJSON_NOEXCEPT &#123; RAPIDJSON_FREE(ptr); &#125;    bool operator==(const CrtAllocator&amp;) const RAPIDJSON_NOEXCEPT &#123;        return true;    &#125;    bool operator!=(const CrtAllocator&amp;) const RAPIDJSON_NOEXCEPT &#123;        return false;    &#125;&#125;;        template &lt;typename BaseAllocator = CrtAllocator&gt;class MemoryPoolAllocator &#123;	...&#125;;	&#125;

4. Reference
官方 Github: https://github.com/Tencent/rapidjson/
英文文档: https://rapidjson.org/
中文文档: https://rapidjson.org/zh-cn/index.html
Unicode 字符代码: https://www.rapidtables.org/zh-CN/code/text/unicode-characters.html
Unicode 15.0 Character Code Charts: https://www.unicode.org/charts/

]]></content>
      <categories>
        <category>OpenSource</category>
      </categories>
      <tags>
        <tag>openSource</tag>
        <tag>rapidjson</tag>
      </tags>
  </entry>
  <entry>
    <title>jq</title>
    <url>/OpenSource/OpenSource/jq/</url>
    <content><![CDATA[jqIntroductionjq 是 stedolan 开发的一个轻量级的和灵活的命令行 JSON 处理器。
它主要用于在命令行界面处理 JSON 输入，并使用给定的过滤条件来过滤符合条件的新的 JSON 串。
通常在类 Unix 环境下，我们可以快速的使用 jq 来进行 JSON 数据格式化过滤和处理。同时需要注意的是，该命令行工具和 awk&#x2F;sed&#x2F;grep 工具一样，属于系统的默认命令，如果系统没有该命令，可以尝试使用如下方式进行安装。
# Ubuntu 系列$ sudo apt-get install jq # CentOS 系列$ yum install jq 



Reference
官方文档：https://stedolan.github.io/jq/
知乎介绍 jq 用法：https://zhuanlan.zhihu.com/p/606945462
个人（上月行）博客介绍 jq 用法：https://shanyue.tech/op/jq.html

]]></content>
      <categories>
        <category>OpenSource</category>
      </categories>
      <tags>
        <tag>openSource</tag>
        <tag>jq</tag>
      </tags>
  </entry>
  <entry>
    <title>BrainMemory</title>
    <url>/Philosophy/Philosophy/BrainMemory/</url>
    <content><![CDATA[

什么东西引发大脑开始这个重建过程？记忆是一个过程，并且当你记忆的时候，实际上就是你把保存在大脑中零零碎碎的信息进行重建。

大脑喜欢色彩。平时使用高质量的有色笔或使用有色纸，颜色能帮助记忆。
大脑集中精力最多只有25分钟。这是对成人而言，所以学习20到30分钟后就应该休息10分钟。你可以利用这段时间做点家务，10分钟后再回来继续学习，效果会更好。
大脑需要休息，才能学得快，记得牢。如果你感到很累，先拿出20分钟小睡一会儿再继续学习。
大脑像发动机，它需要燃料。大脑是一台珍贵而复杂的机器，所以你必须给它补充“优质燃料”。垃圾食品、劣质食品、所有化学制品和防腐剂，不仅损害身体，还削弱智力。英国一项新研究显示，饮食结构影响你的智商。
大脑是一个电气化学活动的海洋。电和化学物质在水里能更好地流动，如果你脱水，就无法集中精力。专家建议，日常生活要多喝水，保持身体必需的水分，而且一天最好不要饮用相同的饮料，可以交换着喝矿泉水、果汁和咖啡等。另外，研究资料显示，经常性头痛和脱水有关。
大脑喜欢问题。当你在学习或读书过程中提出问题的时候，大脑会自动搜索答案，从而提高你的学习效率。从这个角度说，一个好的问题胜过一个答案。
大脑和身体有它们各自的节奏周期。一天中大脑思维最敏捷的时间有几段，如果你能在大脑功能最活跃的时候学习，就能节省很多时间，会取得很好的学习效果。
大脑和身体经常交流。如果身体很懒散，大脑就会认为你正在做的事情一点都不重要，大脑也就不会重视你所做的事情。所以，在学习的时候，你应该端坐、身体稍微前倾，让大脑保持警觉。
气味影响大脑。香料对保持头脑清醒有一定功效。薄荷、柠檬和桂皮都值得一试。
大脑需要氧气。经常到户外走走，运动运动身体。
大脑需要空间。尽量在一个宽敞的地方学习，这对你的大脑有好处。
大脑喜欢整洁的空间。最近的研究显示，在一个整洁、有条有理的家庭长大的孩子在学业上的表现更好。为什么，因为接受了安排外部环境的训练后，大脑学会了组织内部知道的技巧，你的记忆力会更好。
压力影响记忆。当你受到压力时，体内就会产生皮质醇，它会杀死海马状突起里的脑细胞，而这种大脑侧面脑室壁上的隆起物在处理长期和短期记忆上起主要作用。因此，压力影响记忆。最好的方法就是锻炼。
大脑并不知道你不能做哪些事情，所以需要你告诉它。用自言自语的方式对大脑说话，但是不要提供消极信息，用积极的话代替它。
大脑如同肌肉。无论在哪个年龄段，大脑都是可以训练和加强的。毫无疑问，不要寻找任何借口。不要整天呆在家里无所事事，这只能使大脑老化的速度加快。专业运动员每天都要训练，才能有突出表现。所以你一定要“没事找事”，不要让大脑老闲着。
大脑需要重复。每一次回顾记忆间隔的时间越短，记忆的效果越好，因为多次看同一事物能加深印象，但只看一次却往往容易忘记。
大脑的理解速度比你的阅读速度快。用铅笔或手指辅助阅读吗？不，用眼睛。使用这种方法的时候，需要你的眼睛更快地移动。
大脑需要运动。站着办公效率更高。
大脑会归类，也会联系。如果你正在学习某种东西，不妨问问自己：它让我想起了什么？这样做能帮助你记忆，因为大脑能把你以前知道的知识和新知识联系起来。
大脑喜欢开玩笑。开心和学习效率成正比，心情越好，学到的知识就越多，所以，让自己快乐起来吧！

]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>philosophy</tag>
        <tag>brainMemory</tag>
      </tags>
  </entry>
  <entry>
    <title>English</title>
    <url>/Philosophy/Philosophy/English/</url>
    <content><![CDATA[

1. English learning2. Website
cambridge  网页版的剑桥词典。
youglish YouGlish是一款利用Youtube的视频资源查找单词发音的工具。 Youtube很多视频都有文字稿（transcript）， YouGlish就是利用这些文字稿帮助你进行搜索。
danci88 英语单词听写
如何正确的使用新概念提高自己的写作能力 恶魔奶爸Sam教你怎样学习英语的基础写作。
有什么相见恨晚的背单词方法？ 知乎里面讲解如何高效的背单词的方法。
怎么练好英语口语？ 知乎中回答如何去练好口语的文章。
VOA美国之音: 一个让你免费学英语的网站，每周服务全球1.64亿的民众。每一条都是由美国本土资深专业播音员录制，让你戴上耳机，就能听到最标准的英语发音。分为常速和慢速，更有针对性的听力模式，适用于不同阶段的英语学习者。
chicagotribune
omaha
usnews
popsci
stackexchange
painintheenglish
多邻国：闯关式的学习各种不同的语言。

3. YouTube video
 International Phonetic Alphabet (IPA) | English Pronunciation IPA 发音教程，附带了赖世雄书里没有的基础规则和英美对比。
How to Pronounce Contractions: American English Pronunciation Rachel 教你怎样发英语中连读的音。Rachel 在YouTube上有英语学习的频道，教的课程很好，值得去学习。重点学习。
engVid: Learn English 综合性的免费英语学习网站，非常强大，很多老师很多视频，官方网站。重点学习。
EnglishLessons4U频道
JamesESL English Lessons频道
Learn English with Emma频道
English Jade - Learn English频道


Tarle Speech &amp; Language Services - English Pronunciation 教你怎样去学习单词的发音，并且老师很漂亮。重点学习。
SPEAK ENGLISH with SOZO-X 通过很很形象的视频教你怎样去学习发音。重点学习。
mmmEnglish  Emma老师的发音柔软清透、温和迷人。重点学习。

4. 英语学习经验之谈
A Programmer’s Guide to English Github上开源的项目，分享程序员学习英语的经历。
English-level-up-tips-for-Chinese 作者自己学习英语的一些经历。
everyone-can-use-english 李笑来写的关于一本书名叫《人人都能用英语》，讲述了自己对英语学习的一些见解。

5. NotesLearning in context like this will help.
思考英语的时，在你的头脑你不要更多的翻译.

Think in simple sentences.
Name objects around you in English in your head.
Have small conversations with yourself in English. 
每天花费一点时间，让自己用英语说一些对话，先试试30 days如何？


Change one of your everyday life things to English.  
用英语说自己身边的事物，如：Calendar, reading english newspaper, listening to news in english


Keep trace so you’re doing it everyday.
recap your day in English.

]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>philosophy</tag>
        <tag>english</tag>
      </tags>
  </entry>
  <entry>
    <title>EnglishElegantSentences</title>
    <url>/Philosophy/Philosophy/EnglishElegantSentences/</url>
    <content><![CDATA[ 
英文美句Books are the ever-burning lamps Of accumulated  wisdom.  书籍是积累智慧的长明灯。 
Seemingly meaningless little thought or ideas When acted upon have a potential to explode into great projects. 看似无足轻重的小想法或念头一旦得以实施，就具有演变成伟大事业的潜能。
Like the spring torrent flowing eastward, without tarry. 恰似一江春水向东流。 
Let life be beautiful like summer flowers and death like autumn leaves. 生如夏花般绚烂，死如秋叶般静美。
The joy of living comes from what we put into living, not from what we seek to get from it.生活的乐趣来自我们对生活所做的投入，而非所求。
Actions speak louder than words.行胜于言。
Let us accept new challenges, think beyond our limits and keep in mind the ethics of life.让我们迎接新的挑战，打破常规、创新思维，并坚守道德。
I wish you all the best in your future prospects and endeavors.祝愿大家前程似锦，一帆风顺。
Love alters not with his brief hours and weeks, but bears it out even to the edge of doom. 爱情时光虽短暂，却不会变迁，直到世界末日，直到天长地久。
Life is only an illusion.浮生若梦。
I like for you to be still, it is as though you were absent. And you hear me from far away and my voice does not touch you. 我喜欢你是寂静的，仿佛你消失了一样。你从远处聆听我，我的声音却无法触及你。
With utmost sincerity no difficulty is insurmountable. 精诚所至，金石为开。 
My love for you will always grow, with every passing year.时光流转，我对你的爱历久弥新。
The possibilities are limited only by our imagination.只有想不到，没有做不到。
The heart is not conquered by force, but by love and tolerance.心不是靠武力征服，而是靠爱和宽容大度。
Create your own life and then go out and live it with absolutely no regrets.创造你自己的人生，并无怨无悔地去过这一生吧。
Happiness is a butterfly, which when pursued, is always just beyond your grasp, but which, if you will sit down quietly, may alight upon you.幸福犹如蝴蝶，当你追逐它时，你永远捕捉不到，当你静坐下来时，它却可能落在你的身上。
You need to recognize each step of progress you take towards achieving your goals.你成功路上的每一点进步都值得自己的认可。
Your joy for life, transmitted wherever you took your smile, and the sparkle in those unforgettable eyes.你对生活的欣喜，通过你的微笑和你令人难忘的双眸中的闪光，传遍了你的所到之处。
satisfy the demands of the marketplace. 满足市场需求。
It can be so much more than just memorization and retention.学习知识不应该只是透过死记硬背的方式。
That is the most beautiful moonrise I’ve seen in my entire life.那是我这辈子见过的最美丽的月出时分。
With a lot of hard work and a good education, everything is possible.只要你愿意努力工作，努力接收教育，任何事情都是可能的。
You need to recognize each step of progress you take towards achieving your goals.你成功路上的每一点进步都值得自己的认可。
Though there is much to be concerned about, there is far, far more for which to be thankful.尽管有很多事让人忧虑，但相比而言，值得感激的事要多得多。
Limiting your options is the same as hanging on to old ideas.限制自己选择的机会等同于固守陈旧的观念。
When you slow yourself down, you’ll gain more time, you’ll accomplish more.舒缓身心时，你能驾驭时间，成就就更多。
The distant rims of the world and of the firmament seemed to be a division in time no less than a division in matter.远处天地交接的界限，是物质的分界，似乎也是时间的分界。
Life calls each of us, average human beings, to acts of extraordinary courage.生活促使我们每一个普普通通的人，都能拥有做出非凡举动的勇气。
It’s true: if the dream is big enough, the facts don’t count.是的，心中有目标，风雨不折腰。
When we’re held back, we’ll go farther and harder.当受到阻碍时，我们就越发坚持与努力。
A few morning gleams infiltrated the liquid strata.几缕晨光渗进水里
That little thought or idea is the beginning of great things if you decide to follow it through.如果你下定决心坚持到底，那个小小的想法或念头就会是你成就伟大事业的开始。
Even the failure to do something is in itself a deed.及时做某件事没有成功，失败本身也是功绩。
That life is too short to be little!.人生苦短休斤斤计较。
The shroud that covers me is a shroud of dust and death; I hate it, yet hug it in love.我身上披的是灰尘与死亡之衣；我恨它，却又热爱地把它抱紧。
Everything that we do is a step in one direction or another.我们所做的一切都是朝着某个方向迈出的一步。
Remember me before the memory of love disappears.在爱的记忆消失之前请记住我。
Our insatiable thirst for knowledge.我们对知识永无止境的渴求。
without&#x2F;beyond remedy.无药可救。
Better by far you should forget and smile than that you should remember and be sad.那么我愿你能微笑着把我忘记，也不要在你的记忆里留下忧伤的痕迹。
Who is there if not the beauty who has sown love seed in my heart for five hundred long years！那不是她么，五百年前在我心中播下爱情种子的美人。
From hill to hill no bird in flight；From path to path no man in sight.千山鸟飞绝，万径人踪灭。
 The best of all ways to lengthen our days is to steal some hours from the night. 一切办法中最好的办法就是延长我们的白天，从夜晚中偷几刻钟。（英国诗人-托马斯.摩尔）
The boundless forest sheds its leaves shower by shower;The endless river rolls its waves hour after hour.无边落木萧萧下，不尽长江滚滚来。
know something about everything, know everything about something. 博与精。
of the people，by the people，for the people.三明主义
I have seen the world, done it all. 阅尽繁华，历尽沧桑。
To face the powder and not to powder the face.不爱红装爱武装。出自毛泽东《七绝·为女民兵题照》。“face the powder”意为“面对硝烟”，“powder the face”则意为“涂脂抹粉”。
Love lives deep in the mind instead of residing in the lips.  爱情埋在心灵深处，并不居住在双唇之间。
His writing is elegant and urbane, full of paradoxes, aphorisms and conceits: The sky has powdered the taiga, shaking velvety down over the vert-de-bronze of the cedars. 他的作品语言优美、雅致，充满悖论、各种金句、天马行空的幻想：天空粉饰那针叶林，轻柔地散落在青绿杉树之上。
Focus is like a muscle you build over time. And, like a muscle, you need to show up and do the work to make it grow.专注力就像是长期锻炼的肌肉，你必须露出来，而且得做点事让它成长。
Years may wrinkle the skin, but to give up enthusiasm wrinkles the soul.岁月流逝只令容颜苍老，激情不再却使心灵枯萎。
To improve is to change; to be perfect is to change often.欲求新，则求变；欲求完美，则求常变。
Life is 10% what happens to you and 90% how you react to it.生活中10%是你将经历的事，而剩下的90%是你如何去应对的过程。
Everything that can be thought at all can be thought clearly. 凡是可思者，皆可想清楚。
Everything that can be put into words can be put clearly. 凡是可书者，皆可写清楚。
The horizon of life is broadened cheiefly by the enlargement of the heart.  生活的地平线是随着心灵的开阔而变得宽广的。
I am a slow walker, but I never walk back.  我走的很慢，但是我从来不会后退。
]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>philosophy</tag>
        <tag>englishElegantSentences</tag>
      </tags>
  </entry>
  <entry>
    <title>FantasticalRealistic</title>
    <url>/Philosophy/Philosophy/FantasticalRealistic/</url>
    <content><![CDATA[


简介将读过的玄幻修真类小说中一些自己感兴趣、认为比较有意思的名字记录下来，用以陶冶情操。
玄幻地域
古虞界
无间魔狱
神禁之地
雷霆之海
渊魔族
落血山脉
妖祖山脉
黑死沼泽
天魔秘境
天圣池
五行秘境
阴魔岭
幻魔渊石窟
陷阴山
生死魔窟
上古阎罗魔族
荒神废墟
虚空秘境
虚海
万象神藏
幽冥星河
血脉圣地
远古天魔秘境
死魔教
黑暗之渊
天工作
星神宫
大宇神山
虚神殿
鲲鹏谷
仙神教
大雷音寺
补天宫
通天剑阁
凝脉期
神魂契约
魂祭
圣晶
圣脉



众神之界
梵帝界
宙天界
月神界
星神界
龙神界
青龙界
南溟界
十方沧澜界
劫魂界
焚月界
阎魔界
天玄大陆
幻妖界
沧云大陆
太初神境
剑灵神族
玄神大会
宙天三千年
天威剑域



天武大陆
鸿蒙界

角色女性
紫薰
陈思思
敖青菱
厉晚雪
上官曦儿
上官婉儿
幽千雪



池妩仸
神曦
苍月
幻彩衣
彩脂
凤雪児
水媚音
楚月婵
千叶影儿
月无垢



彩鳞
萧薰儿
应欢欢
绫清竹
诗静依
秦妖娆
南宫婉
紫菱



青芜
皇甫无双

男性
破天
冷无双
帝天一
严赤道
付乾坤
欧阳正奇
墨渊白
魔卡拉
风雨雷
轩辕问天
火破云
君惜泪
君无名
星绝空
逆玄
劫渊
清茗
洛劫

人物称号
极镜丹帝
破尘武皇
狂刀武帝
至尊刀帝
玄冰武帝
霸绝武帝
永夜魔君
大悲老人
位面之子



古苍武皇
赤炎魔君
劫天魔帝
天杀星神
始祖神
天狼星神
邪婴
宙天神帝
紫阙月神
梵天神女
天威剑域剑主
天魁星神
渊魔之主
涅轮魔帝



鸿蒙至尊
通天至尊
鸿古至尊

体质
天生道体
完美魔化体质
空间之体
冰雪神体
天生媚体
天生剑体
天生灵体
刀神体
天生火源体
天生玉体
天生雷体
轮回魔体
魔媚之体
太宙神体
时间圣体
宇宙无极体
神魔体
荒古之体
寒冰玉体
星光体
无上古体
不灭龙身
光明圣体
血阳神体
太阴空灵体
月神体
玉骨冰肌之体



邪神玄脉
凤凰魂源
凤凰神魂
龙神血脉
龙神之髓
龙神魂源
玄罡
冰凰源血
冰凰神魂
金乌源血
金乌魂源
星神血
冰雪琉璃心
九玄玲珑体
远古天灵
无垢神魂
黎娑



虚无神体
雷神体
九天玄灵体
天灵古体
天象之体
火神体
八窍之体
不败神体
万凶之体
无上毒体

玄技功法
天赋数值
时间规则
神魂离体
无漏境界
规则之力
空间道则之力
魂灭大劫
鸿蒙雷劫
天龙雷神劫
灭世雷劫
天道誓言
武道真谛



凤凰颂世典
光明玄力
邪神诀
大道浮屠诀
天狼狱神典
冰凰封神典
金乌焚世录
星神碎影
逆世天书
永夜幻魔典
黑暗永劫
生命神迹
断月拂影
幻光雷极
流光雷隐
玄罡幻神
绯红之炎
天道神力


神通

残夜
流月
梦道
因果印
生死印
真假印
古族不灭指
生死因果真假本源大阵
心动雷音
定神术
踏天一步


本源

金
木
水
火
土
雷
生死
因果
真假
轮回
太初
默灭
禁制
杀戮

灵宝
乾坤造化玉碟
魔魅心石
劫天诛魔剑
劫天魔帝剑
宙天珠
天毒珠
音蝶刃
太古玄舟
遁月仙宫
邪婴万劫轮
龙鳞宝甲
轮回镜
幻心蝶语枪
神谕
破魔剑
雾光剑
神风钺
圣雷剑
慏龙刀
生命神水
龙曦玉液
诛天始祖剑
鸿蒙生死印
乾坤刺
弑神绝殇毒
血魂晶魄

灵草
奇异灵虫
万年苦韵芝
七彩灵果
幽冥婆罗花



神农仙草
赤莲药王
紫晶玉兰
雪域灵芝王
真龙果
天山雪参
地灵之根

神兽
凤凰
龙神
金乌



虚龙
兽神

兵器
九转苍翎

职业
炼药师
血脉师
炼器师
阵法师
禁制师
驯兽师
驯虫师
鉴宝师
精神师
机关师
符文师



天相师

修真等级
武者：人级，地级，天级，玄级，武宗，武尊，武王，武皇，武帝，凡圣，地圣，天圣，圣主，人尊，地尊，天尊，至尊，超脱之境
凡体九境：初玄境、入玄境、真玄境、灵玄境、地玄境、天玄境、王玄境、霸玄境、君玄境
神玄七境：神元境、神魂境、神劫境、神灵境、神王境、神君境、神主境 
远古真神之境：神灭境、真神、创世神、始祖神



境界：武徒、武者、武师、大武师、武灵、武宗、武尊、武王、武皇（大能）、凡圣、大圣、半步大帝、大帝、神主、至尊、神将、仙灵、古神、道祖。
功法：分为天，地，玄，黄，无品等五个品级，每个品级又分高，中，低，三个阶别。
相师：玄级，地级，天级。
灵药的等级：普通、稀珍，药王。
药典：分为黄、玄、地、天、圣五个等级，神农药典为唯一的圣级药典。

]]></content>
      <categories>
        <category>Philosophy</category>
      </categories>
      <tags>
        <tag>philosophy</tag>
        <tag>fantasticalRealistic</tag>
      </tags>
  </entry>
  <entry>
    <title>Work</title>
    <url>/Product/Product/Work/</url>
    <content><![CDATA[1. Owner意识
认真负责
积极主动

2. 时间观念
做事有计划


计划制定过程中，尽可能把每一项拆的很细。粒度越细，计划就越精准，实际开发与计划之间的误差就会越小。
设置关键节点的可检查产出。


工作安排分主次

3. 有始有终
先想清楚目标，再具体实现。

不仅要做需求开发，还要关注目标i与收益之间的情况。系统上线后，须持续关注使用效果。（方便后续的技术优化）

根据具体问题设定优化目标。优化到什么程度？满足什么样的要求？


4. 闭环思维
凡是有交代，件件有着落，事事有回音。    
有问题及时反馈，形成闭环。沟通要有结论，通知要有反馈，TO DO 要有验收。
定期主动进行阶段性的反馈。 防止执行者与 leader 之间信息不对称，得不到及时的反馈。从 leader 的角度思考，其实仅仅想知道项目是否在正常推进，是否遇到问题需要解决。
总结（季度总结）时须罗列的要点
项目取得了哪些收益？
对业务有哪些提升。



5. 规范准则
设计规范

代码规范

上线规范
熟悉上线流程、回滚操作，了解一些常见的约定规则。

建议：如果事情拿不准，不妨多问问其他的同事，不要凭感觉做事。



规范并不是一成不变的，充分理解了规范和约定后，若果觉得存在有不妥的地方，可以跟全组同学讨论，是否采纳新的建议，然后及时去更新迭代。其实，让规范与约定与时俱进，也是另一种形式的敬畏。
6. 事不过二
所有的评审与问题讨论，不要超过两次
同样的错误不能犯第二次。每次故障之后，Casestudy都必须进行深刻的总结复盘，对故障原因进行5Why分析，给出明确可执行的To Do List。每次季度总结会，大家自我反省问题所在，在下个季度必须有所改善，不能再犯类似的错误。

7. 设计优先
软件架构的目标，是为了让构建与维护系统的所需人力资源最小化。


架构设计，并不仅仅关系到系统的质量，还关乎团队的效能问题。很多团队也有明文规定，开发周期在3pd以上的项目必须有设计文档，开发周期在5pd以上的项目必须有设计评审。
设计优先”这一原则，要求写别人看得懂的设计。我们了解一个系统最直接的途径就是结合设计文档与代码。
设计的过程是一种智力上的创造，它是个人与集体智慧的结晶。

如何让设计变得通俗易懂？

设计应该尽量使用比较合理的逻辑，进而把设计中的一些点组织起来。比如可以使用从抽象到具体，由总到分的结构来组织材料。
以需求为出发点，通过合理的抽象把问题简化，讲清楚各个模块之间的关系，再详细分述模块的实现细节。
做完设计之后，可以发给比较资深的RD或者PM审阅一下，根据他们的反馈再进行完善。好的设计，一定是逻辑清晰易懂、细节落地可执行的。

8. 学习
在项目中学习和总结持续提升自己的技术能力和软素质，并将其应用于项目实施交付中，相信一定会取得双赢的结果。
在工作中，多去跟不同级别的同学聊一聊，或者做一个360度评估，这有助于我们更加客观地评价自己。
向那些优秀的同学看齐，学习他人的优点。

9. 提问
波克定理告诉我们，只有在争辩中，才可能诞生最好的主意和最好的决定。


提问之前，明确自己想要表达的内容，尽可能条理清晰的罗列出要点。
设计评审的目的，是让大家针对方案提出改进意见并达成一致，如果全程“打酱油”，那就失去了评审的意义。我们鼓励大家多提问，把自己内心的疑惑表达出来，然后通过交流的方式得到答案。

参考

美团技术：写给工程师的10条精进建议

]]></content>
      <categories>
        <category>Product</category>
      </categories>
      <tags>
        <tag>product</tag>
        <tag>work</tag>
      </tags>
  </entry>
  <entry>
    <title>Beckhoff</title>
    <url>/Protocol/Protocol/Beckhoff/</url>
    <content><![CDATA[References
官网: https://www.beckhoff.com/en-en/
在线资料 Beckhoff Information System: https://infosys.beckhoff.com/
PC-Control 杂志: https://www.pccontrols.net/
虚拟学院: https://tr.beckhoff.com.cn/course/index.php

]]></content>
      <categories>
        <category>Protocol</category>
      </categories>
      <tags>
        <tag>protocol</tag>
        <tag>beckhoff</tag>
      </tags>
  </entry>
  <entry>
    <title>SMTP</title>
    <url>/Protocol/Protocol/SMTP/</url>
    <content><![CDATA[1. 简介SMTP（Simple Mail Transfer Protocol）即简单邮件传输协议，尽管邮件服务器可以用SMTP发送、接收邮件，但是邮件客户端只能用 SMTP 发送邮件，接收邮件一般用 IMAP 或者 POP3。邮件客户端使用 TCP 的 25 号端口与服务器通信。
SMTP在1982年首次被定义在  RFC 821 ，在2008它被更新为扩展的SMTP协议，补充在文件 RFC 5321 ，扩展的协议是目前使用最广泛的协议。
2. 命令SMTP命令由 4 个不区分大小写的字母组成，如果命令带参数，则用空格与参数隔开，每条命令用回车换行结尾 CRLF。
2.1. EHLO（Extended hello）or  HELO（hello）这个命令用于说明自己是SMTP客户端身份，参数包含客户端的域名(domain)。其中EHLO是SMTP补充协议（ RFC 5321 ）中用于替换HELO命令的新命令，协议规定服务器支持EHLO命令的时候，尽量使用EHLO命令，为了兼容以前的版本，要求服务器继续支持HELO命令。如果收到回复OK，说明发送者和接收者处于初始状态，所有的状态表和缓存区都被清零。
2.2. MAIL这个命令的参数是发送者邮箱 ，参数中有 FROM关键字，这个命令会清空之前的发送者邮箱（the reverse-path buffer）、接收者邮箱（forward-path buffer）和邮件数据（the mail data buffer）。
2.3. RCPT （recipient）用于指定一个邮件接收者，参数中有TO 关键字，指定多个接收者通过重复使用这个命令。
2.4. DATA这个命令没有参数，告诉服务器接着要发送邮件内容。邮件内容包含邮件标题项（message header section ）和邮件正文（message body），标题项（Header Fields ）是以项目名（field name）为行的起点，接着是冒号(“:”)，跟着是内容（field body）以回车换行结束（CRLF），下面是标题项的例子From: &#66;&#111;&#x62;&#64;&#x65;&#120;&#97;&#x6d;&#112;&#x6c;&#x65;&#x2e;&#99;&#x6f;&#109;To: &#65;&#108;&#x69;&#x63;&#x65;&#x40;&#101;&#x78;&#97;&#x6d;&#x70;&#x6c;&#x65;&#x2e;&#99;&#x6f;&#x6d;Cc: &#116;&#104;&#x65;&#98;&#x6f;&#x73;&#115;&#x40;&#101;&#120;&#x61;&#109;&#112;&#x6c;&#x65;&#x2e;&#x63;&#111;&#109; 
2.4.1. subject: subject其中From、To、Cc、subject就是项目名，冒号后是内容。邮件的标题区与正文区需要用一个空行隔开。两者共同组成DATA命令的参数，正文区用只有一个点字符 . 的单行来结束。
2.5. SEND初始化邮件事务，邮件数据被转发到一个或多个终端。
2.6. SOML（SEND OR MAIL)初始化邮件事务，邮件数据被转发到一个或多个终端或邮箱。
2.7. SAML（SEND AND MAIL）初始化邮件事务，邮件数据被转发到一个或多个终端和邮箱。
2.8. RSET（RESET）这个命令用来终止邮件事务（mail transaction），任何已经存储的发送者、接收者、邮件数据（mail data）信息都被丢弃，缓存区被清零。
2.9. VRFY（VERIFY）验证邮箱是否存在，如果参数是用户名，则返回一个全名（如果存在）。
2.10. EXPN（EXPAND）验证邮箱列表
2.11. HELP返回帮助信息，带参数时候，返回指定的帮助信息。
2.12. NOOP这个命令指示服务器收到命令后不用回复 “OK”
2.13. QUIT关闭传输通道。
2.14. TURN交换邮件发送者和接收者的角色，这个命令用在建立连接成本高的时候，TCP连接不用这个命令。这个命令会产生安全问题，只有在服务器可以被授权作为客户端时候才能用。
3. 原理SMTP被设计基于以下交流模型：当用户需要发邮件时候，邮件发送者(sender-SMTP)建立一个与邮件接收者(receiver-SMTP)通信的通道，发送者发送SMTP命令给接收者，接收者收到后对命令做回复。
通信通道被建立后，发送者发送 MAIL 命令来指定发送者的邮件，如果接受者接收这个邮件，就回复 OK ，接着发送者发送 RCPT命令来指定接收者的邮箱，如果被接收同样回复OK，如果不接受则拒绝（不会终止整个通话）。接收者邮箱确定后，发送者用DATA命令指示要发送数据，并用一个 .  结束发送。如果数据被接收，会收到OK ，然后用QUIT结束会话。
SMTP 发送邮件步骤

用 MAIL 命令给出发送者的身份
这个命令告诉接收者，开始一个新的邮件事务，重置所有的状态表和缓存区，包括接受者信息和邮件数据，被用于报告错误，如果命令被接受，返回250 OK

用一个或者多个RCPT命令给出接收者信息
这个命令提供一个接收者邮箱，如果被接受返回250 OK，如果不能被识别，返回550 Failure，这个第二步可以被重复多次。

用 DATA命令给出邮件数据
如果被接受，返回354，并认为所有后续行都会邮件数据信息。当收到文本结束符时候，返回 250 OK。邮件数据的末尾必须被指明，为了激活命令和回复的对话。通过发送只包含一个英文句号的行，来提示邮件数据结束。


4. Reference
RFC 2821: Simple Mail Transfer Protocol

C语言使用SMTP发送邮件_yanglx2022的博客-CSDN博客_c语言发送邮件

SMTP协议介绍_Ouyang_Lianjun的博客-CSDN博客_smtp


      
]]></content>
      <categories>
        <category>Protocol</category>
      </categories>
      <tags>
        <tag>protocol</tag>
        <tag>sMTP</tag>
      </tags>
  </entry>
  <entry>
    <title>Siemens</title>
    <url>/Protocol/Protocol/Siemens/</url>
    <content><![CDATA[
Siemens ProtocolReferences
Siemens communications overview: Siemens S7 Common 通信概述

]]></content>
      <categories>
        <category>Protocol</category>
      </categories>
      <tags>
        <tag>protocol</tag>
        <tag>siemens</tag>
      </tags>
  </entry>
  <entry>
    <title>protocol</title>
    <url>/Protocol/Protocol/protocol/</url>
    <content><![CDATA[Terms
pattern
ethernet
transport
chunk
bulk

Network Topology 

host
links
router
driver
socket
iptable
network interface
layer
source
destination
MTU: Maximium Transmission Unit
TCP: Transmission Control Protocol
UDP: user Datagram Protocol

OSI
Physical
bit
symbol


Data link
frame
ID
offset
flag
payload
data link
sequence
field


Network
datagram
packet


Transport
segment


Session
session


presentation
Application

]]></content>
      <categories>
        <category>Protocol</category>
      </categories>
      <tags>
        <tag>protocol</tag>
      </tags>
  </entry>
  <entry>
    <title>Qt</title>
    <url>/Qt/Qt/Qt/</url>
    <content><![CDATA[

1. 信号与槽函数
QT中使用 connect()来操作信号与槽

connect() 中的第五个参数作用：只有在多线程处理时才有意义。如果是多线程，默认使用队列，如果是单线程，默认使用直接的方式。队列：槽函数所在线程和接收者一样；直接连接：槽函数所在线程与发送者一样。


信号

signals: 就是信号代码段的标志，这个标志不带 public 、protected、private 等前缀，那是因为信号默认强制规定为公有类型，这样才能保证其他对象能接收到信号。


自定义信号
返回值是void，只需要声明，不需要实现
函数中可以有参数，可以重载
触发信号使用 emit 关键字


标准的信号


槽函数

自定义槽函数
早期Qt版本必须写到public slots下，现在高级版本可以直接写在public下
返回值为void，需要声明，也需要实现
可以有参数，可以重载


标准的槽函数


 注意点 

信号可以连接信号
一个信号可以连接多个槽函数。
多个信号可以连接同一个槽函数。
信号与槽函数的参数类型必须一一对应。
信号的参数个数可以多于槽函数的参数个数，反之则不行。
信号与槽函数重载时，需要将将信号与槽函数分别定义为函数指针，再传入函数的地址，否则编译器会出错。函数指针：void (*p)(int) = fun
在Qt4中，槽函数必须使用 slots 关键字来修饰，使用下面的方式来调用信号与槽函数。
connect(&amp;sender, SIGNAL(mySignal), &amp;ricever, SOLT(mySlot));这样做的缺点：SIGNAL和 SOLT这两个宏将mySignal和mySlot函数的名字各自转化为字符串，而不做错误检查，而是在运行时才给你报错。因此，不建议使用Qt4的标准，采用Qt5的标准比较好。





2. 对象树Qt 内部维护了一个对象树，通过父类对象来回收子类对象的资源。
父类：按照继承关系来说的。
父对象：按照从属关系来说的。
3. lambda表达式
lambda表达式也叫匿名函数表达式，其中函数没有名称。
格式：[]()&#123;&#125;，需要在项目配置文件中加入 CONFIG += c++11，才有效，现在高版本Qt已经默认将该项添加到配置文件中了。
[]标识符，匿名函数
=: 将类中所有的成员变量、局部变量，按值方式传递。
&amp;: 将类中所有的局部变量按照引用传递。
this: 将类中所有的成员变量按值方式进行传递。


()参数
标识重载的()操作符参数，若没有参数时，这部分可以省略，参数通过按值(a, b) 或按引用(&amp;a, &amp;b)两种方式进行传递。
mutable 关键字，修改值传递进来的拷贝值，而并不是原来的值。


{} 函数实现体
函数中具体实现的内容


返回值
一般使用 -&gt;来表示返回值：[]()-&gt;int&#123;&#125;



4. 对话框
模态对话框（阻塞对话框）：创建对话框后不可以对其它的对话框进行操作。
非模态对话框：创建对话框后可以对其它的对话框进行操作。

5. Qt内存回收机制
指定父对象
如果不指定父对象，子控件与父控件之间没有任何的关系。若指定父对象后，对象上的子对象自动显示。
两种方式指定父对象：
setParent();  函数
通过构造函数传参数来指定父类对象：QPushButton* btn3 = new QPushButton(this);




子类对象指定父类对象后，若子类对象是动态分配的，不需要手动 delete 释放，父类对象会自动释放内存。
注意：
必须要指定父类对象，否则就需要手动释放。
父对象直接或间接继承于 QObject 类。



6. QStringQt 库中对字符串类型进行了封装，QString 类提供了所有字符串操作方法，给开发带来了便利。 由于第三方库的类型基本上都是标准的类型，即使用std::string或char *来表示字符 (串) 类型，因此在Qt框架下需要将QString转换成标准字符 (串) 类型。
7. std::string和char *的相互转换
将char *或char[]转换为std::string
std::string ss,str;const char *y=&quot;hello&quot;;const char z[]=&quot;hello world&quot;;ss=y;str=z;

将std::string转换为char *或char[]，有3种方法，推荐第二种方法

1)尾部不会附加结束符’\0’
std::string str=&quot;abc&quot;;char *p=str.data();

2)尾部附加结束符’\0’
std::string str=&quot;Pigman&quot;;char ch[10];strcpy(ch,str.c_str());
3)尾部不会附加结束符’\0’，第二个参数为复制字符个数，第三个为复制位置
std::string str(&quot;pig can fly&quot;);char *p;str.copy(p,3,0);*(p+3)=&#x27;\0&#x27;;　　//　手动添加结束符



8. QString和std::string相互转换，以及避免出现乱码QString qstr;std::string str;//　　QString转std::stringstr=qstr.toStdString();str=(const char*)qstr.toLocal8bit();　　　　　　//　中文字符串避免出现乱码//　　std::string转QStringqstr=QString::fromStdString(str);qstr=QString::fromLocal8bit(str.c_str());　　//　中文字符串避免出现乱码


9. QString和char *相互转换
QString转为char *
两种方法  1. 先转为std::string，再转为char *，如上所示  2. 先转为QByteArray，再转为char *  QString ss(&quot;Flying without wings&quot;);QByteArray sr=ss.toLocal8Bit();char ch[10];strcpy(ch,sr.data());


char *转为QString
char *ch=&quot;westlife&quot;;QString str(ch);   // Qt5     QString str = QString::fromUtf8(ch);    //  Qt4

10. Qt常用类10.1. QFrame
QFrame与QWidget的区别：
QWidget类是所有用户界面对象的基类。QFrame是基本控件的基类，QWidget是QFrame基类。其关系如下 QPushButton,QLabel… -&gt; QFrame -&gt;QWidget

Widget是用户界面的基本单元：它从窗口系统接收鼠标，键盘和其他事件，并在屏幕上绘制自己。每个Widget都是矩形的，它们按照Z-order进行排序。




10.2. QBoxLayout
QBoxLayout 可以在水平方向或垂直方向上排列控件，由QHBoxLayout、QVBoxLayout所继承。
QHBoxLayout：水平布局，在水平方向上排列控件，即：左右排列。
QVBoxLayout：垂直布局，在垂直方向上排列控件，即：上下排列。



10.3. QComboBoxQComboBox 是下拉列表框组件类，它提供一个下拉列表供用户选择，也可以直接当作一个 QLineEdit 用作输入。QComboBox 除了显示可见下拉列表外，每个项（item，或称列表项）还可以关联一个 QVariant 类型的变量，用于存储一些不可见数据。
10.4. SpacerQSpacerItem类为布局提供了一个空白区。
10.5. QStackedWidgetQStackedWidget继承自 QFrame。QStackedWidget类提供了多页面切换的布局，一次只能看到一个界面。QStackedWidget可用于创建类似 QTabWidget提供的用户界面。
10.6. QPushButtonsetCheckable(true)为属性，表示可以选中
setChecked（true）为属性的值，表示已经选中
10.7. QStringQString QString::trimmed() const   返回值为去除了字符串中的开头和结尾的空字符，不能去除掉字符串内部的空字符。
QString QString::simplified() const  返回值为去除了字符串开头和结尾空的字符，并且字符串内部的空字符也去掉。
11. 多线程多线程编程也使用回调函数作为新线程里的任务函数。
TCP Client 接口
connectToHost(IP, Port)函数连接服务端
readyRead()信号是否被触发来判断是否有数据传入，如果该信号被触发，则调用自定义函数（如：ClientRecvData()）来保存接收到的数据。通过connect()函数，将信号readyRead()与槽函数ClientRecvData()建立映射关系。在槽函数ClientRecvData()中通过read()函数接收数据
关闭 TCP 连接
void QAbstractSocket::disconnectFromHost()void QAbstractSocket::close()void QAbstractSocket::abort()
TCP Server 接口 
QHostAddress::Null表示一个空地址；
QHostAddress::LocalHost表示IPv4的本机地址127.0.0.1；
QHostAddress::LocalHostIPv6表示IPv6的本机地址；
QHostAddress::Broadcast表示广播地址255.255.255.255；
QHostAddress::Any表示IPv4的任意地址；
QHostAddress::AnyIPv6表示IPv6的任意地址。
ewConnection() 来判断是否接收到了新的连接，当服务端接收到一个客户端的连接时，就会触发信 newConnection()
nextPendingConnection() 函数获得连接客户端的SOCKET套接字：
readyRead()来判断是否有数据传入，当客户端向服务端成功发送数据之后，就会在服务端触发readyRead()信号
12. Qt Creator 快捷键
F1  查看帮助
F2  跳转到函数定义（和Ctrl+鼠标左键一样的效果）
Shift+F2    声明和定义之间切换
F4: 同名.h与.cpp文件之间快速的切换 
ctrl + shift + ↑或↓: 整行向上或向下移动
ctrl + alt + ↑或↓: 将当前行整行向上或向下复制
shift + F5:   停止调试
F5:           启动调试
Ctrl+1        欢迎模式
Ctrl+2        编辑模式
Ctrl+3        调试模式
Ctrl+4        项目设置模式
Ctrl+5        帮助模式    
Ctrl+6        输出模式
ESc           切换到编辑模式
Ctrl+B        编译工程
Ctrl+R        运行工程
Ctrl+I        自动对齐
Ctrl+/        注释行，取消注释行
Ctrl+F        查找替换当前选中的内容
Ctrl+I        自动对齐
Ctrl+Shift+F  查找内容
F5            开始调试
Shift+F5      停止调试
F9            设置和取消断点
F10           单步前进
F11           单步进入函数
Shift + F11   单步跳出函数
Ctrl+ Tab     快速切换已打开的文件
快速在(.cpp)文件中添加方法的实体：将光标移动到 .h 文件中的方法声明，先按 Alt(按住)+ Enter，再按 回车键 将在 .cpp 中添加该函数的声明。
Ctrl + Shift + R 一次性修改多个变量

13. References
关于QT的系统总结（非常全面，非常好）
Qt 学习之路 2：简单些了Qt一些主要的学习内容。
Qt 资料大全：一去丶二三里 CSDN博主总结的Qt学习的资料。
QT读取和写入文件：讲解了QFile、QFileInfo、QTemporaryFile、QDir的相关用法。
QT学习笔记8：QDir类及其用法总结：QDir类提供了访问系统目录结构及其内容的与平台无关的方式。
Qt拷贝文件、文件夹、创建文件夹、删除文件夹操作
QT创建TCP Socket通信
https://cryfeifei.top/2020/05/30/qt-ji-chu-jiao-cheng/-QString, Std::string, char *相互转换

]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>qt</tag>
      </tags>
  </entry>
  <entry>
    <title>FQA</title>
    <url>/Redis/Redis/FQA/</url>
    <content><![CDATA[思考
如果使用了 Redis，每次 Redis 操作的耗时是多少？对于大批量操作的场景，Redis 有使用 Pipeline 做优化吗？Redis 集群是否有考虑不兼容的操作方式？如何实现高性能的等价操作？
Redis 集群的内存用量大小，有无监控？
Redis 前面是否需要多加一层本地 Cache，直接在服务本地处理（如限制某个 token 一定时间只能使用一次，一个用户一天只能投一次票等等）

References
Redis 集群配置：https://blog.csdn.net/aloneno/article/details/96370167

]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>fQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis</title>
    <url>/Redis/Redis/Redis/</url>
    <content><![CDATA[

1. 如何学 Redis如何花费很少的时间掌握 Redis 的知识和使用经验，去解决更多的问题。需要自己抓住主线，在自己的脑海中绘制一幅 Redis 全景知识图，从整体上去看 Redis，建立一套完整的体系架构。下面这幅图概述了 Redis 学习的“两大维度，三大主线”。
“两大维度”：指系统维度和应用维度，“三大主线”：是指高性能、高可靠和高可扩展。
从系统维度上说，需要了解 Redis 的各项关键技术的设计原理，这些能够为你判断和推理问题打下坚实的基础，而且，你还能从中掌握一些优雅的系统设计规范，例如 run-to-complete 模型、epoll 网络模型，这些可以应用到你后续的系统开发实践中。
从应用维度上，按照两种方式学习: “应用场景驱动”和“典型案例驱动”，一个是“面”的梳理，一个是“点”的掌握。比如，缓存和集群是 Redis 的两大广泛的应用场景，而提到缓存场景，需要想到缓存机制、缓存替换、缓存异常等一连串的问题。
三大主线：

高性能主线，包括线程模型、数据结构、持久化、网络框架；
高可靠主线，包括主从复制、哨兵机制；
高可扩展主线，包括数据分片、负载均衡。



2. 概念NoSQL 数据库

NoSQL &#x3D; Not Only SQL（不仅仅是 SQL），泛指 non-relational（非关系型数据库）。今天随着互联网 web2.0 网站的兴起，比如谷歌或 Facebook 每天为他们的用户收集万亿比特的数据， 这些类型的数据存储不需要固定的模式，无需多余操作就可以横向扩展，就是一个数据量超大。传统的 SQL 语句库不再适应这些应用了。 NoSQL 数据库是为了解决大规模数据集合多重数据种类带来的挑战，特别是超大规模数据的存储。
NoSQL 数据库特点：采用聚合数据结构存储数据，去掉了关系数据库的关系型特性，数据之间一旦没有关系，使得扩展性、读写性能都大大提高。

什么是 redis？

Redis 全名叫 Remote Dictionary Server，即远程字典服务，是一个开源的用 C 语言编写、遵守 BSD 协议、基于内存运行并支持持久化的日志型、key-Value 的数据库、并提供多种语言的API。为了保证效率，Redis 将数据缓存在内存（memory）中，周期性的将数据写入磁盘。
redis 是 Nosql 数据库中使用较为广泛的非关系型内存数据库，redis 内部是一个key-value 存储系统。它支持存储的 value 类型相对更多，包括 string（字符串）、list（链表）、set（集合）、zset（sorted set –有序集合）、 hash（哈希类型）、位图，hyperloglogs 等数据类型。Redis 基于内存运行并支持持久化的 NoSQL 数据库，是当前最热门的 NoSql 数据库之一，也被人们称为数据结构存储服务器。

Redis 的主要优点

Redis 支持数据的持久化，可以将内存（memory）中的数据保持在磁盘（disk）中，重启的时候可以再次加载进行使用。
Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。
Redis 支持数据的备份，即主从（master-slave） 模式的数据备份。

Redis 应用场景

用作缓存数据：将经常需要查询的数据存储在内存（memory） 而不是磁盘中，来提高效率。
用作消息队列：相当于消息订阅系统，只能用于对数据一致性不高的业务中，对数据一致性要求较高时，建议用消息中间件，比如 ActiveMQ、RocketMQ。
计数器：比如统计点击率、点赞率，可以快速实现计数和查询的功能。redis 具有原子性，可以避免并发问题。
电商网站信息：大型电商平台初始化页面数据的缓存。比如去哪儿网购买机票的时候首页的价格和你点进去的价格会有差异。
热点数据：比如新闻网站实时热点、微博热搜等，需要频繁更新。总数据量比较大的时候直接从数据库查询会影响性能。

3. 历史Redis 的作者 antirez

Redis v4.0（引入多线程处理异步任务）
Redis v6.0（正式在网络模型中实现 I&#x2F;O 多线程）

4. 配置Redis/src/ 目录相关文件功能描述

redis-server: redis 服务器
redis-cli: redis 命令行客户端
redis-benchmark: redis 性能测试工具
redis-check-aof: aof 文件修复工具
redis-check-rdb: 文件检查工具

/usr/lib/systemd/system/ 目录下存放的都是开机自启动服务。

loglevel: 日志级别。开发阶段可以设置成 debug，生产阶段通常设置为 notice 或者 warning。
logfile: 日志文件保存路径，默认下没有配置。
requirepass： 配置 Redis 的访问密码。默认不配置密码，即访问不需要密码验证。 此配置项需要在protected-mode=yes 时起作用。

5. 启动Redis 客户端与服务器的启动。

redis-cli：启动 Redis 客户端
redis-cli -h host -p port -a password：远程机器上启动 Redis 客户端
redis-server：启动 Redis 服务器

可执行程序后面不跟参数，后台直接启动 server
[root@redis_181 redis-6.0.16]# redis-server &amp;[1] 1796[root@redis_181 redis-6.0.16]# 1796:C 23 Nov 2021 06:59:05.276 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo1796:C 23 Nov 2021 06:59:05.276 # Redis version=6.0.16, bits=64, commit=00000000, modified=0, pid=1796, just started1796:C 23 Nov 2021 06:59:05.276 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf1796:M 23 Nov 2021 06:59:05.277 * Increased maximum number of open files to 10032 (it was originally set to 1024).                _._           _.-``__ &#x27;&#x27;-._      _.-``    `.  `_.  &#x27;&#x27;-._           Redis 6.0.16 (00000000/0) 64 bit  .-`` .-```.  ```\/    _.,_ &#x27;&#x27;-._ (    &#x27;      ,       .-`  | `,    )     Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;|     Port: 6379 |    `-._   `._    /     _.-&#x27;    |     PID: 1796  `-._    `-._  `-./  _.-&#x27;    _.-&#x27; |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;| |    `-._`-._        _.-&#x27;_.-&#x27;    |           http://redis.io  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27; |`-._`-._    `-.__.-&#x27;    _.-&#x27;_.-&#x27;| |    `-._`-._        _.-&#x27;_.-&#x27;    |  `-._    `-._`-.__.-&#x27;_.-&#x27;    _.-&#x27;      `-._    `-.__.-&#x27;    _.-&#x27;          `-._        _.-&#x27;              `-.__.-&#x27;


可执行程序后面跟参数，比如指定配置配置文件、指定端口，再在后台启动 server
[root@redis_181 redis-6.0.16]# redis-server ./redis.conf  --port 1123 &amp;

// 启动 client$redis-cli -h 127.0.0.1 -p 6379 -a &quot;mypass&quot;redis 127.0.0.1:6379&gt;redis 127.0.0.1:6379&gt; PING   // 检测 redis 服务是否启动PONG// 远程登录时，未指定密码，连接后再密码验证$redis-cli -h 127.0.0.1 -p 6379redis 127.0.0.1:6379&gt;auth &quot;your passwd&quot;OK

6. 命令6.1. General command
info: 查看 Redis 的所有统计信息。
select index: 切换数据库。
dbsize: 查看当前数据库中 key 的数目。
flushdb: 清空当前库。
flushall: 清空所有数据库。
config get *: 查看 Redis 中的配置信息。

6.2. KEYSRedis 键（key）命令用于管理 redis 的键。

key pattern: 查找所有匹配给定模式的键。示例：keys * : 查询数据库中所有的键。

常用的符号

？: 匹配一个字符 
*: 匹配任意个字符（包括0个字符）
[]: 匹配括号间的任一字符
\* : 匹配字符x，用于转义符号；若要匹配 ？，则使用 \?

127.0.0.1:6379&gt; keys *1) &quot;wang&quot;2) &quot;my_set&quot;3) &quot;deng&quot;4) &quot;my_zset&quot;5) &quot;my_table&quot;6) &quot;name&quot;7) &quot;key2&quot;8) &quot;s_set&quot;9) &quot;key1&quot;

6.3. EXISTSexists key：判断一个按键是否存在，如果按键存在，则返回整数类型1，否则返回0
127.0.0.1:6379&gt; exists li(integer) 0127.0.0.1:6379&gt; exists wang(integer) 1

6.4. DELdel key1, key2 ... 删除一个或多个按键，返回值是删除的键的个数。
127.0.0.1:6379&gt; del match_rank s_set(integer) 2

6.5. DUMPdump key：序列化给定的key ，如果 key 不存在，那么返回 nil； 否则，返回序列化之后的值。
序列化生成的值有以下几个特点：

它带有 64 位的校验和，用于检测错误，RESTORE 在进行反序列化之前会先检查校验和。
值的编码格式和 RDB 文件保持一致。
RDB 版本会被编码在序列化值当中，如果因为 Redis 的版本不同造成 RDB 格式不兼容，那么 Redis 会拒绝对这个值进行反序列化操作。
序列化的值不包括任何生存时间信息。

127.0.0.1:6379&gt; get name&quot;jackpeter&quot;127.0.0.1:6379&gt; dump name&quot;\x00\tjackpeter\x06\x00\x94\\\xe0\xa8&gt;\x0ef\xf8&quot;127.0.0.1:6379&gt; dump na(nil)

6.6. MOVEmove key db：将当前数据库的键值 key 移动到给定的数据库 db 当中，移动成功返回 1，失败则返回 0。
如果当前数据库(源数据库)和给定数据库(目标数据库)有相同名字的给定 key ，或者 key 不存在于当前数据库，那么 MOVE 没有任何效果。
6.7. TYPEtype key1, key2, ...: 获取按键的数据类型。数据类型可以是 string、hash、list、set、zset。
127.0.0.1:6379&gt; type namestring

6.8. RENAME
rename key key1：将键值 key 修改为 key1

renamenx key key1：仅当键值 key1 不存在当前数据库中时，才可以将 key 修改为 key1

randomkey：从当前数据库中随机返回一个 key 。
127.0.0.1:6379&gt; rename name my_nameOK127.0.0.1:6379&gt; renamenx my_name age   // 数据库中已存在age键(integer) 0127.0.0.1:6379&gt; get my_name&quot;jackpeter&quot;127.0.0.1:6379&gt; renamenx my_name tt(integer) 1127.0.0.1:6379&gt; randomkey&quot;key2&quot;127.0.0.1:6379&gt; randomkey&quot;age&quot;

6.9. TTLredis 在实际使用过程中一般用作缓存，然而缓存的数据一般都需要设置生存时间，也就是到期后销毁数据。

expire key seconds：键值对的生存时间为 seconds，时间到后，销毁键值对中的数据
TTL key：以秒为单位，返回给定 key 的剩余生存时间（TTL, time to live）。
TTL返回值：
大于 0 的数字：剩余生存时间，单位为秒
-1 ： 没有生存时间，永久存储
-2 ： 数据已经被删除




pttl key：以毫秒为单位返回 key 的剩余的过期时间。
persist key 清除键值对的生存时间，key将永久保持。注意：重新设置值也会清除生存时间。

127.0.0.1:6379&gt; set my_live timeOK127.0.0.1:6379&gt; get my_live&quot;time&quot;127.0.0.1:6379&gt; ttl my_live(integer) -1127.0.0.1:6379&gt; expire my_live 20(integer) 1127.0.0.1:6379&gt; ttl my_live(integer) 18127.0.0.1:6379&gt; ttl my_live(integer) 14127.0.0.1:6379&gt; ttl my_live(integer) 1127.0.0.1:6379&gt; ttl my_live(integer) -2127.0.0.1:6379&gt; get my_live(nil)127.0.0.1:6379&gt; set my_live timeOK127.0.0.1:6379&gt; ttl my_live(integer) -1127.0.0.1:6379&gt; expire my_live 2000(integer) 1127.0.0.1:6379&gt; ttl my_live(integer) 1996127.0.0.1:6379&gt; ttl my_live(integer) 1993127.0.0.1:6379&gt; get my_live&quot;time&quot;127.0.0.1:6379&gt; persist my_live(integer) 1127.0.0.1:6379&gt; ttl my_live(integer) -1127.0.0.1:6379&gt; get my_live&quot;time&quot;

7. 基本数据类型7.1. string(字符串)string 类型是 Redis 最基本的数据类型，一个 key对应一个 value ，一个键最大能存储 512MB。
基础命令

set key value：设置key对应的value 
mset key value [key value]：设置多个key对应的value 
get key：获取key对应的value
mget key：获取多个key对应的value
incr key：当 value 值为整数时，将当前 key 对应的键值每次加一，并返回递增后的值。
incrby key num：当value值为整数时，将当前key对应的键值每次加 num，并返回递增后的值。
incrbyfloat key num：当value值为浮点数时，将当前key对应的键值每次加 num，并返回递增后的值。
decr key：将当前key对应的键值每次减一，并返回递减后的值。
decrby key num：将当前key对应的键值每次减 num，并返回递减后的值。
append key value：向原来key对应的value 末尾添加value，返回追加后字符串的总长度。
strlen key：获取key对应的value的长度。 若键值不存在则返回0
getrange key start end：获取key对应的value中的子字符串，start和end为value的索引下标，从0开始。
getbit key offset：返回key对应的value在字符串中offset偏移位置处的bit值（存在为1，不存在为0）。

redis 127.0.0.1:6379&gt; SET name &quot;Jack&quot;OKredis 127.0.0.1:6379&gt; GET name&quot;Jack&quot;127.0.0.1:6379&gt; type namestring127.0.0.1:6379&gt; mset age 20 sex man  score 100OK127.0.0.1:6379&gt; mget age sex score1) &quot;20&quot;2) &quot;man&quot;3) &quot;100&quot;127.0.0.1:6379&gt; get wang&quot;700&quot;127.0.0.1:6379&gt; incr wang(integer) 701127.0.0.1:6379&gt; get wang&quot;701&quot;127.0.0.1:6379&gt; incrby wang 10(integer) 713127.0.0.1:6379&gt; incrby wang 12(integer) 725127.0.0.1:6379&gt; decr wang(integer) 724127.0.0.1:6379&gt; decr wang(integer) 723127.0.0.1:6379&gt; decrby wang 5(integer) 718127.0.0.1:6379&gt; decrby wang 3(integer) 715127.0.0.1:6379&gt; append score 10(integer) 5127.0.0.1:6379&gt; get score&quot;10010&quot;127.0.0.1:6379&gt; strlen score(integer) 5127.0.0.1:6379&gt; get name&quot;jack&quot;127.0.0.1:6379&gt; append name peter(integer) 9127.0.0.1:6379&gt; get name&quot;jackpeter&quot;127.0.0.1:6379&gt; getrange name 0 3&quot;jack&quot;

7.2. hash(哈希)Redis hash是一个string类型的 field 和 value 的映射表，是一个键值对集合，hash特别适合用于存储对象。
基础命令

hset key field value：向键值为key的hash中添加字段为field，值为value的数据。

hsetnx key field value：向键值为key的hash中添加字段为field，值为value的数据，只有当这个字段不存在时才有效。

返回1：如果字段是个新的字段，并成功赋值
返回0：如果哈希集中已存在该字段，没有操作被执行


hget key field：从hash表中返回键值为key，字段为field的value值。

hmset key field value [field value]  向键值为key的hash中添加多个字段为field，值为value的数据。

hmget key field [field]：从hash表中返回键值为key，多个字段为field的value值。

hgetall key：得到hash集合中所有的键值key和值value。

hkeys key：获取hash中所有的field值。

hvals key：获取hash中所有的value值。

hlen key：获取hash中所有field的数量。

hexists key field： 判断键值为key的hash表中是否存在字段field。

注意：hset命令不区分插入和更新操作，当执行插入操作时，hset返回结果为1，当执行更新操作时，返回结果为0


hincrby key field num：每次向键值为key，字段为field的hash中添加 num

hincrbyfloat key field num：每次向键值为key，字段为field的hash中添加浮点数 num

hdel key field [field ...]：删除hash表中键值为key中的一个或多个字段field，返回的结果为被删除字段field的个数。

hscan key cursor  [MATCH pattern] [COUNT count]：迭代哈希表中的键值对。
// 往hash表中插入数据，user是一个键值key127.0.0.1:6379&gt; hset user username zhangsan(integer) 1127.0.0.1:6379&gt; hget user username&quot;zhangsan&quot;127.0.0.1:6379&gt; hmset user password 123OK127.0.0.1:6379&gt; hmset user name ZS age 23OK127.0.0.1:6379&gt; hgetall user1) &quot;username&quot;2) &quot;zhangsan&quot;3) &quot;password&quot;4) &quot;123&quot;5) &quot;name&quot;6) &quot;ZS&quot;7) &quot;age&quot;8) &quot;23&quot;127.0.0.1:6379&gt; hmget user age name1) &quot;23&quot;2) &quot;ZS&quot;127.0.0.1:6379&gt; hkeys user1) &quot;username&quot;2) &quot;password&quot;3) &quot;name&quot;4) &quot;age&quot;127.0.0.1:6379&gt; hexists user age(integer) 1127.0.0.1:6379&gt; hexists user sex(integer) 0127.0.0.1:6379&gt;127.0.0.1:6379&gt; hlen user(integer) 4127.0.0.1:6379&gt; hvals user1) &quot;zhangsan&quot;2) &quot;123&quot;3) &quot;ZS&quot;4) &quot;23&quot;127.0.0.1:6379&gt; hsetnx user name jock(integer) 0127.0.0.1:6379&gt; hsetnx user sex woman(integer) 1127.0.0.1:6379&gt; hscan user 21) &quot;0&quot;2)  1) &quot;username&quot;    2) &quot;zhangsan&quot;    3) &quot;password&quot;    4) &quot;123&quot;    5) &quot;name&quot;    6) &quot;ZS&quot;    7) &quot;age&quot;    8) &quot;23&quot;    9) &quot;sex&quot;  10) &quot;woman&quot;

7.3. list(列表)Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。列表最多可存储 $2^{32} - 1$ 元素 (4294967295, 每个列表可存储40多亿)。
基础命令

lpush key value1 [value2, value3 ...]： 往list列表头部中添加一个或多个数据。

rpush key value1 []value2, ...：往list列表尾部中添加一个或多个数据。

linsert key before | after pivot value：把value值插入在key列表的基准值 pivot 的前面或后面。

lrange key start stop：获取列表指定范围内的元素

lindex key index：通过索引获取列表中index处的元素

llen key：获取列表长度

lrem key count value：移除列表中出现count次，值为value的元素

count &gt; 0: 从头往尾移除值为 value 的元素。
count &lt; 0: 从尾往头移除值为 value 的元素。
count &#x3D; 0: 移除所有值为 value 的元素。


lpop key：移出并获取列表的第一个元素

rpop key：移出并获取列表的最后一个元素

blpop key1 [key2] timeout：移出并获取列表的第一个元素， 如果列表没有元素，会阻塞列表直到等待超时或发现可弹出元素为止。

brpop key1 [key2] timeout：移除列表中的最后一个元素，返回一个双元素的多批量值，其中第一个元素是弹出元素的 key，第二个元素是 value。如果列表没有元素，会阻塞列表直到等待超时或发现可弹出元素为止。

brpoplpush source destination timeout：从source列表中弹出最右边的值，将弹出的元素从最左边插入到另外一个destination列表中并返回它；如果列表没有元素，会阻塞列表直到等待超时或发现可弹出元素为止。

rpoplpush source destination：从source列表中弹出最右边的值，将弹出的元素从最左边插入到另外一个destination列表中并返回它；

lset key index value：通过index去改变list中的值

ltrim key start stop：让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。


127.0.0.1:6379&gt; type my_listlist127.0.0.1:6379&gt; llen my_list(integer) 4127.0.0.1:6379&gt; lrange my_list 0 31) &quot;peach&quot;2) &quot;pear&quot;3) &quot;banana&quot;4) &quot;apple&quot;127.0.0.1:6379&gt; lindex my_list 2&quot;banana&quot;127.0.0.1:6379&gt; lpush my_list  aa aa bb aa bb(integer) 9127.0.0.1:6379&gt; lrange my_list 0 81) &quot;bb&quot;2) &quot;aa&quot;3) &quot;bb&quot;4) &quot;aa&quot;5) &quot;aa&quot;6) &quot;peach&quot;7) &quot;pear&quot;8) &quot;banana&quot;9) &quot;apple&quot;127.0.0.1:6379&gt; lrem my_list 2 aa(integer) 2127.0.0.1:6379&gt; lrange my_list 0 61) &quot;bb&quot;2) &quot;bb&quot;3) &quot;aa&quot;4) &quot;peach&quot;5) &quot;pear&quot;6) &quot;banana&quot;127.0.0.1:6379&gt; llen my_list(integer) 7127.0.0.1:6379&gt; blpop my_list 31) &quot;my_list&quot;2) &quot;bb&quot;127.0.0.1:6379&gt; lrange my_list 0 51) &quot;bb&quot;2) &quot;aa&quot;3) &quot;peach&quot;4) &quot;pear&quot;5) &quot;banana&quot;6) &quot;apple&quot;127.0.0.1:6379&gt; brpop my_list 31) &quot;my_list&quot;2) &quot;apple&quot;127.0.0.1:6379&gt; brpoplpush my_list temp_list 5&quot;banana&quot;127.0.0.1:6379&gt; lrange my_list 0 51) &quot;bb&quot;2) &quot;aa&quot;3) &quot;peach&quot;4) &quot;pear&quot;127.0.0.1:6379&gt; lrange temp_list 0 51) &quot;banana&quot;127.0.0.1:6379&gt; lset my_list 1 helloOK127.0.0.1:6379&gt; lrange my_list 0 51) &quot;bb&quot;2) &quot;hello&quot;3) &quot;bb&quot;4) &quot;aa&quot;5) &quot;peach&quot;6) &quot;pear&quot;127.0.0.1:6379&gt; rpush my_list gg(integer) 5127.0.0.1:6379&gt; lrange my_list 0 51) &quot;bb&quot;2) &quot;hello&quot;3) &quot;bb&quot;4) &quot;aa&quot;5) &quot;gg&quot;127.0.0.1:6379&gt; lrange my_list 0 51) &quot;bb&quot;2) &quot;hello&quot;3) &quot;bb&quot;4) &quot;aa&quot;5) &quot;peach&quot;6) &quot;pear&quot;127.0.0.1:6379&gt; rpop my_list&quot;pear&quot;127.0.0.1:6379&gt; rpoplpush my_list temp_list&quot;peach&quot;

通过Redis 1.0就引入的list结构我们就能实现一个分布式的消息队列，满足一些简单的业务需求。但list结构作为消息队列服务有一个很致命的问题，它没有广播功能，一个消息只能被消费一次。而在大型系统中，通常一个消息会被下游多个应用同时订阅和消费，例如当用户完成一个订单的支付操作时，需要通知商家发货，要更新物流状态，可能还会提高用户的积分和等级，这些都是不同的下游子系统，他们全部会订阅支付完成的操作，而list一个消息只能被消费一次在这样复杂的大型系统面前就捉襟见肘了。
可能你会说那弄多个list，生产者向每个list中都投递消息，每个消费者处理自己的list不就行了吗。这样第一是性能不会太好，因为同一个消息需要被重复的投递，第二是这样的设计违反了生产者和消费者解耦的原则，这个设计下生产者需要知道下游有哪些消费者，如果业务发生变化，需要额外增加一个消费者，生产者的代码也需要修改。
7.4. set(集合)Redis Set 是 string 类型的无序集合。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 在 Redis 可以添加，删除和测试成员存在的时间复杂度为 O（1）。集合中最大的成员数为 $2^{32} - 1$ (4294967295, 每个集合可存储40多亿个成员)。
Redis 非常人性化的为集合提供了 求交集、并集、差集等操作, 那么就可以非常方便的实现如共同关注、共同喜好、二度好友等功能, 对上面的所有集合操作,你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中。
命令

sadd my_set member [...]: 向my_set集合中添加一个或多个member元素

sdiff key1 key2: 返回ke1集合中除去与key2集合中共有的元素

sinter key1 key2: 返回key1集合与key2集合的交集的元素

smembers my_set: 查看my_set集合中所有的元素

scard my_set: 查看my_set集合中的元素的数量

sismember my_set &quot;one&quot;: 判断my_set 集合中是否有 one 成员值

smove source destination member: 将source集合中的member成员移动到destination集合中

spop my_set [count] 从my_set集合中随机删除元素并返回返回一个或多个随机元素。

count参数将在更高版本中提供，但是在2.6、2.8、3.0中不可用。


srandmember my_set [count] 从my_set集合中随机获取一个元素值

不使用count 参数的情况下该命令返回随机的元素，如果key不存在则返回nil。

使用count参数,则返回一个随机的元素数组，如果key不存在则返回一个空的数组。

Redis 2.6开始，可以接受 count 参数，如果count是整数且小于元素的个数，返回含有 count 个不同的元素的数组，
如果count是个整数且大于集合中元素的个数时，仅返回整个集合的所有元素，
当count是负数，则会返回一个包含 count 绝对值的个数元素的数组；如果count的绝对值大于元素的个数，则返回的结果集里会出现一个元素出现多次的情况。


srem my_set member [...] 从my_set集合中删除指定的一个或多个元素。

sunion my_set1 my_set2 返回my_set1集合与my_set2集合中所有元素的并集。

sunionstore set_key set_key1 set_key2 返回set_key1集合与set_key2集合中所有元素的并集，并将结果存储在新的集合set_key中。

sscan my_set  迭代当前数据库中my_key集合的元素


127.0.0.1:6379&gt; sadd my_set one(integer) 1127.0.0.1:6379&gt; sadd my_set two(integer) 1127.0.0.1:6379&gt; sadd my_set three(integer) 1127.0.0.1:6379&gt; smembers my_set1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; scard my_set(integer) 3127.0.0.1:6379&gt; smembers my_set1) &quot;two&quot;2) &quot;one&quot;3) &quot;three&quot;4) &quot;four&quot;127.0.0.1:6379&gt; srandmember my_set&quot;four&quot;127.0.0.1:6379&gt; srandmember my_set&quot;one&quot;127.0.0.1:6379&gt; srandmember my_set 21) &quot;two&quot;2) &quot;three&quot;127.0.0.1:6379&gt; srandmember my_set 31) &quot;two&quot;2) &quot;one&quot;3) &quot;three&quot;127.0.0.1:6379&gt; srandmember my_set 51) &quot;two&quot;2) &quot;one&quot;3) &quot;three&quot;4) &quot;four&quot;127.0.0.1:6379&gt; srandmember my_set -11) &quot;four&quot;127.0.0.1:6379&gt; srandmember my_set -21) &quot;two&quot;2) &quot;four&quot;127.0.0.1:6379&gt; srandmember my_set -51) &quot;three&quot;2) &quot;two&quot;3) &quot;two&quot;4) &quot;four&quot;5) &quot;one&quot;

应用场景

1.共同好友、二度好友
2.利用唯一性,可以统计访问网站的所有独立 IP
3.好友推荐的时候,根据 tag 求交集,大于某个 临界值 就可以推荐

7.5. zset(sorted set 有序集合)Redis 有序集合和集合一样也是 string 类型元素的集合，且不允许重复的成员。redis 通过 score 来为集合中的成员进行从小到大的排序。有序集合的成员(member) 是唯一的,但分数 (score) 却可以重复。
命令

zadd key score member：将指定成员添加到键值为key的有序集合里面
zcard key: 返回key集合中的成员数量。
zcount key min max：返回key集合中分数在最小和最大值之间的成员数据的个数。
zincrby key increment member:  在有序集合key中的成员数据member的score值加上增量increment值。
zrevrange key start stop [withscores]: 按照逆序排序返回有序集合key中在start和stop区间范围内的元素。
zrange key start stop [withscores]: 返回有序集合key中在start和stop区间范围内的元素。start和stop都是全包含的区间。
分数值是一个双精度的浮点型数字字符串。+inf和-inf都是有效值。 
加上 withscores 选项时，将元素的分数与元素一起返回。



127.0.0.1:6379&gt; zcard my_zset(integer) 3127.0.0.1:6379&gt; zrange my_zset 0 2 withscores1) &quot;first&quot;2) &quot;1&quot;3) &quot;second&quot;4) &quot;2&quot;5) &quot;third&quot;6) &quot;2&quot;127.0.0.1:6379&gt; zcount my_zset 1 3(integer) 3127.0.0.1:6379&gt; zcount my_zset (1 3(integer) 2127.0.0.1:6379&gt; zincrby my_zset 5 first&quot;6&quot;127.0.0.1:6379&gt; zrange my_zset 0 2 withscores1) &quot;second&quot;2) &quot;2&quot;3) &quot;third&quot;4) &quot;2&quot;5) &quot;first&quot;6) &quot;6&quot;

应用场景

1.带有权重的元素,LOL游戏大区最强王者
2 排行榜

rpush
7.6. rpoplpush功能：原子性的将源列表（source list） 中的元素从尾部移除，从目的列表（destination list）的头部依次添加元素到到  list 中。
应用程序可以通过2个list组和来完成消息的消费和确认功能，使用rpoplpush从list A中消费消息并移入list B，等消息处理完毕后在从list B中删除消息，如果在处理消息过程中应用异常宕机，恢复后应用可以重新从list B中读取未处理的消息并处理。这种方式为消息的消费增加了ack机制。
brpoplpush
8. 持久化Redis 的持久化策略分为两种，一种为 RDB，另一中为 AOF。
8.1. RDBRDB（Redis DataBase） 是 Redis 默认的持久化方案。在指定的时间间隔内，执行指定次数的写操作，将内存中的数据写入到磁盘中。即在指定目录下生成一个 dump.rdb 文件， Redis 重启通过加载 dump.rdb 文件来恢复数据。
Redis 单独创建（fork）一个子进程来进行持久化，将数据写到一个临时文件中，待持久化过程结束后，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程不进行任何 I&#x2F;O 操作，确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那么 RDB 方式要比 AOF 方式更加高效。
优点：

适合大规模的数据恢复；
对数据的完整性和一致性要求不高。

缺点：

在一定时间间隔内做一次备份，若Redis 意外挂掉，最后一次持久化后的数据可能丢失。
Fork 时，内存中的数据被克隆了一份，会花费 2 倍的内存空间。

生成 dump.rdb  文件可通过 save 或 bgsave 命令操作。

save：只管保存，其他不管，操作时全部阻塞。
bgsave：在后台异步执行快照操作，同时还可以响应客户端的请求。
lastsave：获取最后一次成功执行快照的时间。

save 秒 写操作次数默认配置save 60 10000     1分钟内改了 1万次save 300 10       5分钟内改了 1次save 900 1        15分钟内改了 1次

动态停止 RDB 保存的规则：配置文件中设置为空，redis-cli config set save &quot;&quot;
rdbcompression：对于存储到磁盘中的快照，可以设置是否进行压缩存储．如果是的话，redis 会采用 LZF 算法进行压缩；如果你不想消耗 CPU 来进行压缩的话，可以关闭此功能。
8.2. AOFAOF(Append Only File) 以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来（读操作不记录），只追加文件但不可以改文件，Redis 启动时，会读取文件来重新构建数据。换言之，redis 重启后就根据日志文件中的内容将写指令从前到后执行一次，来完成数据的恢复工作。
Rewrite
AOF 采用文件追加方式，使文件会越来越大，为避免出现此种情况，新增了重写机制，当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数搌的最小指令集，可以使用命令 bgrewriteaof
重写原理：AOF 文件持续增长而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后再rename），遍历新进程的内存中数据，每条记录有一条 Set 语句。重写 aof 文件的操作，并没有读取旧的 aof 文件，而是将整个内存中的数据库内容用命令的方式重写到了一个新的 aof 文件中，这点和快照有点类似。
触发机制：Redis 会记录上次重写的 AOF 大小，默认配置：AOF 文件大小是上次 rewrite 后大小的一倍，且文件大于 64M 时触发。
优势

每秒同步。命令：appendfsync always，同步持久化，每次发生数据变更就会被立即记录到磁盘，性能较差，但数据完整性较好。
每次修改就同步。命令：appendfsync everysec，异步操作，每秒记录，若果一秒内宕机，有数据丢失。
不同步。命令：appendfsync no

缺点

对相同数据集的数据而言，aof 文件要远大于 rdb 文件，恢复速度慢与 rdb。
aof 运行效率要慢与 rdb，每秒同步策略效率较好，不同步效率和 rdb 相同。

小建议

如果只希望服务器在运行的时候存在，可以不使用任何的持久化。

Redis 能否开启两种持久化？
能，Redis 重启时会优先载入 AOF 文件来恢复原始的数据，通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集完整。RDB 的数据不实时，若同时使用两者时，服务器重启也只会找 AOF 文件。那要不要只使用 AOF呢？作者建议不要，因为 RDB 更适合用于备份数据库（AOF 在不断变化不好备份）。

关于性能的建议：
1、 因为 RDB 文件只用作后备用途，建议只在 slave上 持久化 RDB 文件，而且只要15分钟备份一次就够了，只保留 save 900 1 这条规则。2、如果 Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单，只需要加载自己的 AOF 文件就可以了；代价是带来了持续的 I/O，二是AOF rewrite 是将 rewrite 过程中产生的新数据写到新文件，这个过程造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite 的频率，AOF 重写的大小默认值 64M 太小了，可以设到 5G 以上：默认超过原大小 100％ 大小时重写可以改到适当的数值。3、如果不 Enable AOF，仅靠 Master-Slave Replication 实现高可用性也可以。能省掉一大笔 I/O 也减少了 rewrite 时带来的系统波动。代价是如果 Master/slave 同时挂掉，会丢失十几分钟的数据，启动脚本也要比较两个 Master/slave 中载入较新的那个的 RDB 文件。

9. 事务Redis 事务可以一次性执行多个命令，本质是一组命令的集合。事务具有的特性

事务是一个单独的隔离操作：事务中的所有命令都会被序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
Redis 事务具有部分原子性：Redis 同一个事务中如果有一条命令执行失败，后面的命令仍然被执行，没有回滚。
没有隔离级别的概念：队列中的命令没有提交之前都不会被实际的执行，因为事务还没有提交。事务开启后，在事务没有提交之前任何的命令都不会被执行。

Redis 事务命令

multi：标记一个事务块的开始。
discard: 取消事务，丢弃所有 multi 之后发的命令，所有返回都是 OK。
exec：执行所有 multi 之后发的命令。
watch key [...]: 锁定键值key，直到执行列 multi、exec 命令。如果 WATCH 命令在事务执行之前，监控了一个或多个 key，若在 WATCH 之后有任何的 key 值被改动了，那么 EXEC 命令执行的事务都被抛弃，同时返回 Nullmulti-bulk 应答，便于通知调用者事务执行失败。 
unwatch : 取消 WATCH 命令对所有键值 key 的监视。

一个事物从开始到执行经历三个阶段：开始事务（multi）、命令入队（queued）、执行事务（exec）
# 案例：邓某人给王某人转账500元127.0.0.1:6379&gt; set deng 1000OK127.0.0.1:6379&gt; set wang 200OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; incrby deng -500QUEUED127.0.0.1:6379&gt; incrby wang 500QUEUED127.0.0.1:6379&gt; exec1) (integer) 5002) (integer) 700

乐观锁策略：提交版本必须大于记录当前版本才能执行更新。
10. pub&#x2F;sublist 作为消息队列应用场景受到限制很重要的原因在于没有广播，所以 Redis 2.0 中引入了一个新的数据结构pubsub。pubsub 虽然不能算作是 list 的替代品，但它确实能解决一些 list 不能解决的问题。
pubsub 引入一个概念叫 channel，生产者通过 publish 接口投递消息时会指定 channel，消费者通过 subscribe 接口订阅它关心的 channel，调用 subscribe 后这条连接会进入一个特殊的状态，通常不能在发送其他请求，当有消息投递到这个 channe l时 Redis 服务端会立刻通过该连接将消息推送到消费者。这里一个 channel 可以被多个应用订阅，消息会同时投递到每个订阅者，做到了消息的广播。
另一方面，消费者可以会订阅一批 channel，例如一个用户订阅了浙江的新闻的推送，但浙江新闻还会进行细分，例如“浙江杭州xx”、“浙江温州xx”，这里订阅者不需要获取浙江的所有子类在挨个订阅，只需要调用 psubscribe “浙江*”就能订阅所有以浙江开头的新闻推送了，这里 psubscribe 传入一个通配符表达的 channel，Redis 服务端按照规则推送所有匹配channel的消息给对应的客户端。
Redis 发布订阅(pub&#x2F;sub)是一种进程间的消息通信模式：发送者(publish)发送消息，订阅者(subscribe)接收消息。 Redis 客户端可以订阅任意数量的频道。
Redis 发布订阅命令

subscribe channel [channel ...]: 订阅给定的一个或多个频道的信息。
psubscribe pattern [pattern ...]: 订阅一个或多个频道，返回接收到的信息，但频道名支持通配符。
unsubscribe [channel [channel] ...]: 退订指定的频道。
punsubsrcibe [pattern [pattern] ...]: 停止发布到指定模式的频道。
publish channel message: 给频道channel发布一条消息，返回收到消息的客户端数量。 
pubsub subcommand [argument [argument ...]]: 查看订阅与发布系统状态。


一般实际工作中使用的很少，用的第三方消息中间件。例如RabbitMQ、RocketMQ 等。

消息订阅者(client2 、 client5 和 client1)订阅频道 channel1：
消息发布者发布消息到频道channel1，会被发送到三个订阅者：
10.1. pubsub的不足之处处pubsub 的消息数据是瞬时的，它在 Redis 服务端不做保存，publish 发送到 Redis 的消息会立刻推送到所有当时subscribe 连接的客户端，如果当时客户端因为网络问题断连，那么就会错过这条消息，当客户端重连后，它没法重新获取之前那条消息，甚至无法判断是否有消息丢失。
pubsub 中消费者获取消息是一个推送模型，这意味着 Redis 会按消息生产的速度给所有的消费者推送消息，不管消费者处理能力如何，如果消费者应用处理能力不足，消息就会在 Redis 的 client buf 中堆积，当堆积数据超过一个阈值后会断开这条连接，这意味着这些消息全部丢失了，在也找不回来了。如果同时有多个消费者的 client buf堆积数据但又还没达到断开连接的阈值，那么 Redis 服务端的内存会膨胀，进程可能因为 oom 而被杀掉，这导致了整个服务中断。
10.2. 优缺点优势

消息具备广播能力

psubscribe 能按字符串通配符匹配，给予了业务逻辑的灵活性

能订阅特定 key 或特定命令的系统消息


不足

Redis 异常、客户端断连都会导致消息丢失

消息缺乏堆积能力，不能削峰填谷。推送的方式缺乏背压机制，没有考虑消费者处理能力，推送的消息超过消费者处理能力后可能导致消息丢失或服务异常


10.3. 用途Redis 用作消息队列的原因：高吞吐量、低延时、需要一个消息服务但又不想额外引入一堆依赖。

高吞吐量：通过优化持久内存版的持久化流程，让吞吐接近内存版甚至超过内存版吞吐。
低延时：通过rdma在多副本间同步数据，降低半同步下写入数据的延时。

10.4. 消息队列出现解决的问题消息队列主要是为了解决3类问题，应用模块的解耦、消息的异步化、削峰填谷。目前主流的消息队列都能满足这些需求，所以在实际选型时还会考虑一些特殊的功能是否满足，产品的性能如何，具体业务场景下的成本怎么样，开发的复杂度等。
11. stream消息丢失、消息服务不稳定的问题严重限制了 pubsub 的应用场景，所以 Redis 需要重新设计一套机制，来解决这些问题，这就有了后来的 stream 结构。
11.1. 特性一个稳定的消息服务需要具备几个要点，要保证消息不会丢失，至少被消费一次，要具备削峰填谷的能力，来匹配生产者和消费者吞吐的差异。在2018年Redis 5.0加入了stream结构，这次考虑了list、pubsub在应用场景下的缺陷，对标kafka的模型重新设计全内存消息队列结构，从这时开始Redis消息队列功能算是能和主流消息队列产品pk一把了。
11.2. 改进点stream的改进分为多个方面：

存储空间：存储message数据使用了listpack结构，这是一个紧凑型的数据结构，不同于list的双向链表每个节点都要额外占用2个指针的存储空间，这使得小msg情况下stream的空间利用率更高。

功能

stream引入了消费者组的概念，一个消费者组内可以有多个消费者，同一个组内的消费者共享一个消息位点（last_delivered_id），这使得消费者能够水平的扩容，可以在一个组内加入多个消费者来线性的提升吞吐，对于一个消费者组，每条msg只会被其中一个消费者获取和处理，这是pubsub的广播模型不具备的。
不同消费者组之前是相互隔离的，他们各自维护自己的位点，这使得一条msg能被多个不同的消费者组重复消费，做到了消息广播的能力。
stream中消费者采用拉取的方式，并能设置timeout在没有消息时阻塞，通过这种长轮询机制保证了消息的实时性，而且消费速率是和消费者自身吞吐相匹配。


消息不丢失

stream的数据会存储在aof和rdb文件中，这使Redis重启后能够恢复stream的数据。而pubsub的数据是瞬时的，Redis重启意味着消息全部丢失。
stream中每个消费者组会存储一个last_delivered_id来标识已经读取到的位点，客户端连接断开后重连还是能从该位点继续读取，消息不会丢失。
stream引入了ack机制保证消息至少被处理一次。考虑一种场景，如果消费者应用已经读取了消息，但还没来得及处理应用就宕机了，对于这种已经读取但没有ack的消息，stream会标示这条消息的状态为pending，等客户端重连后通过xpending命令可以重新读取到pengind状态的消息，继续处理。如果这个应用永久宕机了，那么该消费者组内的其他消费者应用也能读取到这条消息，并通过xclaim命令将它归属到自己下面继续处理。



Redis stream保证了消息至少被处理一次，但如果想做到每条消息仅被处理一次还需要应用逻辑的介入。
消息被重复处理要么是生产者重复投递，要么是消费者重复消费。

对于生产者重复投递问题，Redis stream为每个消息都设置了一个唯一递增的id，通过参数可以让Redis自动生成id或者应用自己指定id，应用可以根据业务逻辑为每个msg生成id，当xadd超时后应用并不能确定消息是否投递成功，可以通过xread查询该id的消息是否存在，存在就说明已经投递成功，不存在则重新投递，而且stream限制了id必须递增，这意味了已经存在的消息重复投递会被拒绝。这套机制保证了每个消息可以仅被投递一次。

对于消费者重复消费的问题，考虑一个场景，消费者读取消息后业务处理完毕，但还没来得及ack就发生了异常，应用恢复后对于这条没有ack的消息进行了重复消费。这个问题因为ack和消费消息的业务逻辑发生在2个系统，没法做到事务性，需要业务来改造，保证消息处理的幂等性。


11.3. stream的不足stream的模型做到了消息的高效分发，而且保证了消息至少被处理一次，通过应用逻辑的改造能做到消息仅被处理一次，它的能力对标kafka，但吞吐高于kafka，在高吞吐场景下成本比kafka低，那它又有哪些不足了。
首先消息队列很重要的一个功能就是削峰填谷，来匹配生产者和消费者吞吐的差异，生产者和消费者吞吐差异越大，持续时间越长，就意味着steam中需要堆积更多的消息，而Redis作为一个全内存的产品，数据堆积的成本比磁盘高。
其次stream通过ack机制保证了消息至少被消费一次，但这有个前提就是存储在Redis中的消息本身不会丢失。Redis数据的持久化依赖aof和rdb文件，aof落盘方式有几种，通过配置appendfsync决定，通常我们不会配置为always来让每条命令执行完后都做一次fsync，线上配置一般为everysec，每秒做一次fsync，而rdb是全量备份时生成，这意味了宕机恢复可能会丢掉最近一秒的数据。另一方面线上生产环境的Redis都是高可用架构，当主节点宕机后通常不会走恢复逻辑，而是直接切换到备节点继续提供服务，而Redis的同步方式是异步同步，这意味着主节点上新写入的数据可能还没同步到备节点，在切换后这部分数据就丢失了。所以在故障恢复中Redis中的数据可能会丢失一部分，在这样的背景下无论stream的接口设计的多么完善，都不能保证消息至少被消费一次。
12. tairRedis stream 的不足也是内存型数据库特性带来的，它拥有高吞吐、低延时，但大容量下成本会比较高，而应用的场景也不完全是绝对的大容量低吞吐或小容量高吞吐，有时应用的场景会介于二者之间，需要平衡容量和吞吐的关系，所以需要一个产品它的存储成本低于 Redis stream，但它的性能又高于磁盘型消息队列。
另一方面R edis stream 在 Redis 故障场景下不能保证消息的不丢失，这导致业务需要自己实现一些复杂的机制来回补这段数据，同时也限制了它应用在一些对一致性要求较高的场景。为了让业务逻辑更简单，stream 应用范围更广，需要保证故障场景下的消息持久化。
兼顾成本、性能、持久化，这就有了 Tair 持久内存版。
12.1. Tair持久内存版特性Tai 持久内存版引入了 Intel 傲腾持久内存（下面称作AEP），它的性能略低于内存，但相同容量下成本低于内存。Tair 持久内存版将主要数据存储在 AEP上，使得相同容量下，成本更低，这使同样单价下 stream 能堆积更多的消息。
参考：阿里开发：Redis消息队列发展历程
13. Master&#x2F;Slave replicationMaster&#x2F;Slave replication(主从复制) master 以 write 为主，slave 以 read 为主。
原理

Slave 启动成功后连接 master时，会发送一个 sync 命令，master 接受到命令后，启动后台的存盘进程，同时收集所有接受到的哦用于修改数据集命令，后台进程执行完毕后，master 将传送整个数据文件到 slave，完成一次完全同步。


全量复制：slave 服务在接受到数据库文件的数据后，将其存盘并加载到内存中。

增量复制：master 继续将新收集到的所有修改命令依次传递给 slave，完成同步，但是只要是重新连接 master，一次完全同步将被自动执行。

作用

读写分离
容灾恢复



pidfile portlogfiledbdumpfile

命令  slaveof IP port     从机连接主机：slaveof 192.168.58.39 6379   info replication

哨兵模式（sentinel）
master 挂掉后，有哨兵进程在运行，在 slave 中自动投票选出一台机器作为 master，其余的为仍为 slave；若之前挂掉的 master 机器重新连接，此时这台机器不能再为 master 了，通过哨兵自动转化为 slave。
14. Redis 连接Redis中，一共有16个数据库，分别是0~15，一般情况下，进入数据库默认编号是0

select index：切换到指定的index数据库
quit：关闭当前连接
ping：查看服务是否运行
echo msg：打印字符串
auth psd：验证密码是否正确
swapdb index1 index2：交换同一Redis服务器上两个数据库的数据，执行成功返回OK 。

15. Redis Server
dbsize：返回当前数据库中所有key的数目

flushdb：删除当前数据库中的所有key

flushall：清空所有数据库中的所有key

bgsave：在后台异步保存当前数据库的数据到磁盘，会立即返回 OK 状态码。edis forks, 父进程继续提供服务以供客户端调用，子进程将DB数据保存到磁盘然后退出。如果操作成功，可以通过客户端命令 lastsave 来检查操作结果。

client list：列出所有已连接客户端信息和统计数据。
id: 唯一的64位的客户端ID(Redis 2.8.12加入)。addr: 客户端的地址和端口fd: 套接字所使用的文件描述符  r: 客户端套接字（在事件 loop 中）是可读的（readable）  w: 客户端套接字（在事件 loop 中）是可写的（writeable） age: 以秒计算的已连接时长idle: 以秒计算的空闲时长flags: 客户端 flag。    O: 客户端是 MONITOR 模式下的附属节点（slave）    S: 客户端是一般模式下（normal）的附属节点    M: 客户端是主节点（master）    x: 客户端正在执行事务    b: 客户端正在等待阻塞事件    i: 客户端正在等待 VM I/O 操作（已废弃）    d: 一个受监视（watched）的键已被修改， EXEC 命令将失败    c: 在将回复完整地写出之后，关闭链接    u: 客户端未被阻塞（unblocked）    U: 通过Unix套接字连接的客户端    r: 客户端是只读模式的集群节点    A: 尽可能快地关闭连接    N: 未设置任何 flagdb: 该客户端正在使用的数据库 IDsub: 已订阅频道的数量psub: 已订阅模式的数量multi: 在事务中被执行的命令数量qbuf: 查询缓冲区的长度（字节为单位， 0 表示没有分配查询缓冲区）qbuf-free: 查询缓冲区剩余空间的长度（字节为单位， 0 表示没有剩余空间）obl: 输出缓冲区的长度（字节为单位， 0 表示没有分配输出缓冲区）oll: 输出列表包含的对象数量（当输出缓冲区没有剩余空间时，命令回复会以字符串对象的形式被入队到这个队列里）omem: 输出缓冲区和输出列表占用的内存总量events: 文件描述符事件cmd: 最近一次执行的命令

client id：返回当前连接的ID；Redis 5 新增的命令。

client setname connection-name：为当前连接分配一个名字connection-name，这个名字会显示在CLIENT LIST命令的结果中，用于识别当前正在与服务器进行连接的客户端。

client getname：返回当前连接由 CLIENT SETNAME设置的名字。如果没有用CLIENT SETNAME设置名字，将返回一个空的值。

client kill addr:port：关闭指定地址和端口号的客户端

client pause timeout：将所有客户端的访问暂停给定的毫秒数

可以在MULTI&#x2F;EXEC中一起使用CLIENT PAUSE 和INFO replication以在阻塞的同时获取当前master的偏移量。用这种方法，可以让slaves处理至给定的复制偏移节点。


info [section]：返回关于Redis服务器的各种信息和统计数值。通过给定可选的参数 section ，可以让命令只返回某一部分的信息:
server: Redis服务器的一般信息clients: 客户端的连接部分memory: 内存消耗相关信息persistence: RDB和AOF相关信息stats: 一般统计replication: 主/从复制信息cpu: 统计CPU的消耗commandstats: Redis命令统计cluster: Redis集群信息keyspace: 数据库的相关统计

save：执行一个同步操作，以RDB文件的方式保存所有数据的快照 很少在生产环境直接使用SAVE 命令，因为它会阻塞所有的客户端的请求，可以使用BGSAVE 命令代替。

lastsave：获得租后一次磁盘同步的时间。执行成功时返回UNIX时间戳。客户端执行 BGSAVE 命令时，可以通过每N秒发送一个 LASTSAVE 命令来查看BGSAVE 命令执行的结果，由 LASTSAVE 返回结果的变化可以判断执行结果。

shutsown [nosave] [save]：关闭服务器

恢复数据：只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令。
127.0.0.1:6379&gt; saveOK127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;D:\\Redis-x64-3.0.504&quot;127.0.0.1:6379&gt; bgsaveBackground saving started

command：以数组的形式返回有关所有 Redis命令 的详细信息。

command count：返回 Redis 服务器命令的总数。


16. HyperLogLogRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。
在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 $2^{64}$ 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。
什么是基数?

比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 

Redis HyperLogLog 命令

pfadd key element [elelment ..]： 添加指定元素到 HyperLogLog 中。
pfcount key [key ..]：返回给定 HyperLogLog 的基数估算值。
pfmerge destkey sourcekey [sourcekey]： 将多个 HyperLogLog 合并（merge）为一个 HyperLogLog ， 合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集.

127.0.0.1:6379&gt; pfadd my_log 11 22 33 44(integer) 1127.0.0.1:6379&gt; pfadd you_log 99 88 77 66(integer) 1127.0.0.1:6379&gt; pfcount my_log you_log(integer) 8127.0.0.1:6379&gt; pfcount my_log(integer) 4127.0.0.1:6379&gt; pfmerge all_log you_log my_logOK127.0.0.1:6379&gt; pfcount all_log(integer) 8

17. 集群(cluster)18. 集群方案优化19. 数据一致性20. 高并发访问21. 分布式锁22. 典型问题Redis 使用中会遇见很多的问题，下面一幅图，列出了 Redis 中常见的问题。


22.1. Redis 上踩过的坑
CPU 使用上的“坑”：数据结构的复杂度、跨 CPU 核的访问；
内存使用上的“坑”：主从同步和 AOF 的内存竞争；
存储持久化上的“坑”，在 SSD 上做快照的性能抖动；
网络通信上的“坑”：多实例时的异常网络丢包。

22.2. 缓存基本原理22.3. 缓存淘汰策略22.4. 缓存穿透22.5. 缓存击穿22.6. 缓存雪崩23. Reference
Redis 英文官方网站: https://redis.io/
redis 中文版相关命令用法: http://redis.cn/commands.html
Redis 命令参考: http://redisdoc.com/
Redis学习教程: https://piaosanlang.gitbooks.io/redis/content/index.html
Redis 作者Bolg 网站：http://antirez.com/latest/0
Redis 开机自启动脚本: https://www.jianshu.com/p/a73e0565e2a1
工具手册：《Redis 使用手册》
原理书：《Redis 设计与实现》
实战书：《Redis 开发与运维》
Redis Github  官方源码: https://github.com/redis/redis
Redis LPUSH 命令详解教程-嗨客网: https://haicoder.net/redis/redis-lpush.html
数据库redis系列—- redis tutorial: https://kingjcy.github.io/post/database/redis/redis/

]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>RedisCluster</title>
    <url>/Redis/Redis/RedisCluster/</url>
    <content><![CDATA[

构建一个稳定、高性能Redis集群1️⃣数据怕丢失 -&gt; 持久化（RDB&#x2F;AOF）
2️⃣恢复时间久 -&gt; 主从副本（副本随时可切）
3️⃣故障手动切换慢 -&gt; 哨兵集群（自动切换）
4️⃣读存在压力 -&gt; 扩容副本（读写分离）
5️⃣写存在压力&#x2F;容量瓶颈 -&gt; 分片集群
6️⃣分片集群社区方案 -&gt; Twemproxy、Codis（Redis 节点之间无通信，需要部署哨兵，可横向扩容）
7️⃣分片集群官方方案 -&gt; Redis Cluster （Redis 节点之间 Gossip 协议，无需部署哨兵，可横向扩容）
8️⃣业务侧升级困难 -&gt; Proxy + Redis Cluster（不侵入业务侧）
Redis 架构演化之路











]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redisCluster</tag>
      </tags>
  </entry>
  <entry>
    <title>RedisSourceCode</title>
    <url>/Redis/Redis/RedisSourceCode/</url>
    <content><![CDATA[
Redis 源码自己学习知识，一般先从整体上了解知识点的整个架构，然后再对每个知识点做具体的学习，这样自己感觉学习的知识才成体系，不会觉得很杂乱无章。本部分主要是对 Redis 源码的解读，结合实际开发中踩过的坑，然后深入去看源码，学习源码，学习源码中优秀的设计思想和理念以及编程技巧，从而来加深自己对 Redis 的理解。
下面这张图从整体上概括了 Redis 源码的结构的分布


其中 Redis 源码目录结构如下图
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redisSourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title>redis-install</title>
    <url>/Redis/Redis/redis-install/</url>
    <content><![CDATA[Redis 安装教程生产环境下不能连接外部网络，需用源码的方式编译 Redis 进行安装。在编译之前，先在有网的机器上，下载所需编译的依赖，然后拷贝到目标机器上执行依赖安装，最后再编译 Redis 源码执行安装。
1. 查看系统版本root@VM-8-10-ubuntu:~# lsb_release -aNo LSB modules are available.Distributor ID:	UbuntuDescription:	Ubuntu 20.04.3 LTSRelease:	20.04Codename:	focal

2. 下载Reids源码可以从Redis官网的下载页面下载到最新的源码：
https://redis.io/downloads/
下载完成后我们对其进行解压
tar -xvf redis-6.2.6.tar.gz

3. 安装依赖编译前我们需要先安装编译需要的依赖：
apt install libsystemd-dev libc6-dev

然后进入 deps 目录，编译剩余需要的依赖，输入以下命令以进行：
cd redis-6.2.6/depsmake hiredis linenoise hdr_histogram lua jemalloc -j16

4. 编译 Redis编译依赖完成后就可以开始编译 Redis
# 启用对 systemd 的支持# 将 Redis 编译成可以与 systemd 进行集成的二进制版本，方便使用 systemd 管理 Redis 服务make USE_SYSTEMD=yes

如果系统为多核可以加 -j 线程数来开启多线程编译提升速度，如下文代码所示(此处使用16线程)：
make USE_SYSTEMD=yes -j16


启用对 systemd 的支持，需要先安装 libsystemd-dev 包，它提供了 systemd 的开发头文件和库。

编译完成后如有需要可以进行测试，需要安装 tcl 以支持测试，检查 Redis 的功能是否正常。
apt install tclmake test


Tcl 是一种脚本语言（Tool Command Language），它的库和工具在许多应用中作为嵌入式语言或测试脚本使用。在 Redis 的编译过程中，它主要用于运行 Redis 的测试脚本。
Tcl 在 Redis 中 并非用于核心功能，而是用于 运行测试脚本。Redis 的测试框架依赖 Tcl 解释器来执行测试套件，因此需要在编译后运行 make test 时安装该依赖。

接着将其安装到系统
make install

5. 验证是否启用了 systemd 支持在编译完成后，运行以下命令检查 Redis 是否包含 systemd 支持：
redis-server --help | grep systemd

如果输出包含 --with-systemd，说明 Redis 已成功启用 systemd 支持。
6. 创建服务这里我们使用 systemd 来创建服务，而不是使用过时的 init.d
首先复制一份redis配置到&#x2F;etc下
cp redis.conf /etc/

打开redis.conf，修改以下内容：
修改监听IP，开启外网连接：
bind 0.0.0.0

找到 supervised 并去掉注释，将其设置为 systemd，要不然 systemd 不会检测到 redis 启动成功
supervised systemd

然后为redis设置密码：
找到 requirepass 并去掉注释，将”foobared”修改为你自己需要的密码，这点很重要，没设置容易被攻击！！
requirepass foobared

然后复制redis自带的示例服务文件到systemd，并且创建好redis的数据目录
cd utilscp systemd-redis_server.service /etc/systemd/system/redis-server.servicemkdir -p /var/lib/redis

下面将编辑服务文件
cd /etc/systemd/system/vim redis-server.service

去掉后一个ExecStart 的注释，将上方原有的注释掉，并将下方的配置文件目录改成我们自己的
ExecStart=/usr/local/bin/redis-server /etc/redis.conf

然后设置工作目录，去掉下方 WorkingDirectory 的注释
WorkingDirectory=/var/lib/redis

改好的文件看起来应该是这样子的
[Unit]Description=Redis data structure serverDocumentation=https://redis.io/documentation#Before=your_application.service another_example_application.service#AssertPathExists=/var/lib/redisWants=network-online.targetAfter=network-online.target[Service]#ExecStart=/usr/local/bin/redis-server --supervised systemd --daemonize no## Alternatively, have redis-server load a configuration file:ExecStart=/usr/local/bin/redis-server /etc/redis.confLimitNOFILE=10032NoNewPrivileges=yes#OOMScoreAdjust=-900#PrivateTmp=yesType=notifyTimeoutStartSec=infinityTimeoutStopSec=infinityUMask=0077#User=redis#Group=redisWorkingDirectory=/var/lib/redis[Install]WantedBy=multi-user.target

7. 开启服务并设置开机启动首先看一下服务配的对不对，如果status 显示 Active 则正常。
systemctl start redis-server.servicesystemctl status redis-server.service

正常之后直接设置开机启动即可
systemctl enable redis-server.service

或者一条命令搞定
systemctl enable --now redis-server.service

重新加载服务
sudo systemctl daemon-reload

查看是否设置为开机启动
systemctl is-enabled redis

查看所有已设置为开机启动的服务
systemctl list-unit-files --type=service | grep enabled

8. 非root用户运行redis首先创建用户
useradd redis -s /sbin/nologin -b /var/lib

然后设置运行用户
vim /etc/systemd/system/redis-server.service去掉下面两个注释User=redisGroup=redis

设置完成之后重载systemd并且重启redis-server
systemctl daemon-reload &amp;&amp; systemctl restart redis-server.service

配置完成后可以查看下是不是redis用户在跑，显示User&#x3D;redis就说明配置成功
root@VM-8-10-ubuntu:/var/lib# systemctl show -pUser redis-server.service User=redis



9. 集群配置1.9.1. 配置 Redis 节点每个 Redis 实例都需要一个配置文件。你可以复制默认配置文件并做修改。
配置文件修改（以 /etc/redis/redis.conf 为例）：

启用集群模式：在配置文件中启用集群模式。
cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000

绑定网络接口：确保 Redis 实例可以被集群中的其他实例访问。修改 bind 配置项，或使用 0.0.0.0 绑定所有接口：
bind 0.0.0.0

端口配置：Redis 集群每个节点需要至少 2 个端口（一个是标准端口，另一个用于集群通信）。默认端口是 6379，而集群通信端口是 6379 + 10000。
port 6379cluster-announce-port 6379cluster-announce-bus-port 16379

重复上面的步骤，修改 6 个 Redis 节点的配置文件（分别配置不同的端口）

redis-7000.conf、redis-7001.conf、redis-7002.conf 等。

1.9.2. 启动 Redis 实例使用不同的端口启动 Redis 实例：
redis-server /path/to/redis-7000.confredis-server /path/to/redis-7001.confredis-server /path/to/redis-7002.confredis-server /path/to/redis-7003.confredis-server /path/to/redis-7004.confredis-server /path/to/redis-7005.conf

9.3. 创建 Redis 集群在一台机器上（或集群中的任意机器），使用 redis-cli 创建集群。假设你已经启动了 6 个 Redis 实例，且它们分别监听在 7000 到 7005 端口。
使用以下命令创建集群：
redis-cli --cluster create \  &lt;node1-ip&gt;:7000 \  &lt;node2-ip&gt;:7001 \  &lt;node3-ip&gt;:7002 \  &lt;node4-ip&gt;:7003 \  &lt;node5-ip&gt;:7004 \  &lt;node6-ip&gt;:7005 \  --cluster-replicas 1


--cluster-replicas 1 表示每个主节点有一个从节点。
redis-cli 会自动为你分配槽并将数据分配到集群的节点上。

如果一切正常，redis-cli 会显示成功信息，集群已创建。
9.4. 验证集群状态创建完集群后，可以使用 redis-cli 连接到集群中的任意节点，检查集群状态：
redis-cli -c -p 7000&gt; cluster info

这将显示集群的当前状态，如是否是一个正常的集群、节点数量等。
也可以使用 cluster nodes 查看所有节点的详细信息：
eredis-cli -c -p 7000&gt; cluster nodes

9.5. 访问集群通过 redis-cli 连接到集群，执行命令时，redis-cli 会自动将请求路由到正确的节点。使用 -c 参数启用集群模式：
redis-cli -c -p 7000

然后你可以执行常规的 Redis 命令，比如：
set key valueget key

9.6. 维护集群
添加节点：你可以通过 redis-cli 添加新的节点到集群。
redis-cli --cluster add-node &lt;new-node-ip&gt;:7006 &lt;existing-node-ip&gt;:7000

删除节点：如果你想从集群中删除某个节点：
redis-cli --cluster del-node &lt;existing-node-ip&gt;:7000 &lt;node-id&gt;

]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis-install</tag>
      </tags>
  </entry>
  <entry>
    <title>ccat</title>
    <url>/Shell/Shell/ccat/</url>
    <content><![CDATA[自带语法高亮的 cat – ccat让 cat 源代码时如果带上语法高亮，会不会让工作效率更高一些呢？
把下面的代码放在 .bashrc 终端后面
function ccat() &#123;    local style=&quot;monokai&quot;    if [ $# -eq 0 ]; then        pygmentize -P style=$style -P tabsize=4 -f terminal256 -g    else        for NAME in $@; do            pygmentize -P style=$style -P tabsize=4 -f terminal256 -g &quot;$NAME&quot;        done    fi&#125;

然后安装依赖
sudo pip install pygments
安装完成后，重启终端让脚本生效。
让我们来看看执行的效果，这是新 cat 的效果

我们再对比下老的 cat 现实的效果
!
Referenceshttps://skywind.me/blog/archives/3057
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>ccat</tag>
      </tags>
  </entry>
  <entry>
    <title>crontab</title>
    <url>/Shell/Shell/crontab/</url>
    <content><![CDATA[

crontab 用法简介crontab 命令主要用于设置命令行或者脚本周期性的执行。该命令从标准输入设备读取指令，并将其存放于文件中，以供之后读取和执行。本文主要讲述crontb命令的基本语法和配置方法。
用法crontab 是一个用于管理用户的 cron 任务的命令行工具。它允许你创建、编辑、查看和删除 cron 任务。以下是 crontab 命令的一些常用用法：
命令格式
crontab [-u user] -e -l -r


-u 用户名，不加 -u 参数默认为当前用户。
-e 编辑 crontab 文件。
-l 列出 crontab 文件中的内容。取值来源为 /var/spool/cron下对应的文件
-r 删除 crontab 文件。


查看当前用户的 cron 任务：  crontab -l

  该命令将显示当前用户的 cron 任务列表。

编辑当前用户的 cron 任务：  crontab -e

  该命令将打开一个文本编辑器，允许你编辑当前用户的 cron 任务。在编辑器中，你可以添加、修改或删除 cron 行。完成编辑后保存并关闭编辑器，cron 任务将被更新。

删除当前用户的 cron 任务：  crontab -r

  该命令将删除当前用户的所有 cron 任务。

从文件导入 cron 任务：  crontab &lt;filename&gt;

  该命令将从指定的文件中导入 cron 任务。文件应包含符合 cron 语法的任务行。导入后，它将替换当前用户的所有 cron 任务。

将 cron 任务导出到文件：  crontab -l &gt; &lt;filename&gt;

  该命令将当前用户的 cron 任务导出到指定的文件。
这些是 crontab 命令的一些常见用法。使用这些命令，你可以管理和操作 cron 任务，定期执行你所需要的任务。请注意，使用 crontab 命令需要适当的权限，通常仅限于普通用户管理其自己的 cron 任务。
命令说明
# Example of job definition: .---------------- minute (0 - 59) |  .------------- hour (0 - 23) |  |  .---------- day of month (1 - 31) |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ... |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat |  |  |  |  | *  *  *  *  * command/script

一个定时任务的配置共包括6个字段，分别是分、时、日、月、周、命令行或脚本，每一列取值的范围或者含义如上述格式中注释描述。特别注意一点是命令行或者脚本一定要配置成绝对路径。
每个 * 代表一个时间字段，顺序如下：

第一个 \*：分钟（取值范围：0-59）
第二个 \*：小时（取值范围：0-23）
第三个 \*：日期（取值范围：1-31）
第四个 \*：月份（取值范围：1-12）
第五个 \*：星期（取值范围：0-7，0 和 7 都表示星期天）

command 是要执行的命令或脚本的路径。
示例
0 0 * * * command: 每天午夜 0 点执行一次 command。
*/5 * * * * command: 每 5 分钟执行一次 command。
15 14 * * * command: 每天下午 2:15 执行一次 command。
0 22 * * 1-5 command: 每周一到周五的晚上 10 点执行一次 command。
0 0 1 * * command: 每月 1 号的午夜 0 点执行一次 command。

特殊符号
*：代表任意值。例如在第1列表示每分钟执行，第2列表示每小时执行，第3列表示每天执行。
*/n：表示每隔 n 个单位时间。例如 */6 表示每隔 6 小时。
,：用来分隔多个值。例如，1,15,30 表示分钟 1、15 和 30 分别执行。
-：指定一个范围。例如，1-5 表示从 1 到 5 之间的值。
@reboot：系统启动后立即执行。

示例
每天晚上10点运行rumenz.sh脚本
0 22 * * * /root/rumenz.sh

每月的1,3,7的早上8.30运行rumenz.sh
30 8 1,3,7 * * /root/rumenz.sh

每周六,日的的凌晨2点执行rumenz.sh
0 2 * * 6,0 /root/rumenz.txt

每天的的18点到23点每30分执行rumenz.sh
0,30 18-23 * * /root/rumenz.sh//或者*/30 18-23 * * /root/rumenz.sh

每天凌晨2点访问一个网址
0 2 * * * /usr/bin/curl https://rumenz.com

References
微信公众号：Linux之crontab使用技巧

]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title>shell</title>
    <url>/Shell/Shell/shell/</url>
    <content><![CDATA[

1. Shell一旦启动了终端仿真软件包或者登录 Linux 虚拟控制台，你就会看到 shell CLI 提示符。提示符就是进入shell世界的大门，是你输入 shell 命令的地方。默认 bash shell 提示符是美元符号（ $），这个符号表明 shell 在等待用户输入。  
Shell 命令分为三大类：

内建命令(built-in)
外部命令
用户定义函数（function）、别名（alias）

查找某个命令属于哪类：type -a &lt;命令名称&gt;
2. Bash 终端快捷键Ctrl 开头的快捷键一般是针对字符的，而Alt开头的快捷键一般是针对词的。
2.1. 终端控制
Ctrl + d : 退出当前终端（end of file）
Ctrl + c : 强制终止当前命令，终止的是前台进程
Ctrl + z : 将当前任务暂停并挂在后台
Ctrl + s: 冻结当前terminal的stdin，键盘输入的数据不会马上在terminal显示，而是恢复冻结后，在当前光标之前显示输入的数据。（Suspend）
Ctrl +  q: 恢复当前terminal的stdin（Resume）
 stop + job号: 将前台的进程挂起
fg: 将后台中的命令调至前台继续运行fg %job number: 将放在后台的任务通过指定其 job number，让它在前台工作。%job number是通过jobs命令查到的后台正在执行的命令的序号(不是pid，数字默认从 1 开始)
bg: 进程转到后台bg %number 直接让在后台暂停（stopping）的任务变为运行（running）状态。
jobs：查看放在后台的所有任务。
+ : 代表最近被放到后台的任务号码。
- : 代表最近第二个被放到后台中的任务号码。从第三个任务开始，每个任务前面不在有 + 或者 - 符号存在。


终止后台进程
kill + job号
kill + PID


nohup
在用户注销或脱机后，任务还能继续在后天执行，与系统使用的 terminal 无关。
一般的任务管理的后台与所使用的 terminal 有关，terminal 终止后，后台任务也就终止了。
想要后台的任务在你注销用户后还能继续执行，可以使用 nohup 结合 &amp;  搭配使用。



2.2. 大小写
esc + U 或 Alt + U:  将当前光标之后以空格隔开的单词或者字符转换为大写，包括当前光标(upper)。
esc + L 或 Alt + L:  将当前光标之后以空格隔开的单词或者字符转换为小写，包括当前光标(lower)。
esc + c 或 Alt + C:  将当前光标之后以空格隔开的单词首字母转换为大写。

2.3. 光标移动
Alt + f 前移动一个单词
Alt + b 后移动一个单词
Esc +f 移动到当前单词结尾
Esc + b 移动到当前单词开头
Ctrl + b: 光标向后(backward)移动，与 ← 等价
Ctrl + f: 光标向前移动(forward)，与 → 等价
Ctrl + a：移动光标到命令行首。
Ctrl + e：移动光标到命令行尾。

2.4. 删除
Ctrl + u: 擦除当前光标之前的字符，不包括当前光标
Ctrl + k: 擦除从当前光标之后到行尾的所有字符，包括当前光标
Ctrl + w: 删除当前光标之前以空格隔开的任意长度的字符，不包括当前光标
Alt + d : 擦除当前光标之后的一个单词，包括当前光标
Ctrl + h: 删除当前光标前面的字符，每次删除一个字符
Ctrl + d: 删除当前光标后面的字符，每次删除一个字符
Ctrl + /: 撤销之前擦除的所有字符


擦除：输入的数据还在缓冲内存中，没有被删除，可以复制。

2.5. 粘贴
Ctrl + y: 从当前光标处粘贴之前擦除的字符

2.6. 字符交换
Ctrl + t: 当前光标处字符与前一个字符交换位置
Alt + t : 当前光标处单词与前一个单词交换位置

2.7. 历史记录
Ctrl + r 搜索历史记录
Ctrl + g 退出当前搜索模式（在搜索历史记录下）
fc - l   默认从最后往前显示 16 条历史记录。
Ctrl + p 向上查找历史命令，与 ↑ 等价
Ctrl + n 向下查找历史命令，与 ↓ 等价
Alt + r : 取消当前所有改变的操作，若当前命令从历史记录中来，返回上一次历史记录的原始状态，若当前命令是手动输入，则会清空当前行

2.8. 其它命令
cd -  在两个相邻的目录之间进行切换。
&amp;&amp; 仅在上一个命令成功的情况下，才能执行后面的多个命令
lsblk 以树状的格式列出块设备

3. Shell 启动当你登录 Linux 系统时，bash shell 会作为登录 shell 启动。登录 shell 会从 5 个不同的启动文件里读取命令：

/etc/profile
$HOME/.bash_profile
$HOME/.bashrc
$HOME/.bash_login
$HOME/.profile


/etc/profile 文件是系统上默认的 bash shell 的主启动文件，系统上的每个用户登录时都会执行这个启动文件。

4. 基本命令
解释采用哪种 shell 运行脚本: !#/bin/sh
多条语句之间使用 ; 分割开
输入的命令采用 () 括起来，shell 会 fork 一个新的子 shell 进程执行括号里面的内容。
确定哪些命令是否属于 shell 内建命令：type command[root@DEV-ALWLPT-AP03 log]# type pwdpwd is a shell builtin
数据类型：只有字符串类型。

4.1. 引号双引号优点

双引号里可以有变量。
# 统计字符串的长度string=&quot;abcd&quot;echo $&#123;#string&#125; # 输出 4

双引号里可以出现转义字符。

双引号内的特殊字符可以保持原有的特性，比如 $。
# 使用 echo $var 得到 lang is en_US.UTF-8var=&quot;lang is $LANG&quot;

单引号的限制

单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；
单引号字串中不能出现单引号（对单引号使用转义符后也不行）。# 使用 echo $var 得到 lang is $LANGvar=&#x27;lang is $LANG&#x27;其它示例：  var=200      # =号两边不能有空格  echo $var    # 200  echo &#x27;$var&#x27;  # $var  echo &quot;$var&quot;  # 200，打印变量var的内容

4.2. 变量定义变量时，变量名称不加美元符号($)。
path=&quot;/etc/&quot;  # 定义一个变量path

变量名前面加上 $ 表示显示当前变量的值。
echo $path    # 调用变量echo $&#123;path&#125; # 变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界

[root@DEV-ALWLPT-AP03 log]# path=&quot;/etc/&quot;[root@DEV-ALWLPT-AP03 log]# echo $path/etc/[root@DEV-ALWLPT-AP03 log]# echo $&#123;path&#125;/etc/

没有 $， shell 会将变量名解释成普通的文本字符串。
[root@DEV-ALWLPT-AP03 log]# echo datedate

变量可作为命令行的参数。
[root@DEV-ALWLPT-AP03 log]# path=&quot;/home&quot;[root@DEV-ALWLPT-AP03 log]# ls $pathdata  emqx  emqx4  failed  go  

注意点：

变量名和等号之间不能有空格。
变量首个字符必须为字母(a-z，A-Z)。
变量中间不能有空格，可以使用下划线(_)。
变量不能使用标点符号。
变量不能使用 bash 里的关键字，可用 help 命令查看保留关键字。

4.2.1. 环境变量Linux 的环境变量使用 PATH 表示，多个环境变量参数之间使用 : 分割开，而 Windows 下使用 ; 分割开。打印 Linux 系统的环境变量 echo $PATH

本地变量: VARNAME=value。shell中默认的变量类型为字符串类型，定义时不需要指定类型。
环境变量: 将本地变量提升为环境变量，export VARNAME=value
删除已定义的环境变量或本地变量：unset VARNAME
env | grep VARNAME: 查看系统中的环境变量 VARNAME

显示环境变量可用三种命令查看：env、set、printenv

set 命令会显示出全局变量、局部变量以及用户定义变量，它还会按照字母顺序对结果进行排序。
set -e 命令：当脚本中某条命令报错以后立刻退出shell，不再执行后续代码。
set -u 命令：当使用到未定义的变量以后打印报错信息，然后退出程序。


env 和 printenv 命令不会对变量排序，也不会输出局部变量和用户定义变量。printenv 可以显示个别的环境变量[root@KF-CFT-mongdb3 ~]# printenv HOME/root[root@KF-CFT-mongdb3 ~]# echo $HOME/root

4.2.2. 用户变量除了环境变量， shell 脚本还允许在脚本中定义和使用自己的变量。定义变量允许临时存储数据并在整个脚本中使用，从而使 shell 脚本看起来更像一个真正的计算机程序。
用户变量可以是任何由字母、数字或下划线组成的文本字符串，长度不超过 20 个。用户变量区分大小写，所以变量 Var1 和变量 var1 是不同的。

一般自定义的变量名称使用大写来表示；使用 $ 取出变量的值，使用() 取出命令的值。
引用一个变量值时需要使用美元符，而引用变量来对其进行赋值时则不要使用美元符。#!/bin/bashvalue1=10value2= $value1echo The resulting value is $value2

4.3. 命令替换shell 脚本中最有用的特性之一就是可以从 shell 命令输出中提取信息，并将其赋给变量。把输出赋给变量之后，就可以随意在脚本中使用了。
有两种方法可以将命令输出赋给变量

反引号字符 ``
[root@CentOS7 ~]# var=`ls`[root@CentOS7 ~]# echo $varanaconda-ks.cfg a.txt authorized_keys Desktop Documents Downloads

$() 格式：$(commmand) 执行括号里面的命令功能。例如：$(data)
[root@KF-CFT-mongdb3 ~]# test=$(date)[root@KF-CFT-mongdb3 ~]# echo $test   2021年 11月 08日 星期一 10:52:12 CST

shell 先运行括号中的命令，然后将输出赋给变量 test。注意，赋值等号和命令替换字符之间没有空格。


4.4. 命令行参数$0: 获取 shell 在命令行启动的脚本名，会包含完整的脚本路径。
去掉脚本的路径利用 basename 关键字实现。
# shell 文件 test.sh#! /bin/bashecho hellowordecho $0echo $(basename $0) # 去掉路径名echo $(basename -s .sh $0) # 去掉路径名和后缀[root@DEV-ALWLPT-AP03 log]# ./test.shhelloword./test.shtest.shtest


$1: 第一个参数 
$2: 第二个参数 
$#: 统计命令行参数的个数。
$*: 将 shell 的所有参数当成单个参数。
$@: 单独处理输入的每个参数。
$?: 显示上一次命令的退出状态码。
成功结束的命令退出状态码是 0。
如果一个命令结束时有错误，退出状态就是一个正值；
无效命令会返回一个退出状态码 127。


$$: 显示脚本运行的当前进程 ID 号。
shift: 允许你在不知道参数总数的情况下处理各种脚本参数，该命令会将下一个参数移动到 $1。默认情况下它会将每个参数变量向左移动一个位置，后面也可以指定移动多个参数的位置。如果某个参数被移出，它的值就被丢弃了，无法再恢复。

4.5. basenamebasename 是一个命令行中实用的小工具，可从给定的文件名中删除目录和后缀，并打印出来。
在 Centos7 系统中，已经默认安装了 basename 命令了，该命令包含在 coreutils 安装包里。
[root@DEV-ALWLPT-AP03 log]# rpm -qf /usr/bin/basenamecoreutils-8.22-24.el7_9.2.x86_64

basename 命令默认删除所有结尾的 / 字符：
[root@DEV-ALWLPT-AP03 log]# basename /usr/locallocal

默认情况下，每条输出行以换行符(\n)结尾。要以 NUL 结尾，请使用-z（–zero）选项。
[root@DEV-ALWLPT-AP03 log]# basename -z /usr/locallocal[root@DEV-ALWLPT-AP03 log]#
删除文件名的扩展名
# 第一种[root@DEV-ALWLPT-AP03 log]# basename -s .log IOT-Alert20230303_122511_663.logIOT-Alert20230303_122511_663# 第二种[root@DEV-ALWLPT-AP03 log]# basename IOT-Alert20230303_122511_663.log .logIOT-Alert20230303_122511_663


4.6. 执行数学运算算术代换: 用于基本的算术计算。

echo $[11+12] 两个数相加。
echo $[2#10+16#12] 二进制的 10 加上十六进制的 12，结果按照十进制显示

5. 重定向将脚本的输出重定向到 Linux 系统的不同位置。重定向可以用于输入，也可以用于输出，可以将文件重定向到命令输入。
输入重定向

大于符号 &gt; 是输入重定向命令，将命令的输出发送到一个文件中。ls &gt; test.txt 表示将 ls 命令列出当前目录下所有的文件放到test.txt 中，并覆盖原来 test.txt 文件中的内容。
&gt;&gt; 是一个追加(append)命令，将命令输出的数据追加到文件中。
用法：命令 &gt;&gt; 文件名。例如：pwd &gt;&gt; text.tct 将用pwd生成的数据放到 test.txt 文件中，不会覆盖原来的文件，新加的文件保留到文本后面。



输入重定向

输入重定向将文件的内容重定向到命令，使用小于符号 &lt; 表示，简单的来讲，就是将原本需要由键盘输入的数据，改为由文件内容来替换。形式：command &lt; inputfile  ，小于号说明数据正在从输入文件流向命令。
&lt;&lt;  将文件中的内容追加到输入中。

临时重定向

想在脚本中生成错误信息时，使用输出重定向符来将输出信息重定向到 STDERR 文件描述符，这种方法会重定向每条设定的语句。echo &quot;This is an error message&quot; &gt;&amp;2

永久重定向

脚本中用 exec 命令告诉shell在脚本执行期间重定向某个特定文件描述符，可以重定向大量的数据。exec 1&gt;test

三个标准文件描述符 

STDIN: 标准输入 ，代码为 0，使用 &gt; 或 &gt;&gt; 
STDOUT: 标准输出 ，代码为 1，使用 &lt; 或 &lt;&lt;
STDERR: 标准错误，代码为 2，使用 2&gt; 或 2&gt;&gt;

常见脚本重定向命令解释： script.sh &gt;/dev/null 2&gt;&amp;1
script.sh &gt;/dev/null 2&gt;&amp;1 是一种重定向输出和错误的常见方法。下面是对该命令的解释：script.sh 是要执行的脚本或命令的名称。&gt; 表示重定向输出。/dev/null 是一个特殊的设备文件，通常被称为黑洞。将输出重定向到 /dev/null 意味着将输出丢弃，不会在终端上显示或存储。2&gt; 表示重定向错误。2 是标准错误输出的文件描述符。类似地，将错误输出重定向到 /dev/null 表示将错误信息丢弃。&amp;1 表示将输出重定向到与标准输出相同的位置。在这种情况下，&amp;1 指的是标准输出的文件描述符。因此，&gt;/dev/null 2&gt;&amp;1 的整个命令行意味着将脚本或命令的输出和错误信息都重定向到 /dev/null，即将它们丢弃，而不在终端上显示或存储。

6. 结构化命令许多程序要求对 shell 脚本中的命令施加一些逻辑流程控制。有一类命令会根据条件使脚本跳过某些命令。这样的命令通常称为结构化命令（ structured command）。
6.1. if 语句如果你在用其他编程语言的 if-then 语句，这种形式可能会让你有点困惑。在其他编程语言中，if 语句之后的对象是一个等式，这个等式的求值结果为 TRUE 或 FALSE。但 bash shell 的 if 语句并不是这么做的。
bash shell 的 if 语句会运行 if 后面的那个命令。如果该命令的退出状态码是 0（该命令成功运行），位于 then 部分的命令就会被执行。如果该命令的退出状态码是其他值，部分的命令就不会被执行，bash shell 会继续执行脚本中的下一个命令或者执行 else 部分的内容。fi 语句用来表示 if-then 语句到此结束。
if 语句格式
if commandthen  commandsfi# 另外一种形式if command; then  commandselse  commandsfi# 嵌套ifif command1then  commandselif command2then  more commandsfi

echo &quot;Is it morning? Please answer yes or no.&quot;read YES_OR_NOif [ &quot;$YES_OR_NO&quot; = &quot;yes&quot; ]; then          # 取值必须使用 &quot;&quot;    echo &quot;Good moning!&quot;elif [ &quot;$YES_OR_NO&quot; = &quot;no&quot; ]; then         # 嵌套 if    echo &quot;Good afternoon!&quot;else    echo &quot;Sorry, $YES_OR_NO not recognized. Enter yes or no.&quot;fi


6.1.1. 高级特性bash shell 提供了两项可在 if-then 语句中使用的高级特性：

用于数学表达式的双括号
用于高级字符串处理功能的双方括号

双括号 ((expression)) 命令允许你在比较过程中使用高级数学表达式。双括号命令中可以使用的符号：
var++var--++var--var!     # 逻辑求反!     # 位求反**    # 幂运算&lt;&lt;    # 左位移&gt;&gt;    # 右位移&amp;     # 位与|     # 位或&amp;&amp;    # 逻辑与||    #逻辑或val1=10if (( $val1 ** 2 &gt; 90 ))then  (( val2 = $val1 ** 2 ))  echo &quot;The square of $val1 is $val2&quot;fi


双方括号命令提供了针对字符串比较的高级特性。双方括号命令的格式如下：[[ expression ]]
6.2. case 语句
case 可以匹配字符串额通配符，每条分支语句必须以 ;; 结尾。
esac 表示整个 case 语句块的结束#! /bin/bashecho &quot;Please input yes or no?&quot;read TMP     # 从内尺中读输入的变量case &quot;$TMP&quot; in  Yes|y|Y|YES)      echo &quot;It&#x27;s ok.&quot;;;  [nN]?)      echo &quot;It&#x27;s not ok.&quot;;;   *)       echo &quot;Input error.&quot;;;   # 默认执行esacreturn 0;echo &quot;exec return.&quot;   # 该条命令不执行

6.3. for 语句利用 ls 命令判断当前目录下文件的的类型
#! /bin/bashfor name in $(ls); do  printf &quot;$name &quot;  if [ -d &quot;$name&quot; ]; then    echo &quot;It&#x27;s a dir.&quot;  elif [-f &quot;$name&quot; ]; then    echo &quot;It&#x27;s a file.&quot;  else    echo &quot;others.&quot;  fidone


6.4. while 语句while [ ... ]do   .....done 


6.5. test 条件测试test命令提供了在if-then语句中测试不同条件的途径。如果test命令中列出的条件成立，test命令就会退出并返回退出状态码0。这样if-then语句就与其他编程语言中的if-then语句以类似的方式工作了。如果条件不成立， test命令就会退出并返回非零的退出状态码，这使得if-then语句不会再被执行。

[ -p pipe ] :左右括号分别表示一个命令，与参数之间需要使用空格隔开，并不是普通的括号。

6.5.1. 数值比较
-eq: 等于
-ge: 大于等于
-le: 小于等于
-ne: 不等于
-gt: 大于
-lt: 小于
不能在test命令中使用浮点值，bash shell只能处理整数。

6.5.2. 字符串比较
两个字符串之间可以使用 &gt;、&lt;、=、!= 来比较是否相同。
-n str1: 检查 str1 的长度是否非 0# 判断val1变量是否长度非0，而它的长度正好非0，所以then部分被执行了。if [ -n $val1 ]
-z str1: 检查 str1 的长度是否为 0 # 判断val2变量是否长度为0，而它正好长度为0，所以then部分被执行了。if [ -z $var2 ]

6.5.3. 文件比较
-d file: 检查file是否存在并是一个目录
-e file: 检查file是否存在
-f file: 检查file是否存在并是一个文件
-r file: 检查file是否存在并可读
-s file: 检查file是否存在并非空
-w file: 检查file是否存在并可写
-x file: 检查file是否存在并可执行
-O file: 检查file是否存在并属当前用户所有
-G file: 检查file是否存在并且默认组与当前用户相同
file1 -nt file2: 检查file1是否比file2新
file1 -ot file2: 检查file1是否比file2旧

6.5.4. 逻辑比较
expr1 -a expr2: 逻辑与
expr1 -o expr2: 逻辑或
expr1 ! expr2 : 逻辑非

7. 函数shell函数体中没有函数参数和返回值，函数参数在运行时传递。
格式
// 第一种格式 name为函数名name()&#123;  ...&#125;// 第二种方式: 采用function关键字，name为函数名，后面没有小括号function name&#123;&#125;

返回值

默认情况下，函数的退出状态码是函数中最后一条命令返回的退出状态码。在函数执行结束后（即执行完最后一条命令），可以用标准变量 $? 来确定函数的退出状态码。
语句执行成功，退出状态码为 0，没有执行成功退出状态码为 1；退出状态码的范围在 0~255 之间 
使用 return 命令来退出函数并返回特定的退出状态码。

8. 阻止命令输出有时候，你可能不想显示脚本的输出。这在将脚本作为后台进程运行时很常见。如果在运行在后台的脚本出现错误消息， shell会通过电子邮件将它们发给进程的属主。这会很麻烦，尤其是当运行会生成很多烦琐的小错误的脚本时。
要解决这个问题，可以将 STDERR 重定向到一个叫作 null 文件的特殊文件。 null 文件跟它的名字很像，文件里什么都没有。 shell 输出到 null 文件的任何数据都不会保存，全部都被丢掉了。在 Linux 系统上 null 文件的标准位置是 /dev/null，你重定向到该位置的任何数据都会被丢掉，不会显示。
[root@KF-CFT-mongdb3 ~]# ls -al &gt; /dev/null[root@KF-CFT-mongdb3 ~]# cat /dev/null[root@KF-CFT-mongdb3 ~]#

在输入重定向中将 /dev/null 作为输入文件。由于 /dev/null文件不含有任何内容，程序员通常用它来快速清除现有文件中的数据，而不用先删除文件再重新创建。

在输入重定向中将 /dev/null 作为输入文件。由于 /dev/null 文件不含有任何内容，程序员通常用它来快速清除现有文件中的数据，而不用先删除文件再重新创建。

9. shell调试
. test.sh -n: 检查test.sh脚本中是否有语法错误，但不执行脚本。
. test.sh -x: 跟踪执行的信息，将执行的每一条结果和命令都打印出来。
注意：需要在脚本的头部中添加 #! /bin/bash -x ，跟踪的前后添加 set -x 和 set +x



10. 用户输入处理read 命令

从标准输入（键盘）或另一个文件描述符中接受输入。在收到输入后， read 命令会将数据放进一个变量中。
-p 参数：允许你直接在read命令行指定提示符。
-t选项: 指定一个计时器，等待输入的秒数，在指定的时间内输入值。当计时器过期后， read命令会返回一个非零退出状态码。
-s 参数：避免在read命令中输入的数据出现在显示器上，实际上，数据会被显示，只是read命令会将文本颜色设成跟背景色一样。常常用于用户密码的输入。 read -s -p &quot;Enter your password: &quot; pass

11. 正则表达式两种流行的正则表达式引擎

POSIX 基础正则表达式（ basic regular expression， BRE）引擎。例子：sed 编辑器。
POSIX 扩展正则表达式（ extended regular expression， ERE）引擎。例子：gawk 工具。




11.1. 字符串限定符
.: 匹配任意一个字符。
[]: 匹配括号中的任意一个字符。
-(横线): 在 [] 括号内表示字符范围。eg: [0-9]。
_(下划线) 匹配单个字符。
^: 位于[] 括号的开头，匹配除括号中的字符之外的任意一个字符。示例: [^abf] 匹配除 abf 字符以外的所有字符。
\s: 匹配任意空白字符。
\S: 匹配任意非空白字符。
\d: 匹配任意数字。
\D: 匹配非任意数字。
w: 匹配任意单字字符（字母、数字、下划线）。
W: 匹配任意非单字字符。
[[:xxx:]]: grep 工具转给你预定义的一些字符类。

11.2. 数量限定符
?: 匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。
+: 匹配前面的子表达式一次或多次。
*: 匹配前面的子表达式零次或多次。
&#123;N&#125;: 精确匹配N次
&#123;N,&#125;: 至少匹配N次
&#123;,N&#125;: 最多匹配N次
&#123;M,N&#125;: 至少匹配M次，最多匹配N次

11.3. 位置限定符
^xxx: 匹配以xxx开始的行
$xxx: 匹配以xxx结束的行
xxx\&lt;: 匹配以xxx字符开头的单词 
xxx\&gt;: 匹配以xxx字符结尾的单词
\b: 匹配以xxx字符开始或结尾的单词
\B: 匹配不包含以xxx字符开始或结尾的单词。eg: \Bth\B-----&gt;mythed

11.4. 其他特殊字符
\: 转义字符，可以将普通字符转义为特殊字符，也可以将特殊字符转义为普通字符。

(): 将正则表达式的一部分使用括号括起来，组成一个单元，对整个单元使用数量限定符。

|: 连接两个子表达式。

%: 匹配指定删除内容Shell 中使用百分号，将变量的内容从指定截取内容的后面删除（包括指定截取的内容），并从尾部开始删除。
一个 % 号表示从尾部开始匹配删除，找到最近的内容停止；两个 %% 表示从尾部开始匹配删除，遇到最远的指定内容就停止匹配。
[root@DEV-ALWLPT-AP03 log]# filename=aaabbccddaabbccdd[root@DEV-ALWLPT-AP03 log]# echo &quot;$&#123;filename%bb*&#125;&quot;aaabbccddaa[root@DEV-ALWLPT-AP03 log]# echo &quot;$&#123;filename%%bb*&#125;&quot;aaa

12. tee
作用：将从 STDIN 过来的数据同时发送到显示器和日志文件中。
默认情况下， tee 命令会在每次使用时覆盖输出文件内容。想将数据追加到文件中，必须用 -a 选项。

13. sedsed俗称做流编辑器，以行单位进行字符处理。

格式
sed 参数 &#39;脚本语句&#39; 带操作文件
sed 参数 -f &#39;脚本文件&#39; 带操作文件


脚本语句参数
a(append)：追加
i(insert)：插入
d(delete)：删除
s(substitution) :  sed -i &#39;s/echo/printf/g&#39; for_tmp.sh 将for_tmp.sh脚本文件中的所有echo替换为printf，使用 -i 参数并将修改的内容保存，而非仅仅输出显示到标准输出上。


选项参数
-n：默认情况下，脚本执行完后，自动打模式空间中的内容，使用 -n 可以屏蔽自动打印。
-i: 将修改后的源文件保存
-E：使用扩展正则表达式
-e: 使用多个脚本语句替换 时，需要用 -e 选项。



14. awk以列单位进行字符处理，默认情况下按照TAB或空格对文件进行拆分。

格式
awk 参数 &#39;脚本语句&#39; 带操作文件。例子：ps aux | awk &#39;&#123;print $3&#125;&#39; 打印进程信息中的第三列
awk 参数 -f &#39;脚本文件&#39; 带操作文件


变量
print: 打印输出变量，默认打印数据后自动会换行。
printf: 类似于C语言中的printf函数用法。  
两个特殊的条件：BEGIN、END。例子：统计一个文件中的所有空格数 awk &#39;/^ *$/ &#123;count=count+1&#125; END &#123;print count&#125;&#39; test.txt
常用内建变量
FILENAME：当前输入文件的文件名
NR：当前行的行号，R(record)
NF：当前行所拥有的的列数，F(field)
OFS：输出字段的列分隔符，默认是空格
FS：输入文件的列分隔符，默认是空格和TAB
ORS：输出字段的行分隔符，默认是换行符
RS：输入文件的行分隔符，默认是换行符




例子： 使用 awk 批量杀进程的命令：  ps -ef | grep firefox | grep -v grep | awk &#x27;&#123;print &quot;kill -9 &quot;$2&#125;&#x27;|sh

  说明  #列出了当前主机中运行的进程中包含firefox关键字的进程ps -ef | grep firefox | grep -v grep#列出了要kill掉这些进程的命令，并将之打印在了屏幕上 ps -ef | grep firefox | grep -v grep | awk &#x27;&#123;print &quot;kill -9 &quot;$2&#125;&#x27;#后面加上|sh后，则执行这些命令，进而杀掉了这些进程ps -ef | grep firefox | grep -v grep | awk &#x27;&#123;print &quot;kill -9 &quot;$2&#125;&#x27; | sh

15. expectExpect 是Unix系统中用来进行自动化控制和测试的软件工具，由Don Libes制作，作为Tcl脚本语言的一个扩展，应用在交互式软件中如telnet，ftp，Passwd，fsck，rlogin，tip，ssh等等。该工具利用Unix伪终端包装其子进程，允许任意程序通过终端接入进行自动化控制；也可利用Tk工具，将交互程序包装在X11的图形用户界面中。
expect 参数项：
spawn               交互程序开始后面跟命令或者指定程序expect              获取匹配信息匹配成功则执行expect后面的程序动作send exp_send       用于发送指定的字符串信息exp_continue        在expect中多次匹配就需要用到send_user           用来打印输出 相当于shell中的echoexit                退出expect脚本eof                 expect执行结束 退出set                 定义变量puts                输出变量set timeout         设置超时时间


16. References
Bash快捷键大全: https://linux.cn/article-5660-1.html
Terminator The robot future of terminals: https://gnometerminator.blogspot.com/p/introduction.html
如何在Qt中使用正则表达式: https://blog.csdn.net/Hyc_cheng/article/details/112132963#t5
十分钟学会 tmux: https://www.cnblogs.com/kaiye/p/6275207.html

]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>snippets</title>
    <url>/Shell/Shell/snippets/</url>
    <content><![CDATA[Influxdb// 启动service influxdb start// 远程登录influx -host 172.26.165.132 -port 8086 -username admin -password 123456 -precision rfc3339// UTC时间戳显示 本地登录influx -precision rfc3339 -username iottest -password Lanyou@2020// 查询表show measurements;// 删除名为 cpu_usage 的测量表及其所有数据DROP MEASUREMENT &quot;cpu_usage&quot;// 查最新多少条；升序：ASCselect * from &quot;RT-D-ZX-214&quot; order by time DESC limit 500;// 按照时间段查询select * from &quot;RT-D-ZX-214&quot; where time &gt;= &#x27;2024-07-19T15:07:00Z&#x27; and time &lt; &#x27;2024-07-22T08:00:00Z&#x27;;# 导出influx_inspect export -datadir &quot;/home/iot-services/influxdb/data&quot; -waldir &quot;/home/iot-services/influxdb/wal&quot; -out &quot;influxdb_foundry_out&quot; -database &quot;iotdata&quot; -start &quot;2024-05-03T00:00:00Z&quot;# 导入influx -import -path=/root/influxdb_dump_out -precision=ns其中：  import: 标识导入  path: 导入文件  precision: 导入的数据时间精度



find# 删除最近一小时外的日志find ./*.log -type f -mmin +60 -exec rm -rf &#123;&#125; \;# 删除超过七天的日志find ./*.log -type f -mtime +7 -exec rm -rf &#123;&#125; \;

mysql// dump database# 导出整个库，导出时不包含 GTID 信息mysqldump --set-gtid-purged=OFF -u username -p source_db &gt; source_db.sql# 查看所有数据库的排序规则 SELECT     SCHEMA_NAME,     DEFAULT_CHARACTER_SET_NAME,     DEFAULT_COLLATION_NAMEFROM     information_schema.SCHEMATA;    # 查看当前数据库的排序规则SELECT     SCHEMA_NAME,     DEFAULT_CHARACTER_SET_NAME,     DEFAULT_COLLATION_NAMEFROM     information_schema.SCHEMATAWHERE     SCHEMA_NAME = &#x27;your_database_name&#x27;;# 查看某个库中所有表的排序规则SELECT     TABLE_NAME,    TABLE_COLLATIONFROM     information_schema.TABLESWHERE     TABLE_SCHEMA = &#x27;database_name&#x27;;# 查看某个表的排序规则SHOW TABLE STATUS WHERE Name = &#x27;your_table_name&#x27;;# 查看某张表中所有字段的排序方式SHOW FULL COLUMNS FROM table_name;# 修改某个库排序规则ALTER DATABASE thingcross CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;# 修改表中字段排序规则ALTER TABLE table_name CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci;



shell# 取当前系统中状态为“UP”的网络接口的IP地址ip addr | grep &#x27;state UP&#x27; -A2 | tail -n1 | awk &#x27;&#123;print $2&#125;&#x27; | cut -f1 -d &#x27;/&#x27;# 批量杀死进程ps aux | grep xxx | grep -v grep | awk &#x27;&#123;print &quot;kill -9 &quot; $2&#125;&#x27; | sh

docker# 镜像导出docker save -o images.tar images:tag# 镜像导入docker load images.tar

]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>snippets</tag>
      </tags>
  </entry>
  <entry>
    <title>JetbrainsPlugins</title>
    <url>/StudyTool/StudyTool/JetbrainsPlugins/</url>
    <content><![CDATA[
CLION
Themes for IntelliJ-based IDEs：Jetbrains官方提供的可扩展主体下载。
IntelliJ IDEA好看的主题设置（支持自定义）：如何去配置Jetbrains家族类软件的主体颜色配置。
JetBrains-CLion永久激活教程：适用 JetBrains CLion v2019.3&#x2F;3.1&#x2F;3.2&#x2F;3.3 永久激活教程。

]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>jetbrainsPlugins</tag>
      </tags>
  </entry>
  <entry>
    <title>Layout</title>
    <url>/StudyTool/StudyTool/Layout/</url>
    <content><![CDATA[公众号排版留白+重点部分标注
文字字号：15-16px

字间距：1.5-2px

行间距：1.75-2.5px

两侧边距：10-15px

正文字号 14

标题字号 15 或 16

中英文之间增加空格

专有名词注意大小写


当文章段落里面有重点内容时，可以通过加粗以及添加下划线来做标记。
加粗的文字颜色要尽量统一，最好只选一种颜色，这样既能够让整个版面突出重点，又能看起来不突兀。下面三儿为大家放一组对比图片。
]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>layout</tag>
      </tags>
  </entry>
  <entry>
    <title>VSCode</title>
    <url>/StudyTool/StudyTool/VSCode/</url>
    <content><![CDATA[

1. VS Code Shortcuts(快捷键)1.1. Folder
Ctrl + P 快速打开文件
Ctrl+Shift+P 或 F1 显示命令面板
Ctrl+Shift+N 打开一个新的窗口
Ctrl+Shift+W 关闭一个新的窗口
Ctrl+N  新建一个文件
Ctrl+W 关闭文件页面
Ctrl + Shift + T 重新打开已关闭的页面

1.2. Terminal
Ctrl +&#96; 打开或关闭终端集成终端
Ctrl Shift &#96; ：新建集成终端
Ctrl pageUp ：切换到上一个终端
Ctrl pageDown ：切换到下一个终端
Ctrl Shift 5：拆分终端

1.3. Edition
Ctrl + Alt +  ← / → 将当前页面分栏到左边或者右边
Ctrl + Shift + Home/End 删除光标右侧或左侧的所有内容
Ctrl + Backspace 删除上一个单词
Shift+Alt + ↓ / ↑ 向上或向下复制当前行
Alt + ↓ / ↑ 向上或向下移动当前行
Ctrl+F2  批量替换当前文件中所有匹配的文本
Ctrl + Alt + ↓ / ↑ 向上或向下添加光标
Alt + 数字 直接跳到想要跳转的页面
Ctrl Shift o 当前文件中搜索 symbols（匹配到相关的）
Ctrl T 当前 workspace 中搜索 symbols
Ctrl + B 打开或者关闭整个视图
Ctrl K Z 切换禅模式(Toggle Zen Mode)，就可以把侧边栏、面板等全部隐藏。进入禅模式后，按 2次 Escape 键，退出禅模式。

1.4. Folding
Ctrl+K+0  折叠所有代码
Ctrl+K+J  展开所有代码
Ctrl+Shift+[  折叠光标所处代码块内的代码
Ctrl+Shift+]  展开光标所处代码块内的代码

1.5. Groups
Ctrl \ 拆分编辑器
Ctrl 数字 在不同的编辑组之间进行切换
Shift + Alt + 0 切换布局的方向（水平与垂直方向之间切换）

Call HierarchyVS Code 中有一个 show call hierarchy 的功能，显示代码之间的调用关系图。选定一个函数时，按下默认的快捷键  Shift + Alt+H，会显示选定的函数被谁调用或者选定的函数调用了哪些函数。show call hierarchy  提供了两个选项来决定如何显示代码之间的调用关系：

Show Outgoing Calls：如果你选择一个函数，并使用 “Show Outgoing Calls” 功能，它会展示出该函数调用的其他函数或方法。
Show Incoming Calls&quot;：如果你选择一个函数，并使用 “Show Incoming Calls” 功能，它会展示哪些函数或方法调用了当前选定的函数。

2. Configures(配置)VS Code 是以工作区（workspace）来管理工程的，每个工作区下有个隐藏的 .vscode 目录，这个文件夹中包含以下几种文件

settings.json：当前工程环境的配置，设置的配置仅仅只对当前的工程有效，对其它的工程或对当前的用户是不生效的。
tasks.json (compiler build settings)：编译构建环境配置。
launch.json (debugger settings)：调试环境配置。
c_cpp_properties.json (compiler path and IntelliSense settings)：工程级别编译器的配置路径。

VS Code 环境修改支持两种方式：

Json 文件中修改。环境设置都放在 setting.son 文件中。

每个用户有个用户级别的环境配置文件，windows 下位于 C:\Users\user_name\AppData\Roaming\Code\User\settings.json ，其中 user_name 为当前用户的名字，要根据具体的用户去找到对应的路径。 VS Code 中用快捷键 Ctrl+Shift+P 打开命令面板，在面板中输入 Preferences: Open Settings (JSON) 并选择该选项，将会打开用户级别的设置settings.json 文件，然后就可以按照自己的需求编写自己的配置环境。
&#96;&#96;settings.json&#96;文件的优先级：用户级（user） &gt; 工作区(workspace)。

下面是个人一些常用的设置，是通过 Json 格式修改的。
&quot;editor.rulers&quot;: [120],                  // 设置垂直标尺为 120 个字符&quot;editor.lineNumbers&quot;: &quot;relative&quot;,        // 控制整个行号显示与否及如何显示；relative 表示相对显示行号，&quot;files.eol&quot;: &quot;\n&quot;,                       // 文件的换行符&quot;C_Cpp.clang_format_style&quot;: &quot;Webkit&quot;,    // C++ 代码风格&quot;terminal.integrated.defaultProfile.windows&quot;: &quot;Ubuntu-20.04 (WSL)&quot;,  // 默认打开终端// 新增外部终端配置；新增一个Git 终端&quot;terminal.integrated.profiles.windows&quot;: &#123;    &quot;Git-bash&quot;: &#123;        &quot;path&quot;: &quot;C:/Data/Git/bin/bash.exe&quot;    &#125;,&#125;,// Vim 按键绑定配置&quot;vim.handleKeys&quot;: &#123;    &quot;&lt;C-a&gt;&quot;: false,    &quot;&lt;C-f&gt;&quot;: false&#125;,

直接通过界面 UI 的方式去修改，是图形化的操作，比较简单，通过快捷键 Ctrl + , 打开配置修改的 UI 界面，然后再去修改具体的配置。


2.1. Variable一些常见的变量名
$&#123;workspaceFolder&#125; - VS Code当前打开工作区文件夹的路径$&#123;file&#125; - 当前打开文件的绝对路径$&#123;fileBasename&#125; - 当前打开文件的名称$&#123;fileBasenameNoExtension&#125; - 当前打开文件的名称，但是不加后缀名$&#123;fileDirname&#125; - 文件所在的文件夹路径

2.2. Cursor光标配置美化editor.cursorStyle ：光标外部样式



样式
描述



block
实心块 ▇


block-outline
空心块


line
竖线


line-thin
细的竖线


underline
▂


underline-thin
▁


editor.cursorBlinking：光标闪烁样式



样式
描述



solid
不动


blink
常见样式，黑白闪烁


expand
像个嘴巴一样上下开合


phase
进阶版渐变黑白有动画


smooth
丝滑，动画比上面那个慢一点


json 格式配置
// 工作区光标样式&#123;    &quot;editor.cursorBlinking&quot;: &quot;solid&quot;, // 光标固定不闪烁    &quot;editor.cursorStyle&quot;: &quot;line&quot;,     // 光标样式为竖线    &quot;editor.cursorWidth&quot;: 2,          // 光标宽度（可选，单位是像素）    &quot;workbench.colorCustomizations&quot;: &#123;        &quot;editorCursor.foreground&quot;: &quot;00ffff&quot; // 光标设置为青色，可以设置为任何你喜欢的颜色值    &#125;&#125;// 集成终端光标样式&#123;    &quot;workbench.colorCustomizations&quot;: &#123;        &quot;terminalCursor.background&quot;: &quot;#ffffff&quot;, // 设置光标背景色，与终端背景色一致        &quot;terminalCursor.foreground&quot;: &quot;#000000&quot;, // 设置光标前景色，与终端前景色一致        &quot;terminalCursor.animation&quot;: &quot;solid&quot;     // 将光标设置为固定不闪烁    &#125;&#125;


3. Panel(面板)使用 Ctrl Shift P 或 F1 打开命令行的面板（panel），命令面板是根据输入框里的第一个字符来决定提供什么功能的，不同的字符执行的功能不一样。

&gt;：提供所有的命令。
@：扫描当前文件，显示和跳转文件中的符号（Symbols），在 @ 符号后添加冒号：则可以把符号们按类别归类。
?：获取帮助信息。
#：显示和跳转工作区中的符号（Symbols）。
:：跳转到当前文件中的某一行。

面板中直接输入字符执行命令。

process explorer： 查看进程资源管理。

4. workspace(工作空间)VS Code 则选择了一种相对轻量，而且大家都易于理解的方式，那就是所有的操作都基于文件和文件夹。当你打开一个文件夹，VS Code 的核心功能就会对这个文件夹进行分析，并提供对应的功能。
注意工作台最下方的状态栏，当 VS Code 没有打开任何文件夹的时候，它的颜色是紫色的。而如果在工作台中打开了某个文件夹，状态栏的颜色就会变成蓝色。
5. Debugging(调试)VS Code 是把调试功能的最终实现交给插件来完成的。VS Code 提供了一套通用的图形界面和交互方式，比如怎么创建断点、如何添加条件断点、如何查看当前调试状态下参数的值，等等。无论你使用哪个编程语言或者调试器，这一套交互流程都是相似的。
VS Code 为插件作者提供了一套统一的接口，叫做 Debug Adapter Protocol（DAP）。当用户在界面上完成一系列调试相关的操作时，VS Code 则通过 DAP 唤起调试插件，由插件完成最终的操作。
下面这张 VS Code DAP 的流程图也很好地做出了解释：

插件架构
VS Code 主要用 Javascript 和 Node.js 来开发的。VS Code 是通过 Electron 实现跨平台的，而 Electron 则是基于 Chromium 和 Node.js，比如 VS Code 的界面，就是通过 Chromium 进行渲染的。同时， VS Code 是多进程架构，当 VS Code 第一次被启动时会创建一个主进程（main process），然后每个窗口，都会创建一个渲染进程（ Renderer Process）。与此同时，VS Code 会为每个窗口创建一个进程专门来执行插件，也就是 Extension Host。
除了这三个主要的进程以外，还有两种特殊的进程。第一种是调试进程，VS Code 为调试器专门创建了 Debug Adapter 进程，渲染进程会通过 VS Code Debug Protocol 跟 Debug Adapter 进程通讯。另一种则是 Language Server。
下面是 VS Code 的进程架构图

上图中，绿色的就是插件进程 Extension Host 了。VS Code 创建 Extension Host 进程的方式，就是创建一个新的 Electron 进程，并且以 Node.js 的形式运行。也就是说，这个进程就是一个完整的 Node.js 进程，Node.js 版本就是你使用的 Electron 中的 Node.js 。
Plugins(插件)GoBuilt-in Go snippets查看 VS Code 中所有 Go 内建的 snippets，按下快捷键 Ctrl Shift P  打开面板，弹出的面板中输入 Insert Snippet，就可以看到所有内置的代码片段了。



Abbreviation
Description



im
Snippet for import statement


ims
Snippet for a import block


co
Snippet for a constant


cos
Snippet for a constant block


tyi
Snippet for a type interface


tys
Snippet for a struct declaration


pkgm
Snippet for main package &amp; function


func
Snippet for function declaration


meth
Snippet for method declaration


var
Snippet for a single variable


vars
Snippet for a multiple variable


finit
Snippet for init function


fmain
Snippet for main function






ch
Snippet for a channel


map
Snippet for a map


make
Snippet for make statement


in
Snippet for empty interface


new
Snippet for new statement


pn
Snippet for panic






switch
Snippet for switch statement


sel
Snippet for select statement


cs
Snippet for case clause


for
Snippet for a for loop


forr
Snippet for a for range loop






if
Snippet for if statement


el
Snippet for else branch


ie
Snippet for if else


iferr
Snippet for if err !&#x3D; nil






fp
Snippet for fmt.Println()


ff
Snippet for fmt.Printf()


lp
Snippet for log.Println()


lf
Snippet for log.Printf()


lv
Snippet for log.Printf() with variable content






tl
Snippet for t.Log()


tlf
Snippet for t.Logf()


tlv
Snippet for t.Logf() with variable content






wr
Snippet for http Response


hf
Snippet for http.HandleFunc()


hand
Snippet for http handler declaration


rd
Snippet for http.Redirect()


herr
Snippet for http.Error()


las
Snippet for http.ListenAndServe


sv
Snippet for http.Serve






go
Snippet for anonymous goroutine declaration


gf
Snippet for goroutine declaration


df
Snippet for defer statement






tf
Snippet for Test function


bf
Snippet for Benchmark function


ef
Snippet for Example function


tdt
Snippet for table driven test






helloweb
Snippet for sample hello world webapp


sort
Snippet for a custom sort.Sort interface implementation, for a given slice type


6. References
微软官方 Visual Studio Code 文档
c_cpp_properties.json 官方文档
微软官方 variable-reference
VS Code and Go: a superhero’s guide: https://bitfieldconsulting.com/golang/vs-code-go
Microsoft vscode go snippets configure: https://github.com/microsoft/vscode-go/blob/master/snippets/go.json
Microsoft C++ Team Blog: https://devblogs.microsoft.com/cppblog/

]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>vSCode</tag>
      </tags>
  </entry>
  <entry>
    <title>WebsiteReferences</title>
    <url>/StudyTool/StudyTool/WebsiteReferences/</url>
    <content><![CDATA[

1. 博客和知识社区
CSDN : 国内主流的博客，平常访问的比较多。
Stack overflow ：国外很好的技术社区，平时遇见的问题 90% 以上都可以在上面找到。
知乎：国内很好的技术知识问答社区，在上面可以找到许多学习的资料和诸多大咖分享的知识经验。
Github：全球最大的一个开源知识代码托管库，可以找到许多的资源，最常用。
开源中国：国内的开源社区，上面有许多优质的资源，用的频率不是很多。
博客园；开发者的网上家园
segmentfault: 国内 IT 技术问答网站
InfoQ:(Information Queue) 国内的一个在线新闻 &#x2F; 社区网站，旨在通过促进软件开发领域知识与创新的传播，为软件开发者提供帮助。平常用的很少。
老 D 博客：报道当今比较潮流、新的技术。

1.1. Awesome blogs推荐一些优秀大佬自己搭建的博客网站

FreeMind: https://freemind.pluskid.org/
小林Coding: https://xiaolincoding.com/
李文周的博客：https://www.liwenzhou.com/
码神之路：https://www.mszlu.com/
王超的个人博客：https://writings.sh/
腾讯罗志云：https://www.luozhiyun.com/
腾讯大佬个人博客：https://www.hitzhangjie.pro/blog/
雨痕笔记，Go 语言大佬：https://www.yuque.com/qyuhen/go/
I code it：https://icodeit.org/archives/

2. 编程和刷题网站
WolframAlpha: WolframAlpha 是开发计算数学应用软件的沃尔夫勒姆研究公司开发出的新一代的搜索引擎，能根据问题直接给出答案的网站，而不是返回一大堆网页链接，其数据来源包括学术网站和出版物、商业网站和公司、科学机构等等。
谷歌 oppia 开源项目: 谷歌推出的开源在线教育项目，可以交互式的学习
代码规范大全: 一份代码规范大全，列表中包含了大多数主流编程语言的代码规范。
CODELF: 一个用于查找变量名的搜索引擎
Vimeo: 高清视频播客网站
Medium: 国外的知名博客
LeetCode：国外的一个面试刷题网站。非常好。
牛客网: 求职面试必看的网站，各种面试经验和技巧都有分享。
赛码 IT 面试笔试平台
Codewars: 使用各种语言去练习编程，提高自己写代码水平的好地方。
Geeksforgeeks: 是一个主要专注于计算机科学的网站, 可以找到许多编程的问题和算法的练习。
W3school: 编程学习的网站，有许多编程语言学习的教程，可以参考学习。
IBM developerWorks: IT 教程，工具，社区

3. 公开课和在线视频学习
国内平台
网易公开课: 网易旗下的，包含了国内的和国外的高校的各种公开课，优质资源太多了。
网易云课堂: 同样也是网易旗下的，是一个在线学习的平台，与国外的 Coursera 类似。
中国大学 mooc: 国内好的大学都在上面推出了各自高校的厉害学科的课程，为大学生和自学的人提供的平台。
MeTel 国道多媒体：主要面向科研、教学、情报机构提供在线服务学习的平台。在校大学生可以通过学校的网上图书馆免费登录。
学堂在线: 由清华大学推出的全球首个中文大规模开放在线课堂平台。
慕课网：是一个 IT 技能学习的平台，讲的课程还不错，平常用的较少。


国外平台
学术演讲或 PHD 答辩视频网站：VideoLectures.net 是世界上最大的英文学术网络视频，也是一个自由和开放接入教育视频讲座库。
Coursera: 国外一个非常好的在线学习网站，中文和英文的课程都有。
edx: 由麻省理工学院和哈佛大学创建的大规模开放在线课堂平台。课程是英文的，英文不好的学习起来有点吃力，但是课程非常好，老外讲课就是不一样。
udemy：国外的在线学习平台，有许多优秀的工程和教授推出了很多的课程，有免费的也有付费的。平时使用的比较少。
Udacity 优达学城: 由 Sebastian Thrun, David Stavens 和 Mike Sokolsky 注资的一个私立教育组织，它的目标是实现自主学习。上面也有许多的中文和英文课程。平常访问的比较少。
一席演讲
TED: TED 是一个美国创建的机构，宗旨就是 “传播一些值得传播的创意”！这里有非常多的演讲视频，来自各界人士，内容也是五花八门！让你拥有最广的视角，了解更大的世界！
HowCast 话题式视频分享网: 只需在网站上输入 “how to” 就会找到各种解决问题方式，全都是通过视频的方式传播的，内容包含生活技能、日常常见的问题等成千上百个问题解决方式
LiveStream 免费视频直播平台: 是一个免费在线直播站点，供各行业的用户使用。其中所涵盖的栏目有：新闻、游戏、音乐、体育等。Livestream 是这个行业的首个价格相对便宜的，无限制的，没有广告的平台。
Metacafe 在线视频网： 美国著名的在线视频网站，全球最大在线视频网站之一，在该网站你可以获得最新最好的电影、图片、游戏等，也可以与网友共享你所了解的信息。
美国 HBO 家庭影院频道: HBO 获得好莱坞主要的知名电影公司授予独家播映权，包括华纳兄弟、环球片场、梦工厂等，为亚洲的观众提供超级强片。同时它还提供高品质的自制电影、影集和纪录片。为了加强电影的类别，HBO 亦向其他独立发行商搜罗不同的影片，其中包括宝丽金、New Line 及 Castle Rock 等。
ShortFilm 互联网短视频分享网: 这是一个收集和整理互联网中最佳视频短片的目录站点，每天都会从互联网中筛选出最值得推荐的有趣短片，主要栏目包括影视、流行、动漫、纪录片、科幻等
The Verge：- 最受欢迎的科技媒体之一
TV Shows and Movies：正版影视作品和电视节目视频网站
IMDB: 互联网电影资料库:
Vice：国外新锐媒体，年轻人的内容
Brain Pump: 每天学习新东西的地方。
Curious: Get a customized CQ Workout™ delivered to your inbox or mobile, every day.
howstuffworks  计算机类的网站，涵盖软件、硬件网络与安全的方方面面。
tldp.org 向书籍一样的阅读计算机类相关的文章，每篇文章都有深度，只不过全是英文的，需要点耐心阅读。
codescracker 简洁的编程语言学习平台网站。
nptel 印度各大名校联合推出的免费学习网站，可以免费下载相应视频中的 PDF 文件进行学习。
Tutorials Library 各种编程语言的教程文档。
中央研究院 Academia Sinica: 中央研究的 YouTube 频道，里面有许多非常优质的内容。



4. 字幕下载
downsub：DownSub 是免费的网络应用程序，可以直接从 Youtube, VIU, Viki, Vlive 等下载字幕。我们支持下载所有字幕格式, 例如：SRT, TXT, VTT。
zhuwei.me：也可以下 YouTube 网站上的视频，但比 DownSub 功能相对弱一些。

5. YouTube 在线视频下载
QDownloader.io：可以从 YouTube，Instagram，Facebook，Twitter 和许多其他网站下载任意的视频。优点是将 URL 粘贴到页面下载时，自动会获取专栏的视频播放列表，不用每次都复制 URL 再下载，很方便。缺点是在线下载时只能下载 720P 的视频，下载 1080P 的视频需要安装客户端，并且客户端下载时需要代理，下载速度很慢。
YuTube 4K Downloader：支持 1080P 视频的在线下载，只不过下载的速度优点慢，需要忍耐一下。
Youtube: Converter：支持很多格式的下载，不支持自己手动选择下载是 720P 还是 1080P。

6. 产品
人人都是产品经理: 人人都是产品经理是中国最大、最活跃的以产品经理为核心的学习、交流、分享社群，集媒体、教育、招聘、社群活动为一体，全方位服务产品经理。

7. 工具箱
AlteredQualia: 在无需安装任何硬件的情况下，我们仅通过浏览器就能查看各种 3D 影像的技术。
全球电视直播: 全国电视直播是一个功能非常强大的电视直播网站，它支持几百个电视直播的网站，几乎拥有一般电视直播网站拥有的所有频道，它还支持港澳台卫视，国外电视等等。
x Photopea 在线 PS 工具: 是一个完全免费在线 PS 网站，是一个与 PS 电脑软件相似度非常高的在线 PS 网站，让你无需下载软件，也可以拥有和 PS 电脑软件一样的操作和体验。
公式字符化网站: 可以轻松地以手绘恼复杂的数学公式和化学方程式，交给电脑自动帮你转化哟
Curiosity 好奇心知识视频网: 汇集了互联网中优质的知识类视频资源，在这里可以满足你对知识的渴求，通过科学的论证方式来解答你生活中的各种问题，帮助你探索和追求永无止境的知识海洋。
FindIcons 免费图标搜索: FindIcons 是一个免费图标搜索引擎，号称拥有全世界最大的图标库。
Librestock 免费优质素材: LibreStock 网站致力于推荐高清、优质的图片，用户可以通过关键词来搜索想要的素材图片，筛选出来的图片列表可以预览，点击下载的时候会直接跳转到目标站点上。这个网站本身并不提供原创的图片素材，而是通过索引其他网站上的图片资源来达到站内搜索查询的目的。
程序员的工具箱
开源中国的在线工具箱
Compiler Explorer: 在线查看汇编代码
onlinegdb: C&#x2F;C++ 在线编译调试器, 支持在线 GDB 调试，控制台输入
颜色常用对照表：查看各种颜色的名称、RGB 值和 16 进制值
任意 RGB 颜色和 16 进制互转
RegExPal: 在线正则表达式练习工具
vim-adventures: 在线练习 VIM 的一款游戏
ProcessOn: 在线画流程图
ZIP code Query: America 邮编查询

8. 人文
全历史:
Psychology Today: 心理学网站，告诉你，你是谁。
nautil: 一本出于对智慧的探索，关于科学，文化和哲学的杂志
aeon(永旺): 涉及哲学、科学、心理学、文化等不同领域的内容。

9. 科学
重 现 化 学: 微观的角度展示神奇的化学世界。
医学微视: 它是中国医学科学院健康科普研究中心监制的一个网站，并且不提供销售任何产品，它以短视频的形式帮助你了解各种疾病，通俗易懂，让你轻松了解各种医学知识；当我们遇到不懂的医学知识或者健康问题，直接利用这个网站，找到对应的疾病，就可以轻松找到对应的视频。
BBC — Future: 深入报道科学，生命科技

10. 考研
网易考研: 网易考研频道专题，第一时间解读考研行业热点事件，全景呈现事件背后的深刻原因。
中国教育在线考研: 中国教育在线考研频道是一个专业的考研教育服务网络平台，目前国内最具品牌影响力的权威考研门户。
中国研究生招生信息网: 中国研究生招生信息网是隶属于教育部的以考研为主题的官方网站，是教育部唯一指定的研究生入学考试网上报名及调剂网站，主要提供研究生网上报名及调剂、专业目录查询、在线咨询、院校信息、报考指南和考试辅导等多方面的服务和信息指导。
考研帮: 中国最大的考研论坛。

11. PPT
PPTfans PPT 设计: 是一个提供 PPT 文档制作的教学网站，提供专业 PPT 设计服务
PoweredTemplate 商务 PPT 模板: 提供 PPT 模版、网页模版、简报模版、商务图表模版、等丰富资源的站点，但是它的重点是在商务范畴
PPT 模板下载_精美 PPT 模板下载: 优品 PPT，不仅包含一些高质量的模版，而且还有 PPT 图表，PPT 背景图等资源

12. 图片
unsplash: 推荐指数：⭐⭐⭐⭐⭐
Pexels：免费高品质图片网。推荐指数：⭐⭐⭐⭐⭐
阿里巴巴矢量图标素材库: 首页的搜索框就可以输入你想要找的图标，也可以在图标库去寻找。选好你想要的图标之后还可以根据你的需要在线修改颜色，并提供 SVG&#x2F;PNG&#x2F;AI 图片格式的下载。推荐指数：⭐⭐⭐⭐
icons8: 国外的网站，提供各种格式，各种尺寸和配色。Icons8 除了将图示按照类别分类外，还利用不同平台的设计风格准则加以区隔，例如有 iOS10、Windows、Android、Google、Office。推荐指数：⭐⭐⭐⭐⭐
360 壁纸 推荐指数：⭐⭐⭐
花瓣网 推荐指数：⭐⭐⭐⭐
Emoji Cheat Sheet: 各种表情包下载库。推荐指数：⭐⭐⭐⭐⭐
emojiisland 下载 emoji 表情库。推荐指数：⭐⭐⭐⭐⭐
Gratisography: 它为用户提供免费高品质摄影图片，而且所有的图片都可以用于个人或者商业用途。网站图片质量感觉不是很高。推荐指数：⭐
stocksnap: 该网站的图片可以免费用于个人和非商业设计项目呢！推荐指数：⭐⭐
视觉中国：视觉不仅是个图库网站，它还包含了音乐、视频等素材资源，用户可根据个人需求搜索图片资源。若不借助第三方工具，一般需要用户注册、购买后才能下载。推荐指数：⭐
GIF 动画：GIF 动画制作网站。推荐指数：⭐⭐⭐
bigjpg 利用深度学习支持图片无损放大。
photomosh 炫酷的图片制作。推荐指数：⭐⭐
可批量编辑图片 的所有工具：https://www.iloveimg.com/zh-cn
知乎微信编辑器推荐：https://zhuanlan.zhihu.com/p/108676805

13. 电子图书13.1. 文学
我的小书屋：这是一个个人开发者建的电子书资源网站
书格：主要提供的是古籍图书
读书小站 简洁清新的网站，下载各种文学类的电子书。
鸠摩搜书：输入书名就可以搜索大部分的书籍，并且会展示相应图片。
恩京书屋 收集了各种文学类、科技类和动漫类书籍。
书山有路  收集各类文学书籍，提供 mobi,azw3,epub 等格式电子书下载。

13.2. 科技
计算机书籍控：这个网站有计算机专业的书籍，不是很新，有一部分的书籍。
明明三省的网站

13.3. 漫画
Vol.moe：要提供漫画类电子书资源的网站，无论从内容的质量还是数量上来讲，都是比较令人惊喜的

13.4. 其它
Owllook：免费下载各类小说的搜索引擎， 页面清新简洁，无广告，直接输入书名即可搜索
盘搜搜：一个老牌网盘搜索工具，功能非常强大。非常简洁的界面。每天都有更新，不同达人分享自己的 “盘中资源”！盘搜不存储任何网盘内容，无论是工作还是学习都必备。
中国国家图书馆: 一个国家总书库网站。教育资源怎么能少的了书籍资源？这个网站不仅是供国家机关使用，而且还是面对社会大众的，你可以在这里搜索书籍、论文、报刊、甚至古籍、音乐、影视！
仿知网: 仿知网是一个完全可以代替知网的精品网站；是一个非常强大的论文搜索网站。
国专利论文下载: 中国专利全文打包下载
SemanticScholar 免费学术: 该网站是由微软联合创始人 Paul Allen 做的免费学术搜索引擎，其检索结果来自于期刊、学术会议资料或者是学术机构的文献。这个搜索引擎能检索到 80% 的免费论文文献，大约有 300 万份，另外它直接提供图表预览，看起来能方便研究人员省下更多筛选的工作。
shudan.vip 下载各种格式的电子书籍。

参考：有哪些好的电子书下载网站及电子书阅读器推荐
14. 免费下载各种外文科技论文
Z-Library

Booksee: 下载最新的电子图书。

Library Genesis2M : 适合下载较新的论文, 只要是外文书籍和论文基本上都可以搜到并下载，最近几年的论文也可以下载 &#96;

sci-hub: Sci-Hub 是一个在线数据库，其上提供 7600 万篇科学学术论文和文章.

适合下载最新的论文, 文献资源下载网站 https://scihub.org &#x2F; 是哈萨克斯坦牛人 (Alexandra Elbakyan) 开发的可以下载任意谷歌上有电子版链接文献杂志的网站，只要输入你想要下载的文献链接就可以获取到该文献的真实地址并在线浏览，当然更重要的是可以下载。这个是俄罗斯的某黑客给弄的. 原理好像是类似于 RVPN, 借用有权限的学校的 IP 给我们下载相关文献. 适用于所有杂志, 只有极少数的还是不能下载


google 学术网

国内可以山寨访问 Google

中国版 sci-hub: 国外文献免费下载，中国版 SCI-HUB 网址

videolectures : VideoLectures.net 是世界上最大的英文学术网络视频，中文最大的是超星学术视频，需要校园网权限，可以观看最新学术演讲或 PHD 答辩视频。

它的总部设在斯洛文尼亚的约瑟夫斯蒂芬研究所。网站最初是提供计算机科学的视频，后来拓宽到各类学科。自 2006 年以来，已有 10763 个人的 14251 视频讲座资源库。它提供众多免费教学视频，分类广阔，包括了各种自然科学（数学，物理，化学，生物、医学等）、社会科学（商学、哲学、体育等），高质量交流论坛为广大用户提供高质量学习内容。VideoLectures.NET 是一个自由和开放接入教育视频讲座库。包括高校的学术演讲或者 PhD 答辩。这些讲座是由学者在会议，暑期学校，讲习班和科学的许多领域的科学宣传活动。这些讲座都是很前沿的方向的很深入的学术讨论，对不是那个行业方向的人来说很难明白。网站是关于各个领域研究方向的报告视频及 slides，其中不乏很多数据挖掘、机器学习方面的讲解视频，Slides(也就是 ppt) 可以下载


ScienceHUβ: ScienceHUβ是一家全球性的科学技术出版商，可免费提供研究文章和最新研究信息，而对科学界没有任何障碍。


参考 sciencenet.cn
15. 二次元
tunefind:  快速找到热门影视剧的 BGM！
KonaChan 动漫 ACG 壁纸: KonaChan 网站是一个致力于动漫、游戏壁纸图片搜索的站点，喜欢动漫的用户可以根据关键词来搜索自己想要的图片壁纸。想要找个性化的动漫壁纸，只有这种专业的动漫图片网站才有的。
dova 免费的日文 BGM 下载。
nico 日文 BGM 下载。

16. 耍酷
HackerTyper Neo: 伪装成特工，让网吧里围观的小学生们膜拜你的神器！
File Destructor 2.0: 此网站可以随意伪造任意文件格式，任意文件大小的文档, 如果你的死线就在明天而你到现在还什么都没做，那么你可以用它来拖延至少 1 天的时间。
FakeUpdate  模拟多种系统的安装过程，让你上班愉快的摸鱼。
zwcsm  帮你解决今天想要吃什么的难题。
suulnnka.github.io 沙雕文章生成器，搅乱你的脑袋瓜子吧！

17. 电脑壁纸
wallhere
极简壁纸
资源帝

l18. 写作
排版
Github 中文文案排版指北
写给大家看的中文排版指南
中文文案排版细则
中文技术文档写作风格指南


vscode 自动排版加空格插件：vscode-pangu
markdown 发布到公众号之前，采用的排版工具
墨滴：https://mdnice.com
markdown.com.cn: https://markdown.com.cn/editor/  提供模板选择和 CSS 样式微调，一键把外链转成备注信息。
一款高度简洁的微信 Markdown 编辑器：https://doocs.github.io/md/


博客网站搭建
在线阅读网站，基于 vuepress，采用主题 vuepress-theme-hope
hexo: https://hexo.io/zh-cn 框架直接生成整个静态网站，然后直接部署在 Github Pages 上，不用自己购买服务器，省却了一大笔的开下，相当方便。


表情素材：https://www.webfx.com/tools/emoji-cheat-sheet
Log 小图标生成: https://shields.io
代码片段转化为图片：https://carbon.now.sh
配色方案：https://coolors.co
配图1. 知乎技术文章配图指南：https://zhuanlan.zhihu.com/p/96880688 2. 图片

19. 参考
国外：These 62 Websites Will Make You Incredibly Smarter

]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>websiteReferences</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows10</title>
    <url>/StudyTool/StudyTool/Windows10/</url>
    <content><![CDATA[ 

Win10 快捷键在 %SystemRoot%\system32\ 路径下的程序都可以用命令的方法快速打开

mspaint  画图
notepad  记事本
calc     计算器
regedit  打开注册表编辑器
msconfig 打开系统配置
显示系统属性对话框——『Win+Pause』
最大化当前窗口——『Win+↑』
最大化到窗口右侧的屏幕上——『Win+→』
最小化窗口——『Win+↓』
最大化到窗口左侧的屏幕上——『Win+←』
更改桌面上的图标大小——『Ctrl+鼠标滚轮』
打开任务管理器——『Ctrl+Shift+Esc』
关闭任务管理器：ESC
显示预览窗格——『Alt+p』
打开上层文件夹——『Backspace』
显示所选项的属性——『Alt+Enter』
关闭活动的项目或者退出活动程序——『Alt+f4』
关闭网页：Ctrl+W
锁屏：Win+L
win .(句点)  打开表情符号面板 
win | 快速打开设置 
win Shift S 使用系统截图

cmd查看电脑连接了哪些 WIFI
netsh wlan show profile

查看指定 WIFI 下的密码
netsh wlan show profile &quot;ziroom608&quot; key=clear


]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>windows10</tag>
      </tags>
  </entry>
  <entry>
    <title>draw.io</title>
    <url>/StudyTool/StudyTool/draw.io/</url>
    <content><![CDATA[
快捷键
]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>draw.io</tag>
      </tags>
  </entry>
  <entry>
    <title>iPad-tools</title>
    <url>/StudyTool/StudyTool/iPad-tools/</url>
    <content><![CDATA[ 


画画：procreate
unclutter：备忘录存储
picsArt
margin note2（88元）：任意裁剪文件的片段，做笔记
蒙哥阅读器（18元）：阅读英文原著，查生词
Alook浏览器（6元）：视频悬浮看，2倍速
TEDICT（25元）：边听边写学习TED视频

]]></content>
      <categories>
        <category>StudyTool</category>
      </categories>
      <tags>
        <tag>studyTool</tag>
        <tag>iPad-tools</tag>
      </tags>
  </entry>
  <entry>
    <title>TypeScript</title>
    <url>/TypeScript/TypeScript/TypeScript/</url>
    <content><![CDATA[
TypeScript TutorialTypeScript is a typed superset of JavaScript that compiles to plain JavaScript. It offers classes, modules, and interfaces to help you build robust components.
Compile安装 typescript 编译器，终端执行下面的命令，前提是已经安装好 npm 软件包。
sudo npm i typescript -g 

静态编译，每次文件改变后，终端运行 TypeScript 编译器进行编译
tsc [filename]
不推荐这种方式，这种方式太麻烦了，推荐使用自动化编译。
动态编译 TS 工程文件同时监测内容的变化，自动生成 js 文件

终端输入：tsc --init，执行完成后，自动生成一个 tsconfig.json 配置文件。此配置文件是对 ts 文件的全局配置。
终端输入：tsc --watch，监控所有 js 文件的变化，同时自动将 ts 转换为 js。

类型声明类型推断数据类型JavaScript 中包含 8 种数据类型

string
number
boolean
null
undefined
bigint
symbol
object: 包含 Array, Function, Date, Error

Tyscript 中包含的数据类型

拥有 JavaScript 中所有的数据类型
6 个新类型
any
unknown: 类型安全的 any
never
什么值都不能有，不是用来限制变量的
要是是用来限制函数的返回值，一般是很特殊的函数，函数是出不来的，比如死循环或函数中抛出异常。
never 一般是 typescript 推断出来的。


void
用于函数的返回值
void 包含了 undefined，但 undefined 不一定是 void


tuple
ernum


2 个用于自定义类型的方式
type
interface



References
Microsoft official Document: https://www.typescriptlang.org
TypeScript 入门教程: https://ts.xcatliu.com/introduction/index.html

]]></content>
      <categories>
        <category>TypeScript</category>
      </categories>
      <tags>
        <tag>typeScript</tag>
      </tags>
  </entry>
  <entry>
    <title>API</title>
    <url>/Windows/Windows/API/</url>
    <content><![CDATA[Win32 API 后缀
A 表示使用ANSI编码作为标准输入与输出流的文本编码
W 表示使用Unicode作为编码
Ex 表示拓展, 标注了Ex的winapi函数会比没有标Ex的函数多一些参数什么的, 可以说拓展了一些功能
ExA 与 ExW 就是 A,W与Ex的结合了

_beginthreadex函数原型
unsigned long _beginthreadex(    void *security,    // 安全属性， 为NULL时表示默认安全性    unsigned stack_size,    // 线程的堆栈大小， 一般默认为0    unsigned(_stdcall *start_address)(void *),    // 所要启动的线程函数    void *argilist, // 线程函数的参数， 是一个void*类型， 传递多个参数时用结构体    unsigned initflag, // 新线程的初始状态，0表示立即执行，CREATE_SUSPENDED表示创建之后挂起    unsigned *threaddr    // 用来接收线程ID);返回值 : // 成功返回新线程句柄， 失败返回0





线程句柄作用
线程和线程句柄（Handle）不同，线程是一个程序的工作流程，线程句柄是一个内核对象。线程的生命周期就是线程函数从开始执行到线程结束，线程句柄一旦CreateThread返回，如果你不用它操作线程或者等待线程等操作比如waitforsingleobject，就可以CloseHandle。

CloseHandle 只是关闭了一个线程句柄对象，表示我不再使用该句柄，即不对这个句柄对应的线程做任何干预了，和结束线程没有一点关系。若在线程执行完之后，没有调用CloseHandle，在进程执行期间，将会造成内核对象的泄露，相当于句柄泄露，但不同于内存泄露，这势必会对系统的效率带来一定程度上的负面影响。但当进程结束退出后，系统会自动清理这些资源。

关闭一个内核对象。其中包括文件、文件映射、进程、线程、安全和同步对象等。在CreateThread成功之后会返回一个hThread的handle，且内核对象的计数加1，CloseHandle之后，引用计数减1，当变为0时，系统删除内核对象。


WaitForSingleObject函数原型
DWORDWINAPIWaitForSingleObject(  HANDLEhHandle,  DWORDdwMilliseconds);   功能：等待函数 – 使线程进入等待状态，直到指定的内核对象被触发。

第一个参数为要等待的内核对象。
第二个参数为最长等待的时间，以毫秒为单位，如传入5000就表示5秒，传入0就立即返回，传入INFINITE表示无限等待。
因为线程的句柄在线程运行时是未触发的，线程结束运行，句柄处于触发状态。所以可以用WaitForSingleObject()来等待一个线程结束运行。
函数返回值：在指定的时间内对象被触发，函数返回WAIT_OBJECT_0。超过最长等待时间对象仍未被触发返回WAIT_TIMEOUT。传入参数有错误将返回WAIT_FAILED
WaitForMultipleObjects函数原型
WaitForMultipleObjects(    _In_ DWORD nCount,    		// 要监测的句柄的组的句柄的个数    _In_reads_(nCount) CONST HANDLE* lpHandles,   //要监测的句柄的组    _In_ BOOL bWaitAll,  		// TRUE 等待所有的内核对象发出信号， FALSE 任意一个内核对象发出信号    _In_ DWORD dwMilliseconds 	//等待时间);功能： 阻塞多个线程句柄，直到子线程运行完毕，主线程才会往下走


参数一：检测句柄的个数；
参数二：检测句柄的数组；
参数三：TRUE等待所有线程执行完毕，FALSE，任意一个完成就停止阻塞；
参数四：等待时间

其它CreateThread是由操作系统提供的接口，而AfxBeginThread和_BeginThread则是编译器对它的封装。
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>aPI</tag>
      </tags>
  </entry>
  <entry>
    <title>Concept</title>
    <url>/Windows/Windows/Concept/</url>
    <content><![CDATA[Windows 编程基本概念
宽字符：Unicode字符，双字节

窄字符：ASCII字符，单字节

Windows 中所有的底层函数都是 Unicode 编码。
_UNICODE 的例子你可以在 TCHAR.H 中找到，它用来解析TCHAR等类型是宽字符还是单字节字符，以及一些字符串宏的处理结果是宽字符还是单字节。

COM 组件必须使用 Unicode编码（COM组件可以理解为DLL，主要是用于代码重用）。
比如在Windows API中：FindWindowW和FindWindowA。W的意思为wide（宽），A的意思为ASCII

在 Windows.h中有一个UNICODE宏，底层调用宽字节版本，窄字节版本仅作编码转换。

Unicode：一个中文字符长度为1；多字节字符集：一个中文字符长度为2


字符
L表示long
P表示pointer
C表示constant
W表示wide
T：win32环境中有一个_T宏，用来标识字符是否采用Unicode编码（两字节表示一个字符），若程序中定义了Unicode，该字符&#x2F;字符串被作为Unicode字符串，否则就是标准的ANSI（单字节表示一个字符）字符串。
STR表示这个变量是一个字符串。

LPCSTR: long pointer const string，可看成const char*，与PCSTR相似
LPSTR：可看成char*，与PSTR相似
关于wchar_t*的：
LPCWSTR，PCWSTR，LPWSTR，PWSTR
Ascii 与 unicode 互转//unicode转为asciistd::string UnicodeToAscii( const std::wstring&amp; in_str )&#123;	int nNeedChars = WideCharToMultiByte( CP_ACP, 0, in_str.c_str(), -1, 0, 0, 0, 0 );	if (nNeedChars &gt; 0)//再次判断一下	&#123;			std::string temp;		temp.resize(nNeedChars);		::WideCharToMultiByte( CP_ACP, 0, in_str.c_str(), -1, &amp;temp[0], nNeedChars, 0, 0 );		return temp;	&#125; 	return std::string();&#125; //ascii转为unicodestd::wstring AsciiToUnicode( const std::string&amp; in_str )&#123;	int nNeedWchars = MultiByteToWideChar( CP_ACP, 0, in_str.c_str(), -1, NULL, 0 );	if (nNeedWchars &gt; 0)	&#123;		std::wstring temp;		temp.resize(nNeedWchars);		::MultiByteToWideChar( CP_ACP, 0, in_str.c_str(), -1, &amp;temp[0], nNeedWchars );		return temp;	&#125; 	return std::wstring();&#125;

Utf8和Unicode的互转//utf8转为unicodestd::wstring UTF8ToUnicode( const std::string&amp; in_utf8Str )&#123;	int nNeedWchars = MultiByteToWideChar( CP_UTF8, 0, in_utf8Str.c_str(), -1, NULL, 0 );	if (nNeedWchars &gt; 0)	&#123;		std::wstring temp;		temp.resize(nNeedWchars);		::MultiByteToWideChar( CP_UTF8, 0, in_utf8Str.c_str(), -1, &amp;temp[0], nNeedWchars );		return temp;	&#125; 	return std::wstring();&#125; //unicode转为utf8std::string UnicodeToUTF8( const std::wstring&amp; in_wStr )&#123;	int nNeedChars = WideCharToMultiByte( CP_UTF8, 0, in_wStr.c_str(), -1, 0, 0, 0, 0 );	if (nNeedChars &gt; 0)//再次判断一下	&#123;			std::string temp;		temp.resize(nNeedChars);		::WideCharToMultiByte( CP_UTF8, 0, in_wStr.c_str(), -1, &amp;temp[0], nNeedChars, 0, 0 );		return temp;	&#125; 	return std::string();&#125;

Ascii和Utf8的互转 //ascii转为utf8std::string AsciiToUTF8(const std::string&amp; in_asciiStr)&#123;	return UnicodeToUTF8(AsciiToUnicode(in_asciiStr));&#125; //utf8转为asciistd::string UTF8ToAscii(const std::string&amp; in_utf8Str)&#123;	return UnicodeToAscii(UTF8ToUnicode(in_utf8Str));&#125;

GB2312和Unicode的互转 //BIG5 转换成 Unicode：std::wstring BIG5ToUnicode(const std::string&amp; strBIG5String)&#123;	UINT nCodePage = 950; //BIG5	int nNeedWchars = MultiByteToWideChar(nCodePage, 0, strBIG5String.c_str(), -1, NULL, 0);	if (nNeedWchars &gt; 0)	&#123;		std::wstring temp;		temp.resize(nNeedWchars);		::MultiByteToWideChar( nCodePage, 0, strBIG5String.c_str(), -1, &amp;temp[0], nNeedWchars );		return temp;	&#125; 	return std::wstring();&#125; //Unicode 转换成 BIG5：std::string UnicodeToBIG5(const std::wstring&amp; strUnicodeString)&#123;	UINT nCodePage = 950; //BIG5	int nNeedChars = WideCharToMultiByte(nCodePage, 0, strUnicodeString.c_str(), -1, NULL, 0, NULL, NULL);	//再次判断一下	if (nNeedChars &gt; 0)	&#123;		std::string temp;		temp.resize(nNeedChars);		::WideCharToMultiByte( nCodePage, 0, strUnicodeString.c_str(), -1, &amp;temp[0], nNeedChars, 0, 0 );		return temp;	&#125; 	return std::string();&#125;





References
Windows下的字符集转换
https://blog.csdn.net/luoyeaijiao/article/details/7266490
多字节字符集与Unicode字符集
Unicode 和多字节字符集 (MBCS) 支持

]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>concept</tag>
      </tags>
  </entry>
  <entry>
    <title>VisualStudio</title>
    <url>/Windows/Windows/VisualStudio/</url>
    <content><![CDATA[VisualStudio 版本对比因为微软的版本比较乱，所以要理清版本，首先需要区分 VS 和 VC 的含义：

VS（Visual Studio）: 针对多语言（C++、C#、F#、J#、Asp、Web 等）的 IDE 集成开发环境
VC（Visual C++）: 针对 C++ 语言的 IDE 集成开发环境，也称为 MSVC

换言之，VS 包含 VC， VC 只是 VS 的其中一个工具集。
微软历年发布的 IDE 版本如下：



IDE 名称
发布时间
IDE 版本
工具集版本
MSC_VER
MSVC++
系统支持



Visual C++6.0
1998
6
V60
1200
MSVC++ 6.0
WinXP、Win7


Visual Studio 2002
2002
7
V70
1300
MSVC++ 7.0
WinXP、Win7


Visual Studio 2003
2003
8
V71
1310
MSVC++ 7.1
WinXP、Win7


Visual Studio 2005
2005
9
V80
1400
MSVC++ 8.0
WinXP、Win7


Visual Studio 2008
2008
10
V90
1500
MSVC++ 9.0
WinXP、Win7


Visual Studio 2010
2010
11
V100
1600
MSVC++ 10.0
WinXP、Win7


Visual Studio 2012
2012
12
V110
1700
MSVC++ 11.0
WinXP、Win7


Visual Studio 2013
2013
13
V120
1800
MSVC++ 12.0
Win7、Win10


Visual Studio 2015
2015
14
V140
1900
MSVC++ 14.0
Win7、Win10


Visual Studio 2017
2017
15
V141
1910
MSVC++ 14.1
Win7、Win10


Visual Studio 2019
2019
16
V142
1920
MSVC++ 14.2
Win7、Win10


Visual Studio 2022
2022
17
V143
1930
MSVC++ 14.3
Win7、Win10


查看 VS 工程版本对于一个 VS 工程，要想知道它是用哪个 VC 编译的，只需要用文本打开根目录下的 *.sln 文件，即可在文件开头找到一段版本说明，例如：
Microsoft Visual Studio Solution File, Format Version 12.00# Visual Studio Version 17VisualStudioVersion = 17.1.32328.378MinimumVisualStudioVersion = 12.0.40629.0

查上表可知，Visual Studio Version 17 即 Visual Studio 2022。
如果以后工程更换了 VS 版本，可以用同样的方法查找版本。
]]></content>
      <categories>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>windows</tag>
        <tag>visualStudio</tag>
      </tags>
  </entry>
  <entry>
    <title>Nodejs</title>
    <url>/node-js/node.js/Nodejs/</url>
    <content><![CDATA[

IntroduceNodejs 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。
Nodejs 中的 JavaScript 运行环境

How to study
JavaScript 基础语法
Node.js 内置 API 模块(fs, path, http)
第三方库：express, mysql

References
Node.js official: http://nodejs.cn/learn/introduction-to-nodejs
英文文章从原理讲解Nodejs: https://www.sitepoint.com/asynchronous-programming-using-async-await-in-c

]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>nodejs</tag>
      </tags>
  </entry>
  <entry>
    <title>npm</title>
    <url>/node-js/node.js/npm/</url>
    <content><![CDATA[

1. introducenpm(Node Package Manager) 是 Node.js 的标准包管理器。
2. npm commandnpm install                              # 安装 package.json 中所有的 dependency npm -v                                   # 显示版本，检查npm 是否正确安装npm install express                      # 安装express模块npm install express@0.0.1                # 安装指定版本npm install -g express                   # 全局安装express模块npm uninstall &lt;package-name&gt;             # 全局卸载指定的 pckagenpm install &lt;package-name&gt; -D            # 安装包依赖到开发环境中，生产环境不会用到 npm install --save-prod xxx              # 安装包依赖到生产环境的本地工程中 npm list                                 # 列出已安装模块npm show &lt;package-name&gt;                  # 显示 package 信息npm update                               # 升级当前目录下的项目的所有 packagenpm update &lt;package-name&gt;                # 升级当前目录下的项目的指定 packagenpm update -g &lt;package-name&gt;             # 升级全局安装的 packagenpm install &lt;package-name&gt;@&lt;version&gt;     # 指定软件包的特定版本，方便进行版本控制

packagepackage 是基于内置模块封装出来的，提供了更高级、更方便的 API，极大的提高了开发效率。
# 快速创建 package.json 文件npm init -y 

package.json 中的 dependencies 节点，专门记录使用 npm install 命令安装了哪些 package。
3. package.json每个 JavaScript 项目（无论是 Node.js 还是浏览器应用程序）都可以被当作 npm 软件包，并且通过 package.json 来描述项目和软件包信息。简单来说 package.json 是管理需要安装的所有依赖文件。
当运行 npm init 初始化 JavaScript&#x2F;Node.js 项目时，将生成 package.json 文件，文件内的内容由开发人员提供：

name：JavaScript 项目或库的名称。
version：项目的版本。通常，在应用程序开发中，由于没有必要对开源库进行版本控制，因此经常忽略这一块。但是，仍可以用它来定义版本。
description：项目的描述。
license：项目的许可证。
scripts: 项目本地允许的命令行工具。

4. package-lock.json该文件描述了 npm JavaScript 项目中使用的依赖项的确切版本。如果 package.json 是通用的描述性标签，则 package-lock.json 是成分表。
5. references
npm official: https://www.npmjs.com
nodejs of npm: https://nodejs.cn/en/learn/getting-started/an-introduction-to-the-npm-package-manager

]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title>xml</title>
    <url>/node-js/node.js/xml/</url>
    <content><![CDATA[

1. 概念什么是XML？

XML一般是指可扩展标记语言，标准通用标记语言的子集，是一种用于标记电子文件使其具有结构性的标记语言。

 开发中使用XML主要有以下两方面应用.

XML做为数据交换的载体，用于数据的存储与传输
XML做为配置文件

2. 书写规范
xml必须有根元素(只有一个)
xml标签必须有关闭标签
xml标签对大小写敏感
xml的属性值须加引号
特殊字符必须转义
xml中的标签名不能有空格
空格&#x2F;回车&#x2F;制表符在xml中都是文本节点
xml必须正确地嵌套

3. XML文件的优点：
XML文档内容和结构完全分离。
互操作性强。
规范统一。
支持多种编码。
可扩展性强。

4. 解析XML文件及优缺点一般有DOM解析和SAX解析。
DOM解析优缺点

优点
允许应用程序对数据和结构做出更改。
访问是双向的，可以在任何时候在树中上下导航，获取和操作任意部分的数据。


缺点
通常需要加载整个XML文档来构造层次结构，消耗资源大。



5. References
菜鸟Xml教程

]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>xml</tag>
      </tags>
  </entry>
  <entry>
    <title>yaml</title>
    <url>/node-js/node.js/yaml/</url>
    <content><![CDATA[

References
yaml 官方教程 
yaml语言教程

]]></content>
      <categories>
        <category>node.js</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title>CPU</title>
    <url>/CPU/Architecture/CPU/CPU/</url>
    <content><![CDATA[

Linux 终端下运行 lscpu 命令查看关于 CPU 架构的信息。
[root@AP03 log]# lscpuArchitecture:          x86_64CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                8On-line CPU(s) list:   0-7Thread(s) per core:    1Core(s) per socket:    2Socket(s):             4NUMA node(s):          1Vendor ID:             GenuineIntelCPU family:            6Model:                 15Model name:            Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHzStepping:              1CPU MHz:               2099.998BogoMIPS:              4199.99Hypervisor vendor:     VMwareVirtualization type:   fullL1d cache:             32KL1i cache:             32KL2 cache:              256KL3 cache:              20480KNUMA node0 CPU(s):     0-7Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc arch_perfmon pebs bts nopl tsc_reliable nonstop_tsc eagerfpu pni ssse3 cx16 x2apic tsc_deadline_timer hypervisor lahf_lm tsc_adjust arat

对上面的显示结果进行解释：

Architecture: 表示系统的架构，这里是 x86_64，表示 64 位的 x86 架构。
CPU op-mode(s): 表示CPU支持的操作模式，这里支持32位和64位操作模式。
Byte Order: 表示系统的字节序，这里是Little Endian，表示低位字节存储在内存的低地址。
CPU(s): 表示CPU的总核心数，这里是8个核心。
On-line CPU(s) list: 表示在线的CPU核心列表，从0到7。
Thread(s) per core: 表示每个核心的线程数，这里是1，表示没有使用超线程技术。
Core(s) per socket: 表示每个CPU插槽的核心数，这里是2个核心。
Socket(s): 表示CPU插槽的数量，这里是4个插槽。
NUMA node(s): 表示NUMA（非一致性内存访问）节点的数量，这里是1个节点。
Vendor ID: 表示CPU制造商的标识，这里是GenuineIntel，表示英特尔的CPU。
CPU family: 表示CPU家族，这里是6。
Model: 表示CPU的型号，这里是15。
Model name: 表示CPU的型号名称，这里是Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz。
Stepping: 表示CPU的步进号，这里是1。
CPU MHz: 表示CPU的时钟频率，这里是2099.998 MHz。
BogoMIPS: 表示CPU的BogoMIPS值，这是一个用于性能比较的指标。
Hypervisor vendor: 表示虚拟化平台的供应商，这里是VMware。
Virtualization type: 表示虚拟化的类型，这里是full，表示完全虚拟化。
L1d cache: 表示CPU的一级数据缓存大小，这里是32KB。
L1i cache: 表示CPU的一级指令缓存大小，这里是32KB。
L2 cache: 表示CPU的二级缓存大小，这里是256KB。
L3 cache: 表示CPU的三级缓存大小，这里是20480KB。
NUMA node0 CPU(s): 表示NUMA节点0上的CPU核心列表，从0到7。
Flags: 表示CPU的特性标志，包括对特定指令集的支持等。

说明：

对 Socket 的理解：术语 “Socket” 在计算机网络中通常用于描述套接字（socket），表示网络通信的端点。套接字是一种应用程序接口（API），用于在网络中建立通信连接。在CPU上指的是CPU插槽接口，英文名称为：CPU socket 或 CPU slot。是一种安装CPU的物理接口，提供了电力和信号连接，这些插槽通常具有特定的形状和布局，以适应特定类型的CPU。

]]></content>
      <categories>
        <category>CPU</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>cPU</tag>
      </tags>
  </entry>
  <entry>
    <title>x86</title>
    <url>/Chip/Architecture/Chip/x86/</url>
    <content><![CDATA[



References
Intel® 64 and IA-32 Architectures Software Developer Manuals: https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html
x86 and amd64 instruction reference: https://www.felixcloutier.com/x86
x86 instruction Set: https://en.wikipedia.org/wiki/X86_instruction_listings
USC university Intro to x86 Instruction Set: https://ee.usc.edu/~redekopp/cs356/slides/CS356Unit4_x86_ISA.pdf
x64 Cheat Sheet: https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatsheet.pdf
standford Guide to x86-64: https://web.stanford.edu/class/cs107/guide/x86-64.html
Intel x86 Instruction Set Architecture: https://www.csie.ntu.edu.tw/~cyy/courses/assembly/10fall/lectures/handouts/lec14_x86isa.pdf

]]></content>
      <categories>
        <category>Chip</category>
      </categories>
      <tags>
        <tag>architecture</tag>
        <tag>chip</tag>
        <tag>x86</tag>
      </tags>
  </entry>
  <entry>
    <title>Compose-k8s</title>
    <url>/Docker/CloudNative/Docker/Compose-k8s/</url>
    <content><![CDATA[


Docker Compose Kubernetes 区别Docker Compose和Kubernetes是两个不同的容器编排工具，它们解决了不同层次的问题，并且适用于不同规模和复杂度的应用程序。以下是它们之间的主要区别：
1. 复杂度和规模
Docker Compose： Docker Compose适用于相对较小、简单的应用，通常在单机或者少量主机上运行。它通过一个简单的docker-compose.yml文件来定义和管理应用程序的多个服务，适用于开发、测试、本地部署等场景。
Kubernetes： Kubernetes是一个用于自动化部署、扩展和管理容器化应用程序的开源平台，适用于大规模、复杂的分布式系统。它可以管理数千个容器，并提供高可用性、自动伸缩、负载均衡等功能。

2. 编排和管理
Docker Compose： Docker Compose提供了一个相对简单的编排模型，适用于启动和管理少量的容器服务。它对单机或者少量主机上的容器进行编排和管理。
Kubernetes： Kubernetes提供了复杂的编排和管理功能，包括自动负载均衡、自动伸缩、滚动更新、服务发现、配置管理等。它能够跨多个主机自动调度容器，并保证应用程序的高可用性和稳定性。

3. 生态系统和扩展性
Docker Compose： Docker Compose主要关注于Docker容器，是Docker生态系统的一部分。它的主要功能是在单机或少量主机上管理Docker容器。
Kubernetes： Kubernetes是一个独立于容器运行时的容器编排平台，它不仅支持Docker，还支持其他容器运行时，如containerd和cri-o。Kubernetes有一个庞大的生态系统，有许多第三方工具和插件可以扩展其功能。

4. 适用场景
Docker Compose： 适用于开发和测试环境，以及小型应用的部署。它对于本地开发环境的搭建非常方便，能够快速启动多个相关服务。
Kubernetes： 适用于大规模、高可用性的生产环境。Kubernetes提供了更强大的容器编排和管理能力，适用于需要高度可扩展性和自动化管理的复杂应用。

总的来说，如果你的应用规模较小，且你主要使用Docker容器，那么Docker Compose可能是一个更简单、更方便的选择。而如果你的应用规模较大，需要高度自动化、高可用性和复杂的容器编排功能，那么Kubernetes可能更适合你的需求。
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>docker</tag>
        <tag>compose-k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Compose</title>
    <url>/Docker/CloudNative/Docker/Compose/</url>
    <content><![CDATA[

1. Introduce2. Abbreviation


缩写
英文全称
说明



dev
development
开发


sit
System Integrate Test
系统整合测试（内测）


uat
User Acceptance Test
用户验收测试


pet
Performance Evaluation Test
性能评估测试（压测）


sim
simulation
仿真


prd&#x2F;prod
production
产品&#x2F;正式&#x2F;生产


2.1. Install1. 下载镜像sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose2. 添加可执行权限chmod +x /usr/local/bin/docker-compose3. 终端查看是否安装成功docker-compose --version

配置 kafka
KAFKA_ADVERTISED_HOST_NAME：广播主机名称，一般用IP指定KAFKA_ZOOKEEPER_CONNECT：Zookeeper连接地址，格式：zoo1：port1,zoo2:port2:/pathKAFKA_LISTENERS：Kafka启动所使用的的协议及端口KAFKA_ADVERTISED_LISTENERS：Kafka广播地址及端口，也就是告诉客户端，使用什么地址和端口能连接到Kafka，这个很重要，如果不指定，宿主机以外的客户端将无法连接到Kafka，比如我这里因为容器与宿主机做了端口映射，所以广播地址采用的是宿主机的地址及端口，告诉客户端只要连接到宿主机的指定端口就行了KAFKA_BROKER_ID：指定BrokerId，如果不指定，将会自己生成

2.2. Docker Compose command命令行终端输入 docker compose --help 查看 docker compose 的用法。
[root@dev-tdepoc-ap01 ~]# docker compose --helpUsage:  docker compose [OPTIONS] COMMANDDefine and run multi-container applications with Docker.Options:      --ansi string                Control when to print ANSI control characters (&quot;never&quot;|&quot;always&quot;|&quot;auto&quot;) (default &quot;auto&quot;)      --compatibility              Run compose in backward compatibility mode      --dry-run                    Execute command in dry run mode      --env-file stringArray       Specify an alternate environment file.  -f, --file stringArray           Compose configuration files      --parallel int               Control max parallelism, -1 for unlimited (default -1)      --profile stringArray        Specify a profile to enable      --progress string            Set type of progress output (auto, tty, plain, quiet) (default &quot;auto&quot;)      --project-directory string   Specify an alternate working directory                                   (default: the path of the, first specified, Compose file)  -p, --project-name string        Project nameCommands:  build       Build or rebuild services  config      Parse, resolve and render compose file in canonical format  cp          Copy files/folders between a service container and the local filesystem  create      Creates containers for a service.  down        Stop and remove containers, networks  events      Receive real time events from containers.  exec        Execute a command in a running container.  images      List images used by the created containers  kill        Force stop service containers.  logs        View output from containers  ls          List running compose projects  pause       Pause services  port        Print the public port for a port binding.  ps          List containers  pull        Pull service images  push        Push service images  restart     Restart service containers  rm          Removes stopped service containers  run         Run a one-off command on a service.  scale       Scale services  start       Start services  stop        Stop services  top         Display the running processes  unpause     Unpause services  up          Create and start containers  version     Show the Docker Compose version information  wait        Block until the first service container stops  watch       Watch build context for service and rebuild/refresh containers when files are updatedRun &#x27;docker compose COMMAND --help&#x27; for more information on a command.



# 创建和启动容器，-d 表示：后台运行，detached 简称docker compose up -d# 删除实例docker compose down# 列出目前正在运行相关容器docker compose ps# 启动docker compose start# 停止docker composr stop# 重启docker compose restart# 容器运行时执行输入的命令# 登录到redis中 -a redis密码docker-compose exec redis redis-cli -a redis123# 登录到mysqldocker-compose exec  mysql  mysql -uroot -pMysql@root123



3. References
Docker Compose offical doc: https://docs.docker.com/compose/
Compose 模板文件：https://yeasy.gitbook.io/docker_practice/compose/compose_file

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>docker</tag>
        <tag>compose</tag>
      </tags>
  </entry>
  <entry>
    <title>Install</title>
    <url>/Docker/CloudNative/Docker/Install/</url>
    <content><![CDATA[

Linux 换源更换方法Ubuntu采用apt作为软件安装工具，其镜像源列表记录在/etc/apt/source.list文件中。首先将source.list复制为source.list.bak备份，然后将source.list内容改为需要的镜像源列表即可。修改完成后保存source.list文件，执行：
sudo apt update

等待更新完成即可。
常用国内镜像源本节均为 Ubuntu 20.04 的镜像源列表。若为其他版本，将所有focal更改为其他版本代号即可。
常用的Ubuntu版本代号如下：
Ubuntu 22.04：jammyUbuntu 20.04：focalUbuntu 18.04：bionicUbuntu 16.04：xenial

Ubuntu 通常采用“形容词+小动物”作为版本代号（默认的壁纸），在镜像源列表中只有第一个词。此外，默认注释了代码源以提高速度，注释了预发布软件源（可能不稳定）。如有需要可以取消注释。建议将所有常用镜像源保存在/etc/apt目录下，并命名为类似source.list.aliyun的形式，需要使用时直接复制替换source.list文件即可。
阿里云deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse# deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse# deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse# deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse# deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse## Pre-released source, not recommended.# deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse# deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse

清华deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted universe multiverse## Pre-released source, not recommended.# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse

中科大deb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiversedeb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse## Pre-released source, not recommended.# deb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse# deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse

网易163deb http://mirrors.163.com/ubuntu/ focal main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiversedeb http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse# deb-src http://mirrors.163.com/ubuntu/ focal main restricted universe multiverse# deb-src http://mirrors.163.com/ubuntu/ focal-security main restricted universe multiverse# deb-src http://mirrors.163.com/ubuntu/ focal-updates main restricted universe multiverse# deb-src http://mirrors.163.com/ubuntu/ focal-backports main restricted universe multiverse## Pre-released source, not recommended.# deb http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiverse# deb-src http://mirrors.163.com/ubuntu/ focal-proposed main restricted universe multiverse





5. Docker 安装平台支持（Supported platforms）：Docker 引擎（Docker Engine ）支持 Linux 、macOS、Win10（通过 Docker 桌面版）等不同的平台安装，还支持静态二进制文件的安装。
5.1. CenOS7 下安装Docker 并非一个通用的容器工具，它依赖于已存在并运行的 Linux 内核环境。Docker 实际上是在已运行的 Linux 下制造了一个隔离的文件环境，因此它执行的效率几乎等同于所部署的 Linux 主机。Docker 必须部署在带有Linux 内核的系统上。
安装前提条件
目前，CentOS 仅支持发行版中内核，要求系统为 64 位，32 位的操作系统暂时不支持，Linux 系统的内核版本为 3.8 以上。
查看 Linux 内核版本
// 查看 Linux 发行版[root@redis_181 ~]# cat /etc/redhat-releaseCentOS Linux release 7.9.2009 (Core)// 查看内核版本、硬件架构、主机名称、操作系统类型等信息[root@redis_181 ~]# uname -a    Linux redis_181 3.10.0-1160.49.1.el7.x86_64 #1 SMP Tue Nov 30 15:51:32 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux



5.2. Windows 下安装Docker 官网介绍 Windows下安装 Docker有两种方式，一种是在 Windows 子系统（WSL）中安装 Docker，另一种在带有 Windows 虚拟化技术的 Windows 容器中安装。
5.2.1. WSL 下安装WSL 已安装好后，在WSL2 里面的终端按照下面的步骤执行：

配置 docker 源

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \   &quot;deb [arch=amd64] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu \   $(lsb_release -cs) \   stable&quot;sudo apt update


安装 docker-ce
sudo apt install -y docker-ce

启动 docker
sudo service docker start

Ubuntu 下安装移除已安装的 docker
sudo apt-get remove docker docker-engine docker-ce docker.iosudo apt-get update

添加docker的使用的公钥
# Add Docker&#x27;s official GPG key:sudo apt-get updatesudo apt-get install ca-certificates curl gnupgsudo install -m 0755 -d /etc/apt/keyringscurl -fsSL https://mirrors.aliyun.com/docker-ce/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgsudo chmod a+r /etc/apt/keyrings/docker.gpg# Add the repository to Apt sources:echo \  &quot;deb [arch=&quot;$(dpkg --print-architecture)&quot; signed-by=/etc/apt/keyrings/docker.gpg] https://mirrors.aliyun.com/docker-ce/ubuntu \  &quot;$(. /etc/os-release &amp;&amp; echo &quot;$VERSION_CODENAME&quot;)&quot; stable&quot; | \  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt-get update

安装docker-ce
sudo apt-get install -y docker-ce

启动docker
sudo systemctl status docker

运行hello-world
sudo docker run hello-world


Docker mirror
yandex.ru: 俄罗斯Yandex镜像网站 # 用法docker pull cr.yandex/mirror/nginx
hub.atomgit.com:可信镜像中心
status.1panel.top: 国内 Docker 服务状态 &amp; 镜像加速监控
Github DockerHub 国内加速镜像列表

References
https://docs.docker.com/engine/install/ubuntu/
Control Docker with systemd: https://docs.docker.com/config/daemon/systemd/
Install Docker Engine from binaries: https://docs.docker.com/engine/install/binaries/
cgroupfs-mount: https://github.com/tianon/cgroupfs-mount

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>docker</tag>
        <tag>install</tag>
      </tags>
  </entry>
  <entry>
    <title>Internal</title>
    <url>/Docker/CloudNative/Docker/Internal/</url>
    <content><![CDATA[

1. 理解 Docker 内部原理
Docke 容器本质上是宿主机的进程。
namespace 实现了资源隔离。
cgroups 实现了资源限制。
写时复制机制(copy-on-write)实现了高效的文件操作。

1.1. namespace资源隔离linux 内核提拱了 6 种 namespace 隔离的系统调用，如下图所示，但是真正的容器还需要处理许多其他工作。



namespace
系统调用参数
隔离内容



UTS
CLONE_NEWUTS
主机名或域名


IPC
CLONE_NEWIPC
信号量、消息队列和共享内存


PID
CLONE_NEWPID
进程编号


Network
CLONE_NEWNET
网络设备、网络战、端口等


Mount
CLONE_NEWNS
挂载点（文件系统）


User
CLONE_NEWUSER
用户组和用户组


实际上，linux 内核实现 namespace 的主要目的，就是为了实现轻量级虚拟化技术服务。在同一个 namespace下的进程合一感知彼此的变化，而对外界的进程一无所知。这样就可以让容器中的进程产生错觉，仿佛自己置身一个独立的系统环境中，以达到隔离的目的。
2. References
Docker Internals: http://docker-saigon.github.io/post/Docker-Internals/

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>docker</tag>
        <tag>internal</tag>
      </tags>
  </entry>
  <entry>
    <title>docker</title>
    <url>/Docker/CloudNative/Docker/docker/</url>
    <content><![CDATA[

1. 为什么会出现 Docker？为了解决运行环境和配置的问题。开发人员在部署好的机器上开发，开发完成后，交付给测试和运维人员，而他们也需要在相同的环境下进行测试和产品的运维，需要部署同样的环境。在部署的过程中可能会存在环境不一致的问题，需要去逐一解决，这样很费时、费力。那么有没有一种技术，测试人员或运维的人员直接将开发人员的部署的环境直接拿来用？将开发人员打包好的环境，类似像安装软件一样，直接安装在测试环境或运维环境的机器上。随着技术的发展，真的有这一门技术，那就是 Docker，直接将打好的包，形成一个镜像文件（image），通过 Docker 引擎（engine）部署到其他的操作系统上，实现了一次部署，处处运行。
2. Thinking学习三部曲：理论、实操、总结
3. Docker 是什么Docker 是基于 Go 语言实现的云开源项目。主要目标是“build, ship and run any app, anywhere”，通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的 APP 及运行环境能做到“一次镜像，处处运行”。
Docker 是在 Linux 容器技术的基础上发展起来的。将应用打包成镜像，通过镜像成为运行在 Docker 容器上面的示例。Docker 能运行在任何的操作系统上，实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机器上就可以一键部署了，大大简化了操作。
从面向对象的角度看 docker：Docker 利用容器，独立运行一个或一组应用，这些程序或服务都在容器里面，容器就类似于一个虚拟化的运行环境，容器是镜像创建的运行实例。
从镜像的角度看 docker：可以把容器看做是一个简易版的 Linux 环境，包括 root 用户权限、进程空间、用户空间、网络空间等，还有一些应用程序。
4. Docker 与传统虚拟机有什么不同？
传统虚拟机不仅在操作系统上模拟一套虚拟的硬件，还需要模拟出一个完成的操作系统，然后再模拟出的操作系统上运行所需的进程（即软件）。
Docker 容器它没有自己的内核，也没有进行硬件的虚拟化，Docker 容器内的应用进程直接运行在宿主机（安装 Docker 软件的操作系统）的内核上，因此 Docker 容器要比传统虚拟机更轻便，占用系统资源少。每个容器之间相互隔离，容器与容器之间的进程彼此个不影响，并且每个容器都有自己的文件系统。
Docker 是内核级虚拟化，不像传统的虚拟化技术需要额外的 Hypersion 支持，因此一台物理机器上可以运行多个容器的示例，大大提升了物理机器的 CPU 和 内存的利用率，节省了很多钱。

5. 为什么 Docker 比虚拟机快？
Docker 有比虚拟机更少的抽象层。由于 Docker 不需要 Hyperversion（虚拟机）实现硬件资源虚拟化，运行在 Docker 容器上的程序直接使用的是实际物理机器的硬件资源，因此 CPU、内存利用率在 Docker 上有跟明显的优势。


Docker 利用的是宿主机的内核，不需要加载操作系统的内核。当新建一个容器时，Docker 不需要和虚拟机一样加载一个操作系统的内核，而是利用的是宿主机的内核，避免了操作系统的加载、寻址、系统内核返回等比较费时、费资源的过程。当新建一个虚拟机时，虚拟机软件需要先加载操作系统，然后再返回，这个过程是非常耗时的，分钟级别的，而 Docker 则是直接省略了这一过程，新建一个 Docker 容器只需要几秒钟，非常的快。


Docker 优点

轻便：Docker 是基于容器的虚拟化，仅包含业务运行所需要的环境。
高效：不需要操作系统的虚拟化开销。
灵活性更高：支持多网络配置、分层存储和包管理。

6. Windows系统上为什么能运行 Docker？Docker在早期是只专注于Linux虚拟化实现的一种容器技术，因为Linux得天独厚的 Namespace 和 CGroup 等系统内隔离机制特性，使得在 Linux更易实现，在经过容器技术的疯狂发展推崇之后，微软看到了这一红利，在于2014 年宣布与 Docker 公司合作，将容器技术迁移到 Windows 上，这一动作让 Windows 改变了过去，只能通过VM等大型虚拟机软件通过装Linux来装Docker的现状，现在也可以很轻量级的将Docker融入系统中使用了。由于Windows系统和Linux在实现上还是有些差别，尽管我们在Docker上的操作大致相同，仍然需要注意一些事项。
没有安装 WSL 的Windows，运行 Docker 原理：

Docker 在 Windows 系统上安装时，Docker 会创建一个基于Linux的虚拟机，叫做 MobyLinuxVM 虚拟机，这个虚拟机是基于Alpine Linux的。Docker应用程序会连接到此虚拟机，你便可以开始创建具有必要操作组件的容器了。为了与本地网络和NAT（网络地址转换）进行通信，在Docker安装中会为虚拟机配置一个子网，以便你的容器在应用程序中使用。不过不必担心，MobyLinuxVM虚拟机是运行在Hyper-V，这是Windows是一项虚拟化技术，相比虚拟机之类的非常轻量级，容器可以共享主机内核，任务管理器里面可以看到对应进程。

7. Docker ComponentDocker 中有三个重要的组件：Image，Container，Repository。只有理解了这些概念后，学习 Docker 就很轻松了。


镜像（Image）

Docker 镜像是一个特殊的文件系统，用来创建 Docker 容器，一个镜像可以创建很多个容器。比如 CentOS7 官方镜像。
Docker 中除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。
镜像不包含任何的动态数据，镜像中的内容在构建之后不会再被改变。


容器（Container）

Docker 利用容器，独立运行一个或一组应用，而应用程序或服务都运行在容器里面。
容器就类似于一个虚拟化的运行环境，容器是镜像创建运行时的实例，就像是面向对象程序设计中的类 和 实例 一样，镜像相当于类，容器相当于类的实例。
容器为镜像提供了一个标准的、容器之间相互隔离的运行环境，容器可以被创建、启动、停止、删除、暂停等。
创建的容器有两部分组成：一个是最小最核心的赖以生存的 Linux 内核文件，另一个是具体的应用程序。


仓库（Repository）

集中存放镜像文件的地方，类似 Git 的远程仓库。
仓库分为私有仓库和公开的仓库。私有仓库：比如公司内部搭建专门存放镜像文件的地方；公共仓库：任何人都能访问专门存放镜像文件的地方。全球最大的公开仓库是 Dockerhub(https://hub.docker.com)。在中国境内由于一些著名的原因，访问 Dockerhub 仓库比较慢，可以配置国内的镜像仓库，比如阿里云、网易等等。



7.1. Docker 镜像加载原理Docker 镜像实际上由一层一层的文件系统组成的，这种文件系统叫 UnionFS（联合文件系统）。Docker 镜像底层是引导文件系统 bootfs，这一层与典型的 Linux&#x2F;Unix 系统是一样的，包含 boot 加载器和内核。当 boot 加载完成之后，整个内核就存在与内存中了，此时的内存权已由 bootfs 转移给内核，然后系统会卸载 bootfs。

bootfs 全名叫 boot file system，主要包含 BootLoader 和 kernel，BootLoader 主要是引导加载 kernel，Linux 刚启动时会加载 bootfs 文件系统。


rootfs（root file system）在 bootfs 文件系统之上，包含的是 Linux 系统中的 /dev、/proc、/bin、/etc 等标准目录和文件。rootfs 就是各种不同的操作系统的发行版，比如 Ubuntu、Redhat等。

对于一个精简的 OS，rootfs 可以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用 Host 的kernel，自己只需要提供 rootfs 就行了。可见对于不同的 Linux 发行版，bootfs 基本是一致的，rootfs 会有差别，因此不同的发行版可以公用 bootfs。
7.2. Docker image layerDocker 镜像层是 只读 的，容器层是 可写 的。当容器启动时，一个新的、具有写权限的层被加载到容器的顶部，这一层通常成为“容器层”，容器层之下的都叫“镜像层”。所有对容器的添加、删除、修改等操作都只会发生在容器层中。
镜像层

容器层

Docker 镜像分层的优点：资源共享、方便复制迁移。比如：有多个镜像都是从相同的基类镜像（base）构建而来，那么 docker Host 只需在磁盘上保存一份 base 镜像，同时内存中也只需要加载一份 base 镜像，就可以为所有的容器服务了。

7.3. Docker 原理
8. Docker Architecture
Docker 是一个 Client-Server 结构的系统，Docker 守护进程（daemon）运行在主机（host）上，然后通过 Socket 连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。

8.1. Docker 运行流程
用户是使用 Docker Client 与 Docker Daemon建立通信，并发送请求给 Docker daemon。
Docker Daemon 作为 Docker 架构中的主体部分，苜先提供 Docker Server 的功能使其可以接受 Docker Client的请求。
Docker Engine 执行 Docker 内部一系列工作，每一项工作都是以一个 Job 的形式的存在。
Job 运行的过程中，当需要容器镜像时，则从 Docker Registry 中下镜像，并通过镜像管理驱动 Graph drver 将下载镜像以 Grap 的形式存储。
当需要为 Docker 创建网络环境时，通过网络管理驱动 Network driver 创建并配置 Docker 容器网络环境。
当需要限制 Docker 容器运行资源或执行用户指令等操作时，则通过 exec driver 来完成。
libcantainer 是一项独立的容器管鋰包，network driver 以及 exec driver 都是通过 libcontainer 来实现具体对容器操作。

9. Docker Command运行 Docker 的格式：docker [OPTIONS] COMMAND
说明：

docker 为 docker 引擎的前缀，表示通过 docker 来执行命令。 
带有 [] 部分是可选项，这部分可要可不要，根据具体情况来定。
COMMAND 是必须的，要运行的 Docker  命令。

Docker 官方命令参考：https://docs.docker.com/reference/
9.1. helpstart, stop, status docker
# 启动服务systemctl start docker# 停止服务systemctl stop docker# 查看 Docker 服务运行状态systemctl status docker# 设置 Docker 开机启动systemctl enable docker

help 信息
# 查看Docker版本信息docker version# 查看 Docker 概要信息docker info# 查看 Docker 总体帮助文档docker --help# 查看 Docker 命令帮助文档，command 指具体的命令docker command --help 

其它
# 卸载相关依赖$ sudo yum remove docker-ce docker-ce-cli containerd.io# 清空工作路径$ sudo rm -rf /var/lib/docker$ sudo rm -rf /var/lib/containerd

9.2. Container Command9.2.1. docker run在一个新的容器中运行一条命令。在指定的镜像中创建一个具有写权限的容器层（container layer），然后运行指定的命令。
用法
docker run [OPTIONS] IMAGE [COMMAND] [ARG...]

Docker run中的可选项
OPTIONS:  -i, --interactive   交互式运行容器  -t, --tty           给容器重新分配一个伪终端（pseudo-TTY）  -p(小写)            拉 container 的端口号到主机（host）上  -P(大写)            随机分配一个端口号  -d, --detach       后台运行容器和打印容器ID  --name=“容器名字”   给容器分配一个名字，不指定名字时，docker 会随机分配一个

要启动 docker，运行 Docker run 命令即可，我们思考下，执行 docker run 命令 docker 引擎都干了什么。底层是怎样实现的？

示例1
docker run -it 36c607e7b14d /bin/bash  命令表示：交互式启动一个镜像 ID 为 36c607e7b14d 的 zookeeper 容器，并在容器中执行  /bin/bash 命令。
[root@redis_181 ~]# docker imagesREPOSITORY           TAG       IMAGE ID       CREATED        SIZEwurstmeister/kafka   latest    2dd91ce2efe1   2 weeks ago    508MBzookeeper            latest    36c607e7b14d   3 weeks ago    278MBhello-world          latest    feb5d9fea6a5   3 months ago   13.3kB[root@redis_181 ~]# docker run -it 36c607e7b14d /bin/bashroot@c9fa3e7753a5:/apache-zookeeper-3.7.0-bin#

示例2
交互式的方式启动一个容器，并给容器起一个新名字，同时分配一个伪终端。在标准输入中用 bash 命令启动伪终端。
[root@redis_181 ~]# docker run -it --name=kafka wurstmeister/kafka /bin/bashbash-5.1#

示例3
后台运行 Docker 容器
前提：要想 Docker 容器在后台运行，就必须有一个前台进程。若果容器运行的命令不是那些一直挂起的命令（比如：tail，top等），容器启动后就会自动退出。
[root@redis_181 ~]# docker run -d redis:6.0.877e61214ea8c95c007dc02928d01179ba964e63a9c1861a870fedb6f4938dd56

9.2.2. docker ps列出本地主机中当前正在运行的容器信息
用法    docker ps [OPTIONS]OPTIONS:  -a, --all             Show all containers (default shows just running)  -f, --filter filter   Filter output based on conditions provided      --format string   Pretty-print containers using a Go template  -n, --last int        Show n last created containers (includes all states) (default -1)  -l, --latest          Show the latest created container (includes all states)      --no-trunc        Don&#x27;t truncate output  -q, --quiet           Only display container IDs  -s, --size            Display total file sizes[root@redis_181 ~]# docker psCONTAINER ID   IMAGE                COMMAND       CREATED         STATUS         PORTS     NAMES176f87942045   wurstmeister/kafka   &quot;bash&quot;        5 seconds ago   Up 5 seconds             angry_pikeab67455c4ee2   wurstmeister/kafka   &quot;/bin/bash&quot;   2 minutes ago   Up 2 minutes             kafka# 查看本地主机中的所有容器docker ps -a

9.2.3. exit从容器中退出。退出容器有两种方式：

容器中执行 exit 命令后，直接退出，同时容器也停止了。
按 Ctrl + p + q 组合命令后，退出容器，当容器不停止，后台还在运行。

9.2.4. docker start启动容器
docker start &lt;容器id或容器名&gt;

9.2.5. docker stop关闭容器
docker stop &lt;容器id或容器名&gt;例子：  批量停止所有的容器  docker stop $(docker ps -a | awk &#x27;&#123;print $1&#125;&#x27;| tail -n +2)

9.2.6. docker restart重启容器
docker restart &lt;容器ID或容器名&gt;


9.2.7. docker kill强制停止容器
docker kill &lt;容器ID或容器名&gt;


9.2.8. docker rm删除以停止的容器
docker rm &lt;容器ID或容器名&gt;


9.2.9. docker top显示一个容器内部运行的进程。用法：docker top CONTAINER [ps OPTIONS]
示例
[root@redis_181 ~]# docker ps  CONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS      NAMES  77e61214ea8c   redis:6.0.8   &quot;docker-entrypoint.s…&quot;   15 seconds ago   Up 13 seconds   6379/tcp   focused_almeida[root@redis_181 ~]# docker top 77e61214ea8c  UID        PID      PPID        C       STIME  TTY        TIME    CMD  polkitd             9516        9497    0      08:17     ?       00:00:00            redis-server *:6379

9.2.10. docker inspect查看容器的内部细节信息。
用法    docker inspect [OPTIONS] NAME|ID [NAME|ID...]OPTIONS:  -f, --format string   Format the output using the given Go template  -s, --size            Display total file sizes if the type is container      --type string     Return JSON for specified type示例    docker inspect 容器ID

9.2.11. docker exec重新进入原先已退出的容器内部。
用法    docker exec [OPTIONS] CONTAINER COMMAND [ARG...][OPTIONS]:  -d, --detach 在容器中后台执行命令；   -i, --interactive=true | false ：打开标准输入接受用户输入命令

示例
docker exec -it &lt;容器ID&gt; /bin/bash# 使用 /bin/bash 命令前台交互的重新进入到容器内部 [root@redis_181 ~]# docker exec -it 77e61214ea8c /bin/bashroot@77e61214ea8c:/data#

9.2.12. docker attach重新进入原先已退出的容器内部，并将本地标准输入、输出和错误流附加到正在运行的容器。
用法    docker attach [OPTIONS] CONTAINEROPTIONS:  --detach-keys string   Override the key sequence for detaching a container  --no-stdin             Do not attach STDIN  --sig-proxy            Proxy all received signals to the process (default true)

注意：docker exec 与 docker attach 的区别

docker attach  直接进入容器命令行的终端，不会启动新的进程，用 exit 命令退出容器时，会导致容器停止。
外部终端查看 docker 容器的 ID
[root@CentOS7 ~]# docker psCONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES86fcdb251eb9   ubuntu    &quot;/bin/bash&quot;   6 minutes ago   Up 6 minutes             romantic_murdock

指定容器 ID，进入 docker 容器内部
[root@CentOS7 ~]# docker attach 86fcdb251eb9root@86fcdb251eb9:/#root@86fcdb251eb9:/# lsbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var

执行 exit 命令退出容器后，再次查看容器的进程，发现容器没有跑起来，已经停止运行了。
root@86fcdb251eb9:/# exitexit[root@CentOS7 ~]# docker psCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES

执行 docker exec 是在容器内部打开新的终端，并且可以启动新的进程，用 exit 命令退出容器时，不会导致容器停止。
外部终端查看 docker 容器的 ID
[root@CentOS7 ~]# docker psCONTAINER ID   IMAGE     COMMAND       CREATED          STATUS          PORTS     NAMES178c5e88904a   ubuntu    &quot;/bin/bash&quot;   20 seconds ago   Up 19 seconds             eager_ellisS

指定容器 ID 和命令，比如指定 ID 为 178c5e88904a 的容器，以交互式的方式重新打开一个伪终端后进入容器内部。
[root@CentOS7 ~]# docker exec -it 178c5e88904a  /bin/bashroot@178c5e88904a:/#

执行 exit 命令退出容器后，再次查看容器的进程，发现容器还在后台运行，并没有停止。
root@178c5e88904a:/# exitexit[root@CentOS7 ~]# docker psCONTAINER ID   IMAGE     COMMAND       CREATED         STATUS         PORTS     NAMES178c5e88904a   ubuntu    &quot;/bin/bash&quot;   3 minutes ago   Up 3 minutes             eager_ellis

9.2.13. docker cp在容器和本地文件系统（本地主机）之间拷贝文件或文件夹。
用法    docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH    docker cp [OPTIONS] SRC_PATH CONTAINER:DEST_PATHOPTIONS:  -a, --archive       Archive mode (copy all uid/gid information)  -L, --follow-link   Always follow symbol link in SRC_PATH

9.2.14. docker logs查看容器内部日志
用法    docker logs [OPTIONS] CONTAINEROPTIONS:      --details        Show extra details provided to logs  -f, --follow         Follow log output      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)  -n, --tail string    Number of lines to show from the end of the logs (default &quot;all&quot;)  -t, --timestamps     Show timestamps      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)

9.2.15. docker export导出一个容器文件系统作为一个 tar 包。
用法    docker export [OPTIONS] CONTAINEROptions:  -o, --output string   Write to a file, instead of STDOUT


示例
[root@redis_181 ~]# docker ps -aCONTAINER ID   IMAGE                COMMAND                  CREATED          STATUS                    PORTS      NAMES302e76d7a7af   redis:6.0.8          &quot;docker-entrypoint.s…&quot;   19 minutes ago   Up 19 minutes             6379/tcp   elated_feistelbdbd7d438f8f   hello-world          &quot;/hello&quot;                 2 days ago       Exited (0) 2 days ago                elastic_chaplygin# 下面两种方式是等效的[root@redis_181 ~]# docker export bdbd7d438f8f &gt; hello.tar                    hello.tar [root@redis_181 ~]# docker export -o=&quot;hw.tar&quot; bdbd7d438f8f                    hw.tar  

9.2.16. docker import从 tar 包中的内容创建一个新的文件系统，再导入为 Docker 镜像。
用法  docker import [OPTIONS] file|URL|- [REPOSITORY[:TAG]]OPTIONS:  -c, --change list       Apply Dockerfile instruction to the created image  -m, --message string    Set commit message for imported image      --platform string   Set platform if server is multi-platform capable

示例
# cat 文件名.tar | docker import - 镜像用户/镜像名:镜像版本号    [root@redis_181 ~]# cat hello.tar | docker import - john/hello:5.0    sha256:ed584048180e082610c982dc8f56ccf9618872f80d5848d0e8c840dfd46c13bc    [root@redis_181 ~]# docker images    REPOSITORY           TAG       IMAGE ID       CREATED          SIZE    john/hello           5.0       ed584048180e   12 seconds ago   13.3kB    wurstmeister/kafka   latest    2dd91ce2efe1   2 weeks ago      508MB  # 从远程位置导入   docker import https://example.com/exampleimage.tgz # 从本地文件中导入   docker import /path/to/exampleimage.tgz

9.3. Image Command9.3.1. docker  images列出本地主机上已下载的所有 Docker 镜像
用法    docker images [OPTIONS] [REPOSITORY[:TAG]]OPTIONS:  -a, --all   显示所有的镜像，包括默认隐藏的中间镜像（历史镜像）  -q, --quiet 只显示镜像 ID


示例
[root@redis_181 ~]# docker imagesREPOSITORY           TAG       IMAGE ID       CREATED        SIZEwurstmeister/kafka   latest    2dd91ce2efe1   2 weeks ago    508MBzookeeper            latest    36c607e7b14d   3 weeks ago    278MBhello-world          latest    feb5d9fea6a5   3 months ago   13.3kB

显示结果说明
REPOSITORY：镜像的仓库源TAG：镜像的标签版本号IMAGE ID：镜像 IDCREATED：镜像创建时间SIZE：镜像大小

同一个仓库源可以有多个 TAG 版本，说明仓库源有不同的版本，用 REPOSITORY:TAG 来表示不同的镜像。比如 redis:6.0.8 表示从仓库源获取的是 redis 版本为6.0.8 ，在这个 Docker engine 中还可以拉取 redis 版本为 5.0 的仓库源，用 redis:5.0 表示，二者可以同时共存。若在拉取镜像时不指定镜像的标签版本，Docker 将默认使用 TAG 为 latest 的版本（最新版本）。
9.3.2. docker  search从仓库源中搜索某个镜像
用法    docker search [OPTIONS] TERMOPTIONS：  -f, --filter filter   Filter output based on conditions provided      --format string   Pretty-print search using a Go template      --limit int       Max number of search results (default 25)      --no-trunc        Don&#x27;t truncate output


显示结果说明
[root@redis_181 ~]# docker search redisNAME                             DESCRIPTION                                     STARS     OFFICIAL   AUTOMATEDredis                            Redis is an open source key-value store that…   10443     [OK]grokzen/redis-cluster            Redis cluster 3.0, 3.2, 4.0, 5.0, 6.0, 6.2      83sameersbn/redis                                                                  83                   [OK]rediscommander/redis-commander   Alpine image for redis-commander - Redis man…   73                   [OK]redislabs/redisearch             Redis With the RedisSearch module pre-loaded…   47redislabs/rejson                 RedisJSON - Enhanced JSON data type processi…   39redislabs/redisinsight           RedisInsight - The GUI for Redis                35redislabs/redis                  Clustered in-memory database engine compatib…   32oliver006/redis_exporter          Prometheus Exporter for Redis Metrics. Supp…   31arm32v7/redis                    Redis is an open source key-value store that…   24arm64v8/redis                    Redis is an open source key-value store that…   19redislabs/rebloom                A probablistic datatypes module for Redis       18                   [OK]redislabs/redisgraph             A graph database module for Redis               17                   [OK]redislabs/redismod               An automated build of redismod - latest Redi…   17                   [OK]webhippie/redis                  Docker image for redis                          11                   [OK]insready/redis-stat              Docker image for the real-time Redis monitor…   10                   [OK]s7anley/redis-sentinel-docker    Redis Sentinel                                  10                   [OK]redislabs/redistimeseries        A time series database module for Redis         10goodsmileduck/redis-cli          redis-cli on alpine                             9                    [OK]centos/redis-32-centos7          Redis in-memory data structure store, used a…   6clearlinux/redis                 Redis key-value data structure server with t…   3wodby/redis                      Redis container image with orchestration        1                    [OK]tiredofit/redis                  Redis Server w/ Zabbix monitoring and S6 Ove…   1                    [OK]xetamus/redis-resource           forked redis-resource                           0                    [OK]flant/redis-sentinel-proxy       Redis sentinel proxy by enriclluelles writte…   0                    [OK]


NAME：镜像名称
DESCRIPTION：镜像说明
STARS：点赞数量
OFFICIAL：是否是官方的
AUTOMATED：是否是自动构建的

9.3.3. docker pull从仓库源中拉取指定的镜像或仓库
用法    docker pull [OPTIONS] NAME[:TAG|@DIGEST]OPTIONS:  -a, --all-tags                Download all tagged images in the repository      --disable-content-trust   Skip image verification (default true)      --platform string         Set platform if server is multi-platform capable  -q, --quiet                   Suppress verbose output

示例
从 docker 仓库中拉取 redis 镜像，拉取时不指定版本，Docker 引擎默认从仓库源拉取最新的版本[root@redis_181 ~]# docker pull redis拉取时指定版本 TAG[root@redis_181 ~]# docker pull redis:6.0.8

9.3.4. docker rmi删除指定的镜像（rmi: Remove one or more images）
用法    docker rmi [OPTIONS] IMAGE [IMAGE...]OPTIONS:  -f, --force      Force removal of the image      --no-prune   Do not delete untagged parents

示例：

删除单个镜像
[root@redis_181 ~]# docker rmi -f hello-worldUntagged: hello-world:latestUntagged: hello-world@sha256:975f4b14f326b05db86e16de00144f9c12257553bba9484fed41f9b6f2257800Deleted: sha256:feb5d9fea6a5e9606aa995e879d862b825965ba48de054caab5ef356dc6b3412

删除多个镜像
[root@redis_181 ~]# docker rmi -f redis:6.0.8 rdis:5.0

# 使用脚本：删除以myapp开头的所有镜像#!/bin/bashfor image in $(docker images | grep &#x27;^myapp&#x27; | awk &#x27;&#123;print $3&#125;&#x27;); do    docker rmi -f $imagedone


用参数续传来删除，将查找到的 Ubuntu 镜像 ID 传入要删除的表达式后面[root@redis_181 ~]# docker rmi -f $(docker images -q ubuntu)Untagged: ubuntu:latestUntagged: ubuntu@sha256:b5a61709a9a44284d88fb12e5c48db0409cfad5b69d4ff8224077c57302df9cfDeleted: sha256:d13c942271d66cb0954c3ba93e143cd253421fe0772b8bed32c4c0077a546d4dDeleted: sha256:0eba131dffd015134cb310c284b776c1e44d330146cd2f0e30c4e464d0b76d24

9.3.5. docker system df查看镜像、容器、数据卷所占用的空间大小
[root@redis_181 ~]# docker system dfTYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLEImages          3         3         785.9MB   0B (0%)Containers      5         0         344B      344B (100%)Local Volumes   5         5         2B        0B (0%)Build Cache     0         0         0B        0B可选项	# 清理磁盘，删除关闭的容器、无用的数据卷和网络，以及无tag的镜像	docker system prune		# 清理掉所有的 Docker 镜像，包括你暂时关闭的容器，以及暂时没有使用的 docker 镜像	docker system prune -a

显示结果说明

TYPE：类型
TOTAL：总数
ACTIVE：激活状态
SIZE：大小
RECLAIMABLE：可回收

9.3.6. docker save保存一个或多个镜像到 tar 包中，默认是通过标准输出流。 
用法  docker save [OPTIONS] IMAGE [IMAGE...]OPTIONS:  -o, --output string   Write to a file, instead of STDOUT

9.3.7. docker load从一个 tar 包或标准输入中导入 Docker 镜像。
用法  docker load [OPTIONS]OPTIONS:  -i, --input string   Read from tar archive file, instead of STDIN  -q, --quiet          Suppress the load output

示例
docker image ls# 两种方式都是等效的docker load --input fedora.tardocker load &lt; busybox.tar.gzdocker images

9.3.8. docker build从一个 Dockerfile 中构建一个 Docker 镜像。
用法docker build [OPTIONS] PATH | URL | -

10. Docker 下安装软件Docker下安装软件的步骤

搜索镜像。去docker 官网去搜索镜像。
拉取镜像
查看镜像
启动镜像：注意端口映射。
停止容器
移除容器

11. Docker Volume11.1. Volume 是什么？卷就是目录或文件，存在于一个或多个容器中，由 docker 挂载到容器，但不属于联合文件系统，因此能绕过联合文件系统（Union File System）提供一些用于持续存储或共享数据的特性。
卷的设计目的：就是数据的持久化，完全独立于容器的生存周期，因此 docker 不会在容器删除时删除其挂载的数据卷。
命令用法
docker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录    镜像名// 实例docker run -it --privileged=true -v /home/docker_data:/data  --name redis-7 redis /bin/bash// 默认情况下，容器内的目录具有读写权限：rW// 限制容器内的权限，具有只读属性 rodocker run -it --privileged=true -v /宿主机绝对路径目录:/容器内目录:ro    镜像名

11.2. Volume 能干吗？将运行的环境打包镜像，run 后形成容器实例运行。若 Docker 容器产生的数据不进行备份，那么当容器的实例删除后，容器内的数据也就没有了，为了能保存数据在 docker 中，因此使用卷（volume）。
数据卷的特点

可在容器之间共享或重用数据。
卷中的更改可以直接实时生效。
数据卷的生命周期一直持续到没有容器使用它为止。
数据卷中的更改不会包含在镜像的更新中。

12. Dockerfile镜像构建的方式有两种，一种是通过 docker build 执行 Dockerfile 里的指令来构建镜像，另一种是通过 docker commit 将存在的容器打包成镜像，通常我们都是使用第一种方式来构建容器镜像。
12.0.1. 构建的基本原则
镜像层数尽可能少
使用多阶段构造。 所谓多阶段构建，实际上是允许在一个 Dockerfile 中出现多个 FROM 指令。最后生成的镜像，以最后一条 FROM 构建阶段为准，之前的 FROM 构建阶段会被抛弃。通过多阶段构建， 后一个阶段的构建过程可以直接利用前一阶段的构建缓存，有效降低镜像大小。一个典型的场景是将编译环境和运行环境分离。
使用最小的基础镜像
避免不必要的安装包
一个容器只运行一个进程
构建缓存

12.0.2. BuildkitBuildkit是改进后的后端，用于替代传统的Docker构建器。自2018年起，它已经与Docker捆绑在一起，并成为Docker引擎23.0版本的默认构建器。
它提供了一些特殊的功能：

改进的缓存能力；
并行构建不同的层；
延迟拉取基础镜像（≥Buildkit 0.9）；

使用Buildkit时，会发现docker build命令的输出看起来更清晰、更结构化。
在Docker版本低于23.0时，使用Buildkit的一种典型方法是设置Buildkit参数如下：
DOCKER_BUILDKIT=1 docker build --platform linux/amd64 . -t someImage:someVersionDOCKER_BUILDKIT=1 docker push someImage:someVersion

12.0.3. BuildxBuildx是Docker的一个插件，能够充分利用Docker中的Buildkit的潜力。它的创建是因为Buildkit支持许多新的配置选项，不能全部以向后兼容的方式集成到docker build命令中。
12.1. Dockerfile 是什么？Dockerfile 是用来构建 Docker 镜像的文本文件，是一条条构建镜像所需的指令和参数构成的脚本。
关键字字母必须大写，后面必须有一个空格，以及至少一个参数。每条指令都会创建一个新的镜像层，并对镜像层进行提交。
12.2. docker commit基于原有镜像的改变，创建一个新的镜像（image）。
用法
docker commit -m &quot;提交的描述信息&quot; -a=&quot;作者&quot; 容器ID 目标镜像名:[标签名]Usage:  docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Create a new image from a container&#x27;s changesOptions:  -a, --author string    Author (e.g., &quot;John Hannibal Smith &lt;hannibal@a-team.com&gt;&quot;)  -c, --change list      Apply Dockerfile instruction to the created image  -m, --message string   Commit message  -p, --pause            Pause container during commit (default true)

12.3. Dockerfile builderDockerfile 是一个文本文件，其内包含了一条条的 **指令(Instruction)**，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。
注意：

Docker 镜像构建使，确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。可以添加一组命令做清理的工作，删除为了编译构建所需要的软件。
在构建镜像时，RUN, ADD, COPY 指令对应的层会增加镜像大小，其他命令并不会增加最终的镜像大小。

# 清除构建缓存 build cachedocker builder prune -a -f

从 Docker 17.05 版本起， Docker 才开始支持容器镜像的多阶段构建(multi-stage build)，所以使用 docker 版本必须高于 17.05 （多阶段构建的意思就是把编译的过程也放同一个 Dockerfile 里，不用在自己的开发机或服务器上编译，再把编译出的二进制程序打入镜像）。
语法说明
FROM：指定需要使用的基础镜像；MAINTAINER：定义脚本维护者；VOLUME：指定持久化文件目录；WORKDIR：切换到工作目录；ADD：将宿主机中的文件拷贝至 image 中，且会自动处理 URL 和解压 tar 压缩包。COPY：将文件和目录拷贝至 image 中。RUN：镜像构建时执行的命令；ENTRYPOINT：容器参数配置；


例子：传统方式构建
# Go语言编译环境基础镜像FROM golang:1.16-alpine# 拷贝源码到镜像COPY server.go /build/# 指定工作目录WORKDIR /build# 编译镜像时，运行 go build 编译生成 server 程序RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GOARM=6 go build -ldflags ‘-w -s’ -o server# 指定容器运行时入口程序ENTRYPOINT [“/build/server”]

多级构建
## 1 编译构建阶段#  Go语言编译环境基础镜像FROM golang:1.16-alpine AS build# 拷贝源码到镜像COPY server.go /build/# 指定工作目录WORKDIR /build# 编译镜像时，运行 go build 编译生成 server 程序RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 GOARM=6 go build -ldflags ‘-w -s’ -o server## 2 运行构建阶段#  采用更小的运行时基础镜像FROM scratch# 从编译阶段仅拷贝所需的编译结果到当前镜像中COPY —from=build /build/server /build/server# 指定容器运行时入口程序ENTRYPOINT [“/build/server”]


12.3.1. RUNRUN  # 用来执行命令的，运行一个 RUN 就表示构建一层镜像的层数

12.3.2. COPY12.3.3. ENV设置环境变量
格式
ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;...



12.3.4. EXPOSE// 格式EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]

在 Dockerfile 中写入这样的声明有两个好处:

一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；
另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。

要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，
EXPOSE 指令是声明容器运行时提供服务的端口，这只是一个声明，仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。
12.3.5. WORKDIR# 格式WORKDIR 工作目录路径

使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。
不同层之间的执行环境是不一样的，是两个完全不同的容器。WORKDIR 的作用有效范围在当前层中，即下一个 RUN 执行之前。 
12.3.6. USER格式：USER &lt;用户名&gt;[:&lt;用户组&gt;]
USER 指令和 WORKDIR 相似，都是改变环境状态并影响以后的层。WORKDIR 是改变工作目录，USER 则是改变之后层的执行 RUN, CMD 以及 ENTRYPOINT 这类命令的身份。
注意，USER 只是帮助你切换到指定用户而已，这个用户必须是事先建立好的，否则无法切换。
RUN groupadd -r redis &amp;&amp; useradd -r -g redis redisUSER redisRUN [ &quot;redis-server&quot; ]

如果以 root 执行的脚本，在执行期间希望改变身份，比如希望以某个已经建立好的用户来运行某个服务进程，不要使用 su 或者 sudo，这些都需要比较麻烦的配置，而且在 TTY 缺失的环境下经常出错。建议使用 gosu。
# 建立 redis 用户，并使用 gosu 换另一个用户执行命令RUN groupadd -r redis &amp;&amp; useradd -r -g redis redis# 下载 gosuRUN wget -O /usr/local/bin/gosu &quot;https://github.com/tianon/gosu/releases/download/1.12/gosu-amd64&quot; \ &amp;&amp; chmod +x /usr/local/bin/gosu \ &amp;&amp; gosu nobody true# 设置 CMD，并以另外的用户执行CMD [ &quot;exec&quot;, &quot;gosu&quot;, &quot;redis&quot;, &quot;redis-server&quot; ]



12.4. 问题12.4.1. 优化的基本原则
变动越小的命令，越靠前，增加 cache 使用率。
合并目的相同的命令，减少构建层(layer)数。
使用国内源，或者内网服务加速构建。
少装些东西，不是代码依赖的就尽量别装。
记得加上合适的注释，以便日后的维护。

12.4.2. 镜像构建很慢在dockerfile里面加上这个，或者全局挂代理，直接外网build就可以了。
RUN sed -i &quot;s/archive.ubuntu./mirrors.aliyun./g&quot; /etc/apt/sources.listRUN sed -i &quot;s/deb.debian.org/mirrors.aliyun.com/g&quot; /etc/apt/sources.listRUN sed -i &quot;s/security.debian.org/mirrors.aliyun.com\/debian-security/g&quot; /etc/apt/sources.list



12.4.3. 镜像瘦身镜像构建后，发现构建的体积很大，需要减小体积。

用 distroless 去除容器中所有不必要的东西。

distroless镜像只包含应用程序及其运行时依赖项，不包含程序包管理器、shell 以及标准 Linux 发行版中可以找到的任何其他程序都没有，是原始操作系统的精简版，没有额外的二进制文件。

在生产环境中运行容器，并且关心性能问题，使用 distroless 更合适。

用小体积的的 Alpine 基础镜像。

Alpine 是一个基于 musl libc 和 busybox 的面向安全的轻量级 Linux 发行版。

注意点：

基于 Alpine 基础镜像构建容器可能会导致非预期的行为，因为标准 C 库是不一样的。



13. Docker network[root@redis_181 ~]# docker network create --driver bridge --subnet=172.18.0.0/16 --gateway=172.18.0.1 zk_network7de8536fcab27bd0318f783fbe4c2ce5f72123fbe646f559eaf80e742bde63c5[root@redis_181 ~]#[root@redis_181 ~]# docker network lsNETWORK ID     NAME         DRIVER    SCOPE2914ee1d3e2a   bridge       bridge    local9a2d889dab32   host         host      localc6cc0e89cb3c   none         null      local7de8536fcab2   zk_network   bridge    local



13.1. bridgeDcoker 服务默认会创建一个 docker0 网桥（其上有一个docker0内部接口），该桥接网络的名称为 docker0，它在内核层连通了其它的物理或虚拟网卡，这就将所有的容器和本地主机都放到同一个物理网络。Docker 默认制定了 docker0 接口的 IP 地址和子网掩码，让主机和 container 之间可以通过网桥互相通信。 
13.2. Hostcontainer 将不会获得一个独立的 Network namespace ，而是和宿主机公用一个 Network namespace。container 将不会虚拟自己的网卡而是使用宿主机的IP和端口。
14. 面试问题
解释 Docker 的虚悬镜像是什么？
 仓库命、标签命都是 none 的镜像，俗称为虚悬镜像(dangling image)。


15. FAQ15.1. Docker 空间占用清理参考：https://blog.csdn.net/longailk/article/details/122728982
Docker下&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2空间清理办法

docker的overlay2中存的都是什么？存的是我们的镜像文件和容器内的文件

如何清理 /var/lib/docker/overlay2？

删除不用的镜像
检查是否有容器内的服务会往容器内的本地写文件
检查各容器的磁盘占用，如果有发现磁盘占用过高的情况则对应处理【原则上如果容器内服务有写文件行为，则写文件的目录应当挂载到宿主机上，而不是直接往容器的本地写
需要应急处理的话可以先进入容器内直接删除容器内可以删除的文件



16. References
Docker 官网：https://docs.docker.com/
Dockerhub，安装 Docker 镜像文件的仓库：https://hub.docker.com/
docker docs strtage: https://docs.docker.com/storage/storagedriver
Docker搭建Zookeeper&amp;Kafka集群
THE CONTAINER NETWORKING LANDSCAPE: CNI FROM COREOS AND CNM FROM DOCKER 一篇英文文章，讲解 docker 和 container ecosystem。
Microsoft introduce docker-defined: https://docs.microsoft.com/zh-cn/dotnet/architecture/microservices/container-docker-introduction/docker-defined
Github 英文讲解 CNI - the Container Network Interface
Docker 社区版源码：https://github.com/moby/moby
Docker在Windows的使用说明: http://www.520code.net/index.php/archives/39
Docker Containers and Kubernetes: An Architectural Perspective
Docker 总体架构
Docker and Kubernetes Security: Principles &amp; Practices 深入讲解了 Docker 的底层原理。
Dockerfile 定制镜像：https://yeasy.gitbook.io/docker_practice/image/build
Dockers镜像瘦身：https://docs.erda.cloud/blog/post/2021/07/15/docker-compression/
如何优化 docker 镜像体积：https://waynerv.com/posts/how-to-reduce-docker-image-size/
构建 Go 应用 docker 镜像的十八种姿势：https://www.cnblogs.com/kevinwan/p/16033634.html
容器技术原理(一)：从根本上认识容器镜像：https://waynerv.com/posts/container-fundamentals-learn-container-with-oci-spec

]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins</title>
    <url>/Jenkins/CloudNative/Jenkins/Jenkins/</url>
    <content><![CDATA[


JenkinsJenkins是一款开源 CI&amp;CD 软件，用于自动化各种任务，包括构建、测试和部署软件。

CI&#x2F;CD持续集成、自动部署流程

开发人员将代码push到gitlab中，触发jenkins的自动pull拉取代码，通过maven编译、打包，然后通过执行shell脚本使docker构建镜像并push到私服（或者阿里云）仓库，此操作完成后jenkins服务器上再执行SSH命令登录到部署服务器，docker从仓库（私服）拉取镜像，启动容器。整个操作流程完成。
References
【Linux】Docker 搭建 Jenkins: https://open.alipay.com/portal/forum/post/125401045
https://www.cnblogs.com/kevinwan/p/16007379.html
微服务从代码到k8s部署应有尽有大结局(k8s部署)：https://www.cnblogs.com/kevinwan/p/16007379.html

]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka</title>
    <url>/Kafka/CloudNative/Kafka/Kafka/</url>
    <content><![CDATA[

1. 思考● 了解发布和订阅消息模型以及该模型如何被应用在大数据生态系统中
● 学习使用Kafka生产者和消费者来生成消息和读取消息
● 了解Kafka保证可靠性数据传递的模式和场景需求
● 使用Kafka构建数据管道和应用程序的最佳实践
● 在生产环境中管理Kafka，包括监控、调优和维护
● 了解Kafka的关键度量指标
● 探索Kafka如何成为流式处理利器

2. 优缺点
使用文件系统，大量依赖操作系统中的 page cache，而非应用内 cache，这样可以内存充分利用，而且更加稳定（防止 GC）因为是 OS 维护 page cache，所以故障之后容易恢复，不用重建OS 会比较激进的把内存用作 page cache。
因为访问模式固定，使用 Persistent Queue 作为数据结构
使用 zero-copy optimization，不用频繁的跟 user space 交互因为大部分在操作在内存中进行，而且使用了 zero-copy，所以性能瓶颈可能只会出现下网络上
选用 pull 模型，从而避免了 push 模型中 push 速度与消费速度不一致，导致 consumer 压力过大的问题
采用了 ISR（ in-sync replicas ） 来保证备份中数据是一致的，ISR 的集合维护在 ZooKeeper 中（0.9版本之前，而0.9版本之后数据（offset）存储在kafka本地）。 
没有采用一般的多数票选举的方法。
因为为了性能没有使用 fsync，所以可能导致数据不能完整恢复
提供大量的可配置空间，方便使用者在 Consistency 与 Availability 中选择

3. Kafka 是什么？Kafka是由Apache软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。
Kafka 有点像消息系统，允许发布和订阅消息流。从这点来看，它类似于 ActiveMQ 、RabbitMQ 或 IBM 的 MQSeries 等产品。尽管看上去有些相似，但 Kafka 与这些传统的消息系统仍然存在很多重要的不同点，这些差异使它完全不同于消息系统。有三个不同的点：第一，作为一个现代的分布式系统， Kafka 以集群（cluster）的方式运行，可以自由伸缩，处理公司的所有应用程序。 Kafka 集群并不是一组独立运行的 broker，而是一个可以灵活伸缩的中心平台，可以处理整个公司所有的数据流。第二， Kafka 是一个真正的存储系统，可以存储数据，只要您愿意，保存多久都可以 。作为数据连接层（connecting layer）， Kafka 提供了数据传递保证可复制（replicated）、持久化（persistent），保留多长时间完全可以由你来决定。第三，流式处理将数据处理的层次提升到了新高度 。 消息系统（Messaging systems）只会传递消息，而 Kafka 的流式处理能力让你只用很少的代码就能够动态地处理派生流和数据集。Kafka 的这些独到之处足以让你刮目相看，它不只是“另一个消息队列” 。  
另外一种角度看 Kafka：认为它是一种实时版的（real-time） Hadoop，这也是设计和构建 Kafka 的原始动机之一。Hadoop 让你存储和定期处理大量的数据文件，而 Kafka 让你存储和持续处理大规模的数据流。从技术角度来看，它们有着惊人的相似之处，很多人将新兴的流式处理看成批处理（batch processing）的超集。它们之间的最大不同体现在：持续的低延迟处理（low-latency processing）和批处理之间的差异上。Hadoop 和大数据主要应用在数据分析上，而 Kafka 因其低延迟的特点更适合用在核心的业务应用（core applications）上。业务事时刻在发生，Kafka 能够及时对这些事件作出响应，基于Kafka 构建的服务直接为业务运营提供支撑，提升用户体验。  
Kafka 是一个分布式的基于发布-订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。
4. 诞生的目的开始是 Linkedin 内部建立的一个基础设施系统，虽然有很多数据库和系统可以用来存储数据，但是他们发现在他们当前的架构中缺少一种东西来帮助处理连续不断的数据流（handle the continuous flow of data）。在开发 Kafka 之前，他们实验了各种现成的解决方案，从消息系统（messaging systems ）到日志聚合系统（log aggregation），再到 ETL 工具，但这些都无法满足他们的需求。 
因此，他们想从零开始开发一个系统。他们的想法是替换掉专注于大量处理的数据，像关系型数据库（relational databases ）、键值对存储（key-value stores）、索引搜索（search indexes）或缓存（caches），而是专注于处理数据的持续变化和不断增长的流，基于这样的想法去构建一个数据系统，事实上，是一个数据架构（data architecture ）。
这个想法实现后比他们最初期望适用性更广泛。尽管 Kafka 一开始被用在社交网络的实时应用和数据流当中，而现在已经成为下一代数据架构的基础。大型零售商正在基于持续数据流改造他们的基础业务流程，汽车公司正在从互联网汽车那里收集和处理实时数据流，银行也在重新思考基于 Kafka 改造他们的基础流程和系统。  
4.1. Kafka 在这当中充当了怎样的角色？Kafka 是一个流平台（streaming platform  ），在这个平台上 让你发布和订阅数据流，去存储它们、处理它们，这就是构建 Kafka 的初衷。  以这种方式来看待数据确实与人们习惯的想法有所不同，但它确实在构建应用和架构方面表现出了强大的抽象能力。  
Kafka 常常会被拿来与现有的技术作比较：企业级消息系统（enterprise messaging systems,）、大数据系统（如 Hadoop）和数据集成（data integration）或 ETL工具。与它们每一个比较都有一定的有效性，但也有一些不足。  
4.2. 它与现有的系统比较有什么区别？Kafka 和 ETL 工具或其他数据集等这些工具都擅长移动数据，但它们最大的不同在于 Kafka 颠覆了传统的思维 。 Kafka 并非只是把数据从一个系统拆解出来再塞进另一个系统，它其实是一个面向实时数据流的平台（a platform oriented around real-time streams of events）。也就是说，它不仅可以将现有的应用程序和数据系统连接起来，它还能用于加强这些触发相同数据流的应用。  
5. 发展历程
0.7版本：只有基础消息队列功能，无副本；

0.8版本：增加了副本机制，新的producer API；至此kafka成为一个真正意义上的分布式高可靠消息队列解决方案；

0.9版本：增加权限和认证，新的consumer API，Kafka Connect功能；

0.10版本：引入Kafka Streams功能，bug修复；

0.11版本：增加producer API幂等，事物API，消息格式重构；

1.0和2.0版本：Kafka Streams改进；



6. 消息队列好处

解耦
削峰

两种模式

点对点模式（一对一）
发布-订阅模式（一对多，消费）
消费者的消息由消费者自己来决定，消费者主动拉取数据。缺点：一直在轮询，看消息队列中是否有数据。
生产者主动 push 数据。



7. Kafka 架构7.1. Terminology
Topic（主题）：将数据分类，主题中有分区有副本。kafka 中的数据主要存储在 topic 中。

Partition（分区）：提高 topic 的负载均衡，同时也提高了并发能力。

broker（消息中心）：负责接收和处理消息的服务器。

Follower：相当于备份的作用。


注意：同一个分区（partition）中的数据（topic）只能被同一个消费组中的一个消费者（consumer）消费。
Zookeeper 作用

帮助 kafka 存储信息
存储消费者消费的位置信息。

kafka 消息存储在磁盘。
8. 工作流程Seek 直接找数据的位置
保证 partition 有序，不能保证全局有序。
定位 index 采用 二分查找，
offset + dataSzie
9. 生产者9.1. 分区策略9.2. 数据可靠性保证ISR(In-sync replica set)：同步副本；作用：leader 挂了以后去选择一个新的 leader。

保留了时间参数：0.9版本之前，超过数目参数的最大值后，频繁的要访问内存和Zookeeper，降低了效率，因此删除了。

acks 参数配置

0：
1：

ack 解决的是数据丢失和数据重复问题。
HW 解决的是消费一致性和存储一致性问题。
10. 消费者11. Docker 中使用 Kafka// 创建 topic 为 hellobash-5.1# kafka-topics.sh --create --topic hello --partitions 1 --zookeeper zk1:2181 --replication-factor 1Created topic hello.// 获取 topic 列表bash-5.1# kafka-topics.sh --list --zookeeper zk1:2181hello// 生产者产生消息bash-5.1# kafka-console-producer.sh --topic hello --broker-list kafka1:9092,kafka2:9092&gt;nihao&gt;my &gt;I&#x27;m you&gt;// 消费者消费消息bash-5.1# kafka-console-consumer.sh --topic hello --bootstrap-server kafka1:9092,kafka2:9092nihaomyI&#x27;m you



12. References
Kafka 官网：https://kafka.apache.org/
《Kafka: The Definitive Guide: Real-Time Data and Stream Processing at Scale》
《Kafka 权威指南》
The Apache Kafka C&#x2F;C++ client library API
51CTO 天山老妖S-kafka系列
kafka详细教程
Kafka 入门知识

]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Internals</title>
    <url>/Kubernetes/CloudNative/Kubernetes/Internals/</url>
    <content><![CDATA[

源码分析References
云计算K8s系列—- K8s controller：https://kingjcy.github.io/post/cloud/paas/base/kubernetes/k8s-controller

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>kubernetes</tag>
        <tag>internals</tag>
      </tags>
  </entry>
  <entry>
    <title>etcd</title>
    <url>/Kubernetes/CloudNative/Kubernetes/etcd/</url>
    <content><![CDATA[
Introduceetcd 组成

HTTP Server
Raft 
WAL 
Entry
Snapshot
Store

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>kubernetes</tag>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>kubernetes</title>
    <url>/Kubernetes/CloudNative/Kubernetes/kubernetes/</url>
    <content><![CDATA[

1. IntroduceKubernetes 最初是由Google内部项目 Borg 演化而来的，刚开始研发的时候仅仅只有 3 个人，后来得到 Google 高层的批准，将项目开源，吸引跟多的人参与进来。
2. Thinking国外的工程师的创造力是非常、非常的强，产生的想发都是源自于解决当前生产所面临的问题。他们产生了一个不错的想法，有平台和技术做支撑，能快速的去实现，并推广给大众，让全世界的人都能去用。（2022&#x2F;4&#x2F;8 9:30 Kubernetes 纪录片思考）
3. kubernets cluster architectureKubernetes cluster 由一个 control plane 和一组运行容器化应用程序(applications)的工作机器（称为 nodes）组成。每个 cluster 至少需要一个 worker node 才能运行 Pod。
worker nodes 托管作为应用程序工作负载组件的 Pod。 control plane 管理集群中的 worker node 和 Pod。在生产环境中， control plane 通常跨多台计算机运行，一个集群通常运行多个 nodes，从而提供容错和高可用性。

Kubernets 管理 docker 流程

3.1. Control plane componentscontrol plane 的组件对集群做出全局决策（例如，调度），以及检测和响应集群事件（例如，当 Deployment 的 replicas 字段不满足时启动新的 pod）。
Control plane 组件可以在集群中的任何计算机上运行。但是，为简单起见，设置脚本通常在同一台机器上启动所有 control plane 组件，并且不会在此机器上运行用户容器。有关跨多台计算机运行的控制平面设置示例。

API Server:
集群统一入口，以 Restful 方式交给 etcd 存储，暴露 Kubernetes HTTP API 的核心组件服务器。

Scheduler
查找尚未绑定到节点的 Pod，并将每个 Pod 分配给合适的节点。

etcd
为所有 API 服务器数据提供一致且高度可用的 key value store。

Controller
运行 controller 以实现 Kubernetes API 行为。


Controller

确保预期的 Pod副本数量
确保所有的 node 运行同一个 Pod
可部署一次性任务和定时任务
可部署 stateless, stateful

controller types

Node controller: 负责在节点宕机时进行通知和响应。
Job controller: 监视代表一次性任务的 Job objects，然后创建 Pod 来运行这些任务直到完成。
EndpointSlice controller: 填充 EndpointSlice 对象（以提供 Service 和 Pod 之间的链接）。
ServiceAccount controller: 为新命名空间创建默认 ServiceAccount。

3.2. Node componentsNode 组件在每个节点上运行，维护正在运行的 Pods 并提供 Kubernetes runtime environment。

kubelet
在 cluster 中的每个 node 上运行的代理(agent)，它确保 containers 在 Pod 中运行。kubelet 采用一组通过各种机制提供的 PodSpec，并确保这些 PodSpec 中描述的 containers 正在运行且健康(running and healthy)。kubelet 不管理不是由 Kubernetes 创建的(create)container。

kube-proxy(optional)
kube-proxy 是一个网络代理，它在集群中的每个 node 上运行，实现了 Kubernetes Service 概念的一部分。
kube-proxy 维护节点上的网络规则。这些网络规则(network rules )允许从集群内部或外部的网络 session 到 Pod 进行网络通信。
kube-proxy 使用 operating system packet filtering layer，如果有并且可用 。否则，kube-proxy 会转发流量本身(forwards the traffic itself)。
如果你使用一个网络插件，它自己实现 Service 的数据包转发(packet forwarding )，并提供与 kube-proxy 等效的行为，那么你不需要在集群中的 node 上运行 kube-proxy。

Container runtime
Container runtime 是 Kubernetes 能够高效的运行容器的一个基本组件。它负责管理 Kubernetes 环境中 container 的执行和生命周期(execution and lifecycle)。
Kubernetes 支持的容器运行时有： containerd、CRI-O 以及其它实现了 Kubernetes CRI（Container Runtime Interface）的组件。


4. Workloads4.1. Pod
最小的 Deployment 单元。
一组 container 的集合。
同一个 Pod 内部共享网络命名空间(namespace)、共享同一个 Linux 协议栈。
短暂的生命周期，重启后资源被销毁。

4.2. Workload Management4.2.1. DeploymentDeployment 是一个比 ReplicaSet 更广的 API 对象，可以create、update、rolling-update一个新的服务。
4.2.2. ReplicaSetReplicaSet 是可以独立使用的，但还是建议使用 Deployment 来自动管理ReplicaSet，这样就无需担心跟其他机制不兼容的问题（比如：ReplicaSet 不支持 rolling-update，但Deployment 支持）。
注：ReplicaSet 和 Deployment 是为无状态服务而设计的。
4.2.3. ReplicationController新版 k8s 中建议用 ReplicaSet 来取代 ReplicationController。跟 ReplicaSet 没有本质的区别，只是名字不一样。
4.2.4. StatefulSetStatefulSe 用来解决有状态服务的问题。StatefulSet 中的每个 Pod 的名字都是事先确定的，不能更改。
适用场景： 

稳定的持久化存储。Pod 重新调度后还是能访问到相同的持久化数据，基于PVC 实现。
稳定的网络标志。Pod 重新调度后 PodName 和 HostName 不变，基于 Headless service 来实现。
有序存储，有序扩展。Pod 是有顺序的，在部署或者扩展的时候要依据定义的顺序依次执行，基于 Init containers 来实现。
有序收缩，有序删除。

4.2.5. DaemonSetDaemonSet 确保全部或者一些 Node 上运行有且只有一个 Pod 的副本。当有 Node 加入 Cluster 时，会为他们新增一个 Pod ，当有 Node 从 Cluster 移除时，这些 Pod 会被回收，删除 DaemonSet 将删除它创建的所有 Pod。
使用场景：

运行集群存储 daemon。例如：在每个 Node 上运行 glusterd
在每个 Node 上运行日志收集 daemon。例如：logstash，fluentd
在每个 Node 上运行监控 daemon。例如：Prometheus Node exporter

4.2.6. JobJob 负责批处理任务。即执行一次的任务，它保证批处理任务的一个或多个 Pod 成功结束。
4.2.7. Cron JobCron Job 是基于时间的 Job。即在给定的时间点只运行一次，周期性的在给定时间点运行。
5. Service
service：定义一组 Pod 访问的规则。


每个 Service 对应一个集群内有效的虚拟 IP，集群内部通过虚拟IP访问服务。
Replica Set、Replica Controller 和 Deployment 只是保证了支撑服务的微服务 Pod 的数量，但是没有解决如何访问这些服务的问题。

常见分类

Cluster IP: 默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟 IP。

Node Port: 在 Cluster IP 的基础上，为 service 在每台机器上绑定一个端口，这样就可以通过 NodeIP:NodePort 这样的方式来访问 service。 

LoadBalancer: 在 NodePort 的基础上，借助 cloud provider创建一个外部负载均衡器，并将请求转发到 NodeIP:NodePort
借助云服务商来实现的，云服务商需要收费。

Extern Name: 把集群外部的服务引入到集群内部来，在集群内部直接使用，没有任何代理被创建。


实现方式

userspace
iptables
ipvs

SVC(service) 机制
5.0.1. Headless ServiceKubernetes 的 Headless Service 是一种特殊类型的服务，它允许直接访问 Pod 而不需要通过 Service 进行负载均衡。即没有 Cluster IP 的 service。
通常情况下，Kubernetes 中的 Service 会为一组 Pod 提供一个虚拟的稳定的网络终点，通过负载均衡将请求分发给这组 Pod中的任意一个。但是有时候，我们可能需要直接访问每个 Pod，而不需要负载均衡。
Headless Service 可以通过设置 ClusterIP 为 “None” 来创建。创建 Headless Service 后，Kubernetes 将不会为该 Service 分配一个虚拟的 ClusterIP，而是为每个 Pod 分配一个 DNS 条目。这样，我们就可以通过 Pod 的 DNS 名称直接访问每个Pod，而不需要经过 Service 的负载均衡。
Headless Service 对于一些特定的使用场景非常有用，比如数据库集群或者分布式系统，因为这些系统通常需要直接访问每个Pod，并且不需要负载均衡。
使用场景

不需要负载均衡和 service IP。
用于服务发现机制的项目或者中间件，如 kafka 和 zookeeper 之间进行 leader 选举，采用的是实例之间的实例 IP 通讯。因为 ZK 集群的 Pod 之间需要相互识别后，进行选举状态才会变为就绪，使用无头服务完美的解决这个问题。
发现所有的 Pod，包括未就绪的 Pod。

5.0.2. Stateless
所控制的 Pod 的名字是随机设置的，一个 Pod 出故障了就被丢弃掉，在另一个地方重启一个新的 Pod，名字变了。名字和启动在哪儿都不重要，重要的只是 Pod 总数。
一般不挂载存储或者挂载共享存储，保存的是所有 Pod 共享的状态。

6. Networkk8s 中有 3 层网络


Node Network
是一个真是的网络。

Pod Network
是一个内部的虚拟网络。

Service Network
是一个内部的虚拟网络。


7. Storage7.1. Volume7.2. secret7.3. PV8. Schedule9. Security认证
鉴权
访问控制
原理及其流程
10. Helm集群安装包命令
11. Addons(插件)12. References
官方英文文档: https://kubernetes.io
官方中文文档: https://kubernetes.io/zh/docs/home
Making the Kubernetes Service Abstraction Scale using eBPF, [译] 利用 eBPF 支撑大规模 K8s Service (LPC, 2019)：https://linuxplumbersconf.org/event/4/contributions/458
基于 BPF&#x2F;XDP 实现 K8s Service 负载均衡 (LPC, 2020)https://linuxplumbersconf.org/event/7/contributions/674
深入理解 Kubernetes 网络模型：自己实现 Kube-Proxy 的功能: https://cloudnative.to/blog/k8s-node-proxy
Containerd 使用教程：https://icloudnative.io/posts/getting-started-with-containerd
Kubernetes 的层级命名空间介绍：https://icloudnative.io/posts/introducing-hierarchical-namespaces
Kubernetes 的设计理念：https://jimmysong.io/kubernetes-handbook/concepts/concepts.html
Kubernetes 部署教程：https://zhuanlan.zhihu.com/p/641521752
Docker Containers and Kubernetes: An Architectural Perspective: https://dzone.com/articles/docker-containers-and-kubernetes-an-architectural

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>protobuf</title>
    <url>/Probobuf/CloudNative/Probobuf/protobuf/</url>
    <content><![CDATA[


概念标识号在消息体的定义中，每个字段都必须有一个唯一的标识号，标识号是  $0- 2^{29}-1$ 范围内的一个整数。
消息类型基本类型枚举类型序列化与反序列化三种流（stream）
字节流（byte stream）
文件流（file stream）
字符串流（string stream）

protobuf 中定义服务
v2 和 v3 主要区别
删除原始值字段的字段存在逻辑
删除 required 字段
删除 optional 字段，默认就是
删除 default 字段
删除扩展特性，新增 Any 类型来替代它
删除 unknown 字段的支持
新增 JSON Mapping
新增 Map 类型的支持
修复 enum 的 unknown 类型
repeated 默认使用 packed 编码
引入了新的语言实现（C＃，JavaScript，Ruby，Objective-C）

以上是日常涉及的常见功能，如果还想详细了解可阅读 Protobuf Version 3.0.0
Protobuf 适用场景思考方向：使用这个协议会产生什么影响。

网络带宽
吞吐量
响应速度
传输效率
存储成本

处理大数据包局限
内存占用：在反序列化大型 Protobuf 数据包时，需要将整个数据包加载到内存中。这可能导致内存占用较高，因此在处理非常大的数据包时，可能需要考虑分块处理或其他优化策略。
消息大小限制：Protobuf 有一个默认的消息大小限制（默认为 64MB），超过该限制的数据包将无法正常处理。可以通过调整配置或使用流式处理来解决此问题，但需要注意潜在的影响。

推荐风格
文件(Files)

文件名使用小写下划线的命名风格，例如 lower_snake_case.proto
每行不超过 80 字符
使用 2 个空格缩进


包(Packages)

包名应该和目录结构对应，例如文件在my/package/目录下，包名应为 my.package


消息和字段(Messages &amp; Fields)

消息名使用首字母大写驼峰风格(CamelCase)，例如message StudentRequest &#123; ... &#125;
字段名使用小写下划线的风格，例如 string status_code = 1
枚举类型，枚举名使用首字母大写驼峰风格，例如 enum FooBar，枚举值使用全大写下划线隔开的风格(CAPITALS_WITH_UNDERSCORES )，例如 FOO_DEFAULT&#x3D;1


服务(Services)

RPC 服务名和方法名，均使用首字母大写驼峰风格。
例如：service FooService&#123; rpc GetSomething() &#125;




References
Google 官网教程：https://developers.google.com/protocol-buffers
Github 地址：https://github.com/protocolbuffers/protobuf
Protocol Buffers V3中文语法指南：https://www.liwenzhou.com/posts/Go/Protobuf3-language-guide-zh/
Github Google APIs: https://github.com/googleapis/googleapis/tree/master
Google APIs: https://google.aip.dev/general

思考：编译器中的类型是如何在内存中存储的，不同的类型是怎样区分的？
]]></content>
      <categories>
        <category>Probobuf</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>probobuf</tag>
        <tag>protobuf</tag>
      </tags>
  </entry>
  <entry>
    <title>RocketMQ</title>
    <url>/RocketMQ/CloudNative/RocketMQ/RocketMQ/</url>
    <content><![CDATA[Broker 每隔 30s 向 Name Server 发送心跳，Name Server 如果 120s 没有收到心跳，就会判断 Broker 宕机了。
ConsumeQueue 中的元素内容

前 8 个 bytes 记录消息在 CommitLog 中的偏移量。
中间 4 个 bytes 记录消息消息大小。
最后 8 个 bytes 记录消息中 tag 的 hashcode。

]]></content>
      <categories>
        <category>RocketMQ</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>rocketMQ</tag>
      </tags>
  </entry>
  <entry>
    <title>Install</title>
    <url>/Zookeeper/CloudNative/Zookeeper/Install/</url>
    <content><![CDATA[
zookeeper的安装部署安装zookeeper有两种运行模式：集群模式和单机模式。
下载zookeeper安装包：http://apache.fayea.com/zookeeper/
下载完成，通过 tar -zxvf 解压。
单机环境安装一般情况下，在开发测试环境，没有这么多资源的情况，而且也不需要特别好的稳定性的前提下，我们可以使用单机部署。
初次使用zookeeper，需要将conf目录下的zoo_sample.cfg文件copy一份重命名为zoo.cfg修改dataDir目录，dataDir表示日志文件存放的路径。
集群环境安装在zookeeper集群中，各个节点总共有三种角色，分别是：leader\follower\observer集群模式，采用模拟3台机器来搭建zookeeper集群。分别复制安装包到三台机器上并解压，同时copy一份zoo.cfg。

修改配置文件
server.1&#x3D;IP1:2888:3888【2888:访问zookeeper的端口，3888:重新选举leader的端口】
server.2&#x3D;IP2:2888:3888
server.3&#x3D;IP3:2888:3888
其格式为：server.A&#x3D;B:C:D
A:是一个数字，表示这个是第几号服务器
B:是这个服务器的IP地址
C:表示的是这个服务器于集群中的Leader服务器交换信息的端口
D:表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新Leader。而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于B都是一样，所以不同的Zookeeper实例通信端口号不能一样，所以要给他们分配不同的端口号。
在集群模式下，集群中每台机器都需要感知到整个集群是由哪几台机器组成的，在配置文件中，按照格式server.id&#x3D;host:prot:port，每一行代表一个机器配置。id：指的是server ID，用来标识机器在集群中的机器序号。

新建dataDir目录，设置myid
在每台zookeeper机器上，都需要在数据目录（dataDir）下创建一个myid文件，该文件只有一行内容，对应每台机器的ServerID数字。比如：server.1的myid文件内容就是1.【必须确保每个服务器的myid文件中的数字不同，并且和自己所在机器的zoo.cfg中server.id的id值一致，id的范围是1-255】

启动zookeeper。


Docker Compose 部署参考在https://hub.docker.com中搜索zookeeper在镜像介绍中又使用docker镜像安装单机和集群环境的详细说明。
docker机器上新建文件：stack.yml，将项目内容复制到yml文件中。
services:  zoo1:    image: zookeeper    restart: always    hostname: zoo1    ports:      - 2181:2181    environment:      ZOO_MY_ID: 1      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181  zoo2:    image: zookeeper    restart: always    hostname: zoo2    ports:      - 2182:2181    environment:      ZOO_MY_ID: 2      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181  zoo3:    image: zookeeper    restart: always    hostname: zoo3    ports:      - 2183:2181    environment:      ZOO_MY_ID: 3      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181

然后使用命令 docker-compose -f stack.yml up
如果没有安装docker-compose 参考docker的官方文档：https://docs.docker.com/compose/install/
等待启动完成后使用：.&#x2F;zkCli.sh -server 宿主机IP:2181 即可登录。
常用命令启动ZK服务: 
bin&#x2F;zkServer.sh start 
查看 ZK 服务状态: 
bin&#x2F;zkServer.sh status 
停止 ZK 服务: 
bin&#x2F;zkServer.sh stop 
重启 ZK 服务: 
bin&#x2F;zkServer.sh restart 
连接服务器 
zkCli.sh -timeout 0 -r -server ip:port 
单机安装创建目录
mkdir -p /usr/local/soft/zookeepercd /usr/local/soft/zookeeper

下载解压
wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.9/zookeeper-3.4.9.tar.gztar -zxvf zookeeper-3.4.9.tar.gzcd zookeeper-3.4.9mkdir datamkdir logs

修改配置文件
cd confcp zoo_sample.cfg zoo.cfg

修改zoo.cfg
# 数据文件夹dataDir=/usr/local/services/zookeeper/zookeeper-3.4.9/data# 日志文件夹dataLogDir=/usr/local/services/zookeeper/zookeeper-3.4.9/logs

配置环境变量
vim /etc/profile

在尾部追加
# zk envexport ZOOKEEPER_HOME=/usr/local/soft/zookeeper/zookeeper-3.4.9/export PATH=$ZOOKEEPER_HOME/bin:$PATHexport PATH

编译生效
source /etc/profile

启动ZK
cd ../binzkServer.sh start

查看状态
zkServer.sh status]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>install</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper</title>
    <url>/Zookeeper/CloudNative/Zookeeper/Zookeeper/</url>
    <content><![CDATA[
1. 概念ZooKeeper 是一个分布式的，开放源码的分布式应用程序协同服务。ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。
Zookeeper&#x3D;文件系统+监控通知机制
2. ZooKeeper 应用场景很多分布式协调服务都可以用 ZooKeeper 来做，其中典型应用场景如下：

配置管理（configuration management）：如果我们做普通的 Java 应用，一般配置项就是一个本地的配置文件，如果是微服务系统，各个独立服务都要使用集中化的配置管理，这个时候就需要 ZooKeeper。
DNS 服务
组成员管理（group membership）：比如上面讲到的 HBase 其实就是用来做集群的组成员管理。
各种分布式锁

ZooKeeper 适用于存储和协同相关的关键数据，不适合用于大数据量存储。如果要存 KV 或者大量的业务数据，还是要用数据库或者其他 NoSql 来做。
3. 缺点为什么 ZooKeeper 不适合大数据量存储呢？主要有以下两个原因：

设计方面：ZooKeeper 需要把所有的数据（它的 data tree）加载到内存中。这就决定了ZooKeeper 存储的数据量受内存的限制。这一点 ZooKeeper 和 Redis 比较像。一般的数据库系统例如 MySQL（使用 InnoDB 存储引擎的话）可以存储大于内存的数据，这是因为 InnoDB 是基于 B-Tree 的存储引擎。B-tree 存储引擎和 LSM 存储引擎都可以存储大于内存的数据量。
工程方面：ZooKeeper 的设计目标是为协同服务提供数据存储，数据的高可用性和性能是最重要的系统指标，处理大数量不是 ZooKeeper 的首要目标。因此，ZooKeeper 不会对大数量存储做太多工程上的优化。

4. 特点1）Zookeeper：一个领导者（ Leader） ， 多个跟随者（ Follower） 组成的集群。2） 集群中只要有半数以上节点存活， Zookeeper集群就能正常服务。 所以Zookeeper适合安装奇数台服务器。3） 全局数据一致：每个Server保存一份相同的数据副本， Client无论连接到哪个Server， 数据都是一致的。4） 更新请求顺序执行， 来自同一个Client的更新请求按其发送顺序依次执行。5） 数据更新原子性， 一次数据更新要么成功， 要么失败。6） 实时性， 在一定时间范围内， Client能读到最新数据。  
5. 数据模型（Data Model）
ZooKeeper 数据模型的结构与 Unix 文件系统很类似，整体上可以看作是一棵树，每个节点称做一个 ZNode。每一个 ZNode 默认能够存储 1MB 的数据，每个 ZNode 都可以通过其路径唯一标识。  
ZooKeeper 的数据模型是层次模型。层次模型常见于文件系统。层次模型和 key-value 模型是两种主流的数据模型。ZooKeeper 使用文件系统模型主要基于以下两点考虑：

文件系统的树形结构便于表达数据之间的层次关系。
文件系统的树形结构便于为不同的应用分配独立的命名空间（namespace）。

ZooKeeper 的层次模型称作 data tree。Data tree 的每个节点叫做 znode。不同于文件系统，每个节点都可以保存数据。每个节点都有一个版本(version)，版本从 0 开始计数。
6. data tree 接口ZooKeeper 对外提供一个用来访问 data tree的简化文件系统 API：

使用 UNIX 风格的路径名来定位 znode,例如 &#x2F;A&#x2F;X 表示 znode A 的子节点 X。
znode 的数据只支持全量写入和读取，没有像通用文件系统那样支持部分写入和读取。
data tree 的所有 API 都是 wait-free 的，正在执行中的 API 调用不会影响其他 API 的完成。
data tree 的 API都是对文件系统的 wait-free 操作，不直接提供锁这样的分布式协同机制。但是 data tree 的 API 非常强大，可以用来实现多种分布式协同机制。

7. Znode 分类一个 znode 可以是持久性的，也可以是临时性的，znode 节点也可以是顺序性的。每一个顺序性的 znode 关联一个唯一的单调递增整数，因此 ZooKeeper 主要有以下 4 种 znode：

持久性的 znode (PERSISTENT): ZooKeeper 宕机，或者 client 宕机，这个 znode 一旦创建就不会丢失。
临时性的 znode (EPHEMERAL): ZooKeeper 宕机了，或者 client 在指定的 timeout 时间内没有连接 server，都会被认为丢失。
持久顺序性的 znode (PERSISTENT_SEQUENTIAL): znode 除了具备持久性 znode 的特点之外，znode 的名字具备顺序性。
临时顺序性的 znode (EPHEMERAL_SEQUENTIAL): znode 除了具备临时性 znode 的特点之外，znode 的名字具备顺序性。

8. 事务 ID为了保证事务的顺序一致性，Zookeeper 采用了递增的事务 ID 号(zxid)来标识事务，所有的操作(proposal)都会在被提出时加上 zxid，zxid 是一个 64 位的数字，他高 32 位是 epoch 用来标识 leader 关系是否发生变化，每当有新的 leader 被选举出来，都会有一个新的 epoch，标识当前属于哪个 leader 的领导。
对于 Zookeeper 来说，每次的变化都会产生一个唯一的事务 id，zxid（ZooKeeper Transaction Id）通过 zxid ，可以确定更新操作的先后顺序，如果说 zxid1 小于 zxid2，说明 zxid1 比 zxid 先发生。

SID： 服务器ID。 用来唯一标识一台ZooKeeper集群中的机器，每台机器不能重复， 和myid一致。  
ZXID：事务ID。 ZXID是一个事务ID，用来标识一次服务器状态的变更。 在某一时刻，集群中的每台机器的ZXID值不一定完全一致，这和ZooKeeper服务器对于客户端“更新请求”的处理逻辑有关。  
Epoch： 每个Leader任期的代号。没有Leader时同一轮投票过程中的逻辑时钟值是相同的。每投完一次票这个数据就会增加

9. Zookeeper 的角色
领导者（leader） ：负责进行投票的发起和决议，更新系统状态
学习者（learner） ：包括跟随者（follower）和观察者（observer），follower 用于接受客户端请求并想客户端返回结果，在选主过程中参与投票
Observer ：可以接受客户端连接，将写请求转发给 leader，但 observer 不参加投票过程，只同步 leader 的状态，observer 的目的是为了扩展系统，提高读取速度
客户端（client） ：请求发起方

10. 基本命令
create : 在树中的某个位置创建一个节点
delete : 删除一个节点存在：测试节点是否存在于某个位置
deleteall：删除所有节点
get data : 从节点读取数据
set data： 将数据写入节点
get children : 检索节点的子节点列表
sync : 等待数据被传播


查看 Zookeeper 中包含的 key
ls /



创建一个新的 Znode 创建成功以后我们可以使用 ls /查看我们创建的内容
create /zkMxn muxiaonong ls /[zkMxn, zookeeper]

获取创建 Znode 的内容
get /zkMxn

对 zk 所关联的字符串进行设置
set /zkMxn mxn666

删除 Znode
delete /zkMxn

11. 监听（Watch）监听原理
1） 首先要有一个main()线程2） 在main线程中创建Zookeeper客户端， 这时就会创建两个线程， 一个负责网络连接通信（connet） ， 一个负责监听（listener） 。3） 通过connect线程将注册的监听事件发送给Zookeeper。4） 在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。5） Zookeeper监听到有数据或路径变化， 就会将这个消息发送给listener线程。6） listener线程内部调用了process()方法。  

常见监听点

监听节点上值得变化情况

// 一台机器上改变节点[zk: 192.168.0.191(CONNECTED) 10] set /Yongheng/Dan &quot;Yao&quot;// 另一台机器上监听[zk: localhost:2181(CONNECTED) 9] get -w /Yongheng/DanWATCHER::WatchedEvent state:SyncConnected type:NodeDataChanged path:/Yongheng/Dan


监听节点的子节点变化情况（增加、删除节点）

// 192.168.0.191 机器上增加节点[zk: 192.168.0.191(CONNECTED) 12] create /Yongheng/Qi &quot;GuiFu&quot;Created /Yongheng/Qi// localhost 机器上监听变化[zk: localhost:2181(CONNECTED) 1] ls -w /Yongheng[Dan, Lin, Xue, Yao][zk: localhost:2181(CONNECTED) 2]WATCHER::WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/Yongheng

注意： 无论是节点中的数据还是节点的变化，注册一次，只能监听一次。想再次监听，需要再次注册。  
EnsembleZookeeper 中的集群不叫 cluster，而是叫 ensemble。
Zookeeper 使用的是一致性协议（consensus protocol），所以推荐每个 ensemble 里应该包含奇数（odd）个节点（比如 3 个、 5 个等），因为只有当 ensemble 里的大多数节点处于可用状态， Zookeeper 才能处理外部的请求。也就是说，如果有一个包含 3 个节点的 ensemble，那么它允许一个节点失效。如果 ensemble 包含 5 个节点，那么它允许 2 个节点失效。  
集群中节点个数的选择假设有一个包含 5 个节点的集群（ensemble），为了将修改的配置（包括交换节点）文件写入到集群，你需要重启每一个节点。如果你的集群无法容忍多个节点失效，那么在进行集群维护时就会存在风险。不过，也不建议一个集群包含超过 7 个节点，因为 Zookeeper 使用了一致性协议，节点过多会降低整个集群的性能。  
集群配置为了将 zookeeper 的服务器配置成集群（ensemble），需要一个公共的配置，列出所有的服务器。每台服务器在数据目录（data directory）中创建一个 myid 文件，用 于指明自己的 ID。  如果集群里服务器的 hostnames  是 zoo!.example.com, zoo2.example.com, zoo3 .example.com ，那么配置文件可能是下面这样的：  
tickTime=2000dataDir=/var/lib/zookeeperclientPort=2181initLimit=20syncLimit=5server.1=zoo1.example.com:2888:3888server.2=zoo2.example.com:2888:3888server.3=zoo3.example.com:2888:3888


clientPort：客户端端口号

initLimit：表示 followers  连接到 leader 之间建立初始化连接的时间上限。

syncLimit：表示允许从节点（followers）与主节点（leader）处于不同步状态的时间上限。  

initLimit 和 syncLimit 单位时间是 tickTime。比如：initLimit 的值为20，表示的时间为：20*2000ms&#x3D;40s



配置里还列出了集群中所有服务器的地址，服务器地址遵循的格式 server.X=hostname:peerPort:leaderPort各个参数说明如下：  

X：服务的 ID 号，必须是一个整数（integer），不需要从 0 开始或不要求是连续的。
hostname：服务器的主机名（hostname）或 IP 地址。
peerPort：集群中的服务器彼此之间通信的端口号。
leaderPort：leader 选择执行的 TCP 端口号。

客户端只需要通过 clientPort 就能连接到集群，而集群节点间的通信则需要同时用到这 3 个端口（ peerPort 、 leaderPort 、 clientPort ）。  
除了公共的配置文件外，每个服务器都必须在 data Dir 目录中创建一个叫作 myid 的文件，文件里要包含服务器 ID ， 这个 ID 要与配置文件里配置的 ID 保持一致。完成这些步骤后，就可以启动服务器，让它们彼此间进行通信了。  
12. 面试12.1. 选举机制半数机制，超过半数的投票通过，即通过。（1）第一次启动选举规则：投票过半数时， 服务器 id 大的胜出（2）第二次启动选举规则：

EPOCH 大的直接胜出
EPOCH 相同，事务 id 大的胜出
事务 id 相同，服务器 id 大的胜出

12.2. 生产集群安装多少 zk 合适？安装奇数台。生产经验：

10 台服务器： 3 台 zk；
20 台服务器： 5 台 zk；
100 台服务器： 11 台 zk；
200 台服务器： 11 台 zk

服务器台数多：好处，提高可靠性；坏处：提高通信延时  
13. References
Zookeeper 入门介绍
Centos7 离线安装 zookeeper 并设置服务开机自启 实践笔记

]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Balancer</title>
    <url>/gRPC/CloudNative/gRPC/Balancer/</url>
    <content><![CDATA[BalancerReference
gRPC 源码分析之 Balancer 篇：https://pandaychen.github.io/2019/11/22/GRPC-BALANCER-DEEP-ANALYSIS/

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>balancer</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP2</title>
    <url>/gRPC/CloudNative/gRPC/HTTP2/</url>
    <content><![CDATA[


HPACK在一个 HTTP 请求里面，我们通常在 header 上面携带很多该请求的元信息，用来描述要传输的资源以及它的相关属性。在 HTTP&#x2F;1.x 时代，我们采用纯文本协议，并且使用 \r\n来分隔，如果我们要传输的元数据很多，就会导致 header 非常的庞大。另外，多数时候，在一条连接上面的多数请求，其实 header 差不了多少，譬如我们第一个请求可能 GET /a.txt，后面紧接着是 GET /b.txt，两个请求唯一的区别就是 URL path 不一样，但我们仍然要将其他所有的 fields 完全发一遍。
HTTP&#x2F;2 为了结果这个问题，使用了 HPACK。虽然 HPACK 的 RFC 文档 看起来比较恐怖，但其实原理非常的简单易懂。
HPACK 提供了一个静态和动态的 table，静态 table 定义了通用的 HTTP header fields，譬如 method，path 等。发送请求的时候，只要指定 field 在静态 table 里面的索引，双方就知道要发送的 field 是什么了。
对于动态 table，初始化为空，如果两边交互之后，发现有新的 field，就添加到动态 table 上面，这样后面的请求就可以跟静态 table 一样，只需要带上相关的 index 就可以了。
同时，为了减少数据传输的大小，使用 Huffman 进行编码。这里就不再详细说明 HPACK 和 Huffman 如何编码了。
gRPC基于HTTP&#x2F;2的优缺点优点

HTTP&#x2F;2是一个经过实践检验的公开的标准
天然支持手机、物联网、浏览器
多语言实现容易，每种流行的编程语言都有自己的HTTP&#x2F;2 Client
HTTP&#x2F;2支持Stream和流控
基于HTTP&#x2F;2 在Gateway&#x2F;Proxy很容易支持
HTTP&#x2F;2 安全性有保证
HTTP&#x2F;2 鉴权成熟

缺点

RPC 的元数据的传输不够高效
HTTP&#x2F;2 里一次 gRPC 调用需要解码两次,一次是HEADERS frame，一次是DATA frame
HTTP&#x2F;2 标准本身是只有一个TCP连接，但是实际在 gRPC 里是会有多个TCP连接，使用时需要注意。

Reference
官方RFC文档：https://httpwg.org/specs/rfc7540.html
深入了解 gRPC协议：https://cn.pingcap.com/blog/grpc

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>hTTP2</tag>
      </tags>
  </entry>
  <entry>
    <title>Keepalive</title>
    <url>/gRPC/CloudNative/gRPC/Keepalive/</url>
    <content><![CDATA[
References
gRPC 客户端长连接机制实现及 keepalive 分析：https://pandaychen.github.io/2020/09/01/GRPC-CLIENT-CONN-LASTING/

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>keepalive</tag>
      </tags>
  </entry>
  <entry>
    <title>LoadBalance</title>
    <url>/gRPC/CloudNative/gRPC/LoadBalance/</url>
    <content><![CDATA[References
基于gRPC的注册发现与负载均衡的原理和实战: https://talkgo.org/t/topic/1460

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>loadBalance</tag>
      </tags>
  </entry>
  <entry>
    <title>Metadata</title>
    <url>/gRPC/CloudNative/gRPC/Metadata/</url>
    <content><![CDATA[


Metadata概念在 gRPC 中，metadata 是一些关于请求或响应的元数据信息，以键值对的形式表示，表示特定的RPC调用信息。key 一般是 strings，value 一般也是string，有时可能是二进制数据。它们用于传递一些非负载（payload）相关的数据，例如认证信息、跟踪 ID、时间戳等等。
metadata 可以在客户端和服务端之间进行传递，可以在请求和响应中包含 metadata，也可以通过 gRPC 拦截器（interceptor）对其进行修改、添加或删除。metadata 可以在请求和响应的生命周期中的任何时刻进行操作，并且可以自定义和扩展，以满足特定的应用场景。
在 gRPC 的 API 中，metadata 通常使用 gRPC 的 Metadata 类型来表示，这个类提供了一组 API 来方便开发者操作 metadata，例如：

添加元数据：metadata.put(key, value)
获取元数据：metadata.get(key)
删除元数据：metadata.remove(key)

在 gRPC 中，当客户端发起一个请求时，可以通过 Channel 提供的 withMetadata 方法来添加一些 metadata 信息到请求中。这些 metadata 信息将随着请求一起发送到服务端，服务端可以通过拦截器等机制来获取和处理这些 metadata。同样地，服务端也可以在响应中添加 metadata 信息，这些信息将会随着响应一起发送到客户端。
此外，metadata 还可以通过 Channel 提供的 intercept 方法来进行拦截和修改。拦截器是一种类似于中间件的机制，可以在请求和响应的生命周期中对其进行拦截和修改。使用拦截器，可以在请求和响应中添加、删除、修改 metadata 信息，以实现更加灵活和定制化的 metadata 处理。
原理References
gRPC 官方解释：https://grpc.io/docs/what-is-grpc/core-concepts/#metadata
Go 官方库 Metadata API 接口: https://pkg.go.dev/google.golang.org/grpc/metadata#MD.Get
Chromium metadata Example: https://chromium.googlesource.com/external/github.com/grpc/grpc/+/HEAD/examples/cpp/metadata/
How to set custom headers on a request 论坛讨论: https://groups.google.com/g/grpc-io/c/C8j3zGtL2-M
Github HTTP2: https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>metadata</tag>
      </tags>
  </entry>
  <entry>
    <title>Middleware</title>
    <url>/gRPC/CloudNative/gRPC/Middleware/</url>
    <content><![CDATA[容器中间件部署MySQLRedis]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>middleware</tag>
      </tags>
  </entry>
  <entry>
    <title>ServiceGovernace</title>
    <url>/gRPC/CloudNative/gRPC/ServiceGovernace/</url>
    <content><![CDATA[服务治理服务治理包含的功能：

日志
连接管理
健康检测
负载均衡
优雅启停机
异常重试
业务分组
熔断
限流
链路追踪
服务注册与发现
采集指标
性能分析
配置中心
资源统计

References
Go 微服务实战项目，使用工具一天完成了一个社区后端服务(单体)转换到微服务集群：https://learnku.com/articles/80940
sponge command framework: https://go-sponge.com/sponge-introduce?id=sponge-command-framework

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>serviceGovernace</tag>
      </tags>
  </entry>
  <entry>
    <title>SourceCode</title>
    <url>/gRPC/CloudNative/gRPC/SourceCode/</url>
    <content><![CDATA[1. 目标gRPC C++ 源码的质量很高，学习 Google 工程师门优秀的抽象和设计能力。
2. 特色2.1. 大量高级抽象结构gRPC 的源码为了简化异步代码的编写，同时为了更好的代码复用。设计了许多高级的数据结构。如

grpc_closure
grpc_closure_scheduler
ExecCtx
grpc_combiner
grpc_completion_queue

2.2. 大量设计模式为了提供跨平台能力，grpc核心代码采用了bridge设计模式，因此可以看到各种vtable,这也为阅读源代码增加了困难。
2.3. 异步编程grpc核心库采用reactor设计模式，如grpc_closure就是为了方便异步编程而设计的数据结构。
2.4. 高性能出于性能考虑，gRPC还使用了无锁队列这种高级数据结构，不熟悉其原理的读者可能会陷入各种原子操作的细节中。
2.5. grpc_closure 闭包closure就是闭包的英文名称。简单的理解，闭包函数将创建闭包时的上下文中的变量与自己绑定在一起，将变量的生存期和作用域延长到闭包函数结束。
2.6. 源码2.6.1. 结构2.6.1.1. src&#x2F;core&#x2F;lib&#x2F;surface&#x2F;grpc_init() 声明在 include&#x2F;grpc&#x2F;grpc.h 文件中，而其定义则是在 src&#x2F;core&#x2F;lib&#x2F;surface&#x2F;init.cc 文件中。
目录提供了 gRPC 的核心开发 API，并将【核心组件】转成【函数调用】
比如 channel.h 是中的 grpc_channel 结构和 grpc_channel_create_internal() 函数的声明，在对应的 channel.cc 中有实现。
2.6.1.2. src&#x2F;corecore 提供了低层次的库，提供给高层次库封装用的。 顶层的 API 在 grpc.h 中声明 安全相关的 在 grpc_security.h 中

include&#x2F;grpc&#x2F;grpc.h 是给 C 语言使用的 API
include&#x2F;grpcpp&#x2F;grpcpp.h 是给 C++ 语言使用的 API

Status在gRPC C++ API中，Status是一个封装了错误代码和错误消息的类。它在gRPC中的各个组件中都有应用，例如客户端、服务器和中间件。
当客户端或服务器调用远程过程调用（RPC）时，它们可能会遇到各种状态，如网络错误、超时、未授权访问等。在这些情况下，gRPC C++ API将向调用方返回一个Status实例，该实例包含一个错误代码和一个可选的错误消息。
错误代码在grpc::Status::Code枚举中定义，并包含了gRPC支持的所有错误类型。如果错误消息不为空，它将包含有关错误的详细信息。
通过检查返回的Status实例，程序员可以方便地检查处理gRPC调用时的错误情况，并根据需要采取相关的行动。在一些情况下，调用方可能会利用Status实例的错误信息，向其他代码、日志系统或应用程序用户通知错误发生的情况，以便执行更多的错误处理、调试和故障排除工作。
GoAway 机制gRPC GoAway 是 gRPC 协议中的一种机制，用于在一个 gRPC 服务器从其客户端终止连接时通知客户端。当服务器决定关闭与一个或多个客户端的连接时，它会向这些客户端发送一个 GoAway 帧，以便它们能够进行一些清理操作。
GoAway 帧包含一个最后有效流标识符 (Last-Stream-ID) 和一个可选的错误代码 (Error Code)，指示服务器关闭连接的原因。当客户端收到 GoAway 帧时，它应该停止发送新的请求，并关闭与服务器的连接，同时尽可能处理之前已发送的响应。客户端也可以查看 GoAway 帧的 Last-Stream-ID，以确定是否需要重新发起某些请求。
gRPC GoAway 机制是一种可靠的方法，用于管理长连接和复杂的通信场景，例如负载均衡和故障转移。它可以帮助确保客户端和服务器之间的连接得到有效管理，从而提高系统的可靠性和性能。
gRPC epoll architecture
https://github.com/grpc/grpc/blob/master/doc/core/epoll-polling-engine.md
https://yiakwy.github.io/blog/2017/10/01/gRPC-C-CORE

Visualizing gRPC Language Stackshttps://grpc.io/blog/grpc-stacks/
gRPC: Under the Hood: https://www.oreilly.com/library/view/grpc-up-and/9781492058328/ch04.html
3. References
CSDN：gRPC 源码分析: https://blog.csdn.net/happyanger6/category_9292845.html
RPC原理以及GRPC详解: https://www.cnblogs.com/awesomeHai/p/liuhai.html

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>sourceCode</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPCConPool</title>
    <url>/gRPC/CloudNative/gRPC/gRPCConPool/</url>
    <content><![CDATA[
gRPC 多路复用gRPC超时重连gRPC连接池gRPC 内部有内建的 balancer 去支持连接管理。
Reference
gRPC 应用篇之客户端 Connection Pool：https://pandaychen.github.io/2020/10/03/DO-WE-NEED-GRPC-CLIENT-POOL/
滴滴开源的连接池：https://github.com/shimingyah/pool
GRPC连接池的设计与实现：https://blog.didiyun.com/index.php/2019/12/30/4629/

]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>gRPCConPool</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPCFoundation</title>
    <url>/gRPC/CloudNative/gRPC/gRPCFoundation/</url>
    <content><![CDATA[ 

1. RPC(remote produce call)1.1. 什么是 RPCRPC简称远程过程调用，是一个用于构建基于Client和Server分布式应用程序的技术。目前业界已经有了很多的框架能够用来构建基于RPC的分布式应用，例如SpringBoot，Dubbo和gRPC。
RPC 标准最早是由Bruce Jay Nelson 写的论文 Implementing Remote Procedure Calls中提出的，后期的所有的RPC框架都是在这个标准模式的基础上构建出来的。

具体的执行过程就是下面这个样子

客户端发起一个远程调用,它实际上是调用本地的Client Stub
Client Stub 将接受到的参数进行按照约定的协议规范进行编码，并封装到即将发送的Message中。
Client Stub 将消息发送给RPC Runtime，然后通过网络将包 发送给Server端
服务器端的 RPCRuntime 收到请求后，交给提供方 Stub 进行解码，然后调用服务端的方法， 服务端执行方法，返回结果
服务端的处理结果 同样再经过Server Stub 打包，然后传递给RPC Runtime。
服务端的RPC Runtime再把数据通过网络发送给Client端。
Client 端接收到消息，然后进行 Unpack 处理。

RPC 实现例子：
RPC 局限性
本地函数调用的结果是可预测的，而 RPC 需要经过网络传输，数据在中途可能因为各种原因丢失。
RPC 调用有可能超时，编写程序时需要考虑该情况。
重试一个失败的 RPC 调用有可能造成数据重复，需要考虑幂等。
由于传输数据时需要序列化和反序列化，RPC 在传输复杂对象时会不太方便。

2. gRPC2.1. 如何学习 gRPC?总结一下，学习 RPC 时，我们先要了解其基本原理以及关键的网络通信部分，不要一味依赖现成的框架；之后我们再学习 RPC 的重点和难点，了解 RPC 框架中的治理功能以及集群管理功能等；这个时候你已经很厉害了，但这还不是终点，我们要对 RPC 活学活用，学会提升 RPC 的性能以及它在分布式环境下如何定位问题等等。

掌握 grpc 基础理论
会用 grpc API 去做一些简单的 server、client
掌握 grpc 功能
阅读源码
深刻理解 grpc 功能，成为一个高手

2.2. 概念gRPC 是一个由 Google 开发的高性能开源通用 RPC 框架。在 gRPC 中，客户端应用可以直接调用其他机器上的服务器应用中的方法，如同调用本地对象一样，从而让您更轻松地创建分布式应用和服务。
使用 gRPC 的主要优势之一是用于生成文档；您可以使用服务配置和 API 接口定义文件来生成 API 的参考文档。
2.2.1. Channel在 gRPC 中，Channel 是客户端与服务端之间通信的通道。当客户端需要与服务端进行通信时，它需要创建一个 Channel 对象，通过这个对象来发送请求和接收响应。
Channel 是一个连接池，它会缓存与服务端的连接以提高请求的效率。当客户端发送一个请求时，它会从连接池中获取一个可用的连接，如果连接池中没有可用连接，则会创建一个新的连接。
除了发送请求和接收响应外，Channel 还可以提供一些其他的功能，例如拦截器、事件监听、性能指标等等。

拦截器可以用来拦截请求和响应，并对其进行处理，例如添加认证信息、日志记录等等。
事件监听器可以监听 Channel 中发生的事件，例如连接建立、连接断开、请求发送等等。
性能指标可以用来监控 Channel 中请求的成功率、延迟等指标，帮助开发者进行性能优化。



Clients 可以指定 channel 的参数，去修改gRPC 的默认行为，例如：开启或关闭消息压缩的开关。
一个 channel 是具有状态的，包括 idle 和 connected。


2.2.2. Stub在 gRPC 中，Stub 是客户端使用的一个代理类，它实现了客户端与服务端之间通信的逻辑。通过 Stub 对象，客户端可以调用远程服务提供的 RPC 方法，并将请求发送到服务端进行处理，同时接收服务端返回的响应结果。
在 gRPC 中，每个服务都有一个对应的 Stub 类，该类包含了该服务定义的所有 RPC 方法，客户端可以通过该 Stub 对象来调用这些方法。在 gRPC 中，Stub 类是由 Protocol Buffers 编译器自动生成的，根据服务定义的 .proto 文件，编译器会生成一个对应的 Stub 类，并将其与客户端代码一起编译。

官方解释：On the client side, the client has a local object known as stub (for some languages, the preferred term is client) that implements the same methods as the service. The client can then just call those methods on the local object, and the methods wrap the parameters for the call in the appropriate protocol buffer message type, send the requests to the server, and return the server’s protocol buffer responses.

2.2.3. Metadata1.2. gRPC 特点
语言中立，支持多种语言；
基于 IDL 文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub；
通信协议基于标准的 HTTP&#x2F;2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性，这些特性使得 gRPC 在移动端设备上更加省电和节省网络流量；
序列化支持 PB（Protocol Buffer）和 JSON，PB 是一种语言无关的高性能序列化框架，基于 HTTP&#x2F;2 + PB, 保障了 RPC 调用的高性能。

在一次RPC调用中，负责为客户端代理的节点（gRPC中称之为Stub）会将请求和参数传到服务端，并由Service进行实际的处理，然后将结果返回给Stub，最终返回到客户端中。
1.3. Service definitiongRPC 有 4  种请求和响应模式。
gRPC 是 Google 基于 HTTP&#x2F;2 以及 protobuf 的，要了解 gRPC 协议，只需要知道 gRPC 是如何在 HTTP&#x2F;2 上面传输就可以了。
gRPC 通常有四种模式，unary，client streaming，server streaming 以及 bidirectional streaming，对于底层 HTTP&#x2F;2 来说，它们都是 stream，并且仍然是一套 request + response 模型。
RequestgRPC 的 request 通常包含 Request-Headers, 0 或者多个 Length-Prefixed-Message 以及 EOS。
Request-Headers 直接使用的 HTTP&#x2F;2 headers，在 HEADERS 和 CONTINUATION frame 里面派发。定义的 header 主要有 Call-Definition 以及 Custom-Metadata。Call-Definition 里面包括 Method（其实就是用的 HTTP&#x2F;2 的 POST），Content-Type 等。而 Custom-Metadata 则是应用层自定义的任意 key-value，key 不建议使用 grpc-开头，因为这是为 gRPC 后续自己保留的。
Length-Prefixed-Message 主要在 DATA frame 里面派发，它有一个 Compressed flag 用来表示改 message 是否压缩，如果为 1，表示该 message 采用了压缩，而压缩算法定义在 header 里面的 Message-Encoding 里面。然后后面跟着四字节的 message length 以及实际的 message。
EOS（end-of-stream） 会在最后的 DATA frame 里面带上了 END_STREAM这个 flag。用来表示 stream 不会在发送任何数据，可以关闭了。
ResponseResponse 主要包含 Response-Headers，0 或者多个 Length-Prefixed-Message 以及 Trailers。如果遇到了错误，也可以直接返回 Trailers-Only。
Response-Headers 主要包括 HTTP-Status，Content-Type 以及 Custom-Metadata 等。Trailers-Only 也有 HTTP-Status ，Content-Type 和 Trailers。Trailers 包括了 Status 以及 0 或者多个 Custom-Metadata。
HTTP-Status 就是我们通常的 HTTP 200，301，400 这些，很通用就不再解释。Status 也就是 gRPC 的 status， 而 Status-Message 则是 gRPC 的 message。Status-Message 采用了 Percent-Encoded 的编码方式，具体参考 这里 。
如果在最后收到的 HEADERS frame 里面，带上了 Trailers，并且有 END_STREAM这个 flag，那么就意味着 response 的 EOS。

Unary（一元 RPC）
一元RPC模式也称为简单RPC模式。客户端发送单个请求到服务端，等待服务端的响应。

缺点：

数据包过大造成的瞬时压力

接收数据包时，需要所有数据包都接受成功且正确后，才能够回调响应，进行业务处理（无法客户端边发送，服务端边处理）



server-side streaming（服务端流式RPC）
当数据量大或者需要不断传输数据时候，我们应该使用流式RPC，它允许我们边处理边传输数据。
服务端流式RPC：客户端向服务端发送单个请求，服务端收到客户端的请求后，处理多个响应，这种多个响应所组成的序列被称为”流（stream）“。客户端读来自服务端返回的 stream，直到没有消息为止。


client-side-streaming（客户端流式RPC）
在客户端流 RPC 模式中，客户端发送（write）多个请求给服务器端，而不再是单个请求，一旦客户端完成了发送消息，它等服务端去读（read）完一个序列的消息，由服务端返回一个响应 （response）。


Bidirectional Streaming （ 双向流式RPC）
双向流式RPC 模式：client 发送一定消息序列的请求（request）给 server，而 server 给 client 回的响应也是一定消息序列的响应。双方使用读写流（a read-write stream）去发送一个消息序列，两个流独立操作，双方可以同时发送和同时接收。

注意点：

避免 race condition 或 deadlocks。



在 gRPC 双向流中，每个传输的消息都有一个头部和一个消息体。其中，消息头部包括了消息的元数据，如消息类型、编解码信息、消息 ID 等；消息体则包含了具体的消息内容。这些信息都是通过 Protocol Buffers 进行编解码的。
1.3.1. 流的结束
Client 发送流：通过 Writer-&gt;WritesDone() 结束流
Server 发送流：通过结束 rpc 调用并返回状态码status code的方式来结束流
读取流：通过 Reader-&gt;Read() 返回的 bool 型状态，来判断流是否结束

1.2. proto 文件gRPC 默认采用 protocol buffers 数据传输格式。protocol buffers 是google开发的一种能够将结构数据序列化的数据描述语言。
使用protocol buffers的第一步是要在扩展名为.proto的proto文件中定义序列化的数据的结构。 Protocol buffer 数据会被结构化成一个 message,而这个 message 其实就是一条包含了一些属性（name-value对）的记录。
hello.proto
// proto buffer 语法版本syntax = &quot;proto3&quot;;// 只对Java语言有效option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;option objc_class_prefix = &quot;HLW&quot;;// 包名：用来防止协议消息类型之间发生命名的冲突；C++叫命名空间，Java中叫包名package helloworld;// 定义gRPC服务的接口service Greeter &#123;  // 远程调用方法；HelloRequest为函数参数，HelloReply为函数返回值  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 定义请求的消息格式和类型 message HelloRequest &#123;  string name = 1;  // 唯一字段编号，用于二进制消息格式中识别该字段&#125;// 定义响应的消息格式和类型 message HelloReply &#123;  string message = 1;&#125;

生成 pb.cc、pb.h 、grpc.cc、grpc.pb.h 文件。
// 指定路径下生成 cpp 文件到指定的路径protoc --proto_path=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` --cpp_out=/workspaces/xiot-platform/xiot-platform/iot/server/IOT-ProductServer/proto ./industrial_gateway.proto ./google/protobuf/struct.proto ./google/api/field_behavior.proto// 指定路径下生成 grpc 文件到指定的路径 protoc --proto_path=. --plugin=protoc-gen-grpc=`which grpc_cpp_plugin` --grpc_out=/workspaces/xiot-platform/xiot-platform/iot/server/IOT-ProductServer/proto ./industrial_gateway.proto ./google/protobuf/struct.proto ./google/api/field_behavior.proto 



1.3. gRPC 服务端1.4. gRPC 客户端gRPC 支持两种类型的 client stub。
1.4.1. 同步（Synchronous）同步rpc调用调用完后，client 不立即&#x3D;返回，而是等（wait）server 返回的响应。
1.2. 同步RPC缺点
线程利用率低：线程资源是系统中非常重要的资源，在一个进程中线程总数是有限制的，提升线程使用率就能够有效提升系统的吞吐量，在同步 RPC 调用中，如果服务端没有返回响应，客户端业务线程就会一直阻塞，无法处理其它业务消息。
纠结的超时时间：RPC 调用的超时时间配置是个比较棘手的问题。如果配置的过大，一旦服务端返回响应慢，就容易把客户端挂死。如果配置的过小，则超时失败率会增加。即便参考测试环境的平均和最大时延来设置，由于生产环境数据、硬件等与测试环境的差异，也很难一次设置的比较合理。另外，考虑到客户端流量的变化、服务端依赖的数据库、缓存、第三方系统等的性能波动，这都会导致服务调用时延发生变化，因此，依靠超时时间来保障系统的可靠性，难度很大。
雪崩效应：在一个同步调用链中，只要下游某个服务返回响应慢，会导致故障沿着调用链向上游蔓延，最终把整个系统都拖垮，引起雪崩

1.2.1. 异步（Asynchronous）概念：client 采用非阻塞式（non-blocking）的去调用 server 端返回的响应。异步API 会阻塞线程，直到一个接收或发送一个消息（message）。
异步通信要考虑并行和并发。
C++ gRPC 异步的操作是采用 CompletionQueue 来实现的。CompletionQueue 是一个 event queue。任何异步操作的完成都是完成队列中的一个事件。
异步调用是从 CompletionQueue 中取得响应返回的结果。

在异步客户端中，通过gRPC stub 的异步方法调用，获取ClientAsyncResponseReader的实例。
在异步客户端中，ClientAsyncResponseReader 的Finish方法向 CompletionQueue注册了响应消息处理器和响应消息体的存储容器。
当服务器响应消息到来时，响应消息体被填充到注册的容器中，而响应消息处理器则被push到CompletionQueue中。
从CompletionQueue中获取到响应消息处理器，对响应消息进行处理。

调用基本的流程：

绑定一个 CompletionQueue 到一个 RPC 调用
利用唯一的 void* Tag 进行读写
调用 CompletionQueue::Next() 等待操作完成，完成后通过唯一的 Tag 来判断对应什么请求&#x2F;返回进行后续操作。tag：根据CompletionQueue返回的 tag 知道是哪个对象产生了事件。

1.2.1.1. 实现 C++ gRPC 异步双向流注意事项
使用异步 API：使用 C++ gRPC 提供的异步 API，如 AsyncReaderWriter，而不是同步 API。异步 API 能够在单线程内处理多个客户端请求，提高程序的并发性能。
线程安全：C++ gRPC 是线程安全的，但需要保证在使用 gRPC API 时，线程安全性不受影响。需要注意避免多个线程同时访问同一资源导致的竞态条件问题。
序列化和反序列化：需要将请求和响应数据序列化和反序列化。C++ gRPC 默认使用 Protocol Buffers 作为序列化格式，需要定义好请求和响应消息的格式。
错误处理：在处理异步双向流时，需要注意错误处理。例如，当客户端断开连接时，需要正确处理该事件，避免导致程序异常退出。
流控制：需要合理地使用流控制机制，避免客户端和服务端之间的数据流量过大导致程序崩溃或者性能下降。
代码清晰度：异步编程需要编写更复杂的代码，需要保证代码结构清晰易读，便于维护和修改。

1.2.1.2. API接口
StartCall：开始异步RPC调用。

Finish：等待服务器的响应。

ShutDown() 作用
在gRPC中，ShutDown()是一个方法，用于安全地停止gRPC服务器或客户端的所有RPC处理。它可以使gRPC平滑地退出，并等待任何未完成的RPC处理完成后关闭gRPC，同时确保不会丢失任何信息。
具体来说，对于服务器：
当服务器调用Shutdown()方法时，它将不再处理新的RPC请求，并且直到所有未完成的RPC请求都被处理完毕后才关闭服务器端口, 这样做的好处是，可以确保所有客户端完成所有最终的数据交换。
应用程序可以调用Shutdown方法以便更改服务配置，例如重新加载证书、更改端口等。
也可以设置超时选项，如果所有RPC请求在超时之前没能完成，那么服务器会强制经由Shutdown清理所有未完成的请求，如果不指定超时选项，服务器将一直等待正在处理的请求，即使超过了Graceful Shutdown Deadlin，然后关闭端口。
对于客户端：
当客户端调用Shutdown()方法时，它将使所有未完成的RPC请求立即终止，并且将不会处理新的RPC请求。
客户端在调用Shutdown()方法后仍可创建新的Channels和Stubs实例，但这些实例将在未来的任何RPC处理期间忽略它们。
综上，gRPC中的ShutDown()方法对于确保RPC请求恰当、安全地完成很重要。在服务器和客户端中，ShutDown()方法被用于清理并停止所有正在运行的RPC处理。如果不通过Shutdown()来关闭gRPC，同时存在未完成的RPC请求时，会存在内存泄漏和丢失信息的风险。

Next：一旦服务器的响应到达，调用cq.Next方法来获取响应，并检查状态是否OK。

PrepareAsyncYourMethod：准备一个异步的RPC调用。

grpc::WriteOptions 

grpc::WriteOptions 是构建 gRPC 的时候使用的选项之一，它用于控制服务器在响应请求时的行为。在 gRPC C++ 中，可以使用 grpc::WriteOptions 类来设置写入选项。其中，writeOptions.set_last_message(true) 方法用于设置当前消息是否为 Bidirectional Stream 中的最后一个消息。当设置为 true 时，表示当前消息为最后一个消息，否则表示当前消息为中间消息。

grpc::WriteOptions 主要有以下作用：

用于控制服务器的流控制：当客户端向服务器发送数据时，服务器可以使用 WriteOptions 来控制数据的流量，例如限制数据的大小、速度等。
用于控制服务器的压缩：当客户端向服务器发送数据时，服务器可以使用 WriteOptions 来控制数据的压缩方式，例如使用 Gzip 压缩或其它压缩方式。
用于控制服务器的 Acknowledgement：当客户端发送数据给服务器时，服务器可以使用 WriteOptions 来控制何时发送 Acknowledgement，以及 Acknowledgement 的格式等。





为了防止阻塞，Read，Write和Finish都将从CompletionQueue上的一个Event标记返回，以表明每个操作何时完成。在一个while循环中持续等待，直到一些事件被触发。如果事件是状态事件，那么while循环将退出，否则事件将处理并继续循环等待下一个事件。



1.2.1.3. 多线程对于如何在多线程中使用异步 RPC API 完成队列，官方的的文档说明是：Right now, the best performance trade-off is having numcpu’s threads and one completion queue per thread.
当前，最好的权衡性能的方法是使用创建 cpu 个数的线程数，并在每个线程中都使用一个完成队列。
在高并发和效率方面，使用CompletionQueue可充分利用现代多核处理器。此外，gRPC库本身已经进行了优化以提高性能。最后，您还可以使用流量控制来限制客户端和服务器之间的通信速度。
1.2. gRPC 处理流程当调用 gRPC 服务时，客户端的 gRPC 库会使用 protocol buffers，将 RPC 的请求编排（masrshal）为 protocol buffers 格式，然后通过 HTTP&#x2F;2 进行发送。在服务端，请求会被解排（unmasrshal）。而响应也遵循类似的执行流，从服务端发送到客户端。

编排：将参数和远程函数打包的过程。
解排：解包消息到对应的方法调用的过程。

1.4. gRPC 强大的功能
治理功能。比如连接管理、健康检测、负载均衡、优雅启停机、异常重试、业务分组以及熔断限流。
集群管理功能。

1.4.1. 服务治理每个服务启动的时候，会将自身的服务和IP注册到注册中心，其他服务调用的时候，只需要向注册中心申请地址即可。
保活机制熔断机制&#x2F;限流机制负载均衡channel 复用flow control（流量控制）HTTP&#x2F;2 也支持流控，如果 sender 端发送数据太快，receiver 端可能因为太忙，或者压力太大，或者只想给特定的 stream 分配资源，receiver 端就可能不想处理这些数据。譬如，如果 client 给 server 请求了一个视频，但这时候用户暂停观看了，client 就可能告诉 server 别在发送数据了。
虽然 TCP 也有 flow control，但它仅仅只对一个连接有效果。HTTP&#x2F;2 在一条连接上面会有多个 streams，有时候，我们仅仅只想对一些 stream 进行控制，所以 HTTP&#x2F;2 单独提供了流控机制。Flow control 有如下特性：

Flow control 是单向的。Receiver 可以选择给 stream 或者整个连接设置 window size。
Flow control 是基于信任的。Receiver 只是会给 sender 建议它的初始连接和 stream 的 flow control window size。
Flow control 不可能被禁止掉。当 HTTP&#x2F;2 连接建立起来之后，client 和 server 会交换 SETTINGS frames，用来设置 flow control window size。
Flow control 是 hop-by-hop，并不是 end-to-end 的，也就是我们可以用一个中间人来进行 flow control。

2. Performance3. References
gRPC 英文官方文档：https://grpc.io/
Github仓库解释gRPC设计的原理：https://github.com/grpc/proposal
gRPC 中文文档：与英文版本不同步，不是最新版本。
What is gRPC? Protocol Buffers, Streaming, and Architecture Explained
Introduction to gRPC Part1
Introduction to gRPC Part2
Introduction to gRPC Part3
Introduction to gRPC Part4
gRPC 代码使用的 C&#x2F;C++ 技巧
gRPC 博客归档：https://panzhongxian.cn/tags/grpc/
C++ gRPC 异步 API 实例与优势
https://juejin.cn/post/6998554231837818917
https://stackoverflow.com/questions/68767309/difference-between-sync-and-async-grpc
https://stackoverflow.com/questions/64639004/grpc-c-async-helloworld-client-example-doesnt-do-anything-asynchronously


grpc学习：https://qiankunli.github.io/2020/02/28/grpc.html
gRPC博客学习归档：https://www.cnblogs.com/FireworksEasyCool/category/1693727.html
grpc使用记录(三)简单异步服务实例：C++ 实现
聊一下 gRPC 的 C++ 异步编程
C++ gRPC 异步 API 实例与优势
Lessons learnt from writing asynchronous streaming gRPC services in C++ ：grpc 异步服务端流模式例子。
Github awesome-grpc: https://github.com/grpc-ecosystem/awesome-grpc
https://www.selinux.tech/golang/grpc/what-grpc

可选

微服务治理框架(C++版)详细设计：https://github.com/grpc-nebula/grpc-nebula-c/tree/master/docs
gRPC Load Balancing：https://grpc.io/blog/grpc-load-balancing/

gRPC Issues

C++ Asynchronous Streaming RPC example #10013: https://github.com/grpc/grpc/issues/10013
C++ Async bidi streaming sample #8934: https://github.com/grpc/grpc/pull/8934
Provide a simple event-processing loop for C++ async API #7352: https://github.com/grpc/grpc/issues/7352

其它应对方案

Tradias&#x2F;[asio-grpc: https://github.com/Tradias/asio-grpc

agrpc: https://github.com/npuichigo/agrpc

思考gRPC ：为什么是HTTP&#x2F;2：https://blog.csdn.net/hengyunabc/article/details/81120904

从实践到原理，带你参透 gRPC：https://segmentfault.com/a/1190000019608421 文章写的很详细，值得参考。


]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>gRPCFoundation</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPCOptimize</title>
    <url>/gRPC/CloudNative/gRPC/gRPCOptimize/</url>
    <content><![CDATA[gRPC调优gRPC 默认的参数对于传输大数据块来说不够友好，我们需要进行特定参数的调优。

MaxSendMsgSize: gRPC最大允许发送的字节数，默认 4MiB，如果超过了 gRPC 会报错。Client 和 Server 我们都调到 4GiB。

MaxRecvMsgSizeg: RPC最大允许接收的字节数，默认 4MiB，如果超过了 gRPC 会报错。Client  和 Server 我们都调到 4GiB。

InitialWindowSize: 基于 Stream 的滑动窗口，类似于 TCP  的滑动窗口，用来做流控，默认  64KiB，吞吐量上不去，Client 和 Server 我们调到 1GiB。

InitialConnWindowSize: 基于 Connection 的滑动窗口，默认16 * 64KiB，吞吐量上不去，Client 和Server 我们也都调到 1GiB。

KeepAliveTime: 每隔 KeepAliveTime 时间，发送 PING 帧测量最小往返时间，确定空闲连接是否仍然有效，我们设置为10S。

KeepAliveTimeout: 超过 KeepAliveTimeout，关闭连接，我们设置为 3S。

PermitWithoutStream: 如果为 true，当连接空闲时仍然发送 PING 帧监测，如果为 false，则不发送忽略。我们设置为 true。

MaxConcurrentStreams: 一条gRPC连接允许并发的发送和接收多个Stream。数值小了，吞吐量上不去。Golang的服务端默认是100。

注意：虽然一条连接上面能够处理更多的请求了，但一条连接远远是不够的。一条连接通常只有一个线程来处理，所以并不能充分利用服务器多核的优势。同时，每个请求编解码还是有开销的，所以用一条连接还是会出现瓶颈。



]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>cloudNative</tag>
        <tag>gRPC</tag>
        <tag>gRPCOptimize</tag>
      </tags>
  </entry>
  <entry>
    <title>C++Sheet</title>
    <url>/FAQ/Cpp/FAQ/C++Sheet/</url>
    <content><![CDATA[

1. C++ 面试八股文1.1. 1 .h与 .hpp 文件区别.hpp 本质就是将.cpp的实现代码混入.h头文件当中，定义与实现都包含在同一文件，则该类的调用者只需要include该.hpp文件即可，无需再将cpp加入到project中进行编译。而实现代码将直接编译到调用者的obj文件中，不再生成单独的obj，采用hpp将大幅度减少调用project中的cpp文件数与编译次数，也不用再发布lib与dll文件，因此非常适合用来编写公用的开源库。
使用 hpp 的优点

是Header Plus Plus的简写。（.h和.hpp就如同.c和.cpp似的）
与.h类似，.hpp是C++程序头文件格式。
是VCL专用的头文件,已预编译。
是一般模板类的头文件。
一般来说，.h里面只有声明，没有实现，而.hpp里声明实现都有，后者可以减少.cpp的数量。
.h里面可以有using namespace std，而.hpp里则无。
不可包含全局对象和全局函数。

当hpp文件中存在全局对象或者全局函数，而该hpp被多个调用者include时，将在链接时导致符号重定义错误。要避免这种情况，需要去除全局对象，将全局函数封装为类的静态方法。
1.2. 2 ++i 与 i++ 效率问题
++i 返回的是对象的引用，而 i++ 返回的是对象的原值（但非左值）。
++i 先自增，后返回原对象的对象，没有产生任何临时对象；而 i++，先保存原对象，然后自增，最后返回该原对象的临时对象，需要创建和销毁对象。

1.3. 3 传值、传引用、传指针三者的区别形参

在函数或方法中定义的参数就是形参。
函数没有被调用时，形参并不会占用内存的存储单元，只有当函数被调用时，形参才会被分配内存单元，在函数体执行完后，形参存储的内存单元被释放。

实参

实参可以是常量、变量和表达式，但必须要有确定的值。  
函数调用的时候，先给形参分配内存空间，然后将实参的值拷贝一份给形参，函数体调用结束后，形参分配的内存空间被释放，但是实参分配的内存空间还存在。

传值

可以传实参和形参。
比如函数定义为 fun(int a)，在调用的地方有int x=6， 使用fun(x)调用。这种方式在 fun(int a) 函数内部的对a的修改 不能 导致外部 x 的变化。
值传递时，程序会为形参分配内存空间，并将实参的值赋值给形参，函数体中形参的改变并不会影响实参的值，形参存储的是实参的副本。

传地址

传地址也叫指针传递。
函数定义为 fun(int *a)，形参为指针，调用的时候传递的是参数的地址，例如 int x=6; fun(&amp;x)。 这种方式在 fun(int a)函数内部的对 a 的修改 能 导致外部 x 的变化。

传引用

用 &amp; 符号定义的形参，在参数传递时相当于实参的一个别名，对形参的操作相当于直接对实参进行操作。
函数定义为 fun(int&amp; a)，形参为引用，例如 int x=6; fun(x)。 在 fun(int&amp; a) 函数内部的对变量 a 的修改 能 导致外部 x 的变化。
传引用时，程序不是将直接实参本身的值复制后传递给形参，而是将实参的地址值传递给形参，形参所引用地址上的变量与传递的实参相同，因此，函数体内形参的改变会直接改变实参的值。

]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>fAQ</tag>
        <tag>c++Sheet</tag>
      </tags>
  </entry>
  <entry>
    <title>QueuePushMaxElement</title>
    <url>/FAQ/Cpp/FAQ/QueuePushMaxElement/</url>
    <content><![CDATA[STL Queue 中 最大能 push 多少元素？阅读标准库中的源码可知：Queue 底层是基于 deque 实现的。源码中 push 函数调用的是 deque 容器中的 push_back 函数，而 deque 容器中队列能分配最大的值由 max_size 函数决定，max_size 函数的返回的类型为 size_type。一步一步追踪朔源，发现 size_type 是 size_t 的别名，而 size_t 又是 __SIZE_TYPE__ 的别名，__SIZE_TYPE__ 最终是 long unsigned int 的别名。终于找到源头了，STL 标准库的 Queue 容器最大能 push 多少个值由 long unsigned int 值决定的，而数据类型是跟操作系统的位数相关的，32 位与 64 位操作系统中  long unsigned int 的值是不一样。32 位系统中数值为 $2^{32}$，64 位系统中数值为 $2^{64}$。
下面列出 STL 中的用到的源码部分
// queue 容器中的 push 操作voidpush(const value_type&amp; __x)&#123; c.push_back(__x); &#125;

// queue 容器类模板部分代码template&lt;typename _Tp, typename _Sequence = deque&lt;_Tp&gt; &gt;    class queue    &#123;      // concept requirements      typedef typename _Sequence::value_type _Sequence_value_type;              template&lt;typename _Tp1, typename _Seq1&gt;        friend bool        operator==(const queue&lt;_Tp1, _Seq1&gt;&amp;, const queue&lt;_Tp1, _Seq1&gt;&amp;);      template&lt;typename _Tp1, typename _Seq1&gt;        friend bool        operator&lt;(const queue&lt;_Tp1, _Seq1&gt;&amp;, const queue&lt;_Tp1, _Seq1&gt;&amp;);    public:      typedef typename _Sequence::value_type                value_type;      typedef typename _Sequence::reference                 reference;      typedef typename _Sequence::const_reference           const_reference;      typedef typename _Sequence::size_type                 size_type;      typedef          _Sequence                            container_type;    protected:      /**       *  &#x27;c&#x27; is the underlying container.  Maintainers wondering why       *  this isn&#x27;t uglified as per style guidelines should note that       *  this name is specified in the standard, [23.2.3.1].  (Why?       *  Presumably for the same reason that it&#x27;s protected instead       *  of private: to allow derivation.  But none of the other       *  containers allow for derivation.  Odd.)       */      _Sequence c;        ......    &#125;;

// deque 容器中的 push_back 操作voidpush_back(const value_type&amp; __x)&#123;if (this-&gt;_M_impl._M_finish._M_cur!= this-&gt;_M_impl._M_finish._M_last - 1)&#123;this-&gt;_M_impl.construct(this-&gt;_M_impl._M_finish._M_cur, __x);++this-&gt;_M_impl._M_finish._M_cur;&#125;else_M_push_back_aux(__x);&#125;

// deque 容器中能最大分配的值/**  Returns the size() of the largest possible %deque.  */size_typemax_size() const _GLIBCXX_NOEXCEPT&#123; return _M_get_Tp_allocator().max_size(); &#125;

// 类型的别名typedef size_t  size_type;typedef __SIZE_TYPE__ size_t;#define __SIZE_TYPE__ long unsigned int

]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>cpp</tag>
        <tag>fAQ</tag>
        <tag>queuePushMaxElement</tag>
      </tags>
  </entry>
  <entry>
    <title>VariableAllocate</title>
    <url>/FAQ/Go/FAQ/VariableAllocate/</url>
    <content><![CDATA[How do I know whether a variable is allocated on the heap or the stack?一、C语言中返回函数中局部变量值和指针(1) 在C语言中，一个函数可以直接返回函数中定义的局部变量，其实在函数返回后，局部变量是被系统自动回收的，因为局部变量是分配在栈空间，那为什么还可以返回局部变量，其实这里返回的是局部变量的副本（拷贝）。
(2) 函数返回局部变量地址：局部变量内存分配在栈空间，因为函数返回后，系统自动回收了函数里定义的局部变量，所以运行时去访问一个被系统回收后的地址空间，一定就会发生段错误，这是C&#x2F;C++语言的特点。内存空间分配在堆中即可。
二、GO函数中返回变量，指针示例代码：
package mainimport &quot;fmt&quot;func fun() *int &#123;    //int类型指针函数    var tmp := 1    return &amp;tmp      //返回局部变量tmp的地址&#125;func main() &#123;    var p *int    p = fun()    fmt.Printf(&quot;%d\n&quot;, *p) //这里不会像C，报错段错误提示，而是成功返回变量V的值1&#125;

参考go FAQ里面的一段话：
How do I know whether a variable is allocated on the heap or the stack?From a correctness standpoint, you don&#x27;t need to know. Each variable in Go exists as long as there are references to it. The storage location chosen by the implementation is irrelevant to the semantics of the language.The storage location does have an effect on writing efficient programs. When possible, the Go compilers will allocate variables that are local to a function in that function&#x27;s stack frame. However, if the compiler cannot prove that the variable is not referenced after the function returns, then the compiler must allocate the variable on the garbage-collected heap to avoid dangling pointer errors. Also, if a local variable is very large, it might make more sense to store it on the heap rather than the stack.In the current compilers, if a variable has its address taken, that variable is a candidate for allocation on the heap. However, a basic escape analysis recognizes some cases when such variables will not live past the return from the function and can reside on the stack.

意思是说go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。所以不用担心会不会导致memory leak，因为GO语言有强大的垃圾回收机制。go语言声称这样可以释放程序员关于内存的使用限制，更多的让程序员关注于程序功能逻辑本身。
对于动态new出来的局部变量，go语言编译器也会根据是否有逃逸行为来决定是分配在堆还是栈，而不是直接分配在堆中。
结论：函数内部局部变量，无论是动态new出来的变量还是创建的局部变量，它被分配在堆还是栈，是由编译器做逃逸分析之后做出的决定。
References
Go FAQ: https://go.dev/doc/faq#stack_or_heap
CSDN Go语言—函数返回局部变量地址：https://blog.csdn.net/li_101357/article/details/80209413

]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>fAQ</tag>
        <tag>variableAllocate</tag>
      </tags>
  </entry>
  <entry>
    <title>11-旋转数组的最小数字</title>
    <url>/CodingInterview/Interview/CodingInterview/11-%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%E7%9A%84%E6%9C%80%E5%B0%8F%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[
第11题：旋转数组的最小数字
  题目描述：把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。
  示例1：输入 [3,4,5,1,2]，返回值为 1

思路最直观的解法
从头到尾遍历一遍数组，就能找出最小的元素，这种思路的时间复杂度是 $\Omicron(n)$，这种思路，显然没有利用输入的旋转数组的特性，肯定达不到面试官的要求。

利用二分法查找的思想实现。
定义三个指针，一个指针指向数组的第一个元素 $p_1$，一个指针指向数组的最后一个元素 $p_2$，一个指针指向数组的中间元素 $p_m$。

以输入的 [3,4,5,1,2] 为例子，先把指针 $p1$ 指向第 0 个元素，把指针 $p2$ 指向第 4 个元素，如下图a所示。位于指针中间的数字是 5，它大于指针 $p1$ 指向的数字，因此中间数字 5，一定位于第一个递增的子数组，并且最小的数字一定位于它的后面。因此可移动指针 $p1$ ，让它指向数组的中间，如图b所示。

此时位于这两个中间的数字为1，它小于指针 $p2$ 指向的数字，因此这个中间数字 1 一定位于第二个递增数组，并且最小的数字一定位于它的前面或者它自己就是最小的数字。因此我们可以移动指针 $p2$ ，让它指向两个指针中间的元素，如图c所示。

此时两个指针的距离是 1 ，表明指针 $p1$ 已经指向第一个递增子数组的末尾，而指针 $p2$ 指向第二个递增子数组的开头。第二个子数组的第一个数字就是最小的数字，所以指针 $p2$ 指向的数字就是我们要查找的结果。


考虑特殊情况

当$p_1$, $p_2$, $p_m$ 这三个指针指向的数据都相同时，那么该如何处理了？出现的情况如下图所示


从上面的图片中看出，指针 p1 和指针 p2指向的数字都是 1，并且这两个指针中间的数字也是 1，这 3 个数字相同。在第一种情况中，中间数字位于后面的子数组；第二种情况下，中间数字位于前面的子数组。当这三个指针指向的数字都相同时，我们无法判断中间的数字是位于前面的子数组还是位于后面的子数组，也就无法移动两个指针来缩小查找的范围，得到想要的结果。因此我们只能采用顺序查找的方法去实现。




代码实现class Solution &#123;public:    int minNumberInRotateArray(vector&lt;int&gt; rotateArray) &#123;        if (rotateArray.size() == 0) &#123;            return 0;        &#125;        int low = 0;        int high = rotateArray.size() - 1;        while (low &lt; high) &#123;            // 处理特殊的情况，两边不是递增的序列            if (rotateArray[low] &lt; rotateArray[high]) &#123;                return rotateArray[low];            &#125;                        int mid = (low + high) / 2;            if (rotateArray[mid] &gt; rotateArray[low]) &#123;                  low = mid + 1;   // 左边是递增的序列，取右边的第一个值            &#125;            else if (rotateArray[mid] &lt; rotateArray[high]) &#123;                 high = mid;      // 右边有序列，取右边最小值            &#125;            else &#123;               // 前面两个相等的时候，low加一继续                low++;            &#125;        &#125;        return rotateArray[low];    &#125;&#125;;

]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>codingInterview</tag>
        <tag>11-旋转数组的最小数字</tag>
      </tags>
  </entry>
  <entry>
    <title>215-数组中的第K个最大元素</title>
    <url>/CodingInterview/Interview/CodingInterview/215-%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[
题目：数组中的第K个最大元素描述
在未排序的数组中找到第 k 个最大的元素。请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。
示例 1:
输入: [3,2,1,5,6,4] 和 k = 2输出: 5


示例 2:
输入: [3,2,3,1,2,4,5,5,6] 和 k = 4输出: 4
说明:
你可以假设 k 总是有效的，且 1 ≤ k ≤ 数组的长度。
思路建立一个大根堆，做 k - 1 次删除操作后堆顶元素就是我们要找的答案。
法一：K数值比较小时，可采用快速排序；复杂度：n * log(length)
法二：1、当原数组中的数据顺序不可修改，且K数值很大时（海量数据），采用快速排序可能会占满内存，效率不高。因此使用最大堆数据结构实现。
2、先把前 k 个数据建立一个大根堆，然后对后面的 length-k 个数依次遍历，如果当前数值小于堆顶的值时，，则替换堆顶的值，然后对大根堆做向下调整。复杂度：n * log(k)
复杂度分析

时间复杂度：O(n*log n)，建堆的时间代价是 O(n)，删除的总代价是 O(k*log n)，因为 k &lt; n，故渐进时间复杂为 O(n + k *log n) = O(n *log n)。
空间复杂度：O(log n)，即递归使用栈空间的空间代价。

关键点
建堆
调整堆
删除
代码实现// 调整堆void adjustHeap(vector&lt;int&gt;&amp; input, int i, int length) &#123;    int left = 2 * i + 1;  // i节点的左孩子，i从 0 开始    int right = 2 * i + 2; // i节点的右孩子    int max = i;           // 先设置父节点和子节点三个节点中最大值的位置为父节点下标    if (left &lt; length &amp;&amp; input[left] &gt; input[max])    &#123;        max = left;  // 如果左孩子存在且大于最大值，更新最大值索引    &#125;    if (right &lt; length &amp;&amp; input[right] &gt; input[max])     &#123;        max = right;  //如果右孩子存在且大于最大值，更新最大值索引    &#125;    if (max != i) //最大值不是父节点，则进行交换    &#123;        // int temp = input[i];        // input[i] = input[max];        // input[max] = temp;        swap(input[i], input[max]);     // 交换对应索引位置的节点值        adjustHeap(input, max, length); // 从最大值索引位置向下进行递归调用，保证子树也是最大堆    &#125;&#125;int findKthLargest(vector&lt;int&gt;&amp; nums, int k) &#123;    // 只需要建立一次最大堆，后面再调整最大堆    for (int i =  nums.size() / 2; i &gt;= 0; i--) &#123;          adjustHeap(nums, i,  nums.size());  // 从堆树第一个非叶子节点开始调整    &#125;    int heapSize = nums.size();    for (int i = nums.size() - 1; i &gt;= nums.size() - k + 1; i--) &#123;        swap(nums[0], nums[i]);  //将末尾结点补充到堆顶进行调整        --heapSize;        adjustHeap(nums, 0, heapSize);    &#125;    return nums[0];&#125;]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>codingInterview</tag>
        <tag>215-数组中的第K个最大元素</tag>
      </tags>
  </entry>
  <entry>
    <title>24-反转链表</title>
    <url>/CodingInterview/Interview/CodingInterview/24-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[

题目：反转链表描述输入一个链表，反转链表后，输出新链表的表头。
实例：
输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL

思路法一：利用外部空间
这种方式很简单，先申请一个动态扩容的数组或者容器，比如 ArrayList 这样的。然后不断遍历链表，将链表中的元素添加到这个容器中。再利用容器自身的 API，反转整个容器，这样就达到反转的效果了。最后同时遍历容器和链表，将链表中的值改为容器中的值。
链表按这个顺序重新被设置一边，就达到要求啦。当然你可以可以再新创建 N 个节点，然后再返回，这样也可以达到目的。这种方式很简单，但你在面试中这么做的话，面试官 100% 会追问是否有更优的方式，比如不用外部空间。
法二：双指针迭代（推荐）
申请两个指针，第一个指针叫 pre，最初是指向 nullptr 的。第二个指针 cur 指向 head，然后不断遍历 cur。每次迭代到 cur，都将 cur 的 next 指向 pre，然后 pre 和 cur 前进一位。都迭代完了(cur 变成 nullptr 了)，pre 就是最后一个节点了。

需要定义一个 temp  变量将cur的下一个节点保存起来，因为cur指针改变指向后，后面的链表失效了。

动画效果实现

法三：递归解法
递归的两个条件：
终止条件是当前节点或者下一个节点&#x3D;&#x3D;null在函数内部，改变节点的指向，也就是 head 的下一个节点指向 head 递归函数那句
head.next.next = head
很不好理解，其实就是 head 的下一个节点指向head。递归函数中每次返回的 cur 其实只最后一个节点，在递归函数内部，改变的是当前节点的指向。
关键点先改变指针指向，再移动指针。
复杂度双指针解法：时间复杂度：O(n), 遍历一次链表；空间复杂度 O(1)
代码实现struct ListNode &#123;	int val;	struct ListNode *next;	ListNode(int x) :			val(x), next(NULL) &#123;	&#125;&#125;;// 迭代法实现ListNode* ReverseList(ListNode* pHead) &#123;    ListNode* pre = nullptr;    ListNode* cur = head;    while (cur != nullptr) &#123;        ListNode* temp = cur-&gt;next;        cur-&gt;next = pre;        pre = cur;        cur = temp;    &#125;    return pre;&#125;

参考动画演示+多种解法 206. 反转链表
]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>codingInterview</tag>
        <tag>24-反转链表</tag>
      </tags>
  </entry>
  <entry>
    <title>40-最小的K个数</title>
    <url>/CodingInterview/Interview/CodingInterview/40-%E6%9C%80%E5%B0%8F%E7%9A%84K%E4%B8%AA%E6%95%B0/</url>
    <content><![CDATA[第40题：最小的K个数题目描述：输入n个整数，找出其中最小的K个数。例如输入4,5,1,6,2,7,3,8这8个数字，则最小的4个数字是1,2,3,4。
示例1
输入：[4,5,1,6,2,7,3,8],4

返回值：[1,2,3,4]

实现思路方法一：直接采用排序的方式，调用STL中sort 方法对原数组从小到大排序后取出前 k 个数即可。
vector&lt;int&gt; getLeastNumbers(vector&lt;int&gt;&amp; arr, int k) &#123;    sort(arr.begin(), arr.end());    vector&lt;int&gt; v(k, 0);    for (int i = 0; i &lt; k; ++i) &#123;        v[i] = arr[i];    &#125;    return v;&#125;```    复杂度分析- 时间复杂度：`O(n*log n)`，其中 n 是数组 arr 的长度。算法的时间复杂度即排序的时间复杂度。- 空间复杂度：`O(log n)`，排序所需额外的空间复杂度为 `O(log n)`。### 方法二：利用快速排序的方法实现。实现原理：基于数组的第K个数字来调整，使得比K个数字小的所有数字都位于数组的左边，比第K个数字大的所有数字都位于数组的右边，经过这样的调整后，位于数组中左边的K个数字就是最小的K个数字。```cppclass Solution &#123;public:    int partition(vector&lt;int&gt;&amp; array, int low, int high)    &#123;        int piv = array[low];        while (low &lt; high) &#123;            while ((low &lt; high) &amp;&amp; (array[high] &gt;= piv)) &#123;                high--;            &#125;            array[low] = array[high];            while ((low &lt; high) &amp;&amp; (array[low] &lt;= piv)) &#123;                low++;            &#125;            array[high] = array[low];        &#125;        array[low] = piv;        return low;    &#125;        void quickSort(vector&lt;int&gt;&amp; input, int low, int high, int k)    &#123;        int pivot = partition(input, low, high);                if (pivot == k) &#123;            return;        &#125;        else if (pivot &gt; k) &#123;            quickSort(input, 0, pivot-1, k);        &#125;        else &#123;            quickSort(input, pivot+1, high, k);        &#125;    &#125;        vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k)    &#123;        vector&lt;int&gt; ret;        if (k == 0 || k &gt; input.size()) &#123;            return ret;        &#125;        int low = 0;        int high = input.size() - 1;        quickSort(input, low, high, k);        for (int i=0; i&lt;k; i++)&#123;            ret.push_back(input[i]);        &#125;        return ret;    &#125;&#125;;

时间复杂度为：$\Omicron(n)$ 每次partition的大小为n+n/2+n/4+... = 2n,最坏时间复杂度为 O(n^2), 因为每次partition都只减少一个元素
空间复杂度：$\Omicron(1)$
方法三：最大堆实现利用实现原理：先把前 k 个数据建立一个大根堆，然后对后面的 length-k 个数依次遍历，如果当前数值小于堆顶的值时，则替换堆顶的值，然后对大根堆做向下调整。

可以采用优先级队列，C++中的优先级队列为大根堆。

class Solution &#123;public:    void adjustHeap(vector&lt;int&gt;&amp; input, int i, int length)     &#123;        int left = 2 * i + 1;  // i节点的左孩子，i从 0 开始        int right = 2 * i + 2; // i节点的右孩子        int max = i;           // 先设置父节点和子节点三个节点中最大值的位置为父节点下标        if (left &lt; length &amp;&amp; input[left] &gt; input[max]) &#123;            max = left;        &#125;        if (right &lt; length &amp;&amp; input[right] &gt; input[max]) &#123;            max = right;        &#125;                //最大值不是父节点，则进行交换        if (max != i) &#123;            int temp;            temp = input[i];            input[i] = input[max];            input[max] = temp;            adjustHeap(input, max, length); //递归调用，保证子树也是最大堆        &#125;    &#125;    vector&lt;int&gt; GetLeastNumbers_Solution(vector&lt;int&gt; input, int k)    &#123;        if (input.empty() || k == 0 || k &gt; input.size()) &#123;            return vector&lt;int&gt;&#123;&#125;;        &#125;        vector&lt;int&gt; result;        //建立堆        for (int i = input.size() / 2 - 1; i &gt;= 0; i--) &#123;            adjustHeap(input, i, k); //堆的大小为k        &#125;        //将后面的数依次和K个数的最大值比较        for (int i = k; i &lt; input.size(); i++) &#123;            if (input[0] &gt; input[i]) &#123;                int temp = input[i];                input[i] = input[0];                input[0] = temp;                adjustHeap(input, 0, k);            &#125;        &#125;        for (int i = 0; i &lt; k; i++) &#123;            result.push_back(input[i]);        &#125;        return result;    &#125;&#125;;

时间复杂度：O(nlongk), 插入容量为k的大根堆时间复杂度为O(longk), 一共遍历n个元素空间复杂度：O(k)
方法比较当K数值比较小时，可采用快速排序；当原数组中的数据顺序不可修改，且K数值很大时（海量数据），采用快速排序可能会占满内存，效率不高。此时使用最大堆数据结构实现最好。
参考LeetCode解题思路
]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>codingInterview</tag>
        <tag>40-最小的K个数</tag>
      </tags>
  </entry>
  <entry>
    <title>5-用两个栈实现队列</title>
    <url>/CodingInterview/Interview/CodingInterview/5-%E7%94%A8%E4%B8%A4%E4%B8%AA%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[

第5题：用两个栈实现队列题目描述用两个栈来实现一个队列，完成队列的 Push 和 Pop 操作。 队列中的元素为 int 类型。
解题思路
stack 的特点：先进后出
queue 的特点：先进先出
push 操作就直接往 stack1 中 push， pop 操作需要分类一下：如果 stack2 为空，那么需要将 stack1 中的数据转移到 stack2 中，然后在对 stack2 进行 pop，如果 stack2 不为空，直接 pop 就 ok。

具体代码实现
class Solution&#123;public:    void push(int node) &#123;        stack1.push(node);    &#125;    int pop() &#123;        if (stack2.empty()) &#123;            while(!stack1.empty())&#123;                stack2.push(stack1.top());                stack1.pop();            &#125;        &#125;        int ret = stack2.top();        stack2.pop();        return ret;    &#125;private:    stack&lt;int&gt; stack1;    stack&lt;int&gt; stack2;&#125;;

复杂度
push时间复杂度：$\Omicron(1)$
pop空间复杂度：$\Omicron(1)$


所有题目按照牛客网的顺序来编写，而非剑指offer书上的顺序。所有题目都采用C++实现的，都能在牛客网的OJ上面直接运行。

]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>codingInterview</tag>
        <tag>5-用两个栈实现队列</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/CodingInterview/Interview/CodingInterview/README/</url>
    <content><![CDATA[
Coding Interview为剑指offer的英文名，该文件包含剑指offer中所有题目的具体实现：代码和解题思路。
]]></content>
      <categories>
        <category>CodingInterview</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
        <tag>interview</tag>
        <tag>codingInterview</tag>
      </tags>
  </entry>
  <entry>
    <title>1-两数之和</title>
    <url>/LeetCode/Interview/LeetCode/1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[
1-两数之和题目描述给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。
你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。
你可以按任意顺序返回答案。
 
示例 1：
输入：nums = [2,7,11,15], target = 9输出：[0,1]解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。

示例 2：
输入：nums = [3,2,4], target = 6输出：[1,2]

示例 3：
输入：nums = [3,3], target = 6输出：[0,1]

解法法一：暴力解法class Solution &#123;public:    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;        int len = nums.size();        for (int i = 0; i &lt; len; i++) &#123;            for (int j = i + 1; j &lt; len; j++) &#123;                if (nums[i] + nums[j] == target) &#123;                    return &#123;i, j&#125;;                &#125;            &#125;        &#125;        return &#123;&#125;;    &#125;
算法复杂时间复杂度：$\Omicron(n^2)$空间复杂度：$\Omicron(1)$
法二：利用 hashtable 实现将数组中的元素用hashtable存储，并在这个hashtable中查找 target 与数组中当前位置元素值的差值是否也在当前这个hashtable中，若存在，就将各自对应的下标值输出。

注意：先查询哈希表中是否存在 target - nums[i]，然后再将 nums[i] 插入到哈希表中，保证不会让 nums[i] 和得到的差值重复。

class Solution &#123;public:    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;        unordered_map&lt;int, int&gt; mp;        vector&lt;int&gt;result;        for (int i = 0; i &lt; nums.size(); i++) &#123;            // mp[nums[i]] = i;            auto it = mp.find(target - nums[i]);            if (it != mp.end()) &#123;                result = &#123;&#123;it-&gt;second, i&#125;&#125;;             &#125;            mp[nums[i]] = i;         &#125;        return result;    &#125;&#125;;
算法复杂时间复杂度：$\Omicron(n)$空间复杂度：$\Omicron(n)$，主要为hashtable的开销。
]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>1-两数之和</tag>
      </tags>
  </entry>
  <entry>
    <title>15-三数之和</title>
    <url>/LeetCode/Interview/LeetCode/15-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[
15-三数之和题目描述给你一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c &#x3D; 0 ？请你找出所有和为 0 且不重复的三元组。
注意：答案中不可以包含重复的三元组。
 示例 1：
输入：nums = [-1,0,1,2,-1,-4]输出：[[-1,-1,2],[-1,0,1]]

示例 2：
输入：nums = []输出：[]

示例 3：
输入：nums = [0]输出：[]
题解排序 + 双指针
先对原数组进行排序，在排序好序的数组中先固定一个值，然后将该题转化为求两数之和为一个固定值。
代码class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123;        std::sort(nums.begin(), nums.end());     // 递增排序          int len = nums.size();        vector&lt;vector&lt;int&gt;&gt; arr;                // 保存所有不重复的三元组的结果        if (len &lt; 3) &#123;  // 特判            return &#123;&#125;;        &#125;        for (int i = 0; i &lt; len; i++) &#123;         // 固定第一个数，转化为求两数之和            if (nums[i] &gt; 0) &#123;                  // 第一个数大于 0，后面都是递增正数，不可能相加为零了                return arr;            &#125;            if (i &gt; 0 &amp;&amp; (nums[i] == nums[i - 1])) &#123;                  continue;                       // 去重：如果此数已经选取过，跳过            &#125;            // 双指针在nums[i]后面的区间中寻找和为 0-nums[i] 的另外两个数            int left = i + 1;            int right = len - 1;            while (left &lt; right) &#123;                if (nums[left] + nums[right] &gt; -nums[i]) &#123;                    right--;                     // 两数之和太大，右指针左移                &#125;                else if (nums[left] + nums[right] &lt; -nums[i]) &#123;                    left++;                      // 两数之和太小，左指针右移                &#125;                 else &#123;                    // 找到一个和为零的三元组，添加到结果中，左右指针内缩，继续寻找                    arr.push_back(vector&lt;int&gt;&#123;nums[i], nums[left], nums[right]&#125;);                    left++;                    right--;                    // 去重：第二个数和第三个数也不重复选取                    // 例如：[-4,1,1,1,2,3,3,3], i=0, left=1, right=5                    while (left &lt; right &amp;&amp; nums[left] == nums[left - 1]) &#123;                        left++;                    &#125;                    while (left &lt;right &amp;&amp; nums[right] == nums[right + 1]) &#123;                        right--;                    &#125;                &#125;            &#125;        &#125;        return arr;    &#125;&#125;;

参考
Terry 解三数之和的思路

]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>15-三数之和</tag>
      </tags>
  </entry>
  <entry>
    <title>21-合并两个有序链表</title>
    <url>/LeetCode/Interview/LeetCode/21-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[
21-合并两个有序链表题目描述将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 
 
示例 1：
输入：l1 = [1,2,4], l2 = [1,3,4]输出：[1,1,2,3,4,4]

示例 2：
输入：l1 = [], l2 = []输出：[]

示例 3：
输入：l1 = [], l2 = [0]输出：[0]

思路法一：递归法如果 l1 或者 l2 一开始就是空链表 ，那么没有任何操作需要合并，所以我们只需要返回非空链表。否则就要判断 l1 和 l2 头结点哪个最小，然后递归的决定下一个将要添加到 mergeList中的结点。如果两个链表有一个为空，递归结束。

代码实现
class Solution &#123;public:    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123;        if (l1 == nullptr) &#123;            return l2;        &#125;        if (l2 == nullptr) &#123;            return l1;        &#125;        if (l1-&gt;val  &lt; l2-&gt;val) &#123;            l1-&gt;next = mergeTwoLists(l1-&gt;next, l2);            return l1;        &#125;        else &#123;            l2-&gt;next = mergeTwoLists(l1, l2-&gt;next);            return l2;        &#125;    &#125;&#125;;

复杂度分析时间复杂度：O(n + m)，其中 n 和 m 分别为两个链表的长度。因为每次调用递归都会去掉 l1 或者 l2 的头节点（直到至少有一个链表为空），函数 mergeTwoList 至多只会递归调用每个节点一次。因此，时间复杂度取决于合并后的链表长度，即 O(n+m)。


空间复杂度：O(n + m)，其中 n 和 m 分别为两个链表的长度。递归调用 mergeTwoLists 函数时需要消耗栈空间，栈空间的大小取决于递归调用的深度。结束递归调用时 mergeTwoLists 函数最多调用 n+m 次，因此空间复杂度为 O(n+m)。
法二：迭代法我们可以用迭代的方法来实现上述算法。当 l1 和 l2 都不是空链表时，判断 l1 和 l2 哪一个链表的头节点的值更小，将较小值的节点添加到结果里，当一个节点被添加到结果里之后，将对应链表中的节点向后移一位。
首先，我们设定一个哨兵节点 prehead ，这可以在最后让我们比较容易地返回合并后的链表。我们维护一个 prev 指针，我们需要做的是调整它的 next 指针。然后，我们重复以下过程，直到 l1 或者 l2 指向了 null ：如果 l1 当前节点的值小于等于 l2 ，我们就把 l1 当前的节点接在 prev 节点的后面同时将 l1 指针往后移一位。否则，我们对 l2 做同样的操作。不管我们将哪一个元素接在了后面，我们都需要把 prev 向后移一位。
在循环终止的时候， l1 和 l2 至多有一个是非空的。由于输入的两个链表都是有序的，所以不管哪个链表是非空的，它包含的所有元素都比前面已经合并链表中的所有元素都要大。这意味着我们只需要简单地将非空链表接在合并链表的后面，并返回合并链表即可。
下图展示了 1-&gt;4-&gt;5 和 1-&gt;2-&gt;3-&gt;6 两个链表迭代合并的过程：

代码实现
class Solution &#123;public:    ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123;        ListNode* preHead = new ListNode(-1);        ListNode* prev = preHead;        while (l1 != nullptr &amp;&amp; l2 != nullptr) &#123;            if (l1-&gt;val &lt; l2-&gt;val) &#123;                prev-&gt;next = l1;  // 把 l1 当前的节点接在 prev 节点的后面                l1 = l1-&gt;next;    //将 l1 指针往后移一位            &#125; else &#123;                prev-&gt;next = l2;                l2 = l2-&gt;next;            &#125;            prev = prev-&gt;next;  // 移动prev指针        &#125;        // 合并后 l1 和 l2 最多只有一个还未被合并完，我们直接将链表末尾指向未合并完的链表即可        prev-&gt;next = l1 == nullptr ? l2 : l1;        return preHead-&gt;next;  // 返回合并后的链表    &#125;&#125;;

复杂度分析时间复杂度：O(n + m)，其中 n 和 m 分别为两个链表的长度。因为每次循环迭代中，l1 和 l2 只有一个元素会被放进合并链表中， 因此 while 循环的次数不会超过两个链表的长度之和。所有其他操作的时间复杂度都是常数级别的，因此总的时间复杂度为 O(n+m)。


空间复杂度：O(1)。我们只需要常数的空间存放若干变量。
参考合并两个有序链表
]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>21-合并两个有序链表</tag>
      </tags>
  </entry>
  <entry>
    <title>3-无重复字符的最长子串</title>
    <url>/LeetCode/Interview/LeetCode/3-%E6%97%A0%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[
3-无重复字符串的最长子串题目描述给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。
示例 1:
输入: s = &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。

示例 2:
输入: s = &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。

示例 3:
输入: s = &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。     请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。

示例 4:
输入: s = &quot;&quot;输出: 0


思路采用滑动窗口的思想。
题解
C++版本实现class Solution &#123;public:    int lengthOfLongestSubstring(string s) &#123;        int res = 0; // 记录最长无重复子串的长度        int left = -1; // 指向该无重复子串左边的起始位置的前一个        unordered_map&lt;int, int&gt; m;        for (int i = 0; i &lt; s.size(); ++i) &#123;                        // 判断当前字符是否在HashMap中已存在            // 若当前字符已在HashMap中，且映射值大于left的话，更新 left 为当前映射值            if (m.count(s[i]) &amp;&amp; m[s[i]] &gt; left) &#123;                left = m[s[i]];  // 若存在，移除之前在窗口出现的字符            &#125;                        m[s[i]] = i;  // 更新映射值为当前坐标i,这样保证了 left 始终为当前边界的前一个位置            res = max(res, i - left);   // 计算窗口长度                 &#125;        return res;    &#125;&#125;;

复杂度时间复杂度：O(N)
空间复杂度：O(N)
参考
无重复字符的最长子串 c++实现三种解法 多重循环，hashmap优化，桶优化
滑动窗口
[LeetCode] 3. Longest Substring Without Repeating Characters

]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>3-无重复字符的最长子串</tag>
      </tags>
  </entry>
  <entry>
    <title>53.-最大子序和</title>
    <url>/LeetCode/Interview/LeetCode/53.-%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/</url>
    <content><![CDATA[

53-最大子序和题目描述给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。
 示例 1：
输入：nums = [-2,1,-3,4,-1,2,1,-5,4]输出：6解释：连续子数组 [4,-1,2,1] 的和最大，为 6 。

示例 2：
输入：nums = [1]输出：1

示例 3：
输入：nums = [0]输出：0

示例 4：
输入：nums = [-1]输出：-1

示例 5：
输入：nums = [-100000]输出：-100000


解法法一：暴力解法代码
class Solution &#123;public:    int maxSubArray(vector&lt;int&gt;&amp; nums) &#123;        if (nums.size() == 1) &#123;            return nums[0];        &#125;        int max = INT_MIN;   // 理论上的最小值        for (int i = 0; i &lt; nums.size(); i++) &#123;            int sum = 0;            for (int j = i; j &lt; nums.size(); j++) &#123;                sum += nums[j];                if (sum &gt; max) &#123;                    max = sum;                &#125;            &#125;        &#125;        return max;    &#125;&#125;;


复杂度
时间复杂度$\Omicron(n^2)$
空间复杂度$\Omicron(1)$
法二：动态规划class Solution &#123;public:    int maxSubArray(vector&lt;int&gt;&amp; nums) &#123;        int resultMax = INT_MIN;         int len = nums.size();        vector&lt;int&gt; arr(len);                arr[0] = nums[0];        resultMax = arr[0];        for (int i = 1; i &lt; len; i++) &#123;            arr[i] = max(arr[i - 1] + nums[i], nums[i]);            resultMax = max(resultMax, arr[i]);        &#125;        return resultMax;    &#125;&#125;;


复杂度
时间复杂度$\Omicron(n)$
空间复杂度未优化之前：$\Omicron(n)$
优化
class Solution &#123;public:    int maxSubArray(vector&lt;int&gt;&amp; nums) &#123;        int maxSum = nums[0];        int arr = 0;  // 用于存储数组中前 i-1 个变量的子数组之和        for (const auto&amp; num : nums) &#123;            arr = max(arr + num, num);            maxSum = max(arr, maxSum);        &#125;        return maxSum;    &#125;&#125;;



复杂度
时间复杂度$\Omicron(n)$
空间复杂度优化之后：$\Omicron(1)$
参考最大子序和 c++实现四种解法 暴力法、动态规划、贪心法和分治法 图示讲解
]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>53.-最大子序和</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode-Terminology</title>
    <url>/LeetCode/Interview/LeetCode/LeetCode-Terminology/</url>
    <content><![CDATA[
Terminology英文对应的中文术语

Submit: 提交当前的code到leetcode网站，帮我们提交代码。
Test: 执行样例，看看样例是否能够通过。
Solution: 查看当前最高赞的代码。
Description: 显示问题描述。

如何解题？按照类型刷题，不要按照题号从1依次往后开始刷，这样做效果很慢。
剑指 offer 是大部分公司的出题源头，刷完，面试中基本会遇到现题或者变形题。
Reference
VSCode中配置LeetCode插件
Github官方解释无法登录 LeetCode 节点的临时解决办法

]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>leetCode-Terminology</tag>
      </tags>
  </entry>
  <entry>
    <title>刷题参考</title>
    <url>/LeetCode/Interview/LeetCode/%E5%88%B7%E9%A2%98%E5%8F%82%E8%80%83/</url>
    <content><![CDATA[


Coding4Interviews 仓库中有剑指offer和LeetCode的题解
CodingInterviewChinese2 剑指offer第二版的作者写的源代码
interviews  Kevin Naughton Jr撰写的软件工程技术面试个人指南
CS-Notes  技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计、Java、Python、C++
heAlgorithms&#x2F;C   Collection of various algorithms in mathematics, machine learning, computer science, physics, etc implemented in C for educational purposes.
coding-interview-university 一套完整的学习手册帮助自己准备 Google 的面试
soulmachine&#x2F;leetcode LeetCode题解，151道题完整版
LeetCode All In One 提供所有LeetCode题目的讲解
程序员如何准备面试中的算法 讲解了面试中一些常见的算法题。
algorithm-pattern 算法模板，最科学的刷题方式，最快速的刷题路径。
LeetcodeTop  汇总各大互联网公司容易考察的高频leetcode题🔥
fucking-algorithm  LeetCode算法刷题套路，共 60 多篇原创文章，涵盖了所有题型和技巧，而且一定要做到举一反三，通俗易懂。
leetcode_101:LeetCode上101到题，和你一起你轻松刷题（C++）
即时通讯网：网站内容很丰富，很全面，各种资料都有，平时重点学习。

]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>刷题参考</tag>
      </tags>
  </entry>
  <entry>
    <title>找出数组中比左边的大比右边的小的元素</title>
    <url>/LeetCode/Interview/LeetCode/%E6%89%BE%E5%87%BA%E6%95%B0%E7%BB%84%E4%B8%AD%E6%AF%94%E5%B7%A6%E8%BE%B9%E7%9A%84%E5%A4%A7%E6%AF%94%E5%8F%B3%E8%BE%B9%E7%9A%84%E5%B0%8F%E7%9A%84%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[

题目找出数组中比左边的大比右边的小的元素
题目描述一个整形数组，找出所有满足如下要求的数：所有它左边的数都比它小，所有右边的数都比它大。例如：数组[1, 2, 4, 3, 9, 5, 6, 12, 15]，数组中l,2，12满足条件，时间复杂度要求小于等于O(Xn)，X为常数。
思路定义一个辅助数组存右侧最小值，从右往左依次遍历，将当前值与后一个值的最小值存入辅助数组中；然后再从左往右依次遍历，得到左侧的最大值，当这个值与辅助数组中最小值相等时，满足条；即左边最大等于右边最小时满足条件。
题解#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;vector&lt;int&gt; func(int data[], int len)&#123;    vector&lt;int&gt; vec;    int* right_min = new int[len];       // 定义一个辅助数组存右侧最小值    right_min[len - 1] = data[len - 1];  // 数组的最后一位存最右侧值，设初值    for (int i = len - 2; i &gt;= 0; --i) &#123;        right_min[i] = std::min(data[i], data[i+1]);    &#125;        int left_max = 0;    for (int i = 0; i &lt; len; ++i) &#123;        left_max = std::max(data[i], left_max);        if (left_max == right_min[i]) &#123;            vec.push_back(left_max);        &#125;    &#125;    return vec;&#125;int main() &#123;    int array[] = &#123;1, 2, 4, 3, 9, 5, 6, 12, 15&#125;;    int length = sizeof(array)/sizeof(int);    func(array, length);    return 0;&#125;]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>interview</tag>
        <tag>leetCode</tag>
        <tag>找出数组中比左边的大比右边的小的元素</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile</title>
    <url>/CMake/Linux/CMake/Makefile/</url>
    <content><![CDATA[




1. Makefile
1.1. 什么是 Makefile?
1.2. 什么是 Make 和 configure ？
1.3. 检测程序会检测哪些内容？
1.4. 源码下载
1.5. 操作步骤
1.6. 三个基本要素






1. Makefile1.1. 什么是 Makefile?它是记录编译记录的文件。有两种命名的方式：全小写 makefile 或首字母大写 Makefile。
1.2. 什么是 Make 和 configure ？make 是一个程序，会去找 Makefile ，那 Makefile 怎么写？ 通常软件开发商都会写一个检测程序来侦测使用户的操作环境， 以及操作环境是否有软件开发商所需要的其他功能，该检测程序检测完毕后， 就会主动的建立这个 Makefile 的规则文件， 通常这个检测程序的文件名为 configure 或者是 config 。
1.3. 检测程序会检测哪些内容？
是否有合适的编译可以编译本软件的代码
是否存在有本软件所需要的函数库，或其它的所需的依赖软件
操作系统是否适合本软件，包括 Linux 的内核
内核的头文件（header include）是否存在，驱动程序必须要的检测

1.4. 源码下载同一个软件在不同的平台上执行，需要重新编译，这就是为什么在下载类 Linux 的软件程序时，会提供源码下载。
1.5. 操作步骤
直接使用 make 指令，会生成 Makefile 文件中定义的最终目标文件。
使用 make 自定义变量名，会执行自定义变量名下面定义的规则指令。

1.6. 三个基本要素
目标
依赖
命令

 
  


  

 
  




一个规则

两个函数。每个函数都有返回值

src= $(wildcard ./*c) 查找指定目录 ./ 下所有 .c 的文件，并将函数的返回值赋值给 src 变量
匹配替换函数  obj = $(patsubst ./%.c, ./%.o, $(src)) 将指定目录 ./ 下所有的 .c 替换为 .o文件


三个变量

自定义变量
自动变量
$&lt; 规则中的第一个依赖
$@ 规则中的目标
$^ 规则中的所有依赖


系统维护的变量(一般为大写字符) 
CPPFLAGS 预处理所需要的的选项。如：-I
CFLAGS   编译时使用的参数。-Wall, -g, -c
LDFLAGS  链接库使用的选项。-L -l(小写)
CC 等于gcc




伪目标 .PHONY 

.PHONY: clean
- 表示当前指令执行不成功则忽略当前指令。


模式规则
// 给相同的命令指定一个规则%.o: %c    gcc -c $&lt; -o $@

]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cMake</tag>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title>cmake-tutorial</title>
    <url>/CMake/Linux/CMake/cmake-tutorial/</url>
    <content><![CDATA[

1. CMake 教程2. 语法特性
基本语法格式：命令(参数1 参数2 …)

参数使用花括号括起来。
参数之间使用空格或分号分隔开。


命令是不区分大小的，参数和变量是区分大小写的。


# 给 test.cpp 设置一个变量 TESTset(TEST test.cpp)# 生成可执行文件需要依赖的内容add_executable(test main.cpp test.cpp)ADD_EXECUTABLe(test main.cpp test.cpp)  # 与上一条的用法一样

2.1. 变量获取时使用 $&#123;&#125; 的方式去取值，若在 if 语句中则需要直接使用变量名，不能使用 $&#123;&#125; 的方式。
set(TEST test.cpp)

2.2. CMake 命令CMake 命令官方总共分为 4 大类。

Scripting Commands
Project Commands
CTest Commands
Deprecated Commands

下面仅仅列出常见的一些命令。
2.2.1. cmake_minimum_required# 设置最低CMake版本要求cmake_minimum_required(VERSION 3.12)

2.2.2. project设置工程的名字
语法：project(&lt;PROJECT-NAME&gt; [&lt;language-name&gt;...])project(&lt;PROJECT-NAME&gt;        [VERSION &lt;major&gt;[.&lt;minor&gt;[.&lt;patch&gt;[.&lt;tweak&gt;]]]]        [DESCRIPTION &lt;project-description-string&gt;]        [HOMEPAGE_URL &lt;url-string&gt;]        [LANGUAGES &lt;language-name&gt;...])        # 项目名称project(TestProj)

 设置工程的名字，并存储在变量 TestProj 中，当被上一级的 CMakeLists.txt 调用时，工程的名字被存在变量 CMAKE_PROJECT_NAME 中。
2.2.3. set编译器相关设置
# 添加c++11标准支持set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11&quot;)    # 默认c编译器SET(CMAKE_C_COMPILER &quot;gcc.exe&quot;)# 默认c++编译器SET(CMAKE_CXX_COMPILER &quot;g++.exe&quot;)# 设置编译类型为 debugset(CMAKE_BUILD_TYPE Debug)# 设置编译类型为 releaseset(CMAKE_BUILD_TYPE Release)

GDB 调试设置
# Debug模式 选项: Release Debug MinSizeRel RelWithDebInfoSET(CMAKE_BUILD_TYPE &quot;Debug&quot;)# debug模式下 gdb相关选项SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g2 -ggdb&quot;)  # release模式下 gdb相关选项SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;)  # 开启调试 出现问题时开启# set(CMAKE_CXX_STANDARD_REQUIRED ON)

可执行文件
# 设置可执行文件输出的目录set(EXECUTABLE_OUTPUT_PATH $&#123;PROJECT_BINARY_DIR&#125;/bin)   

2.2.4. add_definitions# 设置字符集add_definitions(-DUNICODE -D_UTF-8) 

2.2.5. add_compile_options添加编译参数
语法：add_compile_options(&lt;option&gt; ...)# 添加编译参数 -Wall std=c++11 -O3add_compile_options(-Wall std=c++11 -O3)



2.2.6. add_library生成库文件
语法：add_library(libname [SHARED | STATIC | MODULE] [EXCULD_FROM_ALL] src1 src2 ...)# 通过变量 SRC 生成 libtest.so 共享库，生成的时候会加上 lib 前缀和 .so 后缀add_library(test SHARED $&#123;SRC&#125;)

2.2.7. add_executable生成可执行文件
# 指定 Src 目录下源文件生成的可执行文件的名字: mainadd_executable(main $&#123;SOURCES&#125;)

2.2.8. add_subdirectory向工程中添加存放源文件的子目录，作为可选项，可指定二进制文件或二进制文件存放的位置。
语法：add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL])# 工程中添加 google 子目录# add_subdirectory(google)



2.2.9. include_directories# 向工程中添加头文件路径，参数项可为一个或多个语法：include_directories(dir1 dir2 ...)include_directories($&#123;TEST_PATH&#125;/include)



2.2.10. file枚举头文件
# 枚举头文件file(GLOB_RECURSE INCLUDES &quot;Inc/*.h&quot; &quot;Inc/*.hpp&quot;)  

2.2.11. aux_source_directory搜索指定目录 dir 下所有的源文件，并将结果列表存储在变量 variable 中。
语法：aux_source_directory(&lt;dir&gt; &lt;variable&gt;)# 搜索 Src 目录下所有的源文件，并将结果列表存储在变量 SOURCES 中aux_source_directory(Src SOURCES) 

2.2.12. link_directories# 依赖的链接库路径link_directories($&#123;TEST_PATH&#125;/cmake/build)

2.2.13. target_link_libraries为目标文件链接所需要的共享库。
语法：target_link_libraries(&lt;target&gt; ... &lt;item&gt;... ...)# 添加链接库# target_link_libraries(demo math) 


target 目标名字必须通过 add_executable() 或 add_library() 命令创建的，不能是一个别名。
item 可以下面几种类型。
A library target name：
A full path to a library file：
A plain library name：
A link flag: 
A generator expression。



2.2.14. if&#x2F;elseif# 区分操作系统MESSAGE(&quot;Identifying the OS...&quot;)if(WIN32)  MESSAGE(&quot;This is Windows.&quot;)elseif(APPLE)  MESSAGE(&quot;This is MacOS.&quot;)elseif(UNIX)  MESSAGE(&quot;This is Linux.&quot;)endif()

2.2.15. install# 安装COPYRIGHT 和 README 文件到 /usr/local/share/doc/cmake 路径下install(files COPYRIGHT destination share/doc/cmake)# 安装脚本文件到 /usr/local/bin 下面install(program run_shell.sh destation bin)# 安装二进制文件到 /usr/local/bin 路径下install(targets hello destation lib)

安装的时候可以指定绝对路径，也可以指定相对路径。其中，使用相对路径时，
cmake_install_prefix 默认安装路径在 /usr/local，自己指定文件安装路径：cmake_install_prefix=/usr
# 安装文件到某个目录下install(directory doc/ destation share/doc/cmake)

安装的文件后面是否带有 /，安装时有很大的区别：

doc/ 文件后带有 / 表示将 doc 路径下的所有文件安装到 /usr/local/share/doc/cmake 路径下。
doc 文件后不带 / 表示将 doc 整个文件安装到 /usr/local/share/doc/cmake 路径下。

3. 构建方式
内部构建，不推荐使用
内部构建会在同级目录产生一大堆中间文件，并放到和源工程同级的位置，但这些中间文件并不是我们所需要的，放在一起使工程显得杂乱无章，结构不清晰。
# 当前目录下编译本目录的 CMakeLists.txt 文件，生成 Makefile 和其它文件cmake .# 当前路径执行 make 命令，生成 targetmake

外部构建：推荐使用
将编译输出的文件与源文件放到不同的目录中。
# 当前目录创建 build 文件夹mkdir build# 进入 build 目录cd build# 编译上级目录的 CMakeLists.txt 文件，生成 Makefile 和其它文件# cmake path，path 是上一级 CMakeLists.txt 文件的路径 cmake ..# 执行 make 命令，生成 targetmake

4. Reference
CMake 官网
Cmake Reference Documentation
CMake Tutorial
CMake Commands
CMake 入门实战
Cmake 大型项目设置指南
CSDN：CMake教程
CLoin 与 CMake详细教程
CMake 添加编译选项
Learn Makefiles With the tastiest examples: https://makefiletutorial.com/

]]></content>
      <categories>
        <category>CMake</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cMake</tag>
        <tag>cmake-tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title>kswapd0</title>
    <url>/FAQ/Linux/FAQ/kswapd0/</url>
    <content><![CDATA[References
kswapd0 进程CPU占用过高

linux CPU占用率高 排查

MySQL 故障诊断：MySQL 占用 CPU 过高问题定位及优化


]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fAQ</tag>
        <tag>kswapd0</tag>
      </tags>
  </entry>
  <entry>
    <title>open-files</title>
    <url>/FAQ/Linux/FAQ/open-files/</url>
    <content><![CDATA[1. 为什么要修改可打开的文件描述符的数量进程每打开一个文件（linux下一切皆文件，包括socket），都会消耗一定的内存资源。如果有不怀好心的人启动一个进程来无限的创建和打开新的文件，会让服务器崩溃。所以linux系统出于安全角度的考虑，在多个位置都限制了可打开的文件描述符的数量，包括系统级、用户级、进程级。这三个限制的含义和修改方式如下：

系统级：当前系统可打开的最大数量，通过 fs.file-max 参数可修改
用户级：指定用户可打开的最大数量，修改 /etc/security/limits.conf
进程级：单个进程可打开的最大数量，通过 fs.nr_open 参数可修改

1.1. 系统级别修改1.2. 用户级别修改1.3. 进程级别修改查看系统参数
[root@KF-CFT-AP2 ~]# ulimit -acore file size          (blocks, -c) 0          # 设定core文件的最大值，单位为 block。data seg size           (kbytes, -d) unlimitedscheduling priority             (-e) 0file size               (blocks, -f) unlimitedpending signals                 (-i) 62795max locked memory       (kbytes, -l) 64max memory size         (kbytes, -m) unlimitedopen files                      (-n) 1024      # 一个进程可以打开文件描述符的数量的最大值pipe size            (512 bytes, -p) 8POSIX message queues     (bytes, -q) 819200real-time priority              (-r) 0stack size              (kbytes, -s) 10240cpu time               (seconds, -t) unlimitedmax user processes              (-u) 62795virtual memory          (kbytes, -v) unlimitedfile locks                      (-x) unlimited



1.4. root 用户修改后其他用户不生效在root用户修改为65536后，用其他用户登录服务器检测ulimit -n 还是1024。那么就是该用户未生效。
修改 /etc/ssh/sshd_config 中配置，将 UsePAM 项值设置为 yes，表示使用 PAM 模块来加载。 
# UsePAM noUsePAM yes

修改完后，重启服务
service sshd restart





系统参数修改临时有效
直接在 shell 中修改参数值，比如1. 修改 core 文件大小	[root@KF-CFT-AP2 ~]# ulimit -c unlimited2. 修改文件打开的个数 open files	[root@KF-CFT-AP2 ~]# ulimit -n 2000其它的参数同理修改

系统参数修永久有效
修改 /etc/security/limits.conf 文件，直接在文件后面追加自己要添加的内容，完成后，登出当前用户，然后再登录，查看改变的值。[root@KF-CFT-AP2 limits.d]# vim /etc/security/limits.conf#        - core - limits the core file size (KB)#        - data - max data size (KB)#        - fsize - maximum filesize (KB)#        - memlock - max locked-in-memory address space (KB)#        - nofile - max number of open files#        - rss - max resident set size (KB)#        - stack - max stack size (KB)#        - cpu - max CPU time (MIN)#        - nproc - max number of processes#        - as - address space limit (KB)#        - maxlogins - max number of logins for this user#        - maxsyslogins - max number of logins on the system#        - priority - the priority to run user process with#        - locks - max number of file locks the user can hold#        - sigpending - max number of pending signals#        - msgqueue - max memory used by POSIX message queues (bytes)#        - nice - max nice priority allowed to raise to values: [-20, 19]#        - rtprio - max realtime priority##&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;##*               soft    core            0#*               hard    rss             10000#@student        hard    nproc           20#@faculty        soft    nproc           20#@faculty        hard    nproc           50#ftp             hard    nproc           0#@student        -       maxlogins       4# End of file# 修改打开文件数* hard nofile 3000* soft nofile 3000

*：表示所有的用户。
注意：有时修改了 /etc/security/limits.conf 文件并没有达到自己所预期的内容，感觉是没有生效。可能的原因：

加载了系统中 /etc/profile 文件中对系统参数的修改。优先级第二高
加载了系统中 /etc/security/limits.d/ 目录下文件的修改，比如：90-nproc.conf 或者 20-nproc.conf文件。优先级第三高

hard limit 只是作为 soft limit 的上限，soft limit 才是你设置的系统当前限制。当你设置 hard limit 后，soft limit 的值就只能小于 hard limit 。普通用户可以降低 hard limit 的值，但是不能提高它，只有 root 用户才能提高 hard limit。

于nproc配置信息的扩展说明:
对max user processes的配置, Linux系统默认先读取/etc/security/limits.conf 中的信息, 如果/etc/security/limits.d/目录下还有配置文件的话, 也会依次遍历读取, 最终, /etc/security/limits.d/中的配置会覆盖/etc/security/limits.conf 中的配置.
另外, max open files和max user processes是不能配置unlimited的 —— 极不安全的设置, 此时系统会使用默认的配置值. 对nproc而言, 默认值的计算方法为:
# 查看系统的 max user processes[kf@ZHCS-AP1 ~]$ cat /proc/sys/kernel/threads-max128108# 计算公式为: default_nproc = max_threads / 2;# 其中, max_threads = mempages / (8 * THREAD_SIZE / PAGE_SIZE);# mempages是机器的物理页面个数, THREAD_SIZE=8K, 所以, 计算公式为: default_nproc = max_threads / 2               = (mempages * PAGE_SIZE) / ( 2 * 8 *THREAD_SIZE )               = total_memory / 128K;              # 计算本机默认nproc配置: cat /proc/meminfo | grep MemTotalMemTotal:       115571480 kBecho &quot;115571480 / 128&quot; | bc902902ulimit -u902682# 算出来default_nproc = 902902, 和实际的902682很接近, # 因为物理页面会存储一些关键数据, 所以实际的比计算出来的要小一些.


用户登录的时候执行sh脚本的顺序：    &#x2F;etc&#x2F;profile.d&#x2F;file    &#x2F;etc&#x2F;profile    &#x2F;etc&#x2F;bashrc    &#x2F;mingjie&#x2F;.bashrc    &#x2F;mingjie&#x2F;.bash_profile 
由于ulimit -n的脚本命令加载在第二部分，用户登录时由于权限原因在第二步还不能完成ulimit的修改，所以ulimit的值还是系统默认的1024。

参考：

&#x2F;etc&#x2F;security&#x2F;limits.conf 详解与配置
Linux-PAM 官方文档
Linux下PAM模块学习总结
Linux下设置最大文件打开数nofile及nr_open、file-max
Linux - 修改系统的max open files、max user processes 
一台Linux服务器最多能支撑多少个TCP连接？ 从底层原理去解释。

]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fAQ</tag>
        <tag>open-files</tag>
      </tags>
  </entry>
  <entry>
    <title>sftp</title>
    <url>/FAQ/Linux/FAQ/sftp/</url>
    <content><![CDATA[

sftp 使用
https://www.myfreax.com/how-to-use-linux-sftp-command-to-transfer-files/
]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fAQ</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh</title>
    <url>/FAQ/Linux/FAQ/ssh/</url>
    <content><![CDATA[SSHSSH 配置SSH 由客户端和服务端的软件组成，客户端可以使用的软件有 SecureCRT、putty、Xshell 等，服务器端运行的是一个 sshd 的服务，通过使用 SSH，可以把所有传输的数据进行加密，而且也能够防止 dns 和 IP 欺骗，SSH 传输的数据是经过压缩的，可以加快传输速度。
OpenSSH（即常说的ssh）常用配置文件有两个 ssh_config 和 sshd_config。其中 /etc/ssh/ssh_config为客户端配置文件，/etc/ssh/sshd_config 为服务器端配置文件。
Tips：在 sshd_config 配置文件中，以 # 加空格开头的是注释信息，以 # 开头的是默认配置信息。

服务端配置文件如下：
[root@AP2 ssh]# cat /etc/ssh/sshd_config#	$OpenBSD: sshd_config,v 1.80 2008/07/02 02:24:18 djm Exp $# This is the sshd server system-wide configuration file.  See# sshd_config(5) for more information.# This sshd was compiled with PATH=/usr/local/bin:/bin:/usr/bin# The strategy used for options in the default sshd_config shipped with# OpenSSH is to specify options with their default value where# possible, but leave them commented.  Uncommented options change a# default value.################# SSH Server 的整体设定 #######################Port 22                    # 设置 sshd 监听的端口，出于安全考虑，端口指定为小于等于 65535，并且非 22     #AddressFamily any#ListenAddress 0.0.0.0      # 设设置 sshd 监听（绑定）的IP地址，0.0.0.0 表示监听所有IPv4的地址，出于安全考虑，设置为指定IP地址，而非所有地址#ListenAddress ::           # IPV6 的地址################## 说明主机的 Private Key 放置的档案 ############ Disable legacy (protocol version 1) support in the server for new# installations. In future the default will change to require explicit# activation of protocol 1Protocol 2                          # 设置协议版本为SSH1或SSH2，SSH1 存在漏洞与缺陷，选择SSH2############################ 私人密钥的文件 ####################HostKey for protocol version 1#HostKey /etc/ssh/ssh_host_key#HostKeys for protocol version 2#HostKey /etc/ssh/ssh_host_rsa_key   # 服务器秘钥文件存放的路径， RSA 私钥#HostKey /etc/ssh/ssh_host_dsa_key   # dsa 密钥#Compression yes                     # 是否可以使用压缩指令# LifeJohne and size of ephemeral version 1 server key#KeyRegenerationInterval 1h          # 多长时间后系统自动重新生成服务器的秘钥#ServerKeyBits 1024                  # 定义服务器密钥的长度# Logging# obsoletes QuietMode and FascistLogging#SyslogFacility AUTH SyslogFacility AUTHPRIV              # 当有人使用 ssh 登录系统时，ssh 会记录信息，记录类型为AUTHPRIV，sshd 服务日志存放在/var/log/secure#LogLevel INFO                       # sshd 日志信息的级别############################## 安全登录 ############################ Authentication:         # 限制用户必须在指定的时限内认证成功，0 表示无限制。默认值是 120 秒#LoginGraceJohne 2m        # 设置指定时间内没有成功登录，将会断开连接，默认单位为 秒#PermitRootLogin yes      # 是否允许他人远程 ssh 登录 root 用户，默认是允许的#StrictModes yes          # 设置ssh在接收登录请求之前是否检查用户根目录和rhosts文件的权限和所有权，                                                     # 建议使用默认值&quot;yes&quot;来预防可能出现的低级错误。#MaxAuthTries 6#MaxSessions 10#RSAAuthentication yes    # 是否开启RSA密钥验证，只针对SSH1#PubkeyAuthentication yes # 是否开启公钥验证，如果使用公钥验证的方式登录时，则设置为yesPubkeyAuthentication yes#AuthorizedKeysFile	.ssh/authorized_keys  # 公钥验证文件的路径，与 PubkeyAuthentication 配合使用#AuthorizedKeysCommand none#AuthorizedKeysCommandRunAs nobody############################# 安全验证 ######################## For this to work you will also need host keys in /etc/ssh/ssh_known_hosts#RhostsRSAAuthentication no   # 是否使用强可信主机认证(通过检查远程主机名和关联的用户名进行认证)。                              # 仅用于SSH-1。这是通过在RSA认证成功后再检查 ~/.rhosts 或                                                                     # /etc/hosts.equiv 进行认证的。出于安全考虑，建议使用默认值&quot;no&quot;                              # similar for protocol version 2#HostbasedAuthentication no   # 与 RhostsRSAAuthentication 类似，但是仅可以用于SSH-2# Change to yes if you don&#x27;t trust ~/.ssh/known_hosts for# RhostsRSAAuthentication and HostbasedAuthentication#IgnoreUserKnownHosts no      # 设置ssh在进行RhostsRSAAuthentication安全验证时是否忽略用户                                                                # 的“/$HOME/.ssh/known_hosts”文件# Don&#x27;t read the user&#x27;s ~/.rhosts and ~/.shosts files#IgnoreRhosts yes             # 验证的时候是否使用“~/.rhosts”和“~/.shosts”文件# To disable tunneled clear text passwords, change to no here!#PasswordAuthentication yes   # 是否开启密码验证机制，如果用密码登录系统，则设置yesPasswordAuthentication yes  #PermitEmptyPasswords no      # 是否允许空密码登录系统，设置为 no，不允许# Change to no to disable s/key passwords#ChallengeResponseAuthentication yesChallengeResponseAuthentication no    #  是否允许质疑-应答(challenge-response)认证########## 与 Kerberos 有关的参数设定，指定是否允许基于Kerberos的用户认证 ######### Kerberos options#KerberosAuthentication no#KerberosOrLocalPasswd yes#KerberosTicketCleanup yes#KerberosGetAFSToken no#KerberosUseKuserok yes###### 与 GSSAPI 有关的参数设定，指定是否允许基于GSSAPI的用户认证，仅适用于SSH2 ##### GSSAPI options#GSSAPIAuthentication no         # 是否允许使用基于 GSSAPI 的用户认证，默认值为 no#GSSAPICleanupCredentials yesGSSAPICleanupCredentials yes#GSSAPIStrictAcceptorCheck yes#GSSAPIKeyExchange no# Set this to &#x27;yes&#x27; to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the ChallengeResponseAuthentication and# PasswordAuthentication.  Depending on your PAM configuration,# PAM authentication via ChallengeResponseAuthentication may bypass# the setting of &quot;PermitRootLogin without-password&quot;.# If you just want the PAM account and session checks to run without# PAM authentication, then enable this but set PasswordAuthentication# and ChallengeResponseAuthentication to &#x27;no&#x27;.#UsePAM noUsePAM yes                   # 是否启用 PAM 插件式认证模块# Accept locale-related environment variables        # 接受环境变量，只有SSH-2协议支持环境变量的传递AcceptEnv LANG LC_CTYPE LC_NUMERIC LC_JohnE LC_COLLATE LC_MONETARY LC_MESSAGESAcceptEnv LC_PAPER LC_NAME LC_ADDRESS LC_TELEPHONE LC_MEASUREMENTAcceptEnv LC_IDENTIFICATION LC_ALL LANGUAGEAcceptEnv XMODIFIERS#AllowAgentForwarding yes    #AllowTcpForwarding yes    # 是否允许允许tcp端口转发，默认为 yes，保护其他的tcp连接#GatewayPorts no           # 是否允许远程客户端使用本地主机的端口转发功能，出于安全考虑，建议禁止################### X-Window下的使用 ################################X11Forwarding no           # 是否允许X11转发#X11DisplayOffset 10        # 指定X11 转发的第一个可用的显示区(display)数字。默认值是 10                            #  防止 sshd 占用了真实的 X11 服务器显示区，从而发生混淆。#X11UseLocalhost yes################# 登入后的设置 #####################################PrintMotd yes         # 打印登录提示信息，提示信息存储在 /etc/moed 文件中#PrintLastLog yes      # 是否显示上次登录信息，默认为 yes#TCPKeepAlive yes      # 是否持续连接，设置yes可以防止死连接                       # 这种消息可以检测到死连接、连接不当关闭、客户端崩溃等异常。在这个情况下，任何                                              # 一端死掉后， SSH 可以立刻知道，而不会有僵尸程序的发生！#UseLogin no           # 是否在交互式会话的登录过程中使用，默认值是&quot;no&quot;。#UsePrivilegeSeparation yes  # 设置使用者的权限#PermitUserEnvironment no#Compression delayed     # 是否对通信进行加密，还是延迟到认证成功之后在加密，可用值：yes, delayed(默认), no#ClientAliveInterval 0   # 服务器端向客户端请求消息的时间间隔, 默认值是为 0，即服务端不向客户端不发送请求；单位为秒#ClientAliveCountMax 3   #服务端如果发现客户端没有响应，则判断一次超时，这个参数就是设置允许超时的次数                         # 这两个配置结合起来，可设置服务端多久与客户端断开连接，                         # 比如，设置 ClientAliveInterval 为 600秒，ClientAliveCountMax 设置为 3，则服务端与客户端                         # 600*3=1800秒，即 30 分钟后与客户端断开连接#ShowPatchLevel no#UseDNS yes                   # 是否禁止DNS反向解析，默认是 yes，一般会注释#PidFile /var/run/sshd.pid    # 存放 sshd 守护进程的进程号文件，默认是：/var/run/sshd.pid#MaxStartups 10               # 设置同时允许几个尚未登入的联机，当用户连上ssh但并未输入密码即为所谓                                                             # 的联机，这个联机中，为了保护主机，所以需要设置最大值，预设为10个，                              # 而已经建立联机的不计算入内。#PermitTunnel no#ChrootDirectory none# no default banner path#Banner none# override default of no subsystems#Subsystem	sftp	/usr/libexec/openssh/sftp-server   # 配置一个外部子系统，仅用于 SSH-2。例如：一个传输文件守护进程Subsystem sftp internal-sftp# Example of overriding settings on a per-user basis#Match User anoncvs#	X11Forwarding no#	AllowTcpForwarding no#	ForceCommand cvs server

CentOS7 默认安装的是 OpenSSH_7.4p1 版本SSH，而 CentOS6 默认安装的是 OpenSSH_5.3p1。
SSH 免密钥登录
原理
不同操作系统间免密访问原理都是一样的，A 主机免密访问 B 主机，需要 A 主机生成的公钥添加到 B 主机的～/.ssh/authorized_keys文件中，这样 A 访问 B，B 拿到 A 的用户连接信息，然后去自己的 authorized_keys 文件中查询看看有没有对应的信息，有就用A的公钥加密一段生成的信息，发给A后用A的私钥解开，之后 A 将解开后的明文信息发送给 B 进行对比，开始否正确，若正确则表明了 A 的公钥是由 A 本人的私钥解开的，即验证了身份的正确性，所以这也是为什么你要免密访问对方主机就要把自己的公钥丢过去的原因。当然这只是个很笼统的说法，只是为了帮助大家快速感性的有个大概认识。


设置步骤：

在一台 Linux&#x2F;Mac&#x2F;Windows 机器上，打开终端，在终端输入 ssh-keygen -t rsa 命令，执行后，要你输入，这一步，直接按回车键，直到完成即可。完成后会在本地主机上的用户目录下 .ssh 文件中生成公钥 id_rsa.pub 和私钥 id_rsa&#96; 文件。
[tim@KF ~]$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/home/tim/.ssh/id_rsa):Created directory &#x27;/home/tim/.ssh&#x27;.Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /home/tim/.ssh/id_rsa.Your public key has been saved in /home/tim/.ssh/id_rsa.pub.The key fingerprint is:30:55:7f:62:a3:e9:13:e4:a8:e5:4f:f0:ca:96:b0:f8 tim@AP2The key&#x27;s randomart image is:+--[ RSA 2048]----+|        ...      ||       .   .     ||      o   . = .  ||       o + + +   ||        S =      ||      .+ + .     ||     ..o..=      ||    . ..o+ .     ||     .E.o .      |+-----------------+[tim@KF ~]$ ll -a .ssh/总用量 16drwx------ 2 tim tim 4096 5月  14 12:36 .drwx------ 5 tim tim 4096 5月  14 12:36 ..-rw------- 1 tim tim 1671 5月  14 12:36 id_rsa-rw-r--r-- 1 tim tim  396 5月  14 12:36 id_rsa.pub[tim@KF ~]$

将本地主机公钥 id_rsa.pub 中的内容拷贝到远程目标机器的 .ssh/authorized_keys 文件中，若远程机器 .ssh 目录下不存在 authorized_keys 文件，则新建一个，并赋予 600 的权限。
[John@AP2 .ssh]$ pwd/home/John/.ssh[John@AP2 .ssh]$ ll -a总用量 23drwx------  2 John John 4096 5月  14 11:39 .drwx------ 13 John John 4096 5月  14 12:26 ..-rw-------  1 John John 1675 5月  14 11:39 id_rsa-rw-r--r--  1 John John  399 5月  14 11:39 id_rsa.pub-rw-r--r--  1 John John  792 2月  21 14:25 known_hosts[John@AP2 .ssh]$[John@AP2 .ssh]$ echo &quot;本地主机公钥 `id_rsa.pub` 中的内容&quot; &gt; authorized_keys[John@AP2 .ssh]$[John@AP2 .ssh]$ chmod 600 authorized_keys[John@AP2 .ssh]$[John@AP2 .ssh]$ ll -a总用量 24drwx------  2 John John 4096 5月  14 11:39 .drwx------ 13 John John 4096 5月  14 12:26 ..-rw-------  1 John John  583 5月  14 11:29 authorized_keys-rw-------  1 John John 1675 5月  14 11:39 id_rsa-rw-r--r--  1 John John  399 5月  14 11:39 id_rsa.pub-rw-r--r--  1 John John  792 2月  21 14:25 known_hosts

重启 sshd 服务，使之生效。
[John@AP2 .ssh]$ service sshd restart

完成上述步骤后，就可以远程免密登录了。
为保证 linux 系统的安全，linux 有个很坑的规定，服务端的 linux下必须保证：

～/.ssh 目录权限必须是 700

非 root 用户的 home 目录权限必须是 700，比如 /home/John 目录权限必须是 700

～/.ssh/authorized_keys 文件的权限必须是 600


只有上面各个文件的权限设置对以后，ssh 远程免密钥登录普通用户才能成功，否则是登录时还是要输入密码，没有设置对。
Reference
sshd_config(5) — Linux manual page
What is SSH Public Key authentication?  SSH.com 官方讲解 SSH 用法，很全面。
SSH远程登录配置文件sshd_config详解
CentOS6.9下升级默认的OpenSSH操作记录（升级到OpenSSH_7.6p1）
SSH 教程: https://wangdoc.com/ssh/key

]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fAQ</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>troubleshooting</title>
    <url>/FAQ/Linux/FAQ/troubleshooting/</url>
    <content><![CDATA[1. linux 日志1.1. 分类
内核日志
由系统服务 syslog 或 rsyslog 同一管理，根据配置文件 /etc/syslog.conf 或  /etc/rsyslog.conf 中的内容，决定将内核消息和各种系统程序的信息记录什么位置。

用户日志
用于记录 Linux 系统用户登录、登出系统的相关信息，包括用户名、登录的终端、登录时间、正在使用的进程操作等。

应用程序日志
第三方应用程序的日志信息。比如公司开发的程序有一套日志记录的模块，来记录程序运行过程中的各种事件信息，便于出错时问题的排查。


1.2. 日志文件解读Linux 系统本身和大部分服务器程序的日志文件默认情况下都放置在目录 /var/log 中。

/var/log/messages：公共日志文件，记录 Linux 内核消息及各种应用程序的消息和事件信息。这个文件包含了系统的重要事件、错误（IO 错误、网络错误）、程序故障、警告和其他相关信息等，对于系统管理员来说是一个非常有用的日志文件。
/var/log/messages 是一个传统的日志文件路径，通常由 Syslog 守护进程（syslogd 或 rsyslogd）负责管理。Syslog 是一个标准的系统日志记录工具，它可以接收来自系统和应用程序的日志消息，并将它们写入不同的日志文件。/var/log/messages 是其中一个主要的日志文件，记录了来自许多不同来源的日志消息。
在许多 Linux 发行版中，/var/log/messages 文件已被替换或合并到其他日志文件中，例如 /var/log/syslog（Debian&#x2F;Ubuntu 等）、/var/log/messages（CentOS&#x2F;RHEL 等）等。因此，实际的日志路径可能因发行版和系统配置而有所不同。
如果你想查看系统日志和消息，可以使用 cat、less、tail 等命令来查看 /var/log/messages 文件或对应的日志文件，具体的命令会因发行版而有所不同。例如：
cat /var/log/messages  # 查看 messages 文件的全部内容less /var/log/messages # 使用 less 分页查看 messages 文件tail -n 50 /var/log/messages # 查看 messages 文件的最后 50 行日志

请注意，查看日志通常需要管理员权限，你可能需要使用 sudo 命令来查看日志文件的内容。

/var/log/cron：记录 crond 计划任务产生的信息。

/var/log/dmesg：在系统启动时，会在屏幕上显示许多与硬件有关的信息，此文件就是记录系统上次启动时产生的这些信息，包含内核缓冲信息（kernel ring buffer）。用 dmesg 命令可查看本次系统启动时与使件有关的信息，以及内核缓冲信息。

/var/log/mailog：记录进入或发出系统的电子邮件的信息。

/var/log/boot.log：记录系统启动时的软件日志信息。

/var/log/secure：记录用户远程登录、认证过程中的信息。

/var/log/wtmp：记录系统所有登录和登出纪录，可用 last 命令查看。

/var/log/btmp ：记录错误登录系统的日志信息，可用 lastb 命令查看。

/var/log/lastlog ：记录最近成功登录的事件和最后一次不成功的登录事件，可用 lastlog 命令查看。


2. 网络故障排查2.1. 检查网线ethtool ethx 命令查看某一网卡的链路是否物理连通，ethx 为网卡的名称。
不知道当前系统的网卡是什么。用 ifconfig 命令查看。
[root@CentOS7 ~]# ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500        inet 192.168.0.180  netmask 255.255.255.0  broadcast 192.168.0.255        inet6 fe80::675b:99f5:ced9:26fa  prefixlen 64  scopeid 0x20&lt;link&gt;        ether 00:0c:29:cc:b7:5e  txqueuelen 1000  (Ethernet)        RX packets 12028  bytes 2033103 (1.9 MiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 1832  bytes 473741 (462.6 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536        inet 127.0.0.1  netmask 255.0.0.0        inet6 ::1  prefixlen 128  scopeid 0x10&lt;host&gt;        loop  txqueuelen 1000  (Local Loopback)        RX packets 32  bytes 2592 (2.5 KiB)        RX errors 0  dropped 0  overruns 0  frame 0        TX packets 32  bytes 2592 (2.5 KiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

可以看到 第一个就是网卡的名称，叫 ens33。
// 查看 网卡 ens33 的状态[root@CentOS7 ~]# ethtool ens33Settings for ens33:        Supported ports: [ TP ]        Supported link modes:   10baseT/Half 10baseT/Full                                100baseT/Half 100baseT/Full                                1000baseT/Full        Supported pause frame use: No        Supports auto-negotiation: Yes        Supported FEC modes: Not reported        Advertised link modes:  10baseT/Half 10baseT/Full                                100baseT/Half 100baseT/Full                                1000baseT/Full        Advertised pause frame use: No        Advertised auto-negotiation: Yes        Advertised FEC modes: Not reported        Speed: 1000Mb/s        Duplex: Full        Port: Twisted Pair        PHYAD: 0        Transceiver: internal        Auto-negotiation: on        MDI-X: off (auto)        Supports Wake-on: d        Wake-on: d        Current message level: 0x00000007 (7)                               drv probe link        Link detected: yes

2.2. 检查网卡状态查看网卡驱动状态
[root@CentOS7 ~]# ethtool -i ens33driver: e1000version: 7.3.21-k8-NAPIfirmware-version:expansion-rom-version:bus-info: 0000:02:01.0supports-statistics: yessupports-test: yessupports-eeprom-access: yessupports-register-dump: yessupports-priv-flags: no

lsmod 查看网络各个模块的加载。
lspci 显示系统中所有 PCI 总线设备或连接到该总线上的所有设备的工具。具体使用参考：lspci命令详解
2.3. 查看网卡配置文件配置文件路径： /etc/sysconfig/network-scripts/ifcfg-ens33
]]></content>
      <categories>
        <category>FAQ</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>fAQ</tag>
        <tag>troubleshooting</tag>
      </tags>
  </entry>
  <entry>
    <title>Timer</title>
    <url>/Timer/Linux/Timer/Timer/</url>
    <content><![CDATA[高性能定时器结构定时器通常至少包含两个成员：

超时时间（相对时间或绝对时间）。
任务回调函数。

有时候还包含回调函数被执行时所需要传入的参数，以及是否重启定时器等信息。
时间轮（Time Wheel）定时器是一种常见的定时器实现方式，它的核心思想是使用一个环形的数组，每个元素都代表一段时间（通常是1毫秒）的时间段。每个时间段内维护一个任务列表，任务按照超时时间加入对应的时间段内。定时器每过一个时间段，时间轮就会转动一位，从而维护待执行的任务列表。
多级时间轮定时器是时间轮定时器的升级版，它使用多个时间轮构成一个层次结构，每个时间轮的精度逐步提高，使得实现更加高效。
具体来讲，一个多级时间轮定时器可以包含多个时间轮，每个时间轮的长度是前一级时间轮的倍数，每个时间轮的精度比前一级时间轮高。最底层的时间轮精度最低，代表的时间段最短，通常是1毫秒。每个时间轮维护一个任务列表，任务按照超时时间加入对应的时间段内。当一个时间轮的最后一个时间段超时后，它会通知上一级时间轮，上一级时间轮的指针会顺时针转动一个位置，对应的任务列表也会被重新分配到下一级时间轮中。最终，当最高层的时间轮转动时，所有待执行的任务都会被处理。
为了保证定时器的效率，可以使用哈希表维护任务列表，可以快速定位到指定的时间段并将任务加入列表中。同时，在时间轮转动时，可以使用类似于桶排序的方式将任务重新分配到下一级时间轮中，以保证时间轮的效率。
如何设计高效的定时器实现多级时间轮的高效定时器需要考虑以下几个方面：

时间轮只存储过期时间在当前时间槽到下一级时间轮之间的任务，减少了遍历时间轮的时间。
每个时间轮的时间间隔是上一级时间轮的整数倍。这样可以方便地将任务传递到下一级时间轮，减少了遍历时间轮的时间。
使用链表来存储任务，可以更快地删除任务。

案例
腾讯开源的 libco 库：是微信后台大规模使用的c&#x2F;c++协程库: 时间轮的方式。
开源 Asio 库：红黑树最小堆算法。
nginx：红黑树最小堆算法。
linux 内核：Hierarchy 时间轮算法。

Reference
深入Linux C&#x2F;C++ Timer定时器的实现核心原理: https://www.cnblogs.com/sunsky303/p/14154190.html
Linux内核时钟系统和定时器实现: http://walkerdu.com/2016/07/25/linux-kernel-timer
Reinventing the timer wheel: https://lwn.net/Articles/646950/
Github Linux 内核高精度 httimer 实现: https://github.com/torvalds/linux/blob/master/kernel/time/hrtimer.c
A new approach to kernel timers: https://lwn.net/Articles/152436/
《Linux-UNIX系统编程手册-上下册》
《the linux programming interface》
《Linux高性能服务器编程·游双》

]]></content>
      <categories>
        <category>Timer</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>timer</tag>
      </tags>
  </entry>
  <entry>
    <title>signal</title>
    <url>/system-program/Linux/system_program/signal/</url>
    <content><![CDATA[


1. Linux 下常用信号解释Linux 终端下输入 man 7 signal 命令，可查看信号的使用手册。
$man 7 signalSIGNAL(7)                 Linux Programmer&#x27;s Manual                 SIGNAL(7)NAME       signal - overview of signalsDESCRIPTION       Linux supports both POSIX reliable signals (hereinafter &quot;standard sig‐       nals&quot;) and POSIX real-time signals.   Signal dispositions       Each signal has  a  current  disposition,  which  determines  how  the       process behaves when it is delivered the signal.       The  entries  in  the  &quot;Action&quot; column of the tables below specify the       default disposition for each signal, as follows:       Term   Default action is to terminate the process.       Ign    Default action is to ignore the signal.       Core   Default action is to terminate the process and dump  core  (see              core(5)).       Stop   Default action is to stop the process.       Cont   Default  action  is  to continue the process if it is currently              stopped.			......		       First the signals described in the original POSIX.1-1990 standard.       Signal     Value     Action   Comment       ──────────────────────────────────────────────────────────────────────       SIGHUP        1       Term    Hangup detected on controlling terminal                                     or death of controlling process       SIGINT        2       Term    Interrupt from keyboard       SIGQUIT       3       Core    Quit from keyboard       SIGILL        4       Core    Illegal Instruction       SIGABRT       6       Core    Abort signal from abort(3)       SIGFPE        8       Core    Floating point exception       SIGKILL       9       Term    Kill signal       SIGSEGV      11       Core    Invalid memory reference       SIGPIPE      13       Term    Broken pipe: write to pipe with no                                     readers       SIGALRM      14       Term    Timer signal from alarm(2)       SIGTERM      15       Term    Termination signal       SIGUSR1   30,10,16    Term    User-defined signal 1       SIGUSR2   31,12,17    Term    User-defined signal 2       SIGCHLD   20,17,18    Ign     Child stopped or terminated       SIGCONT   19,18,25    Cont    Continue if stopped       SIGSTOP   17,19,23    Stop    Stop process       SIGTSTP   18,20,24    Stop    Stop typed at terminal       SIGTTIN   21,21,26    Stop    Terminal input for background process       SIGTTOU   22,22,27    Stop    Terminal output for background process       The signals SIGKILL and SIGSTOP cannot be caught, blocked, or ignored.

1.1. SIGINTSIGINT 是一个重要的操作系统信号，它表示”中断”信号（Interrupt Signal）。SIGINT 信号通常由终端用户通过在终端中按下 Ctrl+C 组合键来发送给正在运行的程序。
SIGINT 信号的主要用途是 请求进程中断当前操作并终止执行。当用户想要停止一个正在运行的程序时，可以通过发送 SIGINT 信号来中断该程序的执行。
一些常见的用例和行为：

终止程序： 当用户在终端中按下 Ctrl+C 时，终端会向正在运行的程序发送 SIGINT 信号，请求它中止执行。程序可以捕捉 SIGINT 信号，并根据需要执行终止处理程序，例如关闭文件、保存数据或释放资源，然后正常退出。
强制终止： 如果程序没有捕捉 SIGINT 信号或捕捉信号后没有正常退出，操作系统可以采取进一步措施来强制终止程序的执行。这时，操作系统会发送 SIGINT 信号的衍生信号 SIGKILL（也称为”杀死信号”），该信号会立即终止进程而无需进一步处理。

1.2. SIGTERMSIGTERM 是一个重要的操作系统信号，它表示”终止”或”终止信号”（Terminate Signal）。SIGTERM 信号用于请求进程正常终止，它向进程发送一个通知，告知进程需要关闭并退出。
与 SIGKILL 信号不同，SIGTERM 信号是一种优雅的终止方式，它允许进程在终止之前进行清理和释放资源。进程可以通过捕捉 SIGTERM 信号并执行特定的终止处理程序来实现优雅的退出。
一些常见的用例和行为：

正常终止： 当用户或系统管理员希望终止某个进程时，通常会发送 SIGTERM 信号给该进程。接收到 SIGTERM 信号的进程可以选择在退出之前完成未完成的操作，保存数据并释放资源。
进程管理： 在进程管理中，SIGTERM 信号是一个常见的方式来终止或关闭特定的进程。比如，当系统需要停止某个后台进程时，可以发送 SIGTERM 信号。
优雅重启： 在一些情况下，进程可能需要重新启动以加载新的配置或更新。在执行重启之前，通常会先发送 SIGTERM 信号给进程，等待它进行清理和关闭，然后再启动新的实例。

值得注意的是，尽管 SIGTERM 信号请求进程优雅地终止，但并不能保证进程一定会退出。进程有权选择是否响应 SIGTERM 信号。如果进程在一定时间内（通常是几秒钟）没有响应 SIGTERM信号，操作系统可能会发送 SIGKILL 信号给进程，这是一种强制终止的方式，会导致进程立即终止且无法进行清理工作
1.3. SIGHUPSIGHUP 是一个表示“挂起”或“终端挂起”的信号。它是 Unix 和类 Unix 系统中的一个操作系统信号。在类 Unix 系统中，进程（包括后台进程）可以接收不同类型的信号，以通知它们发生的某些事件或请求执行某些操作。
SIGHUP 信号通常与终端相关联，当用户从终端注销（退出登录）时，操作系统会向终端关联的所有进程发送 SIGHUP 信号。这意味着进程应该在接收到 SIGHUP 信号时执行某种操作，通常是关闭或重新初始化。
主要用途：

终端关闭时，发送 SIGHUP 信号给相关进程，以确保这些进程在终端会话结束时正确退出或重新初始化。
在某些情况下，SIGHUP 信号还可以用作某些进程的重新加载配置文件的信号，使它们在配置文件更改后可以重新读取新的配置。

在某些情况下，进程可以忽略 SIGHUP 信号，或者通过捕捉信号并执行特定操作来处理它。具体处理方式取决于进程的设计和用途。
]]></content>
      <categories>
        <category>system_program</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>system_program</tag>
        <tag>signal</tag>
      </tags>
  </entry>
  <entry>
    <title>system-program</title>
    <url>/system-program/Linux/system_program/system-program/</url>
    <content><![CDATA[

1. System function1.1. Core concept(概念)
文件函数包括三部分内容

file descriptor  文件描述符
file pointer(fp) 文件指针
file buffer     文件数据缓冲区


文件描述符返回值

0 标准输入
1 标准输出
2 错误
3 文件指针






全部的错误变量 errno 在 Linux 中存放的位置： /usr/include

perror():  打印错误的信息。

文件的实际权限 &#x3D; 用户给定的权限和本地的掩码（umask）取反之后，在进行按位与（&amp;）的操作，可以计算出文件的实际权限。
例如，假设用户给定的权限是 7（读、写、执行），UMASK 是 022。首先，将 UMASK 取反得到 755，然后进行位与操作：
用户给定权限：  111  (7 的二进制表示)UMASK取反：     755  (022 的二进制取反)------------实际权限：     111  (结果)

注：

UMASK 是一种权限掩码，用于在创建新文件或目录时从默认权限中去除一些权限位。在 Unix 和类 Unix系统中，UMASK 通常表示为八进制数字，并且会被应用于文件和目录的权限。

Linux 终端查看 umask 的值
$ umask0022

在Linux系统中，umask 值可以在多个地方进行修改。以下是一些常见的地方：

用户级别配置： 每个用户都可以在其个人的shell配置文件（如~/.bashrc、~/.bash_profile、~/.zshrc等）中设置umask 值。用户级别配置仅适用于特定用户。
系统级别配置： 系统管理员可以在系统范围的 shell 配置文件（通常位于 /etc/profile 或 /etc/bash.bashrc 等）中设置全局的 umask 值，以适用于所有用户。这样，对所有新创建的文件和目录都会应用这个umask值。
PAM配置： PAM（Pluggable Authentication Modules）是 Linux 系统中用于身份验证的模块化框架。系统管理员可以通过修改 PAM 配置文件来设置 umask 值，以在用户登录时应用特定的 umask 设置。
登录脚本： 在一些情况下，系统管理员可以通过修改特定的用户登录脚本来设置 umask 值。例如，对于某个特定用户组，可以在其登录脚本中设置特定的 umask 值。



1.2. Carriage Return &amp;&amp; Line Feed(终端换行)
关于打印

在机械打字机时代，打字机上有个 “打印头（print head）” 的零部件，打印时从左往右自动移动，满一行时需要手动推到最左边，这个动作叫“回车（Carriage Return）”，同时卷轴需要向上卷使纸张上移一行，打印头相对于纸张就是下移一行，这个动作叫做“移行（Line Feed）”。

ANSI 标准规定，转义字符 \r 指代 CR，\n 指代 LF，计算机系统早期广泛采用  CR+LF 指示换行。

UNIX 系统时代存储资源很贵，仅采用 1 个字符 “\n” 指示换行，而 MS-DOS 出于兼容性采用 \r\n 指示换行，后来搬到了 Windows 上，而 Mac 系统则采用 \r 指示换行，Linux、Cygwin 照搬了 \n。

\r\n 换行的文本文件在 Windows 显示正常，在 UNIX、Linux、Cygwin 中行末多出 1 个 “^M”，“^M” 指真实的 Ctrl-M 组合字符；\n 换行的文本文件在 UNIX、Linux、Cygwin 显示正常，在 Windows 中整个文件显示为一行。



C 语言换行符
C 语言中虽然也有转义字符\r、\n，但并不保证与 ASCII 码 CR、LF 等价，在文本模式下，写入\n由系统底层翻译成换行符，读入文本时换行符再由系统底层翻译为 \n。UNIX 系统正是 C 语言写出来的，系统底层就使用 LF 作换行符，系统内外表示一致不需翻译；而 MS-DOS、Windows 系统底层，则在系统内外需要进行 \n 与 CR+LF 的转换工作。


1.3. File I&#x2F;O(文件 I&#x2F;O)库函数与系统函数的关系


1.3.1. open()
创建：O_CREAT 或采用  截断为 0 的方式创建 O_TRUNC
读写：O_RDWR
只读：O_RDONLY
只写：O_WRONLY
文件是否存在：O_EXCL

1.3.2. read()&#x2F;write()
-1 读 &#x2F; 写文件失败
0  文件读完了或文件写成完了
&gt;0 读 &#x2F; 写文件的字节数

1.3.3. lseek()
获取文件的长度
移动文件指针
文件拓展（只能向文件的中间或尾部扩展，不能向前端扩展）

1.3.4. fsyncfsync是一个系统调用（system call）和一个 Unix&#x2F;Linux 命令，用于将文件系统缓冲区中的数据立即写入磁盘，以确保数据持久化保存。在使用 fsync 之前，通常会将数据缓存在操作系统的缓冲区中，以提高 I&#x2F;O 性能。然而，这些缓冲的数据并不是立即写入磁盘，而是由操作系统自行决定合适的时机进行刷新。fsync 允许应用程序强制将数据从缓冲区刷新到磁盘，以确保数据不会在系统崩溃或断电时丢失。
在C语言中，fsync函数的原型如下：
#include &lt;unistd.h&gt;int fsync(int fd);

fsync 函数接受一个文件描述符（file descriptor）fd 作为参数，表示要刷新数据的文件。调用 fsync后，会将该文件相关的数据从操作系统缓冲区立即写入磁盘，并确保数据已经持久化。
请注意：fsync 操作可能会导致磁盘的 IO 延迟，因为数据需要写入磁盘。因此，在使用 fsync 时应谨慎，只在确保数据持久性很重要的情况下使用。
此外，fsync 是一个阻塞式调用，它会一直等待数据写入磁盘完成后才返回。如果对性能有较高要求且可以接受一定的数据丢失，可以考虑使用 fdatasync 函数，它类似于 fsync，但更加高效，不会写入文件的元数据（metadata）。
在命令行下，可以使用fsync命令来刷新文件的缓冲区，命令语法如下：
fsync [FILE]

其中，FILE为要刷新的文件路径。使用 fsync 命令可以在不编写代码的情况下手动刷新文件的缓冲区。
1.3.5. stat()stat(): 查看文件的所有状态信息。进行追踪或穿透，显示追踪到的文件或软连接指定的文件信息。
1.3.6. lstat()lstat(): 查看文件的状态信息。不进行追踪或穿透，直接显示当前文件或软连接的信息。
1.3.7. access()access(): 测试指定文件是否拥有某种权限。
1.3.8. chmod()chmod(): 改变文件的权限
1.3.9. truncate()truncate() 将指定文件的大小由指定参数 length 长度确定，

length 长度大于当前文件，文件将被拓展
length 长度小于当前文件，文件截取，截取值为 length 值

1.3.10. readlink()readlink(): 读一个软链接的值
1.3.11. unlink()
删除一个硬链接数
可以读取临时文件的内容。先创建文件，向文件写，然后读文件中写的内容并将读出的数据写到另外的一个文件中。

1.3.12. opendir()opendir(): 打开一个目录
1.3.13. readdir()readdir(): 读一个目录
1.3.14. closedir()closedir(): 关闭一个目录
1.3.15. dup() &amp;&amp; dup2()dup2() 是一个系统调用函数，在 Unix-like 操作系统（例如 Linux）上使用，用于复制文件描述符（file descriptor）。
功能： dup2() 函数用于复制一个已有的文件描述符，并将它复制到指定的新文件描述符。这样，原先的文件描述符和新的文件描述符都可以引用同一个打开的文件，它们共享相同的文件偏移量和文件状态标志（比如读 &#x2F; 写位置、文件状态等）。
函数原型：
#include &lt;unistd.h&gt;int dup2(int oldfd, int newfd);int dup(int fd);  // 复制 fd 对应的文件表指针，返回下一个可用的文件描述符int dup2(int oldfd, int newfd); // 将 newfd 对应的文件表指针修改为 oldfd 对应的文件表指针

参数说明：

oldfd：已有的文件描述符，它是需要复制的源文件描述符。
newfd：新的文件描述符，它是复制后的目标文件描述符。如果 newfd 已经打开，则会先关闭 newfd 所指向的文件，然后将 oldfd 复制到 newfd。

返回值：

如果复制成功，返回新的文件描述符 newfd。
如果复制失败，返回 - 1，并设置 errno 来指示错误的原因。

注意事项：

在使用 dup2() 函数时，应确保 oldfd 是有效的（已打开的）文件描述符。否则，函数可能返回错误，并设置 errno 为 EBADF（表示文件描述符无效）。
如果 newfd 和 oldfd 已经指向同一个文件描述符，则 dup2() 不会关闭 newfd，但是会返回 newfd 本身。
在使用完 dup2() 复制的新文件描述符后，应当注意及时关闭它，以避免资源泄漏。

示例：
#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;int main() &#123;    int fd1, fd2;    // 打开一个文件，获取文件描述符 fd1    fd1 = open(&quot;file.txt&quot;, O_RDWR | O_CREAT, S_IRUSR | S_IWUSR);    if (fd1 &lt; 0) &#123;        perror(&quot;open&quot;);        return 1;    &#125;    // 复制文件描述符 fd1 到文件描述符 fd2    fd2 = dup2(fd1, 42);    if (fd2 &lt; 0) &#123;        perror(&quot;dup2&quot;);        return 1;    &#125;    // 使用 fd2 进行文件操作    write(fd2, &quot;Hello, dup2!&quot;, 13);    // 关闭文件描述符    close(fd1);    close(fd2);    return 0;&#125;

在上述示例中，我们使用 dup2() 将文件描述符 fd1 复制到了文件描述符 42（newfd）。之后，我们使用 fd2 这个新的文件描述符进行文件写入操作，它和 fd1 共享了同一个文件状态，所以对 fd2 的写入操作也会对 fd1 产生影响。
1.3.16. fcntl()
改变已经打开文件的属性，即获取或设置文件的状态标记。
F_GETFL 获取文件状态参数
F_SETFL 设置文件状态参数

1.4. Environment variables(环境变量)
常见的环境变量

PATH  指定可执行文件搜索路径
SHELL 指定当前所使用的命令解析器
TERM  当前终端类型
LANG  指定语言环境
HOME  用户主目录


常见的环境变量函数

getenv() 获取环境变量值
setenv() 设置环境变量值
3 个参数- 1  覆盖原值- 0  不覆盖- -1 出错


unsetenv() 删除环境变量



2. Process(进程)什么是进程？

在计算中，进程是由一个或多个线程执行的计算机程序的实例。它包含程序代码（code）和运行指令（activity）。取决于操作系统（OS），一个进程可能由多个并行执行指令的执行线程组成。程序本身只是指令、数据及其组织形式的描述，相当于一个名词，进程才是程序（那些指令和数据）的真正运行实例。

2.1. fork()
创建一个子进程过程。一个进程调用 fork() 函数，变为两个进程，各自的进程都有一个返回值。父进程返回值为子进程的 PID（返回值大于 0），子进程的返回值为 0，进程创建成功。

执行 fork 操作之后，是父进程先执行还是子进程先执行，是不确定的，取决于系统内的调度算法。


父子进程之间遵循原则：读时共享写时复制。例如：一个全局变量，子进程只读时，则父子进程共享变量；若子进程对全局变量写操作时，则不共享全局变量。

父子进程共享

共享文件描述符。
共享 mmap 建立的映射区。



子进程与父进程异同点

相同
全局变量
.data
.text
栈、堆
环境变量
用户 ID
宿主目录
进程工作目录
信号处理方式


不同
进程控制块 (当前进程的父进程 ID)
PID
fork 返回值
定时器
未决信号集
进程运行时间



可能用到的函数

getpid()  获取子进程 PID 号
getppid() 获取父进程 PID 号
getuid()  获取当前进程实际用户 ID 号
geteuid() 获取当前进程有效用户 ID 号
getgid()  获取当前进程实际用户组 ID 号
getegid() 获取当前进程有效用户组 ID 号

2.2. exec() 家族
执行 exec() 家族的函数后，将当前进程的内存空间数据替换为要执行函数的内存空间数据。
exec() 家族函数只有失败时才返回，返回值为 -1，程序执行成功时，含食宿不会返回。l(list)	   	   命令行参数列表p(path)			   搜素 file 时使用 path 变量v(vector)			 使用命令行参数数组e(environment)	使用环境变量数组, 不使用进程原有的环境变量，设置新加载程序运行的环境变量


execlp(): 加载一个进程，通过环境变量加载。
execl(): 加载一个进程，通过路径 + 程序名称来加载。
execle(): 加载一个进程，通过路径 + 程序名称来加载，使用自定义环境变量 env。
execv(): 加载一个进程，使用命令行参数数组。
execvp(): 加载一个进程，使用自定义环境变量 env
execvpe(): 加载一个进程，使用命令行参数数组，并加上自定义环境变量 env。

2.3. wait()
什么是孤儿进程？
父进程先与子进程死亡，子进程就成为了孤儿进程，此时子进程的父进程的变为 init 进程，init 进程也称为 init 进程领养孤儿进程。

什么是僵尸进程
子进程结束了，父进程没有回收子进程的内存空间，而子进程的进程控制块（PCB）还存留于操作系统的内核之中，此时的子进程称为僵尸进程（zombie）。

wait() 函数作用

阻塞等待子进程退出
回收子进程的 PCB 内存空间资源
获取子进程死亡的原因// 子进程退出的几种常见的宏if (WIFEXITED(wstatus))         // 进程正常结束&#123;    printf(&quot;exited, status=%d\n&quot;, WEXITSTATUS(wstatus));&#125;else if (WIFSIGNALED(wstatus))  // 进程异常终止&#123;    printf(&quot;killed by signal %d\n&quot;, WTERMSIG(wstatus));&#125;else if (WIFSTOPPED(wstatus))   // 进程处于暂停状态&#123;    printf(&quot;stopped by signal %d\n&quot;, WSTOPSIG(wstatus));&#125;else if (WIFCONTINUED(wstatus))&#123;    printf(&quot;continued\n&quot;);&#125;



一个 waitpid() 或 wait() 函数只能回收一个僵尸进程。回收多个僵尸进程需要循环调用 waitpid() 或 wait() 函数。

waitpid() 函数
函数原型 pid_t waitpid(pid_t pid, int *wstatus, int options);
参数
pid 指定特定的进程 PID，
当 pid=-1 时，传入的是任意进程的 PID
当 pid=0 时，回收当前进程组内（group）的所有子进程；
当 pid=- 进程组 id 时，回收指定进程组内的任意子进程。


*wstatus 子进程退出的状态
options 可以将进程设置为阻塞态（设置为 0）或运行态（设置为 WNOHAGN）


函数返回值
正常运行：pid
失败：-1
当 options=WNOHAGN 时，子进程为非阻塞状态且子进程尚未结束时，返回值为 0


函数作用：指定特定的进程 PID 进行僵尸进程的回收。子进程的状态可以设置为不阻塞，使用宏 WNOHAGN



2.4. IPCIPC(Inter Process Communication) 叫进程间通信。

Linux 中七种文件类型

非伪文件：占用磁盘的存储空间

- 普通文件
d(directory) 目录
l(link) 链接


伪文件：不占用磁盘的存储空间

s(socket) 套接字
b(block)  块设备
c(char)   字符设备
p(pipe)   管道




6 种方式

Pipe(管道：最简单)
Signal(信号：开销最小)
Mmap(共享映射区：无血缘关系)
Socket(本地套接字：最稳定)
Message queue(消息队列)
Semaphore(信号量)



2.4.1. Pipe(管道)分类

匿名管道 (named pipe)
有名管道 (unnamed pipe)

管道本质：是一个伪文件，从内核创建的一个缓冲区。有两个文件描述符引用，一个表示 Read(读端)，一个表示 Write(写端)。

fd[0]————— 管道的 read 端
fd[1]————— 管道的 write 端

2.4.1.1. unamed pipe(匿名管道)pipe 匿名管道：用于非血缘关系之间的进程通信。

原理: 通过环形队列，借助内核缓冲区（4k 大小）来实现的，数据从写端流入管道，从读端流出，这样就实现了进程间通信。

局限性

数据不能自己读写
数据一旦被读走，管道中就没有了，不能反复读取。
管道采用半双工通信方式，数据只能在一个方向上流动。
只能在有 公共祖先 的进程间使用管道。


管道中数据的读与写

人为的规定：子进程从管道中 read，父进程从管道中 write。
读管道
管道中有数据
read() 返回实际读到的字节数。


管道中无数据
管道 写端 被全部关闭: read() 返回皇子为 0
管道 写端 没有被全部关闭: read() 阻塞等待。




写管道
管道读端全部关闭
进程异常终止。可用 SIGPIPE 来捕捉信号。


管道读端没有全部关闭
管道已满，write 阻塞。
管道未满，write 将数据写入，并返回实际写入的字节数。







2.4.1.2. named pipe(有名管道)有名管道中 FIFO 是典型的有名管道。
2.4.2. mmapmmap(shared memory map) 叫共享内存映射。

当标志位 flags 等于 MAP_SHARED 时，创建映射区的权限要小于等于打开文件的权限。
当标志位 flags 等于 MAP_PRIVATE 时，对映射区的权限没有要求，因为 mmap 中的权限是对内存的限制。
创建映射区的过程中隐含的有对映射区的 读操作权限。
映射的文件大小为 0 时，不能再创建映射区。因此，用于映射的文件必须要有实际的大小。
打开或创建的文件偏移量必须为 4k 的正数倍 。因为 MMU 创建的页大小为 4K。
mmap 使用的过程中常常出现 总线错误，通常是由于共享文件存储空间大小导致的。
munmap 函数传入的地址一定是 mmap 函数的返回地址。
映射区的返回值一定需要检查，防止出错。

文件映射到磁盘的内存区域，可以简单的把映射的区域看做一个的类似的数组，即一个指针指向数组的首地址。

父子间进程通信

共享打开的文件
当标志位 flags=MAP_SHARED 时，共享建立的映射区 。当 flags=MAP_PRIVATE 时，父子进程的内核映射区相互独立的，各占一个映射区。


匿名映射

采用宏 MAP_ANONYMOUS 的方式，不需要再使用文件的方法去操作 mmap
注意：只适用于类 Linux 操作系统中，对其它的操作系统（freeBSD）不适用。


通用方法

通过 /dev/zero 目录中系统自带的伪文件 zero，去操作 mmap，实现内存映射。


非血缘关系之间的进程通信，即不同的文件之间通信。

创建映射区的文件只有一个
可以多端读和多端写



2.4.3. Signal(信号)信号：只能携带固定大小量的信息。Linux 系统下通过输入 man 7 signal 查看信号的帮助文档。

进程控制块 (PCB) 信息

进程 pid
进程状态
工作目录
用户 id
组 id
文件描述符表
信号相关的信息，主要指阻塞信号集和未决信号集。


产生信号的机制

通过软件的方式实现，有一定的延迟性（对 CPU 而言），对用户来说，延时很短，不易察觉。
每个进程收到的所有信号，都是由内核负责发送，内核进行处理。


产生信号的几种方式

按键产生，如：Ctrl+c(SIGINT 信号)、Ctrl+z(SIGTSTP 信号)、Ctrl+\(SIGQUIT 信号)，请参考 Linux 下常用信号解释
系统调用产生，如：kill、raise、abort
软件条件产生，如：定时器 alarm
硬件异常产生，如：非法访问内存 (段错误)、除 0(浮点数例外)、内存对齐出错 (总线错误)
命令产生，如：kill 命令


信号的处理方式

执行默认动作
终止进程
终止进程并产生 core 文件，方便调试
忽略信号
暂停（stop）
继续（continue）


忽略 (丢弃) ，并不是不处理信号，而是将信号处理后再进行忽略或丢弃。
捕捉 (调用户处理函数)


阻塞信号集 (信号屏蔽字)：

将某些信号加入集合，对他们设置屏蔽，当屏蔽 x 信号后，再收到该信号，该信号的处理将推后 (解除屏蔽后)


未决信号集

信号产生，未决信号集中描述该信号的位立刻翻转为 1，表信号处于未决状态。当信号被处理对应位翻转回为 0。这一时刻往往非常短暂。
信号产生后由于某些原因 (主要是阻塞) 不能抵达。这类信号的集合称之为未决信号集。在屏蔽解除前，信号一直处于未决状态。


信号的四要素

信号的名字
信号的编号
事件
默认处理动作


两个特殊的信号（9—-SIGKILL，19—-SIGSTOP）不允许信号的忽略和捕捉，只能允许执行默认动作。

进程实际运行的时间 &#x3D; 系统态运行时间 + 用户态运行时间 + 系统等待事件

向进程发送信号的函数

kill() 给指定的进程发送指定的信号。
raise() 给当前进程发送指定的信号。
abort() 给当前进程发送异常终止信号 6)SIGABRT，并产生 core 文件。


alarm() 函数

定时精度为 ms 级别
函数的返回值为：上一次闹钟定时剩余的次数。
每个进程有且只有一个定时器


setitimer() 函数

定时器的精度为 us 级别
可以设置周期性的定时


信号集合

信号集设定
int sigemptyset(sigset_t *set); 将信号位清空（置 0）
int sigfillset(sigset_t *set);  将某个信号集置 1
int sigaddset(sigset_t *set, int signum);  将某个信号加入信号集
int sigdelset(sigset_t *set, int signum); 将某个信号清出信号集
int sigismember(const sigset_t *set, int signum); 判断某个信号是否在信号集中


sigprocmask() 函数  屏蔽信号或解除屏蔽
sigpending() 函数  读取当前进程的 未决信号集


信号的捕捉

signal()：注册一个信号捕捉函数
sigaction()： 检测或修改信号处理动作，即注册一个信号捕捉函数。
sigaction() 函数默认使系统调用中断后不再重新启动。

sa_handler 指定信号捕捉后的处理函数名 (即注册函数)。也可赋值为 SIG_IGN 表忽略 或 SIG_DFL 表执行默认动作

sa_mask 一个信号集在调用信号捕捉函数之前，要将这个信号集加到进程的信号屏蔽字中，仅当从信号捕捉函数返回时，再将进程的信号屏蔽字恢复为原先值。这样，在调用信号处理程序时就能阻塞某些信号。
注意：仅在处理函数被调用期间屏蔽生效，是临时性设置。

sa_flags 通常设置为 0，表使用默认属性，信号捕捉函数执行期间自动屏蔽本信号。

sa_flags 参数

SA_INTERRURT 不重启
SA_RESTART 重启
SA_NODEFER 不希望自动阻塞捕捉到的信号。






函数

pthread_sigmask() : 每个线程均有自己的信号屏蔽集（信号掩码），可以使用 pthread_sigmask 函数来屏蔽某个线程对某些信号的响应处理，仅留下需要处理该信号的线程来处理指定的信号。
sigwait(): sigwait 是同步的等待信号的到来，而不是像进程中那样是异步的等待信号的到来。



2.4.4. Semaphore(信号量)信号量是互斥量的加强版。信号量的初值，决定了信号量占用的线程个数。
信号量相关函数-	sem_init 函数

sem_destroy 函数
sem_wait 函数
sem_trywait 函数
sem_timedwait 函数
sem_post 函数

2.4.5. Message queues(消息队列)
什么是消息队列？

维基百科解释：在计算机科学中，消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的资料，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。

消息队列特点
消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。
消息队列允许一个或多个进程向它写入与读取消息。
管道和消息队列的通信数据都是先进先出的原则。
消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。比 FIFO 更有优势。
消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。
消息队列常常保存在链表结构中，拥有权限的进程可以向消息队列中写入或读取消息。



分类

目前主要有两种类型的消息队列：POSIX 消息队列以及 System V 消息队列。
System V 消息队列目前被大量使用，系统 V 消息队列是随内核持续的，只有在内核重起或者人工删除时，该消息队列才会被删除。

两种模式

点对点模式
发布与订阅者模式

用途

异步处理：处理如短信下发、状态推送、用户注册、数据同步等功能，提高系统的并发能力，集中力量处理重要的部分（同步处理），将非核心功能丢给 MQ。
系统解耦：可在模块、服务、接口等不同粒度上实现解耦。
重试补偿：在跨机器数据传输的整个过程中，只要任意一个环节出错，都会导致问题的产生。可以通过 MQ 的重试补偿机制去尽可能的处理掉这些异常。
流量削锋：对于秒杀场景下的下单处理。服务器收到消息后，首先写入消息队列，然后按照自己的消息处理能力做处理。
日志处理：可以定时将日志写入 MQ，并且主动订阅日志记录。

2.4.6. Socket(套接字)2.5. Race condition(时序竞态)
时序竞态也叫竞态条件。


pause() 函数

作用：将进程主动挂起，等待信号唤醒。调用该函数的进程将被阻塞，直到有信号递达将其唤醒。


sigsuspend() 函数

作用：通过传递的参数 mask 进程信号屏蔽字解决使用 pause() 函数导致的时序竞争的问题。


可重入函数

定义：函数内不能含有 static 变量和 全局变量。反之就是不可重入函数。
信号捕捉函数应设置为可重入函数。


不可重入函数特征、

含有静态的数据结构
调用了 malloc 和 free 函数
是标准的 I&#x2F;O 函数


SIGCHLD 信号回收子进程

子进程接收到 SIGSTOP 信号停止，子进程处在停止态时，接受到 SIGCONT 后唤醒




多个进程之间使用 全局变量 时，可能会导致进程卡死的情况，尽量少使用全局变量或者在访问之前需要加锁。

2.6. Terminal(终端)
分类

字符终端
网络终端
伪终端 (Pseudo Terminal)


linux 系统启动流程
init---&gt;fork---&gt;exec---&gt;getty---&gt; 用户输入账号 ---&gt;login---&gt; 输入密码 ---&gt;exec---&gt;bash

2.7. Process group(进程组)
每个进程都有一个进程组，当父进程，创建子进程的时候，默认子进程与父进程属于同一进程组。
进程组生存期：进程组创建到最后一个进程离开 (终止或转移到另一个进程组)。
相关函数
getpgrp() 获取当前进程的进程组 ID
getpgid() 获取指定进程的进程组的 ID
setpgid() 改变进程默认所属的进程组



2.8. Daemon(守护进程)
通常独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。

创建守护进程模型

创建子进程，父进程退出。所有工作在子进程中进行形式上脱离了控制终端
子进程中创建新会话。setsid() 函数，使子进程完全独立出来，脱离控制
改变当前目录为根目录。chdir() 函数,　防止占用可卸载的文件系统
重设文件权限掩码。umask() 函数，防止继承的文件创建屏蔽字拒绝某些权限，增加守护进程灵活性
关闭文件描述符。即重定向 0/1/2 到 /dev/null，采用函数 dup2()
开始执行守护进程核心工作。
守护进程退出处理程序模型。


守护进程不会随用户的注销而退出，会一直在后台运行。

安装 man posix page
sudo apt-get install manpages-posix-dev

3. Thread(线程)3.1. Core concepts(基础概念)
进程与线程的区别？

根本区别：进程 是操作系统资源分配的最小单元，线程 是任务调度和执行的最小单元。
在性能开销方面：每个进程独享一块地址空间，有属于自己的进程控制块 (PCB)，但子进程与父进程共享进程地址空间，进程之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。
所处环境：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行，通过 CPU 调度，在每个时间片中只有一个线程执行。
内存分配方面：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了 CPU 外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。
包含关系：没有线程的进程可以看做是单线程的，如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线程共同完成的；线程是进程的一部分，线程是轻量级的进程 (LWP: light weight process)，可以看做是寄存器和栈的集合。


查看指定的线程号 LWP: ps -Lf pid(进程) 。

线程号 是 CPU 分配时间轮片的依据。
 线程 ID 是在进程内区分不同的线程


线程共享哪些资源？

共享文件描述符
共享当前线程的工作路径
共享信号的处理方式。（信号与线程混合在一起比较复杂，尽量将两者分开，单独实现）
共享用户 ID 和组 ID
共享内存空间（.text&#x2F;.data&#x2F;.bss&#x2F;heap &#x2F; 共享库，唯独不共享栈空间）。线程之间共享全局变量，进程之间不共享全局变量。


线程哪些资源不是共享的？

线程 ID
处理器现场（寄存器的值）和栈指针
用户栈空间（函数运行占用的空间）
error 变量（是. data 段中一个全局的变量，但每个线程独享 error 变量）
信号屏蔽字
线程调度的优先级



3.2. Function(线程相关函数)
pthread_self()    获得调用线程的线程 ID 号

pthread_create()  创建一个线程

线程退出相关的函数

pthread_exit()  将单个线程退出
exit()          将进程退出
return 语句       函数返回到调用者处


pthread_join() 将子线程回收，回收的是线程的资源。线程没有结束，会一直阻塞等待。

pthread_detach() 实现线程的分离。

返回值：成功返回 0，失败返回失败的错误码。
一般情况下，线程终止后，它的终止状态一直保留到其它线程调用 pthread_join() 获取它的状态为止。
不能对已经处于 detach 状态的线程调用 pthread_join() 函数，因为处于 detach 状态的线程终止后，就会立刻回收它占用的资源，而不是保留终止的状态。
作用：线程结束时自动清理进程控制块 PCB 资源。


pthread_cannel() 杀死或取消线程。

线程的取消并不是实时的，有一定的延时性，需要等待线程达到某个取消点。若子线程中没有使用系统调用，pthread_cannel() 函数无法到达取消点，则 pthread_cannel() 不会执行，需要手动添加一个取消点函数 pthread_testcancel()。
取消点：粗略的理解为是一个系统调用。



3.3. 线程属性设置
主要用的属性
pthread_attr_init() : 线程属性的初始化
pthread_attr_destory() : 线程属性的销毁
pthread_attr_setdetachstate() : 修改线程的属性分离
pthread_attr_setstack() : 修改线程的栈空间地址和大小
pthread_attr_setstacksize() : 只修改线程的栈空间大小



3.4. 注意事项
查看当前线程库版本（NPTL） getconf GNU_LIBPTHREAD_VERSION
主线程退出而子线程不退，则主线程调用 pthread_exit()
避免僵尸线程的方法
调用 pthread_join()
直接将线程设置为分离态 pthread_detach()
在创建子线程之前，将线程的属性设置为分离属性，即创建线程时就指定其属性。


应该避免在多线程中使用 fork() 函数。因为使用 fork() 函数会创建一个新的进程，而在新创建的进程中，只有采用 fork() 函数创建进程的线程会存在，其它的线程都会调用 pthread_exit() 函数而直接退出。
应尽量少将线程和信号结合在一起使用，否则会变得非常复杂。
采用 malloc() 和 mmap() 函数申请的空间，可以在多个线程中进行释放。

3.5. 线程同步
多个线程访问同一个资源，导致数据混乱的原因

共享数据
竞争
多个线程之间没有统一的调度（竞争）机制。


互斥

产生的原因：解决多个线程之间没有统一的调度（竞争）机制。



3.6. 线程之间死锁的原因
导致线程死锁的原因

多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放，而该资源又被其他线程锁定，从而导致每一个线程都得等其它线程释放其锁定的资源，造成了所有线程都无法正常结束。这是从网上其他文档看到的死锁产生的四个必要条件：


1、互斥使用，即当资源被一个线程使用 (占有) 时，别的线程不能使用。
2、不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。
3、请求和保持，即当资源请求者在请求其他的资源的同时保持对原有资源的占有。
4、循环等待，即存在一个等待队列：P1 占有 P2 的资源，P2 占有 P3 的资源，P3 占有 P1 的资源。这样就形成了一个等待环路。


当上述四个条件都成立的时候，便形成死锁。当然，死锁的情况下如果打破上述任何一个条件，便可让死锁消失。


锁机制

互斥锁：确保同一时间只能有一个线程访问共享资源。当锁被占用时试图对其加锁的线程都进入阻塞状态 (释放 CPU 资源使其由运行状态进入等待状态)。当锁释放时哪个等待线程能获得该锁取决于内核的调度。
读写锁：当以写模式加锁而处于写状态时任何试图加锁的线程 (不论是读或写) 都阻塞，当以读状态模式加锁而处于读状态时 “读” 线程不阻塞，“写”线程阻塞。读模式共享，写模式互斥。
条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
自旋锁：上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对 CPU 的霸占会导致 CPU 资源的浪费。 所以自旋锁适用于并行结构 (多个处理器) 或者适用于锁被持有时间短而不希望在线程切换产生开销的情况。



3.7. Mutex(线程互斥)互斥操作，就是对某段代码或某个变量修改的时候只能有一个线程在执行这段代码，其他线程不能同时进入这段代码或同时修改该变量，这个代码或变量称为临界资源。
线程访问共享数据之前需加锁，访问共享数据之后应立即解锁，不能有延迟时间，即锁的 粒度 应越小越好。
互斥量 (mutex) 常见函数

pthread_mutex_init()
pthread_mutex_destroy()
pthread_mutex_lock()
pthread_mutex_trylock()
pthread_mutex_unlock()

读写锁 (read-write lock) 常见函数

pthread_rwlock_init()
pthread_rwlock_destroy()
pthread_rwlock_rdlock()
pthread_rwlock_wrlock()
pthread_rwlock_tryrdlock()
pthread_rwlock_trywrlock()
pthread_rwlock_unlock()

条件变量 (condition) 常见函数

pthread_cond_init()
pthread_cond_destroy()
pthread_cond_wait()
阻塞一个条件变量
释放已经获得的互斥锁
当线程被唤醒时，pthread_cond_wait() 会返回并解除阻塞，重新申请获得互斥锁。


pthread_cond_timedwait() 限时等待一个条件变量
pthread_cond_signal() 唤醒至少一个阻塞在条件变量上的线程
pthread_cond_broadcast() 唤醒全部阻塞在条件变量上的线程

Linux 绝对时间是相对于 1970:00:00:00 这个时间的；如何操作？  time_t cur = time(NULL);                     // 获取当前时间struct timespec t;t.tv_sec = cur + 10;                         // 在 1970:00:00:00 这个时间点上偏移 10 秒pthread_cond_timedwait(&amp;cond, &amp;mutex, &amp;t)    // 调用 pthread_cond_timedwait() 函数
3.7.1. References
进程间的通信方式——pipe（管道）
进程间通信 – 管道
基于 Internet 的 Linux 客户机 &#x2F; 服务器系统通讯设计与实现
Linux 进程间套接字（Socket）通信
Linux 下 socket 编程实现客户机服务器通信的例子
信号量与互斥锁
信号量
Linux 进程间通信——使用共享内存
Linux 进程间通信 (四) - 共享内存
UNIX&#x2F;Linux 进程间通信 IPC 系列（四）消息队列
进程间通信的方式——信号、管道、消息队列、共享内存
认真分析 mmap：是什么 为什么 怎么用

]]></content>
      <categories>
        <category>system_program</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>system_program</tag>
        <tag>system-program</tag>
      </tags>
  </entry>
  <entry>
    <title>vim</title>
    <url>/vim/Linux/vim/vim/</url>
    <content><![CDATA[

1. Philosophyvim 可以看成是一种编程语言。其中，各种按键任意的组合，可以看成是不同程序的接口。

我们思考的有多快，这个工具使用的就有多快！（编程的速度跟上思考的速度！！！或以思维的速度来编辑文本。）
使用它就是为了偷懒儿，编程时减少按键按下的次数，因为使用鼠标很费时，影响编程的效率，不使用鼠标，完全用键盘去编程。
技巧感悟：每一次在按键上敲击时，想一想能否有更简单的方法去替代当前的操作。
诀窍：学会偷懒。其核心在于 “懒”，键盘上能按一次就能完成的工作，绝不按两次。

懒惰（Laziness）这个特点位于程序员的三大美德之首：唯有懒惰才会驱动程序员尽可能的将日常工作自动化起来，解放自己的双手，节省自己的时间。


2. Normal Mode普通模式（Normal Mode）。控制屏幕光标的移动，字符、字或行的删除，移动复制某区段及进入 Insert Mode 或者到 command Line Mode 下。
2.1. CursorVim 有实际行和屏幕行。以行号开头的行对应着一个实际行，它们会占据着屏幕上的一行或几行。当一行文本为适应窗口宽度而回绕时，回绕行的前面则不会显示行号，这个就是屏幕行。  在实际行前面添加 g 命令，则是对屏幕行操作。
光标移动操作：



命令
功能



h
向左移动光标


j
向下移动光标


k
向上移动光标


l
向右移动光标


+
光标移动到非空格符的下一行；等价于 ↓


-
光标移动到非空格符的上一行；等价于 ↑


n
按下数字后再按空格键，光标会向右移动这一行的 n 个字符


0
光标移动到这一行的开头字符处，等价于功能键 [Home]


$
光标移动到这一行的最后面字符处，等价与功能键 [End]


^
移动光标至本行第一个非空字符处


~
字符大小写转换


w(word)
向右移动一个词，光标停在下一个单词的开头，它会跳过空格和标点符号。


W（大写）
向右移动到下一个以空格分隔的单词的开头。


b(back)
从当前光标处 向左 跳到上一个单词的开头。符号也被当做一个单词。


B
从当前光标处 向左 跳到上一个以空格分隔的单词的开头。


e(end of word)
从当前光标处 向右 跳到每个单词的末尾，它会停在单词的最后一个字符上。


E
向右移动到下一个以空格分隔的单词的结尾。






H(Highest)
光标移动到这个屏幕的最上方那一行的第一个字符


M(Middle)
光标移动到这个屏幕的中央那一行的第一个字符


L(Lowest)
光标移动到这个屏幕的最下方那一行的第一个字符


ge
从当前光标处 向左 跳到每个单词的末尾，忽略空格






G
移动到这个文件的最后一行（常用）


nG
n 为数字。移动到文件的第 n 行。例如 20G 则光标会移动到文件的第 20 行（可配合 :set nu）


gg
移动到这个文件的第一行，相当于 1G 啊！ （常用）


ctrl g
列出光标所在行的行号


n 
n 为数字。光标向下移动 n 行（常用）


shift  k
进入帮助模式


&gt;&gt;
向右缩进


&lt;&lt;
向左缩进


%
匹配括号，如果光标在”(“ 上，它移动到对应的 “)” 上，反之，如果它在 “)” 上，它移动到对应的 “(“ 上


.
重复上次 Normal Mode 下的操作


翻页



命令
功能



Ctrl d(down)
屏幕向下滚动半个屏幕


Ctrl u(up)
屏幕向上滚动半个屏幕


Ctrl f(forward)
屏幕向下滚动整个屏幕


Ctrl b(backward)
屏幕向上滚动整个屏幕


Ctrl y
屏幕向上滚动一行


Ctrl e(extra)
屏幕向下滚动一行


用次数做简单的算术运算
&lt;Ctrl a 和 Ctrl x 命令分别对数字执行加和减操作。在不带次数执行时，它们会逐个加减，但如果带一个次数前缀，那么就可以用它们加减任意整数。例如，如果我们把光标移到字符 5 上，执行 10 Ctrl a 就会把它变成 15。(5+10&#x3D;15)

如果光标不在数字上，那么 Ctrl a 命令将在当前行正向查找一个数字，如果找到了，它就径直跳到那里。

2.2. YankYanking 是 Vim 中拷贝命令的名字。由于”c”己经被用于表示 change 了，所以拷贝 (copy) 就不能再用”c”了。但”y”还是可用的。把这个命令称为 “yanking” 是为了更容易记住 “y” 这个键。
要把文本从一个地方拷贝到另一个地方，你可以先删除它，然后用 “u” 命令恢复，再用 “p” 拷到另一个地方。可以使用更简单的方式进行拷贝，用 “y” 命令可以把文字拷贝到寄存器（register）中。然后用 “p” 命令粘贴到别处。

字符操作
yw  复制当前光标所在位置到单词尾字符的内容到 vi 缓存区，相当于复制一个单词
y$  复制光标所在位置到行尾内容到缓存区
y^  复制光标所在位置到行首内容到缓存区


行操作
yy  命令复制当前整行的内容到 vi 缓冲区
5yy 例如：5yy 就是复制 5 行
2yw 例如：2yw 就是复制 2 个单词
复制第 m 行到第 n 行之间的内容，在命令行模式中输入m，ny 例如：3，5y 复制第三行到第五行内容到缓存区。



2.3. Paste
p（小写） 将缓冲区内容粘贴光到标所在行的下面一行。
目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴


P（大写） 将缓冲区内 (buffer) 容粘贴到光标所在行的上面一行( Pastes content before the current cursor position)。
J	将光标所在行与下一行的数据结合成同一行
ddp 交换当前行和其下一行
xp 交换当前字符和其后一个字符

2.4. DeleteDelete 为 Vim 的删除命令，等价于 copy 操作，delete 拷贝当前的文本到 register，然后从当前文档中移除当前的文本。

字符操作 (word)

x（等价与 dl)   删除当前光标下的字符。
X（大写，等价与 dh)   删除当前光标左边的字符，不包括当前光标。
c(change 小写）	修改数据，例如向下删除 10 行，10cj
C（大写，等价与 c$)  修改当前光标所在字符至本行末尾，执行后进入insert 模式。
s（小写，等价与 cl)  修改一个字符，执行后进入insert 模式。
S（大写，等价与 cc)  修改当前光标所在的一整行，执行后进入insert 模式。
D（等价与 d$)	删除当前光标到行尾的所有字符。
nx  例如 3x 删除包括当前光标处向左的三个字符
dw  从当前光标处（包括当前光标）向 前 删除字符或单词（包括空格），一直到下一个单词开头处。
cw（小写） 从当前光标处向 前删除字符或单词，直到遇见空格时停止，执行后进入insert 模式。
c0（小写） 修改当前光标所在的位置至本行首部，执行后进入insert 模式。
cc（小写） 替换一行，执行后进入insert 模式。
c3w     从当前光标处向左删除 3 个 word，并进入 insert 模式。
数字 (n) s 删除 n 个字符，从当前光标开始算起，执行后进入insert 模式。
d0（数字 0) 删除光标所在处，到该行的最前面一个字符


行操作 (Line)

dd  删除光标所在行
ndd 删除光标所在的向下 n 行。例如 3dd 删除包括当前行开始向下的三行文本
d1G	删除光标所在到第一行的所有数据
dG	删除光标所在到最后一行的所有数据
:1,10d 将 1-10 行剪切
J 将光标所在行与下一行的数据结合成一行



2.5. Undo
u(undo 小写） 撤销最近一次的操作，可以使用多次来恢复原有的操作
U（大写） 撤销对整行的操作
Ctrl+R(Redo) 可以恢复对撤消 u（小写） 命令的操作
. （小数点） 重复前一个动作的意思

2.6. Find
/word	向光标之下寻找一个名称为 word 的字符串
?word	向光标之上寻找一个字符串名称为 word 的字符串
在 / 或 ? 之后，使用 n 向下查找，N 从当前字符向上查找。
# 光标移到到单词上面，可以选中整个文本中相同的单词
:nohlsearch 或 (noh) 关闭搜索后的高亮文本
* 查某个变量在哪里被用到，选中需要查的变量，按下 * 后，相同的变量高亮，再用 n 或 N 遍历查找。
/str\&gt; 查找以 str 结尾的单词
/\&lt;str\&gt; 查找以 str 结尾又以 str 开始的单词
f(find): 查找。fw：查找以 w 开头的字符。  
t(to): 跳至。tw：跳转到 w 字符处的前一个字符上。

2.7. Mark
m&#123;mark&#125; 设置标记
`{mark} 返回标记
Mark 是自己定义标记的字母，可以设置的任意按键。



2.8. Motions介绍几种修正和移动文本（Making corrections and moving text）的方法，包括 3 中基本修改文本的方法：

operator-motion（操作符-动作）
Visual Mode（可视模式） 
text objects（文本对象）

2.8.1. operator-motionVim 的强大很大程度上源自操作符与动作命令相结合，Operator + Motion = Action。

4dw 就是操作符-动作的模式，d 是删除操作符，4w 是一个执行命令，表示删除 4 个单词。
5dk：向上删除 5 行，并包括当前行。

SYNOPSIS
# []: 可选# |: 选择列出的其中一个# Command: A generic term used to group/contain the following items# Count:  An optional numerical value to indicate number of executions# Operate: The command to be executed# Motion: The direction the operator should be applied# Text Object: The area the operator should be applied to[count] &#123;operator&#125; &#123;[count] motion|text object&#125;

Abbreviation
c: changea: aroundi: insideb: bracketsw: wordf: findy: yankp: paragrapht: HTML tag


常见 VIM 操作符命令（Vim’s operator commands）



命令
用途



c
Change


d
Delete


y
Yank into register


g~
Swap case （大小写转换）


gu
Make lowercase（转为小写）


gU
（Make uppercase）转为大写


&gt;
（Shift right）增加缩进


&lt;
（Shift left）减小缩进


&#x3D;
（Autoindent）自动缩进


!
使用外部程序过滤 {motion} 所跨越的行


2.8.2. text objects
使用 operator text objects 来修改文本。
例如 da) 表示：Normal 模式下，将光标放在 ( 处，按下 da) 组合键后，一对圆括号中的内容就删除了。

文本对象包括分隔符文本对象和范围文本对象，下面图片中分别列出了通用的文本对象。

2.9. Foldvim 中代码折叠。按照折叠所依据的规则，可以分为 Manual（手工折叠）、Indent（缩进折叠）、Marker（标记折叠）和 Syntax（语法折叠）等。
查看折叠的帮助信息
:help folding     查看折叠的帮助信息:help fold-marker 查看标记折叠帮助信息:help fold-syntax 查看语法折叠帮助信息:help fold-indent 查看缩进折叠帮助信息:help fold-manual 查看手动折叠帮助信息

折叠快捷键
za 打开/关闭当前的折叠zo 打开一个折叠zc 关闭一个折叠zo、zc、za 对应 zO、zC 和 zA：以递归形式改变折叠状态。zR 打开所有的折叠及其嵌套的折叠zr 打开所有的折叠zM 关闭所有的折叠及其嵌套的折叠zm 关闭所有的折叠zd 删除当前折叠zE 删除所有折叠zj 移动至下一个折叠zk 移动至上一个折叠zn 禁用折叠zN 启动折叠


2.9.1. Manual Fold启用手工折叠
:set foldmethod=manual


2.9.2. Indent Fold启用缩进折叠，所有文本将按照（选项 shiftwidth 定义的）缩进层次自动折叠。
:set foldmethod=indent


2.9.3. Syntax Fold启用语法折叠。所有文本将按照语法结构自动折叠。
:set foldmethod=syntax


2.9.4. Marker Fold启用标记折叠，所有文本将按照特定标记（默认为 &#123;&#123;&#123;`和 `&#125;&#125;&#125; ）自动折叠。
:set foldmethod=marker


3. Visual ModeNormal Mode 下按 V（小写） 键进入到 Visual Mode，再根据需要进行复制、粘贴、删除、多光标等不同的操作。

d 删除 
y 复制
p 从当前光标处粘贴，但不会换行。
h, j, k, l 移动光标。一般常配合 d、y 操作进行字符的复制遇与删除。       
% 在匹配到的括号之间上来回跳。
o 切换所选区域的开始与结束位置。

4. Visual Line ModeNormal Mode 下按 Shift + v 组合键或者 V（大写） 键进入到 Visual Line Mode，再根据需要对行 (Line) 进行复制、粘贴、删除、多光标等不同的操作。

gv 重选上次的高亮选区 。

5. Visual Block ModeNormal Mode 下按 Ctrl + v 组合键进入到 Visual Block Mode，再根据需要进行复制、粘贴、删除、多光标等不同的操作。

d 删除所选中的字符
y 复制所选中的字符
p 粘贴所选中的字符
如何一次性改变多行的内容 (Multi cursor)？
光标定位到要操作的地方，按下 Ctrl+v 组合键进入 VISUAL BLOCK 模式，通过 h（左），j（下），k（上），l（右）选取行和列，按下 Shift+i 组合键后，进入 Insert Mode 下的 Multi cursor 操作，输入要插入的内容，此时你发现在 Insert Mode 下只有一行改变了，而不是多行同时改变了，此时需要你连续按两次 Esc 键，你会看到多行改变后的内容，并回到 Normal Mode 。



6. Replace ModeNormal Mode 下进行替换操作。

R 在命令行模式下，替换无限多个字符，执行后进入insert Mode。
r（小写） 替换一个字符，执行后还是在 Normal Mode。
~ 将光标下的字母进行大小写转换，执行后还是在 Normal Mode。
3~      将光标位置开始的 3 个字母改变其大小写
g~~     改变当前行字母的大小写
U       将可视模式下选择的字母全改成大写字母
u       将可视模式下选择的字母全改成小写
gUU     将当前行的字母改成大写
3gUU    将从光标开始到下面 3 行字母改成大写
guu     将当前行的字母全改成小写
gUw     将光标下的单词改成大写。
guw     将光标下的单词改成小写。

7. Insert Mode插入模式 (Insert Mode) 下，可以做文本操作，按「ESC」键或按 Ctrl [ 键可回到  normal 模式。

a(append) 从当前光标所在的下一个字符处插入文本。
A(append after a line) 从光标所在行的最后一个字符处插入文本。
I(insert before line) 在当前所在行的第一个非空格处插入文本。
i(insert after line) 当前光标所在位置之前插入。
o(open a line below) 当前光标所在的下一行处插入新的一行。
O(大写字母：open a line above) 当前光标所在处上一行插入新的一行。

8. Command Line ModeNormal Mode 模式下按下 : 键后进入 Command Line Mode 模式，进行对文件、窗口以及字符的替换等一系列的操作。
8.1. FileCommand Line Mode 下对文件进行操作。

:w [file]	将当前文件另存为另一个名为 file 的文件。
:r [file]	在编辑的数据中，读入另一个文件的数据，并将另一个文件 file 中的内容加到光标所在行后面。
:n1,n2 w [filename]	将 n1 到 n2 的内容保存为成 filename 文件。
:w   将编辑的数据写入 (write) 磁盘文件中。
:w! 若文件属性为『只读』时，强制写入该文件。不过，到底能不能写入，还是跟你对该文件的权限有关！
:q   文件没有修改会退出，文件有修改则不会退出。
:q!  若曾修改过该文件，又不想保存，使用 ! 为强制离开不保存当前文件。
:wq(write quit) 保存并退出，等同于 :x（小写）。
:wq! 强制保存后离开。
:e! 放弃所有修改，并打开原来文件。
:e ftp://192.168.10.76/abc.txt  打开远程文件，比如 ftp 或者 share folder。

Vim 会记录跳转前后的位置，并提供了一些命令让我们能够沿原路返回。Vim 可以同时维护多份跳转列表。实际上，每个单独的窗口都拥有一份自己的跳 转列表。如果你正在使用分割窗口或多标签页，那么  和  命令会始终在当前活动窗口的跳转列表范围内进行跳转。  
跳转

Ctrl o(older) 后退到上一个位置
Ctrl i(newer) 前进到上一个位置

8.2. CommandCommand Line Mode 下一些常见的命令操作。

:normal 执行任意的普通模式命令。
@: 重复 Command Line Mode 下上次的命令。

Command Line Mode 下也支持 Tab 键的自动补全。例如：输入:col 并按下 Ctrl d 按键后，会在命令行模式下面显示可用的补全列表。要想反向遍历补全列表，可以按 Shift-Tab。  
8.3. ReplaceCommand Line Mode 下对字符的替换。

:s/old/new 用 new 替换行中首次出现的 old
:s/old/new/g 用 new 替换行中所有出现的 old
:n1,n2 s/old/new/g 用 new 替换从第 n1 行到第 n2 行中出现的 old
:% s/old/new/g 用 new 替换整篇中出现的 old; (g:global, s: substitute)
判断每个替换的字符是不是确定被替换，可在最后添加控制标志位 c 来操作。例如：:%s/content/copy/gc



8.4. Window
:open file  在窗口中打开一个新的文件，会关闭之前的窗口。
:new 打开一个新窗口，光标停在顶层的窗口上，不会关闭之前的窗口。
:close 关闭窗口，最后一个窗口不能使用此命令，可以防止意外退出 vim。
:tabnew 从前窗口创建新标签页，但不会丢弃原来的文件，退出新建窗口后，会回到上次的窗口处。
:sp 或 :split 将当前文件水平分屏为两个文件
Ctrl w w 在打开的两个窗口之间进行切换（用的多）
Ctrl w j 移动到下方的窗口（用的少）
Ctrl w k 移动到上方的窗口（用的少）
:vsp 将当前文件垂直分屏为两个文件
:vsp file将当前文件与 file 文件两个垂直分屏

8.5. Shell使用 ! 可以执行 shell 的操作，暂时离开 vim, 显示执行 shell 的内容。

:shell 启动一个交互的 shell 会话。
:!&#123;cmd&#125; 在 shell 中执行 {cmd} 命令。例如 :!ls 列出当前目录下文件。
:read !&#123;cmd&#125;   在 shell 中执行 {cmd} ，并把其标准输出插入到光标下方 。
:suspend 或 Ctrl - Z 挂起 vim，回到 shell，按 fg 可以返回 vim。

8.6. Help
:help or F1 显示整个帮助
:help xxx 显示 xxx 的帮助，比如 :help i, :help CTRL-[（即 Ctrl+[的帮助）。
:help &#39;number&#39; Vim 选项的帮助用单引号括起
:help &lt;Esc&gt; 特殊键的帮助用&lt;&gt;扩起
:help -t Vim 启动参数的帮助用-
:help i_&lt;Esc&gt; 插入模式下 Esc 的帮助，某个模式下的帮助用模式_主题的模式帮助文件中位于||之间的内容是超链接，可以用 Ctrl+] 进入链接，Ctrl+o（Ctrl + t）返回

8.7. Comment程序中以 # 开始的行表示为注释，所以要注释某些行，只需在行首加入 #。

:3,5 s/^/#/g 注释第 3-5 行
:3,5 s/^#//g 解除 3-5 行的注释
:1,$ s/^/#/g 注释整个文档。
:%s/^/#/g 注释整个文档，此法更快。

9. RegistersVim 的寄存器是一组用于保存文本的简单容器。它们既可像剪贴板那样，剪切、复制和粘贴文本；也可以记录一系列按键操作，把它们录制成宏。 可用 Ctrl r &#123;register&#125;  命令来调用 Vim 的 register。
9.1. The expression register
The expression register（表达式寄存器） 在 Insert Mode 和 Command Line Mode 中均可以使用，只需要输入 Ctrl r = 键就可以访问这一寄存器。这个寄存器主要用于数值运算。
在插入模式中使用  A 6 chairs, each costing $35, totals $&lt;C-r&gt;=6*35&lt;CR&gt; 6 chairs, each costing $35, totals $210

10. Vim Config
系统级配置文件目录：/etc/vim/vimrc
用户级配置文件目录：~/.vim/vimrc
设置 Tab 的大小 set tabstop=4      &quot; 表示一个 tab 显示出来是多少个空格的长度，默认 8set softtabstop=4  &quot; 表示在编辑模式的时候按退格键的时候退回缩进的长度set shiftwidth=4   &quot; 表示每一级缩进的长度，一般设置成跟 softtabstop 一样set expandtab      &quot; 当设置成 expandtab 时，缩进用空格来表示# set noexpandtab  &quot; noexpandtab 是用制表符表示一个缩进set autoindent     &quot; 按换行键，让代码自动缩进一个 Tab，设置自动缩进
设置文件编码set fileencoding=utf-8
高亮指定的列：numset colorcolumn=num

10.1. Key Mappingnnoremap(normal not recursively map)：表示普通模式下对按键进行非递归映射。
# 按下 &lt;F2&gt; 取消搜索高亮nnoremap &lt;silent&gt; &lt;F2&gt;      :nohlsearch&lt;CR&gt;inoremap &lt;silent&gt; &lt;F2&gt; &lt;C-O&gt;:nohlsearch&lt;CR&gt;


11. Recover Swap File
O(open) 只读打开，不改变文件内容
E(edit) 继续编辑文件，不恢复。swp 文件保存的内容
R 将恢复上次编辑以后未保存文件内容
Q(quit) 退出 vi
D(delete) 删除。swp 文件或者使用 vi -r 文件名 来恢复未保存的内容。

12. Vim SheetVim 命令手抄

13. Vscodevim tricksvscode 中安装 vim 模拟插件。记录一些实用的技巧。
注释

gc 触发行注释。例如：gcc 触发当前行注释；gc2j 触发当前行和下两行注释。（一般结合点号 . 操作会很香）
gC 触发块注释。例如：gCi) 从 ( 开始注释到 ) 结尾处。
gd 跳转到定义。
gh 等同于鼠标悬停显示 types and error messages。
gb 光标高亮显示找到的相同单词，每按一次 gb 就高亮显示一次。

14. References
官方 vim 在线帮助手册: https://vimhelp.org
英文版 Vim Cheat Sheet: https://vim.rtorr.com
Vim Cheat Sheet for Programmers: https://michael.peopleofhonoronly.com/vim
MIT 2020 年 missing-semester lectures vim section: https://missing.csail.mit.edu/2020/editors
vim 学习手册: https://linux.cn/article-8144-1.html
Linux 命令大全–vim 学习: https://ipcmen.com
Vim 的哲学: https://segmentfault.com/a/1190000000458565
vim 常用命令总结: https://www.cnblogs.com/yangjig/p/6014198.html
vim-adventures: https://vim-adventures.com
Vim 快捷键大全: https://www.cnblogs.com/codehome/p/10214801.html
ctags 使用详解: https://blog.csdn.net/foreverling/article/details/80329586
VimScript 五分钟入门（翻译）: https://skywind.me/blog/archives/2193
Github sdaschner dotfiles: https://github.com/sdaschner/dotfiles/blob/master/.vimrc

]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Stanford-CS144</title>
    <url>/Stanford-CS144/Network/Stanford-CS144/Stanford-CS144/</url>
    <content><![CDATA[
4 Layer OSI Model
7 Layer OSI Model

IP


Why is the IP service so simple?

让网络保持简单、最小化。更快、更简化的特性，使其降低维护成本，不需要经常升级。
端到端原则（end-to-end principle）：尽可能正在端主机中实现功能。
允许在顶部构建各种可靠（或不可靠）的服务。
工作于任何的链路层（link layer）：IP对下层链路层的期望很小，连接可以是无线的，也可以是有线的，不需要重传和拥塞控制。

什么是Reliable byte stream?（可靠的字节流）

 Sequence of bytes (in each direction) delivered in order, correctly

RPC: Remote Procedure Call
更深入的细节

IP尝试阻止数据包永远循环。因为IP 路由器通过Internet逐跳转发数据包。

]]></content>
      <categories>
        <category>Stanford-CS144</category>
      </categories>
      <tags>
        <tag>network</tag>
        <tag>stanford-CS144</tag>
      </tags>
  </entry>
  <entry>
    <title>CS6.828</title>
    <url>/MIT-CS6-828/OS/MIT-CS6.828/CS6.828/</url>
    <content><![CDATA[
MIT 6.828 &amp; 6.S081课程

MIT CS8.828, Operating System Engineering 2018年秋季学科大纲。

视频

YouTube：6.828
B站：6.828
B站：6.S081


NOte: 6.828 and 6.S081 will be offered as two separate classes. 6.S081 (Introduction to Operating Systems) will be taught as a stand-alone AUS subject for undergraduates, and will provide an introduction to operating systems. 6.828 will be offered as a graduate-level seminar-style class focused on research in operating systems. 6.828 will assume you have taken 6.S081 or an equivalent class. See the 6.828 web site for more detail about 6.828.

Reference
知乎：MIT6.828-神级OS课程-要是早遇到，我还会是这种 five 系列 
二十八画生征友：一起来通关6.S081&#x2F;6.828吧
MIT6.S081 肖宏辉翻译的课程
胡津铭 Github计算机基础学习笔记

]]></content>
      <categories>
        <category>MIT-CS6.828</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>mIT-CS6.828</tag>
        <tag>cS6.828</tag>
      </tags>
  </entry>
  <entry>
    <title>page-tables</title>
    <url>/Operating-System-Three-Easy-Pieces/OS/Operating-System-Three-Easy-Pieces/page-tables/</url>
    <content><![CDATA[ 



逻辑地址空间是应用程序直接使用的地址空间。
段机制启动、页机制未启动：逻辑地址-&gt;段机制处理-&gt;线性地址&#x3D;物理地址
段机制启动、页机制都未启动：逻辑地址-&gt;段机制处理-&gt;线性地址-&gt;页机制处理-&gt;物理地址
页表(page table): 存储虚拟地址到物理地址的映射(mapping)，是一种数据结构。每一个映射称为页表项(PTE: page table entry)。

]]></content>
      <categories>
        <category>Operating-System-Three-Easy-Pieces</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>page-tables</tag>
      </tags>
  </entry>
  <entry>
    <title>reference</title>
    <url>/Operating-System-Three-Easy-Pieces/OS/Operating-System-Three-Easy-Pieces/reference/</url>
    <content><![CDATA[ 




1. Reference
1.1. 线程API接口
1.2. 线程锁
1.3. 条件变量
1.4. 信号量
1.5. 并发问题





1. Reference1.1. 线程API接口
“Programming With Threads” by Steve Kleiman, Devang Shah, Bart Smaalders. Prentice Hall, January 1996.

1.2. 线程锁
“Cooperating sequential processes” by Edsger W. Dijkstra. 1968. Available online here:http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD123.PDF. One of the early seminal papers. Discusses how Dijkstra posed the original concurrency problem, and Dekker’s solution.
“glibc 2.9 (include Linux pthreads implementation)” by Many authors.. Available here:http://ftp.gnu.org/gnu/glibc. In particular, take a look at the nptl subdirectory where you will find most of the pthread support in Linux today.

1.3. 条件变量
“Information Streams Sharing a Finite Buffer” by E.W. Dijkstra. Information ProcessingLetters 1: 179180, 1972. Available: http://www.cs.utexas.edu/users/EWD/ewd03xx/EWD329.PDF. The famous paper that introduced the producer&#x2F;consumer problem.
“My recollections of operating system design” by E.W. Dijkstra. April, 2001. Available: http://www.cs.utexas.edu/users/EWD/ewd13xx/EWD1303.PDF. A fascinating read for those of you interested in how the pioneers of our field came up with some very basic and fundamental concepts, including ideas like “interrupts” and even “a stack”!

1.4. 信号量
“Hierarchical ordering of sequential processes” by E.W. Dijkstra. Available online here: http://www.cs.utexas.edu/users/EWD/ewd03xx/EWD310.PDF. Presents numerous concurrency problems, including Dining Philosophers. The wikipedia page about this problem is also useful.
“The Little Book of Semaphores” by A.B. Downey. Available at the following site: http://greenteapress.com/semaphores/. A nice (and free!) book about semaphores. Lotsof fun problems to solve, if you like that sort of thing

1.5. 并发问题
“System Deadlocks” by E.G. Coffman, M.J. Elphick, A. Shoshani. ACM Computing Surveys, 3:2, June 1971. The classic paper outlining the conditions for deadlock and how you might go about dealing with it. There are certainly some earlier papers on this topic; see the references within this paper for details. 
“Een algorithme ter voorkoming van de dodelijke omarming” by Edsger Dijkstra. 1964. Available: http://www.cs.utexas.edu/users/EWD/ewd01xx/EWD108.PDF. Indeed, not only did Dijkstra come up with a number of solutions to the deadlock problem, he was the first to note its existence, at least in written form. However, he called it the “deadly embrace”, which (thankfully) did not catch on.
“Deadlock Immunity: Enabling Systems To Defend Against Deadlocks” by Horatiu Jula, Daniel Tralamazza, Cristian Zamfir, George Candea. OSDI ’08, San Diego, CA, December 2008. An excellent recent paper on deadlocks and how to avoid getting caught in the same ones over and over again in a particular system.
“Linux File Memory Map Code” by Linus Torvalds and many others. Available online at: http://lxr.free-electrons.com/source/mm/filemap.c. Thanks to Michael Walfish (NYU) for pointing out this precious example. The real world, as you can see in this file, can be a bit more complex than the simple clarity found in textbooks…

]]></content>
      <categories>
        <category>Operating-System-Three-Easy-Pieces</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>reference</tag>
      </tags>
  </entry>
  <entry>
    <title>uCore</title>
    <url>/Tsinghua-University/OS/Tsinghua-University/uCore/</url>
    <content><![CDATA[
learning Tsinghua University operating system course.
References
清华大学操作系统课程(2019)：Gitbook上清华大学操作系统课程(2019)。
操作系统(Operating Systems) (2019): 清华大学2019学期操作系统课程主页。
操作系统(Operating Systems) (2020): 清华大学2020学期操作系统课程主页。
uCore OS 实验指导书和源码网址 (2020):清华大学2020学期uCore OS 实验指导书。
Operating System Concepts Ninth Edition: 操作系统概念第九版英文版在线主页。

]]></content>
      <categories>
        <category>Tsinghua-University</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>tsinghua-University</tag>
        <tag>uCore</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/project/Go/proj-go/project/README/</url>
    <content><![CDATA[不同目录下构建自己创建的不同 package

项目对应的目录下执行 go mod init project_name，创建一个 go.mod 文件，这种方式需要在环境变量中配置 GO111MODULE=on，表明使用 go mod 方式去进行构建。

开启模块后，$GOPATH 不再被用于解析包的导入， 也就是 go tool 不会从 GOPATH 中寻找应的包


执行 go mod tidy

不同的 package 创建不同的文件，文件名通常与 package 的名字一样

分别在不同的 package 下编写代码

在 main 包中导入自己创建的 package，采用 import 方式导入包的路径

在 main 包的路径下编译，将 main 包编译成一个可执行的文件。go build main.go


]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
        <tag>go</tag>
        <tag>proj-go</tag>
        <tag>project</tag>
      </tags>
  </entry>
  <entry>
    <title>README</title>
    <url>/sqlc-tutorial/Go/proj-go/sqlc-tutorial/README/</url>
    <content><![CDATA[
Initialize a new Go module named tutorial.sqlc.dev&#x2F;appgo mod init tutorial.sqlc.dev/app

]]></content>
      <categories>
        <category>sqlc-tutorial</category>
      </categories>
      <tags>
        <tag>rEADME</tag>
        <tag>go</tag>
        <tag>proj-go</tag>
        <tag>sqlc-tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title>01-12-CPU-Virtualization</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/01-12-CPU-Virtualization/</url>
    <content><![CDATA[ 
1. CPU Virtualization
两种CPU模式
特权模式(privileged mode)，也叫内核模式(kernel mode)
用户模式(user mode)



进程API调用
上下文切换（context switch）：当进程停止时，它的寄存器的值被保存到内存中，通过恢复这些寄存器，操作系统（OS）可以恢复运行该进程。

僵尸态（zombie state）：一个进程处于已退出但未清理的状态。

允许其他的进程（通常是创建的父进程）检查进程的返回代码，并查看刚刚完成的进程是否成功执行。  


fork() 创建一个进程

创建的进程称为子进程（child）
原来的进程称为父进程（parent）
子进程不会从 main() 函数开始执行，而是直接从 fork() 系统调用返回，就好像是子进程调用了 fork()。


wait() 父进程等待子进程执行完毕。

exec() 进程的执行

重定向（redirect）原理

当子进程完成创建后，shell 在调用 exec() 之前关闭了标准输出（standard output），打开了一个新的文件。即将要运行程序的输出结果发送到新打开的文件中，而不是直接打印在屏幕上。


管道原理

调用系统的 pipe() 函数，将前一个进程的输出作为后一个进程的输入。


利用时钟中断获得CPU的控制权。


进程调度（process schedule）
进程调度衡量标准（Scheduling Metrics）

performance（性能）
fairness（公平性）  
response time（响应时间）


调度算法

FIFO(First In, First Out)
最短任务优先（SJF: Shortest Job First）：先运行最短的任务，再运行次短的任务，依次类推。是一种非抢占式调度。
最短完成时间优先（STCF: Shortest Time-to-Completion First）。每当新的工作进入系统时，它就会决定剩余工作和新工作中，谁的剩余时间最少，然后调度该工作。是一种抢占式调度。
轮转（Round Robin）也称为 时间切片（time-slicing）。
原理：在一个时间片内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务就结束了，它反复执行，直到所有的任务完成。
注意：时间片（ time slice）的长度必须是时钟中断周期的整数倍。




SJF, STCF调度算法优化了周转时间（turnaround time），响应时间不好。RR(Round Robin)优化了响应时间，但周转时间不好。


多级反馈队列（Multi-Level Feedback Queue）
MLFO(Multi-Level Feedback Queue)：利用反馈信息来决定任务的优先级。

MLFQ中有许多独立的队列，每个队列有不同的优先级。任何时刻，一个工作只能存在一个队列中，MLFQ总是优先执行高优先级的工作。

MLFQ调度的规则

如果 A 的优先级 &gt; B 的优先级，则运行A，不运行B。
如果 A 的优先级 &#x3D; B 的优先级，则轮转运行A和B。
一个任务进入系统时，被放置在最高优先级。
一旦任务在给定的某一级别上用完了时间分配（无论它放弃了CPU多少次），其优先级就会降低（即，它移动到下一个队列）。
每经过一个时间周期 S后，将所有的任务放入到最高优先级队列中。


调度算法的缺点

会产生饿死的问题，长时间的任务永远无法得到CPU。
用户可能会重写程序，来愚弄调度器，让它给你远超公平的资源。


使用 nice 命令行工具，可以增加或降低工作的优先级，从而增加或降低任务在某个时刻运行的机会。


Proportional Share（比例份额）
proportional-share scheduler（比例份额调度器）也叫fair-share scheduler（公平份额调度器）。

原理：调度器确保每个任务获得一定比例的CPU时间，而不是优化周转时间或响应时间。

两种调度算法

stride scheduling（步长调度）：系统中的任务都有自己的步长，这个值与票数值（number of tickets ）成反比。
彩票调度（ticket scheduling）：分配票数的方法采用随机数的方式。不需要对每个进程记录全局的状态，只需要记录总票数就可以了。



Multiprocessor Scheduling
CPU从缓存中读取数据的原则

程序第一次读取数据时，数据时放在内存中，花费的时间比较长。处理器期望该数据也许会再次使用，将数据放在缓存中。如果之后的时间程序再次使用同样的数据，CPU会先查找缓存。如果找到的数据就在缓存中，得到的数据块的多，程序运行的也很快。


多CPU中解决数据缓存一致性（cache coherence）的问题。

通过监控内存访问。
在总线系统中，采用总线窥探（bus snooping）。
每个缓存都通过监听链接所有缓存和内存的总线，来发现内存的访问。若CPU发现缓存中的数据更新了，会将原来的数据从缓存中移除或修改位新的值。




多个CPU之间访问共享数据或数据结构时，需要使用 互斥锁，来确保数据的正确性。

缓存亲和度（Cache Affinity）

当在特定CPU上运行时，在CPU的缓存中建立一个公平位状态（fair bit of state）。下次运行该进程在相同的CPU上时，由于缓存的数据而执行的更快。相反，在不同的CPU上执行，由于需要重新加载数据而变得较慢。因此，多处理调度器考虑到缓存的这种亲和性，并尽可能得将进程保持在同一个CPU上。


单队列调度（Single-Queue Scheduling）

多队列调度（Multi-Queue Scheduling）


]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>01-12-CPU-Virtualization</tag>
      </tags>
  </entry>
  <entry>
    <title>13-Abstraction-Address-Space</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/13-Abstraction-Address-Space/</url>
    <content><![CDATA[ 

抽象的地址空间 (Abstraction Address Space)问题？
如何管理可用空间？
空间不足时哪些页面该释放？

基础
概念

操作系统需要提供一个易于使用的物理内存抽象，叫做地址空间（正在运行的程序在系统中的内存视图）。
一个进程的地址空间包含运行程序的所有状态。


虚拟化内存的三个作用

透明(transparency): 操作系统提供的假象不应该被应用程序看破。程序不应该感知到内存被虚拟化，让它自认为拥有自己的私有物理内存。
效率(efficiency): 在时间和空间上提高效率
保护(protection): 确保进程受到保护，不受其它进程的影响，操作系统本身也不受进程影响。保护能够在进程之间提供隔离(isolation)，使之每个进程都能在自己独立的环境中运行，避免出错或恶意进程的影响。


注意 

虚拟地址只提供地址如何在内存中分布的假象，只有操作系统（和硬件）才知道物理地址。
从用户的角度（程序员）看到内存中的所有地址都是虚拟地址


总结

虚拟内存系统为程序提供一个巨大的、稀疏的、私有的地址空间的假象，保存了程序的所有指令和数据。
操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转化为物理地址，物理内存根据获得的物理地址去获取所需的信息。



命令
free: 显示系统中的可用和已用内存量
pmap: 查看进程的内存映像信息
参数解释


Address：进程所占的地址空间
Kbytes：该虚拟段的大小
RSS：设备号（主设备：次设备）
Anon：设备的节点号，0表示没有节点与内存相对应
Locked：是否允许swapped
Mode 权限：r&#x3D;read, w&#x3D;write, x&#x3D;execute, s&#x3D;shared, p&#x3D;private(copy on write)
Mapping：bash 对应的映像文件名 
Resident ：表示在内存中驻留的段的空间   
shared ：表示这些北分配的内存是被系统中其他进程共享的。    
private ：表示只能被该进程使用的空间大小。你可以发现share的空间不具有 private的属性。
Prstat －LP 的输出的意义是：
size：就是该进程占用的地址空间。
RSS：实际被分配的内存的大小


查看进程PID
pgep
ps aux | grep …



]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>13-Abstraction-Address-Space</tag>
      </tags>
  </entry>
  <entry>
    <title>14-Interlude-Memory-API</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/14-Interlude-Memory-API/</url>
    <content><![CDATA[ 

内存操作API动态分配内存常见误区
忘记分配内存（Forgetting To Allocate Memory）
 char *src = &quot;hello&quot;;char *dst; // oops! unallocatedstrcpy(dst, src); // segfault and die

没有足够的内存，也称为缓冲溢出
 为字符串声明空间：采用 malloc(strlen(src) + 1) 用法，一边为字符串结束符留出空间。char *src = &quot;hello&quot;;char *dst = (char *) malloc(strlen(src) + 1);strcpy(dst, src); // work properly

忘记初始化分配的内存。忘记在新申请的数据类型中填充一些值，导致程序最终会遇到未初始化的读取，从堆中读取一些未知的数据。        

忘记释放内存，即内存泄露（memory leak）。如果仍然拥有对某块内存的引用，那么垃圾收集器就不会释放它。

在用完之前释放内存，这种错误称为悬挂指针（dangling pointer）。可能会导致程序崩溃或者覆盖有效的内存。

反复释放内存（Freeing Memory Repeatedly），也被称为重复释放（double free）。导致结果未定义。

错误的调用free()


查看内存泄露工具
Purify：现在是商业产品
valgrind：开源工具。（参考：应用 Valgrind 发现 Linux 程序的内存问题）

底层操作系统支持
malloc()与free()函数不是系统调用，而是库调用。malloc库管理虚拟地址空间内的空间。
malloc()与free()基于brk或sbrk系统调用之上。brk作用：改变程序分段的位置，堆结束的位置。
调用mmap()，从操作系统获取内存。mmap()在程序中创建一个匿名内存区域，这个区域不与任何特定文件相关联，而是与交换空间（swap space）相关联。

]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>14-Interlude-Memory-API</tag>
      </tags>
  </entry>
  <entry>
    <title>15-Address-Translation</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/15-Address-Translation/</url>
    <content><![CDATA[ 

地址转换（Address Translation）问题
怎样在内存中重定位运行的进程，同时对该进程透明（transparent）?
怎样提供一种虚拟地址从零开始的假象，而实际上地址空间位于另外某个物理地址？

基础
实现CPU虚拟化遵循的准则：受限直接访问（limited direct execution, LDE）。

原理：让程序运行的大部分指令直接访问硬件，只在一些关键点（如何发起系统调用或发生时钟中断）由操作系统干预，确保“在正确的时间，正确的地点，做正确的事”。


如何高效、灵活地虚拟化内存？

采用基于硬件的地址转换（hardware-based address translation），简称地址转换。
灵活性：程序能以任何的方式去访问自己的地址空间，让系统更容易编程。
高效性：利用硬件的支持，快速的将所有内存访问操作中的虚拟地址转化为物理地址。


地址转换

硬件对每次内存访问进行处理（eg: an instruction fetch, load, or store），将指令中的虚拟地址转化为数据实际存储的物理地址。因此，每次内存引用时，硬件都会进行地址转换，将应用程序的内存引用重定向到内存中的实际位置。
虚拟地址：进程自己看到的地址。
物理地址：实际中内存的地址。


动态重定位（dynamic relocation）也称为基址加界限机制（base and bound）

CPU需要两个硬件寄存器：基址寄存器和界限寄存器。 

基址寄存器: 将虚拟地址转化为物理地址。
界限寄存器也叫限制寄存器(limit register)：确保虚拟地址在进程地址空间的范围内。
界限寄存器记录地址空间的大小，硬件在将虚拟地址与基址寄存器内容求和之前，需检查这个界限。
界限寄存器中记录地址空间结束的物理地址，硬件在转化虚拟地址到物理地址之后才去检查这个界限。


基址寄存器与界限寄存器组成的结构称为内存管理单元(memory management unit, MMU)，只有在内核模式下才能修改这两个寄存器。


操作系统中有记录哪些空闲物理内存没有使用的**空闲列表(free list)**，以便能够为其它进程分配内存。    

进程产生的所有内存引用，怎样转化为物理地址？
 virtual address也可叫偏移量(offset)。physical address = virtual address + base

动态重定位的缺点：会造成内存块中大量的空间被浪费，即称为内部碎片。

内部碎片(internal fragmentation): 指已经分配的内存单元内部有未使用的空间，造成了浪费。


采用静态重定位（static relocation）的缺点

不提供访问保护，进程中的错误地址可能导致对其他进程或操作系统内存的非法访问。
一旦完成，很难将内存空间重定位到其它位置。





]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>15-Address-Translation</tag>
      </tags>
  </entry>
  <entry>
    <title>16-Segmentation</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/16-Segmentation/</url>
    <content><![CDATA[ 

分段(segmentation)思考？
为什么要使用分段？
使用动态重定向，导致在堆和栈之间有一大块“空闲”空间没有被进程使用，但却依然占据了物理内存空间，致使了内存浪费。另外，如果剩余的的物理内存空间无法提供连续区域去放置完整的地址空间（进程的地址空间），那么进程变无法运行。因此，需要支持更大的地址空间，便有了分段的概念。



概念
段：只是地址空间里的一个连续定长的区域。
稀疏地址空间(sparse address spaces)：内存中大量未使用的地址空间。
段错误(segmentation fault)：在支持分段的机器上发生非法的内存访问。也称为段违规(segmentation violation) 。
保护位(protection bit): 为每个段增加了几个位，标识程序是否能够读写该段，或者能否执行该段的代码。
细粒度(fine-grained): 将地址空间划分为大量较小的块。
粗粒度(coarse-grained): 将地址空间分成较大的、粗粒的块。
外部碎片(external fragmentation): 物理内存中充满了许多空闲空间的小洞，很难分配给新的段。

分段处理
硬件在地址转换是使用段寄存器，是如何知道段内偏移量？虚拟地址引用了哪几个段？

显式方法(explicit approach): 用虚拟地址的开头几位来标识不同的段。 前两位告诉硬件引用了哪个段，后12位表示段内偏移。
隐式方法( implicit approach)：硬件通过地址产生的方式来确定段。例如：地址由程序计数器产生，那么地址在代码段。


分段的基本原理：系统运行时，地址空间中的不同段被重定位到物理空间中。即堆和栈之间没有使用的区域就不需要分配物理内存，从而能够将更多的地址空间放进物理地址。

操作系统在上下文切换时应该做什么？

各个段寄存器中的内容必须保存和恢复。
管理物理内存的空闲空间。


使用分段的方式会产生外部碎片，怎样去解决这个难题？

方案一：紧凑物理内存(compact physical memory)，重新安排原有的段。但是，使内存紧凑的成本很高，拷贝段是内存密集型的，会占用大量的处理器时间。
方案二：利用空闲列表管理算法(free-list management algorithm)。
最优匹配(best-fit)
最坏匹配(worst-fit)
伙伴算法(buddy algorithm)
上面采取的两种方案都无法完全消除外部碎片，只是尝试减小外部碎片。最好的方案是：永远不要分配不同大小的内存块。






分段的优缺点

优点
要求的算法很容易
很适合硬件完成，地址转换的开销小。
代码共享。


缺点
产生外部碎片
不足以支持更一般化的稀疏空间。





]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>16-Segmentation</tag>
      </tags>
  </entry>
  <entry>
    <title>17-Free-Space-Management</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/17-Free-Space-Management/</url>
    <content><![CDATA[ 

空闲空间管理(free space management)问题？
如果空闲空间是由大小不同的单元构成，如何管理空间？
什么策略可以让碎片最小化?
不同的方法在时间和空间上的开销如何？

底层机制
空间分割与合并(basics of splitting and coalescing)

空闲的空间可以被分割成许多空闲的小块，但是遇到申请大于内存中剩余空闲的块时，则不会成功，虽然有空闲的块空间。
将内存中散碎的剩余空间结合在一起，因此有了合并机制。在归还一块内存时，查看要归还的内存地址以及邻近的空闲空间块，如果新归还的空间与一个原有空间块相邻，它们就合并为一个较大的空闲空间。


追踪已分配空间的大小(track the size of allocated regions)

内存用完后，实际释放的空间为：头块的大小加上分配给用户空间的大小。


如何利用空闲的内部空间维护一个简单的列表，来追踪空闲和已分配的空间(build a simple list inside the free space to keep track of what is free and what isn’t)

嵌入一个空闲列表(free list)
在堆的空闲空间中建立一个列表，将空闲的内存合并。采用遍历列表，合并相邻块。(go through the list and merge　neighboring chunks)





让堆增长(growing the heap)

堆中的内存耗尽了怎么办？
最简单的是返回NULL
另一个是申请更大的堆。分配程序从很小的堆开始，当空间耗尽时，再向操作系统中申请更大的空间。在大多数UNIX系统中，执行 sbrk 系统调用，找到空闲的内存页，将他们映射到请求进程的地址空间中去，并返回新的堆的末尾地址。



管理空间的基本策略(Basic Strategies)
最优匹配(best fit)
原理：遍历整个空闲列表，找到和请求一样大小或最大的空闲块，然后返回该组候选组中最小的块
优点：避免了空间的浪费。
缺点：遍历整个列表，开销较大。


最差匹配(worst fit)
原理：尝试找到最大的空闲块，分割满足用户的需求后，将剩余中很大块加入空闲列表。
缺点：遍历整个列表，开销较大，导致过量碎片。


首次匹配(first fit)
原理：找到第一个足够大的块，将请求的空间返回给用户，将剩余的空闲空间留给后续的请求。
优点：速度很快，不需要遍历整个列表。
缺点：让空闲列表的开头部分有很多的小块。


下次匹配(next fit)
原理：将指针指向上一次查找结束的位置。
优点：速度很快，不需要遍历整个列表，避免了对列表头部的频繁分割。


分离空闲列表(Segregated Lists)
应用程序经常申请一种或几种大小的内存空间，用一个独立的列表，管理这样的对象，其它大小的请求都交给更通用的内存分配程序。
典型应用：厚块分配程序(slab allocator)，它避免了频繁的对数据结构的初始化和销毁，显著的降低了开销。


Buddy Allocation
核心思想采用二分法去分割与合并。



]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>17-Free-Space-Management</tag>
      </tags>
  </entry>
  <entry>
    <title>18-Introduction-to-Paging</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/18-Introduction-to-Paging/</url>
    <content><![CDATA[ 

分页介绍问题(THE CRUX)？
如何通过分页来实现虚拟内存，避免分段产生的问题？
基本技术是什么？
如何让这些技术运行良好，尽可能减少时间和空间的开销？
页表在哪里存储？
页表的典型内容是什么？
表有多大？
分页是否会使系统变慢？

基础
页表(page table)

为什么要用页表？
为了记录地址空间的每个虚拟地址页放在物理内存中的位置，操作系统为每个进程保存一个数据结构，称为页。


作用
为虚拟地址空间的每个虚拟页保存地址转换(address translation)，让我们知道每个页在物理内存中的位置。


一般来讲，系统中的每个进程都有一个页表，页表的确切结构要么由硬件决定 (older systems)，要么由操作系统灵活的管理 (modern systems)。


重要概念

swap(交换): 允许操作系统将很少使用的页面转移到磁盘上，从而释放物理内存。
虚拟页号(VPN: virtual page number):检索页表
物理帧号(PFN: physical page number)，也称为物理页号(PPN: physical page number)
页表项(PTE: page table entry)。由许多重要的位(bits)构成。
有效位(vaid bit): 用于指示特定地址转换是否有效。对于支持稀疏地址空间很重要。
保护位(protection bit): 表明页是否可以读取(read)、写入(write)或执行(execute).
存在位(present bit)：表明该页是在物理存储器上还是在磁盘上。
脏位(dirty bit)：表明page被带进内存后是否被修改。
参考位(reference bit)也被称为访问位(accessed bit):有时用于追踪页是否被访问，也用于确定哪些页应该保存子在内存中。 




分页很慢(Paging: Also Too Slow)

对于每个内存引用，分页都需要我们执行一个额外的内存引用，以便首先从页表中获取地址转换。


地址转过程
例如一个64bytes进程的虚拟地址空间在访问内存的过程。mov &lt;virtual address&gt;, %eax

需要将虚拟地址划分为两个部分：VPN和页内偏移量(offset)


通过PFN替换VPN来转换虚拟地址，然后将载入发给物理内存。注意：偏移量保持不变，它只是告诉我们页面中的那个字节使我们想要的。



分页的优缺点

优点
灵活性：支持稀疏地址空间。通过完善的分页方法，操作系统能高效的提供地址空间的抽象，不管进程怎样使用虚拟地址空间。
不会导致外部碎片。因为分页将内存划分为固定大小的单元。


缺点
会导致机器变慢（有许多额外的内存来访问页表）和内存浪费（内存被页表塞满，而不是有用的应用程序）。





]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>18-Introduction-to-Paging</tag>
      </tags>
  </entry>
  <entry>
    <title>19-Translation-Lookaside-Buffers</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/19-Translation-Lookaside-Buffers/</url>
    <content><![CDATA[ 

Translation Lookaside Buffers(快速地址转换)问题(crux)？
如何加速虚拟地址转换，避免额外的内存引用？
需要什么硬件支持？
需要什么操作系统参与?

基础
为什么要用快速地址转换？

使用分页作为虚拟内存的核心机制，可能会导致很高的性能开销。 通过将地址空间分割成大量固定大小的单元(units),分页需要大量的映射信息。因为这些映射信息通常存储在物理内存中，所以在转换虚拟地址时，分页逻辑需要对程序生成的每个虚拟地址进行额外的内存查找。 在每条指令获取或显式加载或存储之前，在内存中存储转换信息是非常慢的。


后备缓冲区(translation-lookaside buffer: TLB)也可以称为地址转换缓存。它是虚拟地址到物理地址转换的一个硬件缓存。

TLB miss: CPU没有在TLB中找到转换映射。

cache(高速缓存)原理：利用指令和数据引用中的局部性(locality)。常用的局部性有两种。

时间局部性(temporal locality)：最近访问过的指令或数据项在将来可能很快就会被再次访问。
空间局部性(spatial locality)：如果一个程序访问地址x处的内存，它可能很快就会访问地址x附近的内存。
Hardware caches：无论是指令、数据还是地址转换(在我们的TLB中)，都通过将内存副本保存在小而快速的片上内存中来利用局部性。处理器可以首先检查附近的副本是否存在于缓存中，而不必使用(慢速)内存来满足请求; 如果是，处理器可以快速访问它，避免花费昂贵的时间来访问内存(许多纳秒)。



Who Handles The TLB Miss?
CISC(复杂指令计算机: complex-instruction set computers)

RISC(精简指令计算机:reduced-instruction set computers)

X86架构：硬件必须准确地知道page tables 在内存中的位置(通过页表基寄存器(page table base register))，以及page table的确切格式; 如果没有命中，硬件将“遍历”页表，找到正确page-table entry，并提取想要的转换映射，使用translation更新TLB，然后重试该指令。

现代计算机架构：采用software-managed TLB。在TLB miss时，hardware 抛出一个异常，pauses the current instruction stream，将特权级别提升到内核模式，跳转至trap handler（它是OS的一段代码，目的是：handling TLB misses）。

采用软件处理TLB miss的优点

flexibility(灵活性)：OS可以使用任何的数据结构实现page table。不需要改变硬件。
implicity(简单性)：硬件不需要做太多对TLB miss的处理，只需抛出一个异常，然后让OS未命中的程序去处理完成其余的工作。



TLB Contents: What’s In There?
一条地址映射可能存在TLB中的任意位置，硬件会并行(parallel)的进行查找TLB，找到期望的转换映射。TLB VALID BIT ≠  PAGE TABLE VALID BIT ① page table有效位：标记为无效时：the page has not been allocated by the process，正常运行的程序不应该访问该地址
② TLB有效位：只是指出TLB entry是不是有效地地址映射。TLB的有效位在 performing a context switch中是很重要的。系统可以确保将要运行的 process 不会错误的使用previous process 虚拟地址到物理地址转换的映射。





TLB Issue: Context Switches
进程切换时面临的新问题：TLB包含的 virtual-to-physical translations 仅仅只是对当前正在运行的process有效，对其它的进程无效。

因此，在从一个进程切换到另一个进程时，硬件或操作系统(或两者)必须确保将要运行的进程不会意外地使用之前进程的地址转换。

进程切换时如何管理TLB的内容

当context-switching发生在两个进程之间时，上一个进程在TLB中的translations对于即将运行的进程时无意义的。
hardware or OS应该怎样解决这个问题？
simply flush(清空) the TLB on context switches，这样在下一个进程运行之前，TLB就为空了。
清空操作只是简单的把所有的valid bits设置为0，本质上清空了TLB。
缺点：有一定的开销，:每次进程运行时，当它访问数据和代码页时，都会触发TLB miss。 如果操作系统频繁地在进程之间切换，开销可能很高。


增加硬件支持，实现跨context switches的TLB共享。





Issue: Replacement Policy如何设计TLB的替换策略（ 即：cache replacement）？

向TLB中插入新的entry时，会替换一个old entry。
typical policies(典型的策略)
替换最近最少使用(least-recently-used: LRU)：LRU尝试利用内存引用流中的局部性。
random policy(随机策略)：随机选择一个替换出去。



实际系统中的TLB Entry



结论
通过增加一个小的、专用的片上TLB作为地址转换缓存，大多数memory references就不用访问主内存中的页表。
TLB不能满足所有程序的需求。例如：如果程序在短时间内访问的页数超过了TLB中的页数，则程序将生成大量TLB未命中，因此运行速度会变慢，这种现象称为TLB coverage，可能会对某些程序产生相当严重的问题。
解决的方案：支持larger page sizes。将关键数据结构映射到程序地址空间的某些区域，这些区域被映射到更大的页，是TLB的有效覆盖率增加。
对大页面的支持通常被数据库管理系统(DBMS)之类的程序所利用。


TLB访问很容易成为CPU管道(pipeline)中的瓶颈，特别是所谓的物理索引缓存。

]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>19-Translation-Lookaside-Buffers</tag>
      </tags>
  </entry>
  <entry>
    <title>20-Advanced-Page-Tables</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/20-Advanced-Page-Tables/</url>
    <content><![CDATA[ 
Paging: Smaller Tables问题
如何让页表更小？关键思路是什么？
使用新的数据结构，会导致哪些效率低下？

解决方案
为什么要提出用较小的页表？
基于简单的线性页表太大，消耗的内存太多，系统负担大。



bigger pages
大内存会导致每页的内部浪费，产生内部碎片(internal fragmentation)。

产生的结果：应用程序会分配页，但只使用每页的一小部分，而内存很快就被占满。因此。大多数系统在常见的情况下使用相对较小的页大小(page sizes)。 

Hybrid Approach: Paging and Segments




采用更大的页，这种方法并没有解决问题。

分段与分页结合的方法：是为每个逻辑分段提供一个页表(page table)，不是为进程的整个虚拟地址空间提供单个页表。

采用混合的方式，在MMU结构中，base register不是只向段本身，而是保存该段页表的物理地址；bounds register指示页表的结尾，即它有多少有效pages。在Segmentation中,base register告诉我们每个段在物理内存中的位置。

优点：每个分段都有bounds register，每个bounds register保留了段中最大有效位的值。栈和堆之间未分配的页不在占用page table中的空间，仅将其标记为无效。

缺点：因为使用分段，会导致外部碎片(external fragmentation)。尽管大部分内存是以page-sized为单元进行管理，但是现在页表是任意大小，因此，在内存中为它们寻找内存空间更为复杂。

简单实例

32位虚拟地址空间包含4KB pages地址空间分为4个segments，但只使用 3 个segments结果：硬件负责处理的TLB未命(miss)中时,硬件使用segment bits (SN)来确定要用哪个基址和界限对，然后硬件将其中的物理地址与VPN结合起来，构成page table entry (PTE)的地址。

SN = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SN_SHIFTVPN = (VirtualAddress &amp; VPN_MASK) &gt;&gt; VPN_SHIFTAddressOfPTE = Base[SN] + (VPN * sizeof(PTE))  




Multi-level Page Tables(多级页表)
为什么要用多级页表？

去掉页表中的所有无效区域，而不是将它们全部保存在内存中。


原理

将page table分成page-sized的单元
如果整页的page-table entries (PTEs)无效，就不完全分配该页的page table。


多级页表的工作方式：它只是让线性页表的一部分消失，并用page directory来记录page table的哪些page被分配。

页目录(page directory): 为了追踪page table的页是否有效。page directory可以告诉你page table的page在哪里？或者page table的整个page不包含有效页。

页目录项(page directory entries: PDE): PDE至少要有valid bit 和 page frame number(PFN)

在PDE所指向的page中，至少一个PTE，其有效位被设置为1；如果PDE无效（即等于零），则PDE的剩下部分没有定义。
优点
多级页表分配的page table空间，与你正在使用的地址空间内存量成正比。
页表的每个部分都可以整齐的放入一页中，更容易管理内存。
与线性页表(linear page table)相比,linear page table仅仅是按照VPN索引的PTE数组，整个线性页表必须连续驻留在内存中，对内存的开销占用很大。


缺点
在TLB未命中时，需要从内存加载两次，才能从页表中获取正确的地址信息（一次用于page directory，另一次用于PTE本身）。而线性页表只需要加载一次。多级页表是一个空间换时间的例子。
比较复杂。




多级页表例子

页目录索引(page-directory index: PDIndex)

页目录项(page-directory entry: PDE)

页目录项地址：PDEAddr = PageDirBase + (PDIndex * sizeof(PDE)) 


页表索引(page-table index: PTIndex)：用来索引页表本身

页表项(PTE)地址：PTEAddr = (PDE.PFN &lt;&lt; SHIFT) + (PTIndex * sizeof(PTE))





超过两级页表
理想的多级页表：页表的每一部分都能放入一个page。两级页表没能满足情况。因此采用别的方法。

实现方法：给tree在加一层，将page directory本身拆成多个页，然后在page上添加另一个page directory，指向page directory的page。虚拟地址分割如下：


PD Index 0 用于从顶级page directory中获取page directory entry(PDE)。如果有效，通过合并顶级PDE的物理帧号和VPN的下一部分(PD Index 1)来查询page directory的第二级；最后，如果有效，通过将page-table index与第二级PDE中的地址结合使用，可以形成PTE地址。

The Translation Process: Remember the TLB

在任何复杂的多级页表访问发生之前，硬件首先要检查TLB，在命中时，物理地址直接形成，不用访问页表；只有在TLB为命中时（miss），硬件才需要执行完整的多级查找。


反向页表（Inverted Page Tables）

页表项代表系统中的每个physical page，而不是许多的page tables。
page table entry告诉我们哪个进程正在使用该page，以及该进程的哪个virtual page映射到该physical page。 
要找到正确的page table entry，需要使用hash table。


Swapping the Page Tables to Disk（将页表交换到磁盘）

为了解决有些页表太大，无法一次装入内存。



]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>20-Advanced-Page-Tables</tag>
      </tags>
  </entry>
  <entry>
    <title>21-Swapping-Mechanisms</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/21-Swapping-Mechanisms/</url>
    <content><![CDATA[
Swapping-Mechanisms问题(crux 0f the problem)
HOW TO GO BEYOND PHYSICAL MEMORY?
操作系统如何利用较大，较慢的设备来透明地提供较大的虚拟地址空间的错觉(illusion)。



交换空间(swap space)
什么叫交换空间：在硬盘上开辟一片空间用于物理页(physical pages)的移入和移出。
交换空间的大小是非常重要的，决定了系统在某一时时刻使用的最大内存页数(the maximum number of memory pages)

存在位(The Present Bit)
希望将页(page)交换到(hard disk drive)中，硬件在PTE(page table entry)中查找时，如何判断该页是在内存中还是在硬盘中，则需要使用The Present Bit。若The Present Bit设置为 1， 则page存在于内存中，若The Present Bit设置为 0， 则page存在于硬盘中。

页错误(The Page Fault)
什么是页错误？
PTE访问不在内存中的page时，就会产生page fault。


OS怎么知道所需的页(page)在哪儿？
OS使用PTE中的某些 bit 来存储hard disk drive的地址。当OS接受到page fault时，会在PTE中查找地址，并将request发送到hard disk drive，将page读取到内存中。



交换什么时候发生(When Replacements Really Occur)
当操作系统注意到可用的页少于LW(low watermark: 低水位线)页时，将运行一个负责释放内存的后台线程。后台线程踢出页面，直到有可用的HW页面为止。
background thread(后台线程)也称为交换守护进程(swap daemon)或页守护进程(page daemon)
交换算法的流程
先检查是否有空闲页，而不是直接执行。若没有空闲页，通知后台分页线程按需要释放空闲页。当线程释放一些页时，会重新唤醒原来的线程，然后把需要的页面交换进内存，后台进程会继续工作。



]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>21-Swapping-Mechanisms</tag>
      </tags>
  </entry>
  <entry>
    <title>22-Swapping-Policies</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/22-Swapping-Policies/</url>
    <content><![CDATA[ 
Swapping-Policies问题(crux of the problem)
OS如何决定从内存中踢出哪个页？

Cache Management
AMAT(average memory access time): 内存平均访问时间
$T_M$：the cost of accessing memory
$T_D$：the cost of accessing disk
$P_Miss$：the probability of not finding the data in the cache (a miss)$$AMAT &#x3D; T_M + (P_Miss · T_D)$$



The Optimal Replacement Policy(最优替换策略)
最优替换策略的结果：使总体未命中TLB的数量最少。

最优替换策略只能作为理想的策略作为比较，在实际中很难实现。

3种缓存未命中的类型

compulsory miss：强制性未命中
capacity miss：容量未命中
conflict miss：冲突未命中


采用FIFO和Random策略都可能会踢出重要的page，这个page也许会马上被引用。


基于历史信息的算法去实现一些策略
LRU(Least-Recently-Used)：最少最近使用

LFU(Least-Frequently-Used): 最不经常使用

MFU(Most-Frequently-Used): 最经常使用

MRU(Most-Recently-Used): 最近使用

时间局部性(temporal locality)：近期访问的页可能会在不久的将来再次被访问。

空间局部性(spatial locality): 如果page P被访问，可能围绕它的page也会被访问。

使用位(use bit)，也叫引用位(reference bit)

修改位(modified bit)，也叫脏位(dirty bit)

如何实现LRU替换策略？

OS利用use bit来实现Approximating LRU。OS中的所有page都放在一个circular list中，开始时，时钟指针(clock hand)指向某个特定的page，当进行page replacement时，OS检查当前指向的page的use bit是0还是1；若是1，则OS指向的page最近被使用，不适合被替换，然后将当前page的use bit设置为0，时钟指针递增到下一个page，一直持续找到一个use bit为0的page；若是0，则OS指向的page最近没有被使用，可以进行替换。


采用时钟算法(clock algorithm)不是实现近似LRU的唯一方法。只要任何周期性的清除use bit，然后通过区分use bit 是0还是1来判断该替换哪个page。

加入dirty bit后的时钟算法。扫描没有被使用又没有被修改的page首先踢出(evict)，若没有找到这种page，在查找被修改过且没有被使用的page。


]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>22-Swapping-Policies</tag>
      </tags>
  </entry>
  <entry>
    <title>23-Virtual-Memory-Systems</title>
    <url>/01-Virtualization/OS/Operating-System-Three-Easy-Pieces/01-Virtualization/23-Virtual-Memory-Systems/</url>
    <content><![CDATA[ 
Virtual-Memory-SystemsVMS(virtual Memory System)
RSS(res-ident set size): 驻留集大小

demand zeroing：按需置零

COW(copy-on-write): 写时赋值

一个真实的VAX&#x2F;VMS地址空间
  


virtual address space: 由用户部分和内核部分

user portion: user program code, stack, heap, and other parts reside
kernel portion: kernel code, stacks, heap, and other parts reside


kernel memory allocate(内核内存分配) 

内核空间中，从3G到vmalloc_start 这段地址是物理内存映射区域（该区域中包含了内核镜像、物理页框表mem_map等等）；vmalloc 区域位于物理内存映射区之后;vmalloc_end 的位置接近 4G(最后位置系统会保留一片128k大小的区域用于专用页面映射)。
kmalloc 
保证分配的内存在物理上是连续的
能分配的大小有限
kmalloc 和get_free_page 申请的内存位于物理内存映射区域，而且在物理上也是连续的，它们与真实的物理地址只有一个固定的偏移，因此它们之间存在较简单的转换关系。


vmalloc 
保证分配的内存在虚拟地址空间上是连续的
能分配的大小相对较大
vmalloc 比kmalloc 要慢
vmalloc 申请的内存则位于vmalloc_start～vmalloc_end 之间，与物理地址没有简单的转换关系。




只有被DMA访问的内存是需要物理内存是连续的

user memory allocate(用户内存分配)

malloc


32-bit linux system用户部分和内核部分的虚拟地址空间分配为：0~0xBFFFFFFF为user portion；0xC0000000~0xFFFFFFFF为kernel portion
  

64-bit system: use a four-level table. 64-bit的空间没有完全使用，仅仅只用了底部的 48-bit

底部12-bit作为偏移量，因为x86标准的page size为4KB
顶部16-bit在TLB转换时没有用   



The Page Cache
三个主要来源

memory-mapped files(内存映射文件)
file data(来自设备的文件数据)
metadata(来自设备的元数据)


文件系统调用的读read()和写write()，以及每个进程的堆(heap)和栈(stack)页都保存在page cache hash table(页缓存哈希表)中,一边在需要数据的时候快速的访问。

mmap():  memory-mapped files(内存映射文件)函数。可以使用pmap命令查看。

ASLR(address space layout randomization)：地址空间布局随机化。物理地址与虚拟地址之间的映射地址，在以前的系统中，是固定的地址，但现代操作系统中不是固定的，保证了系统的安全。每次运行，地址会不一样。

Meltdown And Spectre(熔断和幽灵)

meltdownattack.com
spectreattack.com


KPTI(kernel page table isolation): 内核页表隔离


]]></content>
      <categories>
        <category>01-Virtualization</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>01-Virtualization</tag>
        <tag>23-Virtual-Memory-Systems</tag>
      </tags>
  </entry>
  <entry>
    <title>26-Concurrency-and-Threads</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/26-Concurrency-and-Threads/</url>
    <content><![CDATA[ 
Concurrency-and-Threads为什么要使用线程（Thread)？
实现并发性(parallelism)。多个CPU处理多个线程.
避免由于慢速的I&#x2F;O阻塞(block)程序的运行。

关键概念
临界区(critical section): 是访问共享资源( shared resource)的一段代码，一定不能有多个进程同时进行。通常共享资源是一个变量或数据结构。
竞态条件(race condition或data race)：多个执行的线程同时进入临界区时，它们都试图尝试更新共享资源的数据结构，会导致一些不希望的结果。
不确定性(indeterminate): 程序由一个或多个竞态条件组成，程序的输出因运行而异，取决于线程在什么时候运行，导致的结果是不确定的。通常我们希望计算机系统给我们输出的结果是确定的。
互斥(mutual exclusion)：保证了一个线程在临界区内执行，那么其它线程将被阻止进入临界区。

其它点
每个线程都有自己专用的用于计算的寄存器。
线程之间进行上下文切换(context switch): 不需要切换当前使用的page table，即地址空间保持不变。
线程之间的交互
访问共享变量。需要为临界区支持原子性。
一个线程在继续运行之前，必须等待另一个线程完成一些操作。



]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>26-Concurrency-and-Threads</tag>
      </tags>
  </entry>
  <entry>
    <title>27-Thread-API</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/27-Thread-API/</url>
    <content><![CDATA[ 
Thread-API如何构建并发程序的逻辑？
man -k pthread 查看所有线程接口的API

pthread_create参数

thead 指向pthread_t结构体类型的指针
attr  指定线程具有的属性（包括：栈大小、线程调度优先级）
(*start_routine)(void*) 一个函数指针，告诉这个线程应该在哪个函数中运行。
arg  要传递给线程指向的函数中开始执行的参数

pthread_join: 等待线程完成
参数
__th 指定要等待的线程
**__thread_return 需要传入一个指向传入参数值的指针，而不是传入参数值的本身。


使用join确保在退出或进入下一阶段计算之前完成所有线程的工作。

锁(lock)
pthread_mutex_lock

pthread_mutex_unlock

两种初始化锁方法

pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;  这样做锁会这只默认值
在运行时设置锁 int rc = pthread_mutex_init(&amp;lock, NULL);


锁用完后调用 pthread mutex destroy() 

在上锁或解锁的时候，常常需要检查错误代码(error codes)，即加断言(assert)。防止程序在存现问题时，不会简单的退出。


条件变量(Condition Variables)
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex);
int pthread_cond_signal(pthread_cond_t *cond);
pthread cond wait() 调用线程进入休眠，让调用者在睡眠时释放锁。再被唤醒之后返回之前，pthread cond wait()会重新获得锁，从而确保等待线程在等待序列开始时获取与结束时释放锁之间运行的任何时间，它都有锁。

使用 POSIX thread library遵循的准则
简单化(Keep it simple): 线程之间的锁和信号代码应该尽可能简单，复杂的线程交互容易产生 bug。
最小化线程交互(Minimize thread interactions): 每次交互都应该仔细的想清楚，用验证过的、正确的方法来实现。
初始化锁和条件变量(Initialize locks and condition variables): 未初始化的代码有时正常，有时错误，可能或产生奇怪的结果。
检查返回值(Check your return codes)
注意传给线程的参数和返回值(Be careful with how you pass arguments to, and return values from, threads)
每个线程都有自己的栈( Each thread has its own stack)：每个线程之间的局部变量是私有的，共享数据必须在 heap上或者在其它全局可以访问的位置上。
线程之间总是通过条件变量发送信号(Always use condition variables to signal between threads): 不要使用标志位(flag)来同步。
使用参考手册(Use the manual pages)

]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>27-Thread-API</tag>
      </tags>
  </entry>
  <entry>
    <title>28-Thread-Lock</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/28-Thread-Lock/</url>
    <content><![CDATA[ 
Thread-Lock什么是锁(lock)?
是一个某种类型的变量。
这个锁变量(简称锁)保持了锁在某一刻的状态。要么是可用的(available or or unlocked or free)，表示当前没有线程持有锁，线程可以使用该锁；要么是被占用的(acquired or locked or held)，表示当前有线程在临界区( critical section)使用锁。
锁的持有者(the owner of the lock): Calling the routine lock() tries to acquire the lock; if no other thread holds the lock (i.e., it is free), the thread will acquire the lock and enter the critical section;
锁是为编程者提供了最小程度的调度控制(control over scheduling)。
什么是互斥量(mutual exclusion)？
POSIX 库将锁称为互斥量。用来提供线程之间的互斥。


使用不同的锁去保护不同的数据和结构，允许更多的线程进入临界区。

如何实现一种高效的锁？
提供互斥(mutual exclusion)。阻止多线程进入临界区。
公平性(fairness)。是否每一个竞争(contend)线程都有公平的机会抢到锁。
性能(performance)。使用锁增加的时间开销。

控制中断(Controlling Interrupts)
任何一个调用的线程需要执行一个特权的指令去打开和关闭中断，并且信任线程不会滥用资源。
不能在多处理器上实现。
长时间关闭中断会导致中断丢失，导致系统会出现一些问题。
与普通指令执行相比，屏蔽或取消屏蔽中断的代码(code that masks or unmasksinterrupts)往往会被现代CPU缓慢执行。

自旋锁(Spin Locks)
test-and-set instruction也叫原子交换（atomic exchange）。
互斥锁怎样工作
通过测试旧锁的值和设置新锁的值，进行单个原子操作 ，确保只有一个线程获得该锁。


抢占式调度（preemptive scheduler）：不断通过时钟去中断一个线程，让其它的线程可以运算。

自旋锁是一种最简单的锁，在循环里面一直等待，利用CPU，直到有锁可用为止。void lock(lock_t *lock) &#123;  while (TestAndSet(&amp;lock-&gt;flag, 1) == 1)      ; // spin-wait (do nothing)&#125;


评价自旋锁（Evaluating Spin Locks）

正确性（correctness）: 自旋锁仅仅允许单个线程在一定的时间内进入临界区（critical section）
公平性（fairness）: 没有提供让任意一个线程进入都可以进入临界区的保证，没有公平性，可能会导致有线程不会进入临界区（即，饿死）。
性能（performance）
单CPU：对性能的开销很大。当一个线程持有锁进入临界区时被抢占（preempted），调度器可能会运行其它的线程，其它线程都在竞争（contending）锁。在放弃CPU的使用权时，每个线程都会自旋（spin 即，等待）一个时间片段（preempted），导致浪费了CPU的周期。
多CPU：效果很好。自旋（spin）等待其它处理器上的锁是否可用，不会浪费CPU太多的周期时间。




比较和交换（Compare-And-Swap）

在 SPARC 系统中，使用的是 compare-and-swap instruction
在 x86 系统时，使用的是 compare-and-exchange instruction
Compare-And-Swap指令比 test-and-set指令更加强大。



存储条件指令和加载链接指令（Load-Linked and Store-Conditional）
Load-Linked: 从内存中取出值存到寄存器中。
Store-Conditional: 只有在没有发生中间存储到相应地址的情况下，Store-Conditional才会成功（并更新存储在Load-Linked地址上的值）。成功时，返回值为1，并将ptr指向的值更新为value；失败时，返回值为0，不会更新值。

获得和增加指令（Fetch-And-Add）
原子性的增加一个值，并在特定的地址返回一个旧的值
采用 Fetch-And-Add 指令能够保证所有的线程都能抢到锁int FetchAndAdd(int *ptr) &#123;    int old = *ptr;    *ptr = old + 1;    return old;&#125;

如何避免锁在CPU上浪费过多的自旋等待(spin)？不仅需要硬件的支持，还需要 OS 的支持

当前线程在等待（spin）的时候，让出或放弃CPU（just yield）

线程调用 yield() 函数时，线程会主动放弃 CPU，让其它的线程运行。即当前线程的状态由运行态（running）变为就绪态（ready），从而使其它的线程运行。
在单CPU上使用 yield() 运行多线程的方式很有效。当一个线程调用 lock() 时，发现锁被占用，让出CPU，让另外的线程运行，并完成临界区。


缺点

这种方法不能用在多个线程反复竞争（contending）一把锁的情况。因为没有解决线程或饿死的问题，一个线程可能会无限的处在 让出CPU的循环，而其它的线程会反复地进入和推出临界区。
可能会导致优先级翻转问题（priority inversion）。在现代操作系统中为了克服这一问题，使用优先级继承 priority inheritance，让所有的线程都有一样的优先级。



使用队列：睡眠替代一直等待(Using Queues: Sleeping Instead Of Spinning)
使用队列的目的：处理等待的线程，谁在接下来可以获得锁。

在Solaris系统中共采用 park() 函数：让调用的线程休眠

在Solaris系统中共采用 unpack() 函数：通过 threadID 唤醒特定的线程。使用 unpack() 和 pack() 这两个函数，让调用者在获取不到线程时休眠（sleep），在有锁可用时被唤醒（wake）。

在Solaris系统中共采用 setpark() 解决唤醒&#x2F;等待竞争（wakeup&#x2F;waiting race）问题。

Linux操作系统支持 

提供了 futex 接口，让每个 futex都关联一个特定的物理内存位置。
futex wait(address, expected) 当 address中的值等于 expected 中的值时，让被调用的线程休眠（sleep），如果两者不相等，则调用立刻返回。
futex wake(address) 唤醒一个在队列中等待的线程。
代码存储在 gnu libc的 nptl 库中。
核心思想：利用一个整数，同时记录锁是否被持有（整数的最高位）和线程等待者的个数（整数的其余部位）。若锁是负的，表示该锁被持有（held）。




两相锁（Two-Phase Locks）

采用两个阶段处理锁。
第一个spin阶段：先自己等待（自旋：spin）一段时间，希望可以获得锁。
第一个spin阶段：若在第一个阶段没有获得锁，则第二阶段的调用者会进入睡眠（sleep），直到锁可以用。


Linux系统采用的就是两阶锁，但是它 自旋的时间 仅仅只有一次。

常见的方式：在使用 futex 睡眠之前，在循环中固定 自旋的时间 的次数。


]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>28-Thread-Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>29-30-Condition-Variables</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/29-30-Condition-Variables/</url>
    <content><![CDATA[ 
Condition-Variables锁的并发数据结构
并发计数器（Concurrent Counters）
并发链表（Concurrent Linked Lists）
并发队列（Concurrent Queues）
并发散列表（Concurrent Hash Table）

条件变量（Condition Variables）
join() 父线程检查子线程是否实行完毕。
条件变量有两种相关操作
wait()    线程希望自己睡眠的时候，调用
signal()  当线程更改了程序中的某些内容和希望唤醒处于睡眠状态的线程时调用
注意：在调用 wait() 和 signal()时，线程要持有锁，否则会产生一些意想不到的错误。



生产者和消费者
生产者和消费者问题也叫有界缓冲问题，（The Producer&#x2F;Consumer (Bounded Buffer) Problem）
多线程在检查条件变量（condition variables）时，应使用 while，而少使用 if 进行循环。
使用两个条件变量替代一个条件变量来正确的发信号，指示在系统状态改变时，哪类线程应该被唤醒。
在采用生产者和消费者模式时应注意：保证消费者不应该唤醒消费者，生产者不应该唤醒生产者。
要保证高并发和效率：需增加多个缓冲位，保证在睡眠之前，多个值被消费（consumed），同样的在睡眠之前，多个值被生产（produced）。

]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>29-30-Condition-Variables</tag>
      </tags>
  </entry>
  <entry>
    <title>31-Semaphore</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/31-Semaphore/</url>
    <content><![CDATA[ 
semaphore问题（crux）
怎样使用 semaphores 替代 locks 和 condition variables?
什么是 semaphores？
什么是 binary semaphore(二值信号量)？
用锁和条件变量来实现信号量是否简单？
不用锁和条件变量怎样来实现信号量？

信号量（semaphore）
定义：信号量是一个整型值的对象，用两个程序（routines）操作它。

sem_wait()
sem_post()


binary semaphore

locked: 信号量的值设置为 1
unlocked: 信号量的值设置为 0


Semaphores For Ordering（信号量的顺序）

在子进程调用 sem_post 之前，父进程首先会调用 sem_wait 
在父进程会调用 sem_wait 之前，子进程会首先调用 sem_wait()



The Producer&#x2F;Consumer (Bounded Buffer) ProblemDeadlock（死锁）
消费者和生产者都在相互的等待对方，就发生了死锁的情况。
解决方法
减少锁的作用域（scope）。
多线程常用的模式：有界缓冲（bounded buffer）。将互斥锁的获取和释放操作移到临界区附近，将 full 和empty的等待和唤醒操作移动到锁的外面。





Reader-Writer Locks（读者-写者锁）
不同的数据结构可能访问不同类型的锁。

某个线程要更新数据结构，需要调用 rwlock_acquire_lock() 来获得锁，调用 rwlock_release_writelock() 来释放锁。内部通过一个 write 的信号量保证只有一个写着(writer)能获得锁，进入临界状态，从而更新数据结构。

特点

写独占，读共享 
写锁优先级高，即进程中有写操作，读操作则会被阻塞。
使用于读的次数远大于写的次数


缺点

缺少公平性。会导致 reader 很容易饿死。
实现方案很复杂，导致更多的性能开销。



The Dining Philosophers（哲学家就餐问题）
什么是哲学家就餐问题？
5 位哲学家围绕一个圆桌，每位哲学家之间有一把餐叉。哲学家有时需要思考，有时需要餐叉，有时不需要餐叉。而每位哲学家只有同时拿到了左手边和右手边的餐叉，才能吃到东西。


这个问题或涉及竞争和同步的问题。

怎样实现信号量？typedef struct __Zem_t &#123;  int value;  pthread_cond_t cond;  pthread_mutex_t lock;&#125; Zem_t;// only one thread can call thisvoid Zem_init(Zem_t *s, int value) &#123;  s-&gt;value = value;  Cond_init(&amp;s-&gt;cond);  Mutex_init(&amp;s-&gt;lock);&#125;void Zem_wait(Zem_t *s) &#123;  Mutex_lock(&amp;s-&gt;lock);  while (s-&gt;value &lt;= 0)  Cond_wait(&amp;s-&gt;cond, &amp;s-&gt;lock);  s-&gt;value--;  Mutex_unlock(&amp;s-&gt;lock);&#125;void Zem_post(Zem_t *s) &#123;  Mutex_lock(&amp;s-&gt;lock);  s-&gt;value++;  Cond_signal(&amp;s-&gt;cond);  Mutex_unlock(&amp;s-&gt;lock);&#125;


Zemaphores 信号量实现：只使用了一把锁、一个条件变量、一个状态变量来记录信号量的值。注意：但信号量为负数时，没有考虑它等待的线程数。
利用信号量实现锁(lock)和条件变量(condition variables)，是非常棘手的问题。

]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>31-Semaphore</tag>
      </tags>
  </entry>
  <entry>
    <title>32-Common-Concurrency-Problems</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/32-Common-Concurrency-Problems/</url>
    <content><![CDATA[ 




1. 并发编程中出现的缺陷(What Types Of Bugs Exist?)
1.1. Non-Deadlock Bugs(非死锁缺陷)
1.1.1. Atomicity-Violation Bugs(违反原子性缺陷)
1.1.2. Order-Violation Bugs(违反顺序性缺陷)


1.2. Deadlock(死锁)
1.2.1. What is Deadlock(什么是死锁？)
1.2.2. Why Do Deadlocks Occur?(为什么会发什么死锁？)
1.2.3. Conditions for Deadlock(产生死锁的条件)
1.2.4. Prevention(怎样阻止死锁的发生？)







1. 并发编程中出现的缺陷(What Types Of Bugs Exist?)1.1. Non-Deadlock Bugs(非死锁缺陷)非死锁问题占了并发问题的大多数。它们是怎样发生的？如何去修复它？下面我们主要讨论其中的两种：违反原子性缺陷和违反顺序性缺陷。
1.1.1. Atomicity-Violation Bugs(违反原子性缺陷)所谓违反原子性就是 应该一起执行的指令序列没有一起执行。

违反了多个内存之间访问所需的可串行性(serializability)。
解决方案：给共享变量(shared variable)的访问加锁

1.1.2. Order-Violation Bugs(违反顺序性缺陷)所谓违反顺序就是 两个线程所需的顺序没有强制保证。

两个内存访问的预期的预期顺序被打破。
解决方案：利用条件变量的方式。添加锁（lock）、条件变量（condition variables）、状态变量（state variable）。

1.2. Deadlock(死锁)1.2.1. What is Deadlock(什么是死锁？)线程1持有锁 L1，等待另外一个锁 L2释放；线程2持有锁 L2，正在等待锁 L1 释放，因此产生了死锁，即两个线程彼此互相等待。
1.2.2. Why Do Deadlocks Occur?(为什么会发什么死锁？)1.2.3. Conditions for Deadlock(产生死锁的条件)死锁的产生需要下面 4 个条件。

互斥(Mutual exclusion)：线程对需要的资源进行互斥的访问。
持有和等待(Hold-and-wait)：线程持有资源（持有得到的锁），同时又在等待其它资源（希望获得锁）
非抢占(No preemption)：线程获得的资源（锁）不能被抢占。
循环等待(Circular wait)：线程之间存在一个环路，环路上每个线程都持有一个或多个资源（locks），而这个资源又是下一个线程要申请的（requested）。


上述 4 个条件中的任何一个没有满足，死锁（deadlock）都不会发生。 

1.2.4. Prevention(怎样阻止死锁的发生？)
不产生循环等待（ never induce a circular wait）。

简单的系统中采取 全序（total ordering） 方式解决。
复杂的系统采取 偏序（partial ordering ） 方式解决。
技巧：可以通过获取锁的地址来获取锁的顺序（lock ordering）。




锁在持有和等待时，通过原子性的方式避免。

这种方式不能适用与封装（encapsulation），需要准确的知道要持有（held）哪些琐，并且要提前获得（acquire）。 采取这种方式降低了并发。


其它的线程获得锁之前，先释放之前得到的锁。

实现过程中可能会产生活锁（livelock）问题
两个线程可能一直重复地释放锁，又同时都获得锁失败，系统一直的在运行，但不会有任何的进展。


如何解决活锁问题？
在循环结束的时候，先随机等待一个时间，再次重复整个过程，这样可以降低线程之间重复干扰的几率。




完全避免互斥。代码存放在临界区（critical sections），通常很难避免互斥。需要结合硬件指令，构造出不要锁的数据结构。

通过检查和恢复（Detect and Recover）的方法。允许死锁偶尔发生，检查到死锁时再采取行动。


]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>32-Common-Concurrency-Problems</tag>
      </tags>
  </entry>
  <entry>
    <title>33-Event-based-Concurrency</title>
    <url>/02-Concurrency/OS/Operating-System-Three-Easy-Pieces/02-Concurrency/33-Event-based-Concurrency/</url>
    <content><![CDATA[ 


事件循环（An Event Loop）：等待事件发生，当它发生时，检查事件类型，然后做相应的处理（可能是I&#x2F;O请求或者调度其它事件）。
采用 select() 和 poll() 进行事件的接受。
select() 检查I&#x2F;O描述符集合。
基于事件的系统中，遵循的原则：不允许阻塞调用。
采用事件编程的缺点：代码比较复杂、并且与现代操作系统的有些机制集成度较困难。

]]></content>
      <categories>
        <category>02-Concurrency</category>
      </categories>
      <tags>
        <tag>oS</tag>
        <tag>operating-System-Three-Easy-Pieces</tag>
        <tag>02-Concurrency</tag>
        <tag>33-Event-based-Concurrency</tag>
      </tags>
  </entry>
</search>
